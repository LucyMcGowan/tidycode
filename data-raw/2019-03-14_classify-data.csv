code,class,session,id
library(tidyverse),setup,1,1
library(tidyverse),setup,11e21,1
mtcars %>% select(mpg),setup,11e21,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",exploratory,11e21,1
rm(list = ls()),setup,11e21,1
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/FTL_cp.R"")",setup,11e21,1
"spid_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/remove_spid.csv"",     as.is = TRUE)",import,11e21,1
"cmplx_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/cmplx.csv"",     as.is = TRUE)",import,11e21,1
"mgmt_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/mgmt_grp.csv"",     as.is = TRUE)",import,11e21,1
"species_data <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/spid.csv"",     as.is = TRUE)",import,11e21,1
"prop_tripTable <- FTL_cp(FTL, type = ""proportion"", times = 300,     spid_remove, cmplx_remove, mgmt_remove)",import,11e21,1
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",     Sys.Date(), "".Rdata"", sep = """"))",exploratory,11e21,1
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",     Sys.Date(), "".Rdata"", sep = """"))",export,11e21,1
rm(list = ls()),setup,11e21,1
"source(""analysis/analysis_ccm_summerenergy_GSL_LR04.R"")",setup,11e21,1
"source(""analysis/analysis_ccm_summerenergy_GSL_speleoice.R"")",setup,11e21,1
"source(""analysis/analysis_summarise_crossmapping_summerenergy_GSL_LR04.R"")",setup,11e21,1
"source(""analysis/analysis_summarise_crossmapping_summerenergy_GSL_LR04.R"")",setup,11e21,1
"source(""analysis/analysis_orbital_frequencies.R"")",setup,11e21,1
library(plyr),setup,11e21,1
"data <- read.table(""Analysis/Data/ZillowDataSetX"", sep = "","",     stringsAsFactors = FALSE)",import,11e21,1
"source(""Analysis/Data/ZillowAPICalls.R"")",setup,11e21,1
data$MergingCode <- data21$ZipCode,data cleaning,11e21,1
"a <- ddply(data, ~MergingCode, summarise, MeanZestimateAmount = mean(ZestimateAmount)))",data cleaning,11e21,1
"data <- merge(data, a, by = ""MergingCode"")",data cleaning,11e21,1
"data[data$ResponseCode == ""508"" | is.na(data$zpid) == TRUE ,]",data cleaning,11e21,1
"data <- subset(data, select = -c(MergingCode, MeanZestimateAmount,     MeanRZestimateAmount, MeanRZestimateLowValueRange, MeanRZestimateHighValueRange,     Count))",data cleaning,11e21,1
"write.table(data, file = ""Analysis/Data/ZillowDataSetX"", sep = "","")",export,11e21,1
require(plyr),setup,219e20,1
require(dplyr),setup,219e20,1
require(data.table),setup,219e20,1
require(reshape2),setup,219e20,1
require(ggplot2),setup,219e20,1
require(qgraph),setup,219e20,1
require(RColorBrewer),setup,219e20,1
require(cluster),setup,219e20,1
"CNH <- ""/Volumes/NOAA_Data/CNH/""",setup,219e20,1
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",     sep = """"), stringsAsFactors = F, skip = 2)",import,219e20,1
"FTL <- head(FTL, -2)",exploratory,219e20,1
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",     sep = """"), stringsAsFactors = F)",import,219e20,1
"mgmt_grp <- dlply(spid, .(mgmt_grp))",data cleaning,219e20,1
mgmt_grp <- mgmt_grp[2:9],data cleaning,219e20,1
"m.vec <- rep(NA, nrow(FTL))",data cleaning,219e20,1
for (i in 1:length(mgmt_grp)) {,data cleaning,219e20,1
},data cleaning,219e20,1
m.vec[FTL$spid %in% mgmt_grp[[i]]$SPID] = names(mgmt_grp[i]),data cleaning,219e20,1
"tickets <- select(FTL, ftid, veid, year, spid, landed_wt, ppp,     grgroup, grid, tdate, pcid, ifq_landing, processorid, pargrp)",data cleaning,219e20,1
tickets$mgmt_grp <- m.vec,data cleaning,219e20,1
rm(FTL),data cleaning,219e20,1
by_trip <- data.table(tickets),exploratory,219e20,1
"setkey(by_trip, ftid)",data cleaning,219e20,1
"catch <- by_trip[, sum(landed_wt), by = c(""ftid"", ""mgmt_grp"")]",data cleaning,219e20,1
"total_catch <- dcast.data.table(catch, ftid ~ mgmt_grp, fun = sum)",data cleaning,219e20,1
prop_table <- as.data.frame(total_catch),exploratory,219e20,1
"prop_table[, 2:ncol(prop_table)] <- prop_table[, 2:ncol(prop_table)]/rowSums(prop_table[,     2:ncol(prop_table)])",exploratory,219e20,1
"pca_prop <- prcomp(prop_table[, 2:ncol(prop_table)], scale = T)",modeling,219e20,1
"npc <- length(which(summary(pca_prop)[[6]][3, ] <= 0.81))",modeling,219e20,1
"dat_setup <- pca_prop$x[, 1:npc]",modeling,219e20,1
row <- seq(1:nrow(dat_setup)),data cleaning,219e20,1
"dat_setup <- cbind(dat_setup, row)",data cleaning,219e20,1
"dat_setup <- dat_setup[sample(nrow(dat_setup)), ]",data cleaning,219e20,1
"dat_prop <- dat_setup[, 1:(ncol(dat_setup) - 1)]",data cleaning,219e20,1
max.clusts = 30,modeling,219e20,1
samples = 100,modeling,219e20,1
sampsize = 1000,modeling,219e20,1
"clust.dat.prop <- vector(""list"", length = max.clusts)",modeling,219e20,1
set.seed(2),setup,219e20,1
},modeling,219e20,1
rngR = TRUE),modeling,219e20,1
"sampsize = sampsize, keep.data = FALSE, pamLike = TRUE,",modeling,219e20,1
"clust.dat.prop[[i]] <- clara(dat_prop, i, stand = TRUE, samples = samples,",modeling,219e20,1
for (i in 1:max.clusts) {,modeling,219e20,1
"cat(i, ""..."")",modeling,219e20,1
"Sys.Date(), "".Rdata"", sep = """"))",export,219e20,1
"save(clust.dat.prop, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/clustdatprop_"",",export,219e20,1
objectives <- vector(length = max.clusts),modeling,219e20,1
objectives[i] <- clust.dat.prop[[i]]$objective,modeling,219e20,1
},modeling,219e20,1
for (i in 1:max.clusts) {,modeling,219e20,1
asw <- vector(length = max.clusts),modeling,219e20,1
for (i in 2:max.clusts) {,modeling,219e20,1
},modeling,219e20,1
asw[i] <- clust.dat.prop[[i]]$silinfo$avg.width,modeling,219e20,1
"par(mfrow = c(1, 2), omi = c(0, 0, 0, 0))",communication,219e20,1
"plot(objectives, type = ""o"", pch = 19, cex = 0.35, bty = ""n"",     main = ""Objective function"", col = ""tomato1"")",communication,219e20,1
"points(8, objectives[8], lwd = 5, col = ""tomato4"")",communication,219e20,1
"plot(asw, type = ""o"", pch = 19, cex = 0.35, bty = ""n"", main = ""Silhouette Width"",     col = ""turquoise"")",communication,219e20,1
"points(8, asw[8], lwd = 5, col = ""turquoise4"")",communication,219e20,1
nodes = 8,communication,219e20,1
"clust_prop <- list(data_transform = ""prop"", cluster_sol = nodes,     objectives = objectives, asw = asw, clustering = clust.dat.prop[[nodes]]$clustering,     sampsize = sampsize, samples = samples, npc = npc)",modeling,219e20,1
"ind <- cbind(clust_prop$clustering, dat_setup[, ""row""])",modeling,219e20,1
"prop_table$c8[ind[, 2]] <- ind[, 1]",modeling,219e20,1
"mc <- select(prop_table, ftid, c8)",exploratory,219e20,1
"tickets <- merge(tickets, mc, by = ""ftid"")",data cleaning,219e20,1
"save(tickets, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/tickets_"",",export,219e20,1
"save(prop_table, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/prop_table_"",     Sys.Date(), "".Rdata"", sep = """"))",export,219e20,1
"save(clust_prop, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/clust_prop_"",     Sys.Date(), "".Rdata"", sep = """"))",export,219e20,1
"setwd(""/Users/winterb/Research/gesture_categorization/new_paper_new_analyses/data/"")",setup,743e20,1
"d <- read.csv(""street_dice_task.csv"", stringsAsFactors = F)",import,743e20,1
table(d$question.order),exploratory,743e20,1
"d[d$dice.removal == ""removed dice before 1st prompt"", ]$dice.removal <- ""removed before 1st""",data cleaning,743e20,1
"d[d$dice.removal == ""removed dice before 1st task"", ]$dice.removal <- ""removed before 1st""",data cleaning,743e20,1
"d[d$dice.removal == ""removed dice before 2nd task"", ]$dice.removal <- ""removed dice before 2nd""",data cleaning,743e20,1
"table(d$question.order, d$dice.removal)",exploratory,743e20,1
"(xtab <- table(d$question.order, d$dice.removal)[1:2, 3:4])",exploratory,743e20,1
fisher.test(xtab),modeling,743e20,1
"quartz("""", 10, 7)",communication,743e20,1
"par(mai = c(2, 0, 1, 0))",communication,743e20,1
"plot(1, 1, type = ""n"", bty = ""n"", xaxt = ""n"", yaxt = ""n"", xlim = c(0,     2), ylim = c(0, 1), xaxs = ""i"", yaxs = ""i"", xlab = """", ylab = """")",communication,743e20,1
"axis(at = c(0.75, 1.45)[1], side = 1, labels = """", line = 2.5,     tick = F, font = 2, cex.axis = 5)",communication,743e20,1
"rect(xleft = 0.6, xright = 0.9, ybottom = 0, ytop = p1, col = ""darkred"",     border = F)",communication,743e20,1
"text(x = 0.75, y = p1 + 0.11, col = ""darkred"", labels = paste0(round(p1,     2) * 100, ""%""), font = 2, cex = 4.5)",communication,743e20,1
"text(x = 1.45, y = p2 + 0.11, col = ""darkred"", labels = paste0(round(p2,        2) * 100, ""%""), font = 2, cex = 4.5, xpd = NA)",communication,743e20,1
"rect(xleft = 1.3, xright = 1.6, ybottom = 0, ytop = p2, col = ""darkred"",     border = F)",communication,743e20,1
"data2 <- read.table(""Analysis/Data/data2"", sep = "","")",import,935e20,2
MainData <- data2,data cleaning,935e20,2
"write.table(MainData, file = ""Analysis/Data/MainData"", sep = "","")",export,935e20,2
rm(list = ls()),setup,935e20,2
"source(""./analysis/nursery_experiment_inundation/functions/newbinplot.R"")",setup,935e20,2
"source(""./analysis/nursery_experiment_inundation/functions/ranNorm.R"")",setup,935e20,2
"source(""./analysis/nursery_experiment_inundation/functions/newbinplot.R"")",setup,935e20,2
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,935e20,2
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,935e20,2
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,935e20,2
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,935e20,2
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,935e20,2
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,935e20,2
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,935e20,2
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,935e20,2
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,935e20,2
rm(list = ls()),setup,935e20,2
gc(),setup,935e20,2
set.seed(132),setup,935e20,2
ncores = 40,setup,935e20,2
"source(""bergan_cole_analysis.R"")",setup,935e20,2
"source(""bergan_tables.R"")",setup,935e20,2
library(neuroExpressoAnalysis),import,935e20,2
library(dplyr),import,935e20,2
library(viridis),import,935e20,2
library(reshape2),setup,935e20,2
library(ogbox),setup,935e20,2
library(scales),setup,935e20,2
library(gplots),setup,935e20,2
library(stringr),setup,935e20,2
library(magrittr),setup,935e20,2
library(pheatmap),setup,935e20,2
order = cellOrder %>% translatePublishable(),data cleaning,935e20,2
genes = mouseMarkerGenesCombined,data cleaning,935e20,2
"x = x[!grepl(pattern = ""(?!^Pyramidal$)Pyra"", x = names(x),",data cleaning,935e20,2
genes %<>% lapply(function(x) {,data cleaning,935e20,2
}),data cleaning,935e20,2
perl = TRUE)],data cleaning,935e20,2
return(x),data cleaning,935e20,2
genes %<>% lapply(function(x) {,data cleaning,935e20,2
"x[!grepl(pattern = ""Microglia_"", names(x))]",data cleaning,935e20,2
}),data cleaning,935e20,2
geneNames = names(genes),data cleaning,935e20,2
"out <- lapply(1:len(nm), function(j) {",data cleaning,935e20,2
"if (component2 == ""Pyramidal"") {",data cleaning,935e20,2
"print(paste(i, j))",data cleaning,935e20,2
"component1 = """"",data cleaning,935e20,2
"component1 = paste0(component1, ""_"")",data cleaning,935e20,2
}),data cleaning,935e20,2
return(out),data cleaning,935e20,2
nm = names(genes[[i]]),data cleaning,935e20,2
"genesMicroarray = lapply(1:len(genes), function(i) {",data cleaning,935e20,2
"nm = nm[nm %in% (n_expressoSamples %>% select(CellTypes,",data cleaning,935e20,2
]$V1 %>% unlist %>% as.char,data cleaning,935e20,2
component1 = names(genes[i]),data cleaning,935e20,2
"component1, ""PyramidalDeep/"", component2))",data cleaning,935e20,2
PyramidalDeep) %>% unlist %>% unique)],data cleaning,935e20,2
names(out) = nm,data cleaning,935e20,2
},data cleaning,935e20,2
component2 = names(genes[[i]][nm[j]]),data cleaning,935e20,2
"if (component1 == ""All_"") {",data cleaning,935e20,2
"scores = read.table(paste0(""analysis/01.SelectGenes/Quick/"",",data cleaning,935e20,2
"(scores %>% filter(V1 %in% genes[[i]][[nm[j]]]))[1:5,",data cleaning,935e20,2
},data cleaning,935e20,2
else {,data cleaning,935e20,2
"component1, ""CellTypes/"", component2))",data cleaning,935e20,2
}),data cleaning,935e20,2
},data cleaning,935e20,2
"scores = read.table(paste0(""analysis/01.SelectGenes/Quick/"",",data cleaning,935e20,2
names(genesMicroarray) = geneNames,data cleaning,935e20,2
}),data cleaning,935e20,2
"lapply(x, trimNAs)",data cleaning,935e20,2
"genesMicroarray = lapply(genesMicroarray, function(x) {",data cleaning,935e20,2
},import,935e20,2
"assertthat::are_equal(all(genes$Cortex[[i]] %in% scores$V1),",import,935e20,2
unlist %>% as.char,import,935e20,2
"(scores %>% filter(V1 %in% genes$Cortex[[i]]))[1:5, ]$V1 %>%",import,935e20,2
print(names(genes$Cortex[i])),import,935e20,2
}),import,935e20,2
"scores = read.table(paste0(""analysis/01.SelectGenes/QuickJustSingleCell//CellTypes/"",",import,935e20,2
"genesSingleCell = lapply(1:len(genes$Cortex), function(i) {",import,935e20,2
"if (names(genes$Cortex[i]) == ""Pyramidal"") {",import,935e20,2
else {,import,935e20,2
},import,935e20,2
"scores = read.table(paste0(""analysis/01.SelectGenes/QuickJustSingleCell//PyramidalDeep/"",",import,935e20,2
names(genes$Cortex[i]))),import,935e20,2
TRUE),import,935e20,2
names(genes$Cortex[i]))),import,935e20,2
names(genesSingleCell) = names(genes$Cortex),data cleaning,935e20,2
genesSingleCell %<>% lapply(trimNAs),data cleaning,935e20,2
"n_expressoExpr %<>% filter(!grepl(pattern = ""\\|"", Gene.Symbol))",data cleaning,935e20,2
"list[geneDat, exp] = n_expressoExpr %>% sepExpr",data cleaning,935e20,2
rn(exp) = geneDat$Gene.Symbol,data cleaning,935e20,2
design = n_expressoSamples,data cleaning,935e20,2
"dpylrFriendly = cbind(design, t(exp))",data cleaning,935e20,2
library(tidyverse),setup,3.7400000000000002e+22,1
mtcars %>% select(mpg),exploratory,3.7400000000000002e+22,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",exploratory,3.7400000000000002e+22,1
"setwd(""/Users/Aron/dropbox/Middle-Range Theorizing/Second Paper/"")",setup,311e20,3
library(gdata),setup,311e20,3
library(poweRlaw),setup,311e20,3
library(dunn.test),setup,311e20,3
"data <- read.csv(""middle_range_coding_v4_w_borrowing.csv"", header = TRUE,     replacement = ""Organization"")",import,311e20,3
"data <- data[data$Year > 1994, ]",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Indiidual"",     replacement = ""Organization"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Org$"",     replacement = ""Organization"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Firm"",     replacement = ""Organization"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Project"",     replacement = ""Group"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Group/Network"",     replacement = ""Network"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Network"",     replacement = ""Network"")",data cleaning,311e20,3
library(plyr),data cleaning,871e20,4
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Interorg"",     replacement = ""Network"")",data cleaning,311e20,3
library(reshape2),data cleaning,871e20,4
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Technical"",     replacement = ""Artifact"")",data cleaning,311e20,3
library(stringr),data cleaning,871e20,4
library(grid),not sure,871e20,4
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Database"",     replacement = ""Artifact"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Government/national level"",     replacement = ""Government"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Multilevel"",     replacement = ""Other"")",data cleaning,311e20,3
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Online Auction"",     replacement = ""Other"")",data cleaning,311e20,3
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Computational "",     replacement = ""Computational"")",data cleaning,311e20,3
library(gridExtra),communication,871e20,4
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Tool "",     replacement = ""Tool"")",data cleaning,311e20,3
library(Rcpp),not sure,871e20,4
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Nominal "",     replacement = ""Nominal"")",data cleaning,311e20,3
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Proxy "",     replacement = ""Ensemble"")",data cleaning,311e20,3
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Ensemble "",     replacement = ""Ensemble"")",data cleaning,311e20,3
"data$Classification..Exploitation.Exploration[data$Primary..outside.of.IS..or.Secondary..inside.of.IS..borrowing. ==     ""Secondary""] <- ""Exploitation""",data cleaning,311e20,3
"extending_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Classification..instantiation..modifying..or.extending ==         ""Extending"")",data cleaning,311e20,3
library(randomForest),setup,602e20,5
"modifying_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,         data$Classification..instantiation..modifying..or.extending ==    ""Modifying"")",data cleaning,311e20,3
library(caret),setup,602e20,5
library(doMC),setup,602e20,5
library(mmadsenr),setup,602e20,5
library(futile.logger),setup,602e20,5
library(dplyr),setup,602e20,5
library(ggthemes),setup,602e20,5
"instantiation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Classification..instantiation..modifying..or.extending ==         ""Instantiation"")",data cleaning,311e20,3
"exploitation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Classification..Exploitation.Exploration == ""Exploration"")",data cleaning,311e20,3
"exploration_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Classification..Exploitation.Exploration == ""Exploration"")",data cleaning,311e20,3
"instantiation_total_cites <- subset(instantiation_total_cites,     instantiation_total_cites != 0)",data cleaning,311e20,3
"modifying_total_cites <- subset(modifying_total_cites, modifying_total_cites !=     0)",data cleaning,311e20,3
library(ggplot2),communication,871e20,4
"extending_total_cites <- subset(extending_total_cites, extending_total_cites !=     0)",data cleaning,311e20,3
library(ascii),not sure,871e20,4
"hist(instantiation_total_cites, breaks = 50, ylim = c(0, 30),     xlim = c(0, 750))",exploratory,311e20,3
"hist(modifying_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,     750))",exploratory,311e20,3
"hist(extending_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,     750))",exploratory,311e20,3
"source(""powerAnalysis/lib.R"")",not sure,871e20,4
"wilcox.test(extending_total_cites, instantiation_total_cites,     probs = 0.05, alternative = c(""greater""))",exploratory,311e20,3
"wilcox.test(extending_total_cites, modifying_total_cites, probs = 0.05,     alternative = c(""greater""))",exploratory,311e20,3
"wilcox.test(instantiation_total_cites, modifying_total_cites,     probs = 0.05, alternative = c(""less""))",exploratory,311e20,3
"kInputPaths <- list(groundtruth = ""powerAnalysis/output_cluster_summaries_groundtruth.RData"",     Model = ""powerAnalysis/output_cluster_summaries_model.RData"",     Read = ""powerAnalysis/output_cluster_summaries_parzen.RData"")",import,871e20,4
log_instantiation_total_cites <- log(instantiation_total_cites),data cleaning,311e20,3
log_modifying_total_cites <- log(modifying_total_cites),data cleaning,311e20,3
log_extending_total_cites <- log(extending_total_cites),data cleaning,311e20,3
hist(log_instantiation_total_cites),exploratory,311e20,3
hist(log_modifying_total_cites),exploratory,311e20,3
hist(log_extending_total_cites),exploratory,311e20,3
length(log_instantiation_total_cites),exploratory,311e20,3
length(log_modifying_total_cites),exploratory,311e20,3
length(log_extending_total_cites),exploratory,311e20,3
"t.test(log_extending_total_cites, log_instantiation_total_cites,     var.equal = FALSE)",exploratory,311e20,3
"t.test(log_modifying_total_cites, log_instantiation_total_cites,     var.equal = FALSE)",exploratory,311e20,3
"t.test(log_modifying_total_cites, log_extending_total_cites,     data$Classification..instantiation..modifying..or.extending)",exploratory,311e20,3
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~,modeling,311e20,3
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""biasedmodels-classification.log"")",modeling,602e20,5
"posthoc <- TukeyHSD(x = a1, data$Classification..instantiation..modifying..or.extending,     conf.level = 0.95)",evaluation,311e20,3
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Total.Citations.by..ISI.Web.of.Science...SSCI. != ""-"")",data cleaning,311e20,3
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     data$Total.Citations.by..ISI.Web.of.Science...SSCI. != """")",data cleaning,311e20,3
a0 <- aov(log(data$Total.Citations.by..ISI.Web.of.Science...SSCI.) ~     data$Classification..instantiation..modifying..or.extending),modeling,311e20,3
"posthoc <- TukeyHSD(x = a0, ""data$Classification..instantiation..modifying..or.extending"",     conf.level = 0.95)",evaluation,311e20,3
"flog.appender(appender.file(log_file), name = ""cl"")",data cleaning,602e20,5
"extending_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,     data$Classification..instantiation..modifying..or.extending ==         ""Extending"")",data cleaning,311e20,3
"modifying_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,     data$Classification..instantiation..modifying..or.extending ==     data$Classification..instantiation..modifying..or.extending ==         ""Modifying"")",data cleaning,311e20,3
"instantiation_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,     data$Classification..instantiation..modifying..or.extending ==         ""Instantiation"")",data cleaning,311e20,3
"instantiation_IS_cites <- subset(instantiation_IS_cites, instantiation_IS_cites !=     0)",data cleaning,311e20,3
"modifying_IS_cites <- subset(modifying_IS_cites, modifying_IS_cites !=     0)",data cleaning,311e20,3
"extending_IS_cites <- subset(extending_IS_cites, extending_IS_cites !=     0)",data cleaning,311e20,3
"wilcox.test(extending_IS_cites, instantiation_IS_cites, probs = 0.05,     alternative = c(""greater""))",exploratory,311e20,3
"wilcox.test(extending_IS_cites, modifying_IS_cites, probs = 0.05,     alternative = c(""less""))",exploratory,311e20,3
"wilcox.test(instantiation_IS_cites, modifying_IS_cites, probs = 0.05,     alternative = c(""less""))",exploratory,311e20,3
log_instantiation_IS_cites <- log10(instantiation_IS_cites),data cleaning,311e20,3
log_modifying_IS_cites <- log10(modifying_IS_cites),data cleaning,311e20,3
log_extending_IS_cites <- log10(extending_IS_cites),data cleaning,311e20,3
sqrt_instantiation_IS_cites <- sqrt(instantiation_IS_cites),data cleaning,311e20,3
sqrt_modifying_IS_cites <- sqrt(modifying_IS_cites),data cleaning,311e20,3
sqrt_extending_IS_cites <- sqrt(extending_IS_cites),data cleaning,311e20,3
hist(log_instantiation_IS_cites),exploratory,311e20,3
hist(log_modifying_IS_cites),exploratory,311e20,3
hist(log_extending_IS_cites),exploratory,311e20,3
hist(sqrt_instantiation_IS_cites),exploratory,311e20,3
hist(sqrt_modifying_IS_cites),exploratory,311e20,3
hist(sqrt_extending_IS_cites),exploratory,311e20,3
"t.test(log_modifying_IS_cites, log_extending_IS_cites, var.equal = FALSE)",exploratory,311e20,3
library(plyr),setup,311e20,3
"data$Treatment.of.IT <- revalue(data$Treatment.of.IT, c(`Ensemble ` = ""Ensemble"",     `Tool ` = ""Tool"", `Computational ` = ""Computational"", `Nominal ` = ""Nominal"",     `Proxy ` = ""Proxy""))",data cleaning,311e20,3
oneway.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~     data$Treatment.of.IT),modeling,311e20,3
kruskal.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~     data$Treatment.of.IT),modeling,311e20,3
"model <- aov(data = data, formula = Total.Citations.by..ISI.Web.of.Science...SSCI. ~     Treatment.of.IT)",modeling,311e20,3
"TukeyHSD(model, which = ""Treatment.of.IT"", ordered = FALSE, conf.level = 0.95)",modeling,311e20,3
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     NA, 1)",data cleaning,311e20,3
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,     0, 1)",data cleaning,311e20,3
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~     data$Classification..Exploitation.Exploration),modeling,311e20,3
"posthoc1 <- TukeyHSD(x = a1, ""data$Classification..Exploitation.Exploration"",     conf.level = 0.95)",modeling,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Group""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Artifact""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Individual""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Artifact""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Market""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Group""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Individual""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==     ""Market""])",exploratory,311e20,3
a2 <- aov(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI. ~     data$Treatment.of.IT),modeling,311e20,3
"posthoc2 <- TukeyHSD(x = a2, ""data$Treatment.of.IT"", conf.level = 0.95)",evaluation,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==     ""Computational""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==     ""Proxy""])",exploratory,311e20,3
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==         ""Nominal""])",exploratory,311e20,3
a3 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~     data$Classification..Exploitation.Exploration),modeling,311e20,3
"posthoc3 <- TukeyHSD(x = a3, ""data$Classification..Exploitation.Exploration"",     conf.level = 0.95)",evaluation,311e20,3
instantiation_total_cites[instantiation_total_cites == 0] <- 1,data cleaning,311e20,3
m1 <- displ$new(instantiation_total_cites),data cleaning,311e20,3
m1 = displ$new(instantiation_total_cites),data cleaning,311e20,3
m1$setPars(estimate_pars(m1)),modeling,311e20,3
modifying_total_cites[modifying_total_cites == 0] <- 1,data cleaning,311e20,3
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,853e20,3
"RawData <- read_csv(""Sindelar(1988)ReperformedDataAnalysis.csv"")",import,743e20,6
library(tidyverse),setup,6.9199999999999996e+22,1
library(tidyverse),setup,819e20,1
library(tidyverse),setup,687e20,1
library(tidyverse),setup,91e21,1
library(tidyverse),setup,325e20,1
mtcars %>% select(mpg),exploratory,325e20,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",exploratory,325e20,1
rm(list = ls()),setup,933e20,1
"source(""./R/helper/00_helper_lib_load.R"")",setup,933e20,1
"source(""./R/helper/00_helper_model_fcts.R"")",setup,933e20,1
"source(""./R/helper/00_helper_simulation_data.R"")",setup,933e20,1
"source(""./R/helper/99_helper_diagnostics.R"")",setup,933e20,1
"source(""./R/helper/02_helper_pgas.R"")",setup,933e20,1
"source(""./R/01_cBPF_as.R"")",setup,933e20,1
"source(""./R/02_pgas.R"")",setup,933e20,1
simulate_data <- T,setup,933e20,1
init_at_true <- F,data cleaning,933e20,1
pgas_run <- T,data cleaning,933e20,1
set.seed(139423),data cleaning,933e20,1
"source(""./analysis/2018-11-30/00_settings_simulation_run_init.R"")",data cleaning,933e20,1
if (simulate_data) {,data cleaning,933e20,1
},data cleaning,933e20,1
"source(""./analysis/2018-11-30/00_settings_simulation_run.R"")",data cleaning,933e20,1
} else {,data cleaning,933e20,1
"source(""./analysis/2018-11-30/00_settings_simulation_run_init.R"")",data cleaning,933e20,1
"par_true = true_vals, traj_init = deviate_states_init,",modeling,933e20,1
"par_true = true_vals, traj_init = deviate_states_init,",modeling,933e20,1
} else {,modeling,933e20,1
"out_gibbs <- pgas(N = num_particles, MM = num_mcmc, KK = KK,",modeling,933e20,1
if (pgas_run) {,modeling,933e20,1
"TT = TT, y = y_t, yz = yz_t, Za = za_t, Zb = zb_t, Zp = zp_t,",modeling,933e20,1
"Zq = zq_t, priors = c(prior_a, prior_b), par_init = par_init,",modeling,933e20,1
"TT = TT, y = y_t, yz = yz_t, Za = za_t, Zb = zb_t, Zp = zp_t,",modeling,933e20,1
"out_pgas <- pgas(N = num_particles, MM = num_mcmc, KK = KK,",modeling,933e20,1
"Zq = zq_t, priors = c(prior_a, prior_b), par_init = par_init,",modeling,933e20,1
"filtering = FALSE, num_plots_states = 1)",modeling,933e20,1
},modeling,933e20,1
"filtering = TRUE, num_plots_states = num_mcmc)",modeling,933e20,1
"source(""./analysis/2018-11-30/99_analyse_convergence_run.R"")",modeling,933e20,1
"source(""./analysis/2018-11-30/99_analyse_convergence_run.R"")",setup,933e20,1
library(strucchange),setup,536e20,1
library(dplyr),setup,536e20,1
library(ggplot2),setup,536e20,1
library(lubridate),setup,536e20,1
library(forecast),setup,536e20,1
"11), rep(7, 11), rep(8, 11), rep(9, 11), rep(10, 11), rep(11,",data cleaning,536e20,1
"11), rep(2, 11), rep(3, 11), rep(4, 11), rep(5, 11), rep(6,",data cleaning,536e20,1
"2005, 30, 60), beta4 = ifelse(year < 2005, 40, 80), beta5 = ifelse(year <",data cleaning,536e20,1
"9, 1, 0), oct = ifelse(month == 10, 1, 0), nov = ifelse(month ==",data cleaning,536e20,1
"11), rep(12, 11)))) %>% mutate(jan = ifelse(month == 1, 1,",data cleaning,536e20,1
"mutate(date = as.Date(paste(year, ""-"", month, ""-"", ""01"",",data cleaning,536e20,1
"monthly.df <- tbl_df(data.frame(year = rep(2000:2010, 12), month = c(rep(1,",data cleaning,536e20,1
"sep = """"), format = ""%Y-%m-%d"")) %>% arrange(year, month)",data cleaning,536e20,1
"2005, 70, 140), beta8 = ifelse(year < 2005, 80, 160), beta9 = ifelse(year <",data cleaning,536e20,1
beta6) + (july * beta7) + (aug * beta8) + (sept * beta9) +,data cleaning,536e20,1
(march * beta3) + (april * beta4) + (may * beta5) + (june *,data cleaning,536e20,1
(oct * beta10) + (nov * beta11) + (dec * beta12) + e) %>%,data cleaning,536e20,1
"7, 1, 0), aug = ifelse(month == 8, 1, 0), sept = ifelse(month ==",data cleaning,536e20,1
"3, 1, 0), april = ifelse(month == 4, 1, 0), may = ifelse(month ==",data cleaning,536e20,1
"0), feb = ifelse(month == 2, 1, 0), march = ifelse(month ==",data cleaning,536e20,1
"5, 1, 0), june = ifelse(month == 6, 1, 0), july = ifelse(month ==",data cleaning,536e20,1
"11, 1, 0), dec = ifelse(month == 12, 1, 0)) %>% mutate(beta1 = ifelse(year <",data cleaning,536e20,1
"2005, 90, 180), beta10 = ifelse(year < 2005, 100, 200), beta11 = ifelse(year <",data cleaning,536e20,1
"2005, 25, 50), beta12 = ifelse(year < 2005, 15, 30), e = rnorm(132,",data cleaning,536e20,1
"2005, 10, 20), beta2 = ifelse(year < 2005, 20, 40), beta3 = ifelse(year <",data cleaning,536e20,1
"10, 20)) %>% mutate(trips = (jan * beta1) + (feb * beta2) +",data cleaning,536e20,1
"2005, 50, 100), beta6 = ifelse(year < 2005, 60, 120), beta7 = ifelse(year <",data cleaning,536e20,1
"ggplot(monthly.df, aes(x = date, y = trips)) + geom_line() +",communication,536e20,1
geom_point(aes(color = factor(oct))),communication,536e20,1
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2000,",modeling,536e20,1
"1)) ~ factor(month), data = monthly.df)",modeling,536e20,1
plot(f_statistics),communication,536e20,1
"summary(breakpoints(ts(trips, frequency = 12, start = c(2000,",evaluation,536e20,1
"1)) ~ factor(month), data = monthly.df))",evaluation,536e20,1
"beta12 = 15, e = rnorm(132, 20, 20)) %>% mutate(trips = (jan *",data cleaning,536e20,1
"4, 1, 0), may = ifelse(month == 5, 1, 0), june = ifelse(month ==",data cleaning,536e20,1
"beta7 = 70, beta8 = 80, beta9 = 90, beta10 = 100, beta11 = 25,",data cleaning,536e20,1
"2, 1, 0), march = ifelse(month == 3, 1, 0), april = ifelse(month ==",data cleaning,536e20,1
"12, 1, 0)) %>% mutate(int = 100, t = year - 1999, beta1 = 2000 -",data cleaning,536e20,1
"11), rep(12, 11)))) %>% mutate(jan = 1, feb = ifelse(month ==",data cleaning,536e20,1
"arrange(year, month)",data cleaning,536e20,1
"11), rep(7, 11), rep(8, 11), rep(9, 11), rep(10, 11), rep(11,",data cleaning,536e20,1
"6, 1, 0), july = ifelse(month == 7, 1, 0), aug = ifelse(month ==",data cleaning,536e20,1
beta8) + (sept * beta9) + (oct * beta10) + (nov * beta11) +,data cleaning,536e20,1
"20 * t, beta2 = 20, beta3 = 30, beta4 = 40, beta5 = 50, beta6 = 60,",data cleaning,536e20,1
beta1) + (feb * beta2) + (march * beta3) + (april * beta4) +,data cleaning,536e20,1
(may * beta5) + (june * beta6) + (july * beta7) + (aug *,data cleaning,536e20,1
"8, 1, 0), sept = ifelse(month == 9, 1, 0), oct = ifelse(month ==",data cleaning,536e20,1
"""-"", month, ""-"", ""01"", sep = """"), format = ""%Y-%m-%d"")) %>%",data cleaning,536e20,1
"10, 1, 0), nov = ifelse(month == 11, 1, 0), dec = ifelse(month ==",data cleaning,536e20,1
"(dec * beta12) + e) %>% mutate(date = as.Date(paste(year,",data cleaning,536e20,1
"monthly.df <- tbl_df(data.frame(year = rep(2000:2010, 12), month = c(rep(1,",data cleaning,536e20,1
"11), rep(2, 11), rep(3, 11), rep(4, 11), rep(5, 11), rep(6,",data cleaning,536e20,1
geom_point(aes(color = factor(oct))),communication,536e20,1
"ggplot(monthly.df, aes(x = date, y = trips)) + geom_line() +",communication,536e20,1
library(plotrix),setup,795e20,1
library(RColorBrewer),setup,795e20,1
library(ggplot2),setup,56e21,1
library(ggthemes),setup,56e21,1
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,9e22,1
library(ggplot2),import,44e21,7
library(plyr),setup,44e21,7
library(stringr),setup,44e21,7
library(reshape2),setup,44e21,7
library(ascii),setup,44e21,7
"source(""powerAnalysis/lib.R"")",setup,44e21,7
"kSummariesPattern <- ""results/mcmc_summaries_powerAnalysis_chrom%02d.txt""",import,44e21,7
kChromList <- 1:10,import,44e21,7
kNEffField <- 7,import,44e21,7
kThetaPostmeanField <- 1,import,44e21,7
"kSummaryPath <- ""out/mcmc_diagnostics_powerAnalysis.txt""",import,44e21,7
"kPlotPath <- ""out/mcmc_diagnostics_powerAnalysis.pdf""",import,44e21,7
"kQuantiles <- c(5e-04, 0.005, 0.025, 0.05, 0.1, 0.9, 0.95, 0.975,     0.995, 0.9995)",not sure,44e21,7
library(ggplot2),exploratory,486e20,8
"n.eff.list <- lapply(kChromList, function(chrom) data.frame(chrom = chrom,     n.eff = ReadColumnViaPipe(sprintf(kSummariesPattern, chrom),         col = kNEffField, skip = 1)))",not sure,44e21,7
library(dplyr),setup,465e20,9
library(lubridate),data cleaning,486e20,8
"n.eff.df <- Reduce(rbind, n.eff.list)",data cleaning,44e21,7
library(reshape2),setup,465e20,9
rm(n.eff.list),not sure,44e21,7
library(igraph),setup,465e20,9
"rm(list = setdiff(ls(), ""base_path""))",setup,486e20,8
library(tidyr),setup,465e20,9
"load(file.path(base_path, ""data"", ""output"", ""manual_puzzles"",     ""clean_manual_puzzles.RData""))",import,486e20,8
library(ggplot2),setup,552e19,10
"performance <- filter(performance, year(time) != 2016) %>% arrange(time) %>%     mutate(game_nr = 1:nrow(.)) %>% mutate(week = week(time))",data cleaning,486e20,8
library(lubridate),setup,552e19,10
"rm(list = setdiff(ls(), ""base_path""))",setup,552e19,10
"game_nr_end_of_week <- c(performance$game_nr[which(diff(performance$week) !=     0)], max(performance$game_nr))",data cleaning,486e20,8
names(game_nr_end_of_week) <- unique(performance$week),exploratory,486e20,8
"load(file.path(base_path, ""data"", ""output"", ""manual_puzzles"",     ""clean_manual_puzzles.RData""))",import,552e19,10
"graph_rating_progression <- ggplot(data = performance, aes(x = game_nr,     y = user_rating)) + geom_line(colour = ""grey50"") + geom_vline(xintercept = game_nr_end_of_week) +     annotate(""text"", x = game_nr_end_of_week - 10, y = 1200,         angle = 90, label = paste(""week"", names(game_nr_end_of_week),             sep = "" ""))",communication,486e20,8
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,213e20,11
"graphs <- mget(ls()[grep(pattern = ""graph_"", x = ls())])",not sure,486e20,8
"save_path_graphs <- file.path(base_path, ""analysis"", ""output"")",export,486e20,8
"mapply(ggsave, file = paste0(file.path(save_path_graphs, names(graphs)),     "".png""), plot = graphs)",export,486e20,8
files <- list.files(path = diffdir),setup,213e20,11
"reusable <- c(""odds_var"", ""td_bookmax"", ""td_low_odds"")",not sure,486e20,8
"save_path_reusable <- file.path(base_path, ""analyse"", ""multiple variables"",     ""exploratory analysis"", ""output exploratory analysis"", ""bookmakers"",     ""reusable data"")",setup,486e20,8
files[1] <- NA,not sure,213e20,11
files[8] <- NA,data cleaning,213e20,11
files[29] <- NA,data cleaning,213e20,11
files[30] <- NA,data cleaning,213e20,11
files[31] <- NA,data cleaning,213e20,11
"performance <- filter(performance, year(time) != 2016) %>% arrange(time) %>%     mutate(game_nr = 1:nrow(.)) %>% mutate(week = week(time))",data cleaning,552e19,10
files <- files[!is.na(files)],data cleaning,213e20,11
names <- files,data cleaning,213e20,11
"filepath2 <- ""/Data/RigCountByTrajectory.csv""",import,2.9400000000000002e+22,12
"path <- c(getwd(), filepath2)",setup,2.9400000000000002e+22,12
"split <- data.frame(strsplit(names, ""_""))",setup,213e20,11
"game_nr_end_of_week <- c(performance$game_nr[which(diff(performance$week) !=     0)], max(performance$game_nr))",data cleaning,552e19,10
names(game_nr_end_of_week) <- unique(performance$week),data cleaning,552e19,10
"graph_rating_progression <- ggplot(data = performance, aes(x = game_nr,     y = user_rating)) + geom_line(colour = ""grey50"") + geom_vline(xintercept = game_nr_end_of_week) +     annotate(""text"", x = game_nr_end_of_week - 10, y = 1200,         angle = 90, label = paste(""week"", names(game_nr_end_of_week),             sep = "" ""))",communication,552e19,10
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",setup,213e20,11
"mat <- matrix(nrow = dim(split)[2], ncol = 4)",setup,213e20,11
data = data.frame(mat),setup,213e20,11
"colnames(data) <- c(""strain"", ""timepoint"", ""filename"", ""dir"")",setup,213e20,11
},setup,213e20,11
data$filename[i] <- filename,setup,213e20,11
"data$strain[i] <- as.character(split[1, i])",setup,213e20,11
"filename <- paste(split[, i], collapse = ""_"")",setup,213e20,11
"data$timepoint[i] <- as.character(split[4, i])",setup,213e20,11
"for (i in seq(1, (dim(split)[2]))) {",setup,213e20,11
"data$dir[i] <- paste(diffdir, filename, sep = ""/"")",setup,213e20,11
"write.table(data, ""autoanalysisInfo.csv"", sep = "","")",export,213e20,11
"dat <- read.csv(""autoanalysisInfo.csv"", header = TRUE, stringsAsFactors = FALSE)",import,213e20,11
i <- as.numeric(as.character(commandArgs(TRUE)[1])),data cleaning,213e20,11
"gtex.data.file <- file.path("".."", ""data"", ""GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_median_tpm.gct.gz"")",import,857e20,13
"pc.plot.file <- ""../output/gtexpca.png""",import,857e20,13
filename <- dat$filename[i],data cleaning,213e20,11
print(filename),exploratory,213e20,11
library(ggplot2),setup,857e20,13
print(dat$strain[i]),exploratory,213e20,11
library(cowplot),setup,857e20,13
dir.create(filename),setup,213e20,11
setwd(filename),setup,213e20,11
"source(""../code/gtexpca.functions.R"")",setup,857e20,13
gtex <- read.gtex.data(gtex.data.file),import,857e20,13
"library(""dplyr"")",setup,725e20,14
"knit2html(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/StrainTemplate.Rmd"",     output = paste(filename, "".md"", sep = """"), quiet = TRUE)",not sure,213e20,11
"library(""readr"")",setup,725e20,14
library(knitr),setup,213e20,11
"analysisdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/""",setup,213e20,11
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,213e20,11
setwd(diffdir),setup,213e20,11
"cat(sprintf(""Total number of tissue types: %d\n"", nrow(gtex)))",communication,857e20,13
"cat(sprintf(""Total number of genes: %d\n"", ncol(gtex)))",communication,857e20,13
"library(""tximport"")",import,725e20,14
"library(""devtools"")",import,725e20,14
"library(""SummarizedExperiment"")",import,725e20,14
"rows <- !is.element(rownames(gtex), c(""pancreas"", ""whole blood""))",data cleaning,857e20,13
"load_all(""../seqUtils/"")",import,725e20,14
"gtex <- gtex[rows, ]",data cleaning,857e20,13
"load_all(""analysis/housekeeping/"")",import,725e20,14
gtex.pca <- prcomp(gtex),modeling,857e20,13
"sample_names = read.table(""analysis/data/sample_lists/SL1344_names_all.txt"",     sep = ""\t"", comment.char = """", stringsAsFactors = FALSE)[, 1]",import,725e20,14
"print(summary(gtex.pca)$importance[, 1:2])",communication,857e20,13
pdf(NULL),communication,857e20,13
"p <- plot.gtex.top2pcs(gtex, gtex.pca)",exploratory,857e20,13
"ggsave(pc.plot.file, p, height = 4, width = 4, dpi = 200)",exploratory,857e20,13
dev.off(),exploratory,857e20,13
design_matrix = constructDesignMatrix_SL1344(sample_names),not sure,725e20,14
"transcript_data = tbl_df(readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.compiled_tx_metadata.rds"")) %>%     dplyr::rename(gene_id = ensembl_gene_id, transcript_id = ensembl_transcript_id,        ""babk"", 2, replicate)) %>% dplyr::arrange(donor, condition) %>%      gene_name = external_gene_name, chr = chromosome_name)",data cleaning,725e20,14
"filtered_transcscript_data = readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.compiled_tx_metadata.filtered.rds"")",import,725e20,14
"file_names = file.path(""processed/salmonella/salmon/Ensembl_87/"",     design_matrix$sample_id, ""quant.sf"")",import,725e20,14
names(file_names) = design_matrix$sample_id,not sure,725e20,14
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,1.0300000000000001e+22,15
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,1.0300000000000001e+22,15
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,457e20,16
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",     what = character())",import,457e20,16
"info.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/tmp/Copper.2048.both.msOnly.info""",setup,457e20,16
siteSize = 2048,setup,457e20,16
"treatment = ""Copper""",not sure,457e20,16
null = FALSE,not sure,457e20,16
"strand = ""both""",not sure,457e20,16
library(synapseClient),setup,189e20,17
synapseLogin(),setup,189e20,17
"deseq.dat.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",import,457e20,16
"diffexScriptlist = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-04/encodeSkinAnalysis_ExprOnly.R""),     list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/bin/dermalNFData.R""))",not sure,189e20,17
numSam = 6,not sure,457e20,16
"txtfiles = list.files(""."")",setup,189e20,17
"txtfiles = txtfiles[grep(""txt"", txtfiles)]",data cleaning,189e20,17
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",not sure,189e20,17
for (file in txtfiles) {,not sure,189e20,17
},not sure,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",not sure,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",not sure,189e20,17
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",not sure,189e20,17
for (file in txtfiles) {,not sure,189e20,17
},not sure,189e20,17
library(synapseClient),setup,189e20,17
synapseLogin(),setup,189e20,17
"diffexScriptlist = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-04/encodeSkinAnalysis_ExprOnly.R""),     list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/bin/encodeSkinRNASeq.R""),     list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/bin/dermalNFData.R""))",setup,189e20,17
"txtfiles = list.files(""."")",setup,189e20,17
"txtfiles = txtfiles[grep(""txt"", txtfiles)]",exploratory,189e20,17
for (file in txtfiles) {,exploratory,189e20,17
},exploratory,189e20,17
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",exploratory,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",exploratory,189e20,17
},exploratory,189e20,17
for (file in txtfiles) {,exploratory,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",exploratory,189e20,17
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",exploratory,189e20,17
library(synapseClient),exploratory,189e20,17
synapseLogin(),exploratory,189e20,17
"diffexScriptlist = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-04/encodeSkinAnalysis_ExprOnly.R""),     list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/bin/encodeSkinRNASeq.R""),     list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/bin/dermalNFData.R""))",exploratory,189e20,17
"source(""http://rnbeads.mpi-inf.mpg.de/install.R"")",import,2.6200000000000002e+22,18
"txtfiles = list.files(""."")",setup,189e20,17
"source(""https://bioconductor.org/biocLite.R"")",import,2.6200000000000002e+22,18
library(RnBeads),setup,2.6200000000000002e+22,18
"txtfiles = txtfiles[grep(""txt"", txtfiles)]",data cleaning,189e20,17
library(hexbin),setup,2.6200000000000002e+22,18
library(wordcloud),setup,2.6200000000000002e+22,18
"raw.data.dir = ""../../data/raw/Breakefield_HBMVEC_450k/""",import,2.6200000000000002e+22,18
"analysis.dir = ""./RnBeads/analysis""",import,2.6200000000000002e+22,18
"report.dir = file.path(analysis.dir, ""Aug12_pairedCompsByExperiment"")",import,2.6200000000000002e+22,18
"rnb.options(analysis.name = ""Breakefield450k"", assembly = ""hg19"",     import.table.separator = ""\t"", identifiers.column = ""Sample_ID"")",not sure,2.6200000000000002e+22,18
"source(""./MapPRESSTOenh_prom_sym.R"")",import,2.6200000000000002e+22,18
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",not sure,189e20,17
for (file in txtfiles) {,not sure,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",not sure,189e20,17
},not sure,189e20,17
},not sure,189e20,17
for (file in txtfiles) {,not sure,189e20,17
"synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,",not sure,189e20,17
"used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598"")))",not sure,189e20,17
"library(""rjson"")",import,245e20,19
"source(""C:\\Users\\Kitsune\\Documents\\GitHub\\VersionClassifier\\Analysis\\analysisScript1.R"")",import,245e20,19
"mobileJsonCyc = getFiledata(""CyclesMobile.json"")",import,245e20,19
"desktopJsonCyc = getFiledata(""CyclesDesktop.json"")",import,245e20,19
"siblingJsonCyc = getFiledata(""CyclesSibling.json"")",import,245e20,19
"sibMobJsonCyc = getFiledata(""CyclesSibMob.json"")",import,245e20,19
"sibDeskJsonCyc = getFiledata(""CyclesSibDesk.json"")",import,245e20,19
mobileCyc = mobileJsonCyc$Cycle$Data,data cleaning,245e20,19
desktopCyc = desktopJsonCyc$Cycle$Data,data cleaning,245e20,19
rm(list = ls()),setup,3.1800000000000002e+22,20
"prototypes <- read.table(""../prototypes_2.txt"")",setup,3.1800000000000002e+22,20
"source(""https://bioconductor.org/biocLite.R"")",not sure,7.3200000000000004e+22,21
library(RnBeads),import,7.3200000000000004e+22,21
library(hexbin),import,7.3200000000000004e+22,21
library(wordcloud),import,7.3200000000000004e+22,21
"lib = file.path(getwd(), ""pkgs"")",setup,384e20,22
".libPaths(c(lib, .libPaths()))",setup,384e20,22
library(here),setup,384e20,22
"mainDataFile = here(""data"", ""derived_data"", ""tab_data.rda"")",setup,384e20,22
"summaryData = here(""data"", ""derived_data"", ""high_low_table.rda"")",setup,384e20,22
m <- length(r1),not sure,287e20,23
},not sure,287e20,23
n <- length(r2),not sure,287e20,23
"vargha.delaney <- function(r1, r2) {",not sure,287e20,23
"return((sum(rank(c(r1, r2))[seq_along(r1)])/m - (m + 1)/2)/n)",not sure,287e20,23
},setup,384e20,22
load(summaryData),setup,384e20,22
"source(here(""data"", ""stony_creek_process.r""))",setup,384e20,22
} else {,setup,384e20,22
load(mainDataFile),setup,384e20,22
if (file.exists(mainDataFile) && file.exists(summaryData)) {,setup,384e20,22
load(mainDataFile),setup,384e20,22
load(summaryData),setup,384e20,22
"source(here(""analysis"", ""compile_data_hl.r""))",setup,384e20,22
"source(here(""analysis"", ""flowing_ratio.r""))",setup,384e20,22
"source(""../../bin/ctrpSingleAgentScreens.R"")",import,78e21,24
"source(here(""analysis"", ""dist_basics.r""))",setup,384e20,22
"source(here(""analysis"", ""percentile_calc.r""))",setup,384e20,22
"source(here(""analysis"", ""hydro_stats.r""))",setup,384e20,22
"source(here(""analysis"", ""effect_analysis.r""))",setup,384e20,22
"respostasTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50Respostas.csv"",     header = TRUE, sep = "";"")",import,287e20,23
"source(here(""analysis"", ""b_calcs.r""))",setup,384e20,22
"source(here(""analysis"", ""compile_data_hl.r""))",setup,384e20,22
"source(here(""figures"", ""scripts"", ""figure_6.r""))",setup,384e20,22
"source(""../../bin/singleDrugAnalysis.R"")",import,78e21,24
"source(here(""figures"", ""scripts"", ""figure_5.r""))",setup,384e20,22
"source(here(""figures"", ""scripts"", ""figure_4.r""))",setup,384e20,22
ccle.calls = getMSSMprocessedMutationCalls(),import,78e21,24
"source(here(""figures"", ""scripts"", ""figure_3.r""))",setup,384e20,22
"respostasQuartis = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasQuartisRespostas.csv"",     header = TRUE, sep = "";"")",import,287e20,23
"source(here(""figures"", ""scripts"", ""figure_3.r""))",setup,384e20,22
"lib = file.path(getwd(), ""pkgs"")",setup,384e20,22
".libPaths(c(lib, .libPaths()))",setup,384e20,22
"wc <- wilcox.test(respostasTop50$media, respostasQuartis$media)",modeling,287e20,23
tissue.calls = getMSSMTissueOrigin(),not sure,78e21,24
auc.mat <- getCtrpScreensAsMatrix(),not sure,78e21,24
"overlap = intersect(colnames(auc.mat), colnames(ccle.calls))",data cleaning,78e21,24
"effectSize <- vargha.delaney(respostasTop50$media, respostasQuartis$media)",not sure,287e20,23
"case.name = c(""fullread.70ind.over.2"", ""fullread.30ind.over.2"",     ""fullread.10ind.over.2"")",exploratory,487e20,25
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/sum/f.overB.Robj""",setup,487e20,25
"ROC.file.name = ""ROC_overB.pdf""",setup,487e20,25
"hist.file.name = ""hist_overB.pdf""",setup,487e20,25
"ms.null = vector(""list"", length(case.name))",setup,487e20,25
library(ggplot2),import,457e20,26
"ms.alt = vector(""list"", length(case.name))",setup,487e20,25
library(devtools),import,457e20,26
library(data.table),import,457e20,26
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",     case.name[1], "".Robj""))",import,487e20,25
library(reshape2),import,457e20,26
library(survival),import,457e20,26
library(Hmisc),import,457e20,26
library(Cairo),import,457e20,26
pval.alt = as.numeric(pval_list),data cleaning,487e20,25
library(caret),setup,3.1399999999999998e+22,27
library(doMC),setup,3.1399999999999998e+22,27
done.alt = done_res,not sure,487e20,25
library(mmadsenr),setup,3.1399999999999998e+22,27
library(futile.logger),setup,3.1399999999999998e+22,27
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",     case.name[1], "".Robj""))",import,487e20,25
library(dplyr),setup,3.1399999999999998e+22,27
library(ggthemes),setup,3.1399999999999998e+22,27
pval.null = as.numeric(pval_list),not sure,487e20,25
done.null = done_res,not sure,487e20,25
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",     filename = ""per-locus-only-classification.log"")",setup,3.1399999999999998e+22,27
sum(done.alt),not sure,487e20,25
"flog.appender(appender.file(log_file), name = ""cl"")",setup,3.1399999999999998e+22,27
clargs <- commandArgs(trailingOnly = TRUE),setup,3.1399999999999998e+22,27
library(caret),setup,854e20,28
library(doMC),setup,854e20,28
library(mmadsenr),setup,854e20,28
library(futile.logger),setup,854e20,28
library(dplyr),setup,854e20,28
"filename = ""equifinality-3-4-population-data.rda"", args = clargs)",import,3.1399999999999998e+22,27
},import,3.1399999999999998e+22,27
"filename = ""equifinality-3-4-population-data.rda"")",import,3.1399999999999998e+22,27
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,3.1399999999999998e+22,27
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,3.1399999999999998e+22,27
"filename = ""equifinality-3-4-tasampled-data.rda"")",import,3.1399999999999998e+22,27
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,3.1399999999999998e+22,27
if (length(clargs) == 0) {,import,3.1399999999999998e+22,27
"filename = ""equifinality-3-4-tasampled-data.rda"", args = clargs)",import,3.1399999999999998e+22,27
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,3.1399999999999998e+22,27
} else {,import,3.1399999999999998e+22,27
load(pop_data_file),import,3.1399999999999998e+22,27
library(ggplot2),setup,711e20,29
load(ta_sampled_data_file),import,3.1399999999999998e+22,27
"source(""config.worldbank.R"", local = TRUE)",import,711e20,29
"datasets <- read.csv(paste0(metaPath, ""worldbank.metadata."",     sep = "",""), file = paste0(summaryPath, ""correlation"", ""."",     refPeriod, "".csv""), header = T)",import,711e20,29
"cat(paste(""datasetX"", ""datasetY"", ""correlation"", ""pValue"", ""n"",     refPeriod, "".csv""), sep = ""\n"")",communication,711e20,29
library(plyr),import,931e20,30
library(stringr),import,931e20,30
args <- commandArgs(trailingOnly = TRUE),setup,713e20,1
"cat(paste(""dataset"", ""time"", sep = "",""), file = paste0(summaryPath,     ""metadata"", ""."", refPeriod, "".csv""), sep = ""\n"")",communication,711e20,29
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",not sure,3.1399999999999998e+22,27
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",not sure,3.1399999999999998e+22,27
library(reshape2),import,931e20,30
idx <- as.numeric(args[1]),setup,713e20,1
print(idx),setup,713e20,1
"CYdata <- read.csv(""Analysis/Merge/CYmerge.csv"")",import,2.4999999999999998e+22,31
"req <- c(""rstan"")",setup,713e20,1
datasetLength <- nrow(datasets),exploratory,711e20,29
"lapply(req, library, character.only = TRUE)",setup,713e20,1
rm(req),setup,713e20,1
"source(""powerAnalysis/lib.R"")",setup,931e20,30
"flog.info(""Beginning classification analysis of equifinality-4 data sets for per-locus only predictors"", name = ""cl"")",not sure,3.1399999999999998e+22,27
library(dplyr),setup,2.4999999999999998e+22,31
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,3.1399999999999998e+22,27
"sig <- getSig(cuff, alpha = 0.05)",modeling,5.9599999999999996e+22,32
library(plm),setup,2.4999999999999998e+22,31
"flog.info(""Number of cores used in analysis: %s"", num_cores, name = ""cl"")",not sure,3.1399999999999998e+22,27
library(stargazer),setup,2.4999999999999998e+22,31
"source(""./R/VAR_functions.R"")",setup,1.0700000000000001e+22,33
library(lmtest),setup,2.4999999999999998e+22,31
"sigGenes <- getGenes(cuff, sig)",not sure,5.9599999999999996e+22,32
registerDoMC(cores = num_cores),setup,3.1399999999999998e+22,27
"new_tbl <- readRDS(""./analysis/VAR_output/edd_exercises/2018_exercise_2/Chile_s1234_t2.rds"")",import,1.0700000000000001e+22,33
annot <- annotation(sigGenes),not sure,5.9599999999999996e+22,32
"""."", refPeriod, "".csv""), na.strings = """", header = T)",not sure,711e20,29
"pValue, n, sep = "","")",not sure,711e20,29
if (i <= j) {,not sure,711e20,29
"datasetX <- datasets[i, ""identifier""]",not sure,711e20,29
0) {,not sure,711e20,29
"correlation <- cor(data$obsValue.x, data$obsValue.y,",not sure,711e20,29
},not sure,711e20,29
for (i in 1:datasetLength) {,not sure,711e20,29
},not sure,711e20,29
"datasetY <- datasets[j, ""identifier""]",not sure,711e20,29
"duration <- as.numeric(dtend - dtstart, units = ""secs"")",not sure,711e20,29
"""correlation"", ""."", refPeriod, "".csv""), sep = ""\n"",",not sure,711e20,29
print(analysisLine),not sure,711e20,29
if (n < 10 || sd(data$obsValue.x) == 0 || sd(data$obsValue.y) ==,not sure,711e20,29
append = TRUE),not sure,711e20,29
"data <- merge(dataX, dataY, by = ""refArea"")",not sure,711e20,29
n <- nrow(data),not sure,711e20,29
NA,not sure,711e20,29
"plotPath <- paste0(dataPath, ""plots/"", datasetX,",not sure,711e20,29
"""metadata"", ""."", refPeriod, "".csv""), sep = ""\n"", append = TRUE)",not sure,711e20,29
},not sure,711e20,29
"dataY <- read.csv(paste0(observationPath, datasetY,",not sure,711e20,29
for (j in 1:datasetLength) {,not sure,711e20,29
dtstart <- Sys.time(),not sure,711e20,29
"analysisLine <- paste(datasetX, datasetY, correlation,",not sure,711e20,29
"cat(analysisLine, file = paste0(summaryPath,",not sure,711e20,29
"""."", refPeriod, "".csv""), na.strings = """", header = T)",not sure,711e20,29
else {,not sure,711e20,29
"""-"", datasetY, ""."", refPeriod, "".svg"")",not sure,711e20,29
"dataX <- read.csv(paste0(observationPath, datasetX,",not sure,711e20,29
"pValue <- cor.test(data$obsValue.x, data$obsValue.y,",not sure,711e20,29
},not sure,711e20,29
method = correlationMethod)$p.value,not sure,711e20,29
dtend <- Sys.time(),not sure,711e20,29
"use = ""complete.obs"", method = correlationMethod)",not sure,711e20,29
},not sure,711e20,29
"cat(paste(datasetX, duration, sep = "",""), file = paste0(summaryPath,",not sure,711e20,29
"inst.EUS, pola.index, enop, member.dur, CEE)",data cleaning,2.4999999999999998e+22,31
"panel <- select(CYdata, nation, year, diff.EUS, avg.EUS, gen.EUS,",data cleaning,2.4999999999999998e+22,31
warnings(),evaluation,711e20,29
"write.csv(panel, ""Analysis/Merge/panel.csv"")",export,2.4999999999999998e+22,31
warnings(),not sure,711e20,29
"panel2 <- select(panel, -nation, -year, -avg.EUS, -CEE)",data cleaning,2.4999999999999998e+22,31
library(ggplot2),setup,711e20,29
"source(""config.worldbank.R"", local = TRUE)",setup,711e20,29
names <- annot$gene_short_name,data cleaning,5.9599999999999996e+22,32
"new_tbl <- new_tbl %>% dplyr::select(-c(lag_sel_method, t_treshold,       var_size, short_name)) %>% mutate(origin = ""new_code"") %>%   dplyr::select(vars_select(names(.), -starts_with(""rank"")))",data cleaning,1.0700000000000001e+22,33
"forgmt <- list(""SexDiffs"", ""NA"", names)",not sure,5.9599999999999996e+22,32
forgmt <- unlist(forgmt),data cleaning,5.9599999999999996e+22,32
"stargazer(panel2, label = ""fig: summarystatistics"", title = ""Summary Statistics"",         ""Instrumental Euroscepticism"", ""Polarisation Index"",         ""Effective Number of Parties"", ""Membership Duration"",         digits = 2), out = ""Presentation/Latex/summary_statistics.tex"")",communication,2.4999999999999998e+22,31
"write(forgmt, file = ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"",     ncolumns = length(forgmt), sep = ""\t"")",export,5.9599999999999996e+22,32
library(GSA),setup,5.9599999999999996e+22,32
library(caret),import,89e21,34
library(doMC),import,89e21,34
panel$nation <- as.factor(panel$nation),data cleaning,2.4999999999999998e+22,31
"test <- GSA.read.gmt(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"")",import,5.9599999999999996e+22,32
panel$year.f <- as.factor(panel$year),data cleaning,2.4999999999999998e+22,31
panel$CEE.f <- as.factor(panel$CEE),data cleaning,2.4999999999999998e+22,31
library(mmadsenr),setup,89e21,34
"panel <- plm.data(panel, indexes = c(""nation"", ""year.f""))",data cleaning,2.4999999999999998e+22,31
library(futile.logger),setup,89e21,34
"panel <- arrange(panel, nation, year)",data cleaning,2.4999999999999998e+22,31
library(dplyr),setup,89e21,34
library(ggthemes),setup,89e21,34
},setup,89e21,34
ta_duration == tadur),setup,89e21,34
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {",setup,89e21,34
"df_tassize_subset <- dplyr::filter(df, sample_size == ssize,",setup,89e21,34
df_tassize_subset,setup,89e21,34
"pool <- plm(diff.EUS ~ avg.EUS + pola.index + enop + member.dur +     CEE, data = panel, model = ""pooling"")",modeling,2.4999999999999998e+22,31
"source(""analysis/analysis_find_nonzero_configurations.R"")",modeling,33e20,35
"source(""analysis/analysis_ccm_summerenergy_GSL_LR04.R"")",modeling,33e20,35
summary(pool),evaluation,2.4999999999999998e+22,31
rm(list = ls()),setup,8.3699999999999995e+21,36
"setwd(""C:/Users/mcolvin/Documents/projects/Age and Growth/Analysis/Sample Size"")",setup,951e20,37
"source(""analysis/analysis_ccm_summerenergy_GSL_speleoice.R"")",modeling,33e20,35
"EUS.fe <- plm(diff.EUS ~ avg.EUS + pola.index + enop + member.dur +     CEE, data = panel, model = ""within"")",modeling,2.4999999999999998e+22,31
gc(),not sure,8.3699999999999995e+21,36
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""tasampled-classification.log"")",data cleaning,89e21,34
"source(""analysis/analysis_summarise_crossmapping_summerenergy_GSL_LR04.R"")",modeling,33e20,35
"source(""analysis/analysis_summarise_crossmapping_summerenergy_GSL_LR04.R"")",modeling,33e20,35
summary(EUS.fe),evaluation,2.4999999999999998e+22,31
library(knitr),import,8.3699999999999995e+21,36
"source(""analysis/analysis_orbital_frequencies.R"")",modeling,33e20,35
"EUS.re <- plm(diff.EUS ~ avg.EUS + pola.index + enop + member.dur +     CEE, data = panel, model = ""random"")",modeling,2.4999999999999998e+22,31
library(data.table),import,8.3699999999999995e+21,36
library(gdata),import,8.3699999999999995e+21,36
"source(""./src/1_global.R"")",import,951e20,37
library(plyr),import,8.3699999999999995e+21,36
summary(EUS.re),evaluation,2.4999999999999998e+22,31
"flog.appender(appender.file(log_file), name = ""cl"")",export,89e21,34
library(dplyr),import,8.3699999999999995e+21,36
"source(""./src/2_functions.R"")",import,951e20,37
options(dplyr.print_min = 100),setup,8.3699999999999995e+21,36
"source(""./src/3_load.R"")",import,951e20,37
options(dplyr.print_max = 100),setup,8.3699999999999995e+21,36
"source(""./R/VAR_functions.R"")",setup,1.7299999999999999e+22,38
"new_tbl <- readRDS(""./analysis/VAR_output/edd_exercises/2018_exercise_2/Brasil_s1234_t2.rds"")",import,1.7299999999999999e+22,38
siteSize = 2048,setup,39e21,39
"treatment = ""Copper""",setup,39e21,39
"strand = ""both""",setup,39e21,39
library(ggplot2),setup,5.6399999999999996e+22,40
"alt.name = paste0(treatment, ""."", siteSize, ""."", strand, "".alt"")",data cleaning,39e21,39
library(magrittr),setup,5.6399999999999996e+22,40
library(methods),setup,5.6399999999999996e+22,40
"null.name = paste0(treatment, ""."", siteSize, ""."", strand, "".null"")",data cleaning,39e21,39
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",data cleaning,39e21,39
"tcga_path <- ""/home/cliu18/liucj/projects/6.autophagy/TCGA""",setup,5.6399999999999996e+22,40
"afhl_path <- ""/home/cliu18/liucj/projects/6.autophagy/09_afh_vs_afl""",setup,5.6399999999999996e+22,40
"afhl_class <- file.path(afhl_path, ""01_af_h_l_classification"")",setup,5.6399999999999996e+22,40
"props_path <- file.path(afhl_path, ""04_props"")",setup,5.6399999999999996e+22,40
setwd(props_path),setup,5.6399999999999996e+22,40
scripts.dir <- props_path,setup,5.6399999999999996e+22,40
library(dummies),setup,5.6399999999999996e+22,40
"source(""/home/cliu18/liucj/github/RstudioWithGit/autophagy_codes/13_afh_vs_afl/yy_code/cal.r"")",import,5.6399999999999996e+22,40
"clinical <- readr::read_rds(file.path(tcga_path, ""pancan34_clinical.rds.gz""))",import,5.6399999999999996e+22,40
"source(""analysis/data_cleanup.R"")",data cleaning,6.6800000000000004e+22,41
"p62_sample_classification <- readr::read_rds(path = file.path(afhl_class,     "".rds_01_p62_sample_classification.rds.gz"")) %>% dplyr::select(-barcode) %>%     tidyr::nest(-cancer_types)",import,5.6399999999999996e+22,40
"expr_dum <- readr::read_rds(file.path(props_path, "".rds_01_expr_dum.rds.gz""))",import,5.6399999999999996e+22,40
library(ggplot2),import,6.6800000000000004e+22,41
ls(),not sure,6.6800000000000004e+22,41
sum.mRNAAll <- data.frame(),not sure,5.6399999999999996e+22,40
rm(list = ls()),setup,6.6800000000000004e+22,41
"analysis <- ""analysis""",not sure,5.6399999999999996e+22,40
"gdp_education_data <- read.csv(""analysis/data/tidy_gdp_educ_data.csv"",     header = TRUE)",import,6.6800000000000004e+22,41
"sapply(gdp_education_data, class)",exploratory,6.6800000000000004e+22,41
head(gdp_education_data),exploratory,6.6800000000000004e+22,41
ls(gdp_education_data),not sure,6.6800000000000004e+22,41
require(synapser),setup,463e20,42
require(tidyverse),setup,463e20,42
require(singleCellSeq),setup,463e20,42
synapser::synLogin(),not sure,463e20,42
matching_cases <- nrow(gdp_education_data),exploratory,6.6800000000000004e+22,41
matching_cases,exploratory,6.6800000000000004e+22,41
"syn_file <- synapser::synTableQuery(""select id from syn11974770"")",import,463e20,42
"gdp_education_data <- gdp_education_data[order(gdp_education_data$GDP_US_dollars), ]",data cleaning,6.6800000000000004e+22,41
"thirteenth_ranked_country <- gdp_education_data[13, ]",not sure,6.6800000000000004e+22,41
"analysis_dir <- ""syn12508617""",setup,463e20,42
"BaseURL = ""http://stat.columbia.edu/~rachel/datasets/""",setup,7.6000000000000008e+22,43
"BaseFileName = ""nyt""",setup,7.6000000000000008e+22,43
StartNum = 1,setup,7.6000000000000008e+22,43
EndNum = 31,setup,7.6000000000000008e+22,43
class(thirteenth_ranked_country),exploratory,6.6800000000000004e+22,41
"samp.tab <- read.table(synapser::synGet(syn_file)$path, header = T,     as.is = TRUE) %>% dplyr::select(-c(gene_id, gene_type)) %>%     dplyr::rename(Gene = ""gene_name"")",data cleaning,463e20,42
require(org.Hs.eg.db),setup,463e20,42
all.gn <- unique(unlist(as.list(org.Hs.egSYMBOL))),data cleaning,463e20,42
samp.tab <- samp.tab %>% filter(Gene %in% all.gn),data cleaning,463e20,42
library(car),setup,786e20,44
library(lattice),setup,786e20,44
library(ppcor),setup,786e20,44
library(ggplot2),setup,786e20,44
rm(list = ls()),setup,786e20,44
"data <- read.table(file = ""order2size"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2tran"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2erep"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2domain"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2dist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2expr"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2breadth"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""order2solo"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprtran"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprsize"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprerep"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprbreadth"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprdomain"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""exprdist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadthsize"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadthtran"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadtherep"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadthdomain"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadthexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""breadthdist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizetran"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizeorder_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizerep"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizedom_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizedist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""sizeexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""tranorder_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""tranerep"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""trandom"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""trandist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""tranexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""ordererep_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""orderdom_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""orderdist_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""orderexon_BIEN"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""erepdom"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""erepdist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""erepexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""domdist"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""domexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data <- read.table(file = ""distexon"", header = TRUE, sep = ""\t"")",import,786e20,44
"data_subset <- subset(data, breadth == ""low"")",not sure,786e20,44
library(data.table),setup,9.5200000000000008e+22,34
library(cowplot),setup,9.5200000000000008e+22,34
library(knitr),setup,9.5200000000000008e+22,34
library(dplyr),setup,9.5200000000000008e+22,34
library(lubridate),setup,9.5200000000000008e+22,34
"cc <- read.csv(""data-raw/COMU_condition_june2018.csv"", header = T,     as.is = T)",import,9.5200000000000008e+22,34
library(quickpsy),setup,787e20,45
library(randomForest),setup,806e20,1
"cc <- subset(cc, rec != """")",data cleaning,9.5200000000000008e+22,34
library(caret),setup,806e20,1
library(circular),setup,787e20,45
library(doMC),setup,806e20,1
library(mmadsenr),setup,806e20,1
library(cowplot),setup,787e20,45
cc$year <- as.numeric(cc$year),data cleaning,9.5200000000000008e+22,34
"cc <- subset(cc, colony == ""Funk"")",data cleaning,9.5200000000000008e+22,34
library(futile.logger),setup,806e20,1
library(dplyr),setup,806e20,1
"cc <- subset(cc, species == ""COMU"")",data cleaning,9.5200000000000008e+22,34
library(Hmisc),setup,787e20,45
library(ggthemes),setup,806e20,1
cc$dates <- dmy(cc$date),data cleaning,9.5200000000000008e+22,34
"source(""../../bin/singleDrugAnalysis.R"")",setup,908e19,46
cc$bird_weight <- as.numeric(cc$bird_weight),data cleaning,9.5200000000000008e+22,34
cc$condition <- cc$bird_weight/cc$winglength,data cleaning,9.5200000000000008e+22,34
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",     filename = ""population-classification.log"")",import,806e20,1
"cc[which(cc$stage == ""Adult""), ""stage""] <- ""adult""",data cleaning,9.5200000000000008e+22,34
yrs <- 1990:2017,data cleaning,9.5200000000000008e+22,34
"flog.appender(appender.file(log_file), name = ""cl"")",import,806e20,1
oneColumnWidth <- 3.42,not sure,787e20,45
onehalfColumnWidth <- 4.5,not sure,787e20,45
clargs <- commandArgs(trailingOnly = TRUE),setup,806e20,1
"flc <- data.table(filter(cc, stage != ""adult"" & year >= 1990 &     winglength > 30) %>% select(year, condition))",exploratory,9.5200000000000008e+22,34
twoColumnWidth <- 7,not sure,787e20,45
sizeLine1 <- 0.25,not sure,787e20,45
sizeText <- 2.5,not sure,787e20,45
flc <- na.omit(flc),data cleaning,9.5200000000000008e+22,34
"boot <- vector(""list"", 10000)",data cleaning,9.5200000000000008e+22,34
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,806e20,1
},import,806e20,1
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",",import,806e20,1
} else {,import,806e20,1
if (length(clargs) == 0) {,import,806e20,1
"filename = ""equifinality-4-population-data.rda"")",import,806e20,1
"filename = ""equifinality-4-population-data.rda"", args = clargs)",import,806e20,1
load(pop_data_file),import,806e20,1
theme_track <- theme_set(theme_bw(10)),setup,787e20,45
"replace = TRUE)]), by = c(""year"")]",modeling,9.5200000000000008e+22,34
},modeling,9.5200000000000008e+22,34
for (i in seq_along(boot)) {,modeling,9.5200000000000008e+22,34
"boot[[i]] <- flc[, list(rep = i, condition = condition[sample.int(.N,",modeling,9.5200000000000008e+22,34
boot <- rbindlist(boot),modeling,9.5200000000000008e+22,34
"theme_track <- theme_update(panel.border = element_blank(), panel.grid = element_blank(),         size = sizeLine1, linetype = ""solid""), axis.ticks = element_line(size = sizeLine1),         linetype = ""solid""), axis.line.y = element_line(colour = ""black"",         linetype = ""solid""), axis.line.y = element_line(colour = ""black"",     strip.background = element_blank())",visualization,787e20,45
"boot_means <- boot[, list(mean = mean(condition)), by = c(""year"",     ""rep"")]",modeling,9.5200000000000008e+22,34
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",not sure,806e20,1
"boot_ci <- boot_means[, list(lower = quantile(mean, 0.025), upper = quantile(mean,     0.975)), by = c(""year"")]",modeling,9.5200000000000008e+22,34
"flog.info(""Beginning classification analysis of equifinality-4 data sets"",     name = ""cl"")",not sure,806e20,1
"flc_sum <- cbind(flc[, list(mean = mean(condition)), by = c(""year"")],     boot_ci[, 2:3])",modeling,9.5200000000000008e+22,34
"flc_sum <- flc_sum[order(year), ]",modeling,9.5200000000000008e+22,34
x <- sort(unique(flc$year)),data cleaning,9.5200000000000008e+22,34
"y <- tapply(flc$condition, flc$year, mean)",data cleaning,9.5200000000000008e+22,34
"wt <- 1/tapply(flc$condition, flc$year, var)",data cleaning,9.5200000000000008e+22,34
"mod <- lm(y ~ x, weights = wt)",modeling,9.5200000000000008e+22,34
summary(mod),evaluation,9.5200000000000008e+22,34
confint(mod),evaluation,9.5200000000000008e+22,34
rm(list = ls()),setup,2.9400000000000002e+22,47
"predicted <- predict(mod, x = flc$year, se.fit = TRUE, interval = ""confidence"",     level = 0.95)",modeling,9.5200000000000008e+22,34
library(ggplot2),setup,3.6600000000000002e+22,1
"flc_analysis <- cbind(flc_sum, predicted$fit)",modeling,9.5200000000000008e+22,34
library(grid),setup,3.6600000000000002e+22,1
flc_mod <- mod,modeling,9.5200000000000008e+22,34
"source(""analysis/inundation_predicts_species_distributions/data/data_index.R"")",import,2.9400000000000002e+22,47
"ylab <- ""Offspring condition (g/mm)""",visualization,9.5200000000000008e+22,34
"model <- lm(elev ~ dden * diff_mort, weights = abundance, riskratio)",modeling,2.9400000000000002e+22,47
"offspring_condition <- ggplot(data = flc_analysis) + geom_ribbon(aes(x = year,     y = fit), colour = ""grey60"") + geom_point(aes(x = year, y = mean)) +     geom_errorbar(aes(x = year, ymin = lower, ymax = upper),     ymin = lwr, ymax = upr), fill = ""lightgrey"") + geom_line(aes(x = year,         width = 0) + scale_x_continuous(breaks = yrs, expand = c(0.01,         width = 0) + scale_x_continuous(breaks = yrs, expand = c(0.01,     0), limits = c(yrs[1], yrs[28])) + xlab(""Year"") + ylab(ylab) +     cowplot::theme_cowplot() + theme(axis.text.x = element_text(angle = 90,     vjust = 0.5))",visualization,9.5200000000000008e+22,34
summary(model),modeling,2.9400000000000002e+22,47
"model2 <- lm(elev ~ dden + diff_mort, weights = abundance, riskratio)",modeling,2.9400000000000002e+22,47
summary(model2),modeling,2.9400000000000002e+22,47
"model3 <- lm(elev ~ dden, weights = abundance, riskratio)",modeling,2.9400000000000002e+22,47
"adw <- data.table(filter(cc, stage == ""adult"" & year > 2000) %>%     select(year, bird_weight))",data cleaning,9.5200000000000008e+22,34
"model4 <- lm(elev ~ diff_mort, weights = abundance, riskratio)",modeling,2.9400000000000002e+22,47
summary(model3),modeling,2.9400000000000002e+22,47
knitr::opts_chunk$set(tidy = FALSE),communication,8.7299999999999995e+21,1
summary(model4),modeling,2.9400000000000002e+22,47
adw <- na.omit(adw),data cleaning,9.5200000000000008e+22,34
"boot <- vector(""list"", 10000)",data cleaning,9.5200000000000008e+22,34
"par(mfrow = c(2, 2))",export,2.9400000000000002e+22,47
for (i in seq_along(boot)) {,data cleaning,9.5200000000000008e+22,34
"boot[[i]] <- adw[, list(rep = i, bird_weight = bird_weight[sample.int(.N,",data cleaning,9.5200000000000008e+22,34
},data cleaning,9.5200000000000008e+22,34
"replace = TRUE)]), by = c(""year"")]",data cleaning,9.5200000000000008e+22,34
boot <- rbindlist(boot),modeling,9.5200000000000008e+22,34
"boot_means <- boot[, list(mean = mean(bird_weight)), by = c(""year"",     ""rep"")]",modeling,9.5200000000000008e+22,34
"boot_ci <- boot_means[, list(lower = quantile(mean, 0.025), upper = quantile(mean,     0.975)), by = c(""year"")]",visualization,9.5200000000000008e+22,34
library(randomForest),setup,818e19,48
"adw_sum <- cbind(adw[, list(mean = mean(bird_weight)), by = c(""year"")],     boot_ci[, 2:3])",evaluation,9.5200000000000008e+22,34
library(caret),setup,818e19,48
"adw_sum <- adw_sum[order(year), ]",evaluation,9.5200000000000008e+22,34
x <- sort(unique(adw$year)),evaluation,9.5200000000000008e+22,34
library(doMC),setup,818e19,48
library(mmadsenr),setup,818e19,48
"y <- tapply(adw$bird_weight, adw$year, mean)",modeling,9.5200000000000008e+22,34
library(futile.logger),setup,818e19,48
library(dplyr),setup,818e19,48
library(ggthemes),setup,818e19,48
"wt <- 1/tapply(adw$bird_weight, adw$year, var)",evaluation,9.5200000000000008e+22,34
"mod <- lm(y ~ x, weights = wt)",evaluation,9.5200000000000008e+22,34
summary(mod),evaluation,9.5200000000000008e+22,34
confint(mod),evaluation,9.5200000000000008e+22,34
"predicted <- predict(mod, x = adw$year, se.fit = TRUE, interval = ""confidence"",     level = 0.95)",modeling,9.5200000000000008e+22,34
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {",data cleaning,818e19,48
"df_tassize_subset <- dplyr::filter(df, sample_size == ssize,",data cleaning,818e19,48
},data cleaning,818e19,48
df_tassize_subset,data cleaning,818e19,48
ta_duration == tadur),data cleaning,818e19,48
"adw_analysis <- cbind(adw_sum, predicted$fit)",evaluation,9.5200000000000008e+22,34
adw_mod <- mod,evaluation,9.5200000000000008e+22,34
"ylab <- ""Adult mass (g)""",visualization,9.5200000000000008e+22,34
"adult_mass_p <- ggplot(data = adw_analysis) + geom_point(aes(x = year,     y = mean)) + geom_errorbar(aes(x = year, ymin = lower, ymax = upper),     width = 0) + scale_x_continuous(breaks = yrs, expand = c(0.01,     0), limits = c(yrs[1], yrs[28])) + xlab(""Year"") + ylab(ylab) +     cowplot::theme_cowplot() + theme(axis.text.x = element_text(angle = 90,     width = 0) + scale_x_continuous(breaks = yrs, expand = c(0.01,     vjust = 0.5))",visualization,9.5200000000000008e+22,34
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""tasampled-classification.log"")",export,818e19,48
"prey <- read.csv(""data-raw/prey_deliveries.csv"", na.strings = c("""",     ""NA"", ""N/A""), stringsAsFactors = FALSE)",import,9.5200000000000008e+22,34
"whole_capelin <- prey[prey$prey == ""capelin"" & grepl(""^fresh|^eyeless"",     prey$digestion), c(""year"", ""mass"")]",data cleaning,9.5200000000000008e+22,34
low_n <- whole_capelin %>% group_by(year) %>% summarise(n = n()) %>%,exploratory,9.5200000000000008e+22,34
filter(n <= 10) %>% select(year),exploratory,9.5200000000000008e+22,34
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,818e19,48
clargs <- commandArgs(trailingOnly = TRUE),modeling,818e19,48
},data cleaning,818e19,48
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",data cleaning,818e19,48
"filename = ""equifinality-3-ta-sampled-data.rda"")",data cleaning,818e19,48
if (length(clargs) == 0) {,data cleaning,818e19,48
} else {,data cleaning,818e19,48
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",data cleaning,818e19,48
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",data cleaning,818e19,48
"prey <- data.table(whole_capelin[!whole_capelin$year %in% low_n$year,",exploratory,9.5200000000000008e+22,34
]),exploratory,9.5200000000000008e+22,34
library(igraph),setup,543e20,49
prey <- na.omit(prey),data cleaning,9.5200000000000008e+22,34
"boot <- vector(""list"", 10000)",data cleaning,9.5200000000000008e+22,34
library(dplyr),setup,543e20,49
library(parallel),setup,543e20,49
library(purrr),setup,543e20,49
load(ta_sampled_data_file),import,818e19,48
library(stringr),setup,543e20,49
"replace = TRUE)]), by = c(""year"")]",modeling,9.5200000000000008e+22,34
"boot[[i]] <- prey[, list(rep = i, mass = mass[sample.int(.N,",modeling,9.5200000000000008e+22,34
},modeling,9.5200000000000008e+22,34
for (i in seq_along(boot)) {,modeling,9.5200000000000008e+22,34
boot <- rbindlist(boot),modeling,9.5200000000000008e+22,34
"boot_means <- boot[, list(mean = mean(mass)), by = c(""year"",     ""rep"")]",modeling,9.5200000000000008e+22,34
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",not sure,818e19,48
"boot_ci <- boot_means[, list(lower = quantile(mean, 0.025), upper = quantile(mean,     0.975)), by = c(""year"")]",modeling,9.5200000000000008e+22,34
"prey_sum <- cbind(prey[, list(mean = mean(mass)), by = c(""year"")],     boot_ci[, 2:3])",modeling,9.5200000000000008e+22,34
"prey_sum <- prey_sum[order(year), ]",modeling,9.5200000000000008e+22,34
require(plyr),setup,43e21,50
require(dplyr),setup,43e21,50
require(data.table),setup,43e21,50
library(randomForest),setup,846e20,51
require(reshape2),setup,43e21,50
library(caret),setup,846e20,51
require(ggplot2),setup,43e21,50
library(doMC),setup,846e20,51
require(qgraph),setup,43e21,50
library(mmadsenr),setup,846e20,51
library(futile.logger),setup,846e20,51
require(RColorBrewer),setup,43e21,50
library(dplyr),setup,846e20,51
require(cluster),setup,43e21,50
library(ggthemes),setup,846e20,51
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""popsampled-classification.log"")",import,846e20,51
"flog.appender(appender.file(log_file), name = ""cl"")",import,846e20,51
library(ggplot2),setup,5.4000000000000004e+22,1
clargs <- commandArgs(trailingOnly = TRUE),setup,846e20,51
"source(""/Documents/GRADUATE_SCHOOL/Ranalysis/useful.R"")",setup,5.4000000000000004e+22,1
"filename = ""equifinality-3-population-data.rda"")",import,846e20,51
if (length(clargs) == 0) {,import,846e20,51
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,846e20,51
} else {,import,846e20,51
"filename = ""equifinality-3-sampled-data.rda"", args = clargs)",import,846e20,51
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,846e20,51
"filename = ""equifinality-3-sampled-data.rda"")",import,846e20,51
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,846e20,51
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,846e20,51
"filename = ""equifinality-3-population-data.rda"", args = clargs)",import,846e20,51
},import,846e20,51
load(pop_data_file),import,846e20,51
load(sampled_data_file),import,846e20,51
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",import,846e20,51
"flog.info(""Loaded data file: %s"", sampled_data_file, name = ""cl"")",import,846e20,51
"flog.info(""Beginning classification analysis of equifinality-3 data sets with full 4 classes"",     name = ""cl"")",communication,846e20,51
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,846e20,51
"CNH <- ""/Volumes/NOAA_Data/CNH/""",import,43e21,50
"flog.info(""Number of cores used in analysis: %s"", num_cores,     name = ""cl"")",communication,846e20,51
registerDoMC(cores = num_cores),setup,846e20,51
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",     sep = """"), stringsAsFactors = F, skip = 2)",import,43e21,50
"FTL <- head(FTL, -2)",exploratory,43e21,50
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (1:10) *     25, .shrinkage = 0.05)",setup,846e20,51
"training_control <- trainControl(method = ""repeatedcv"", number = 10,     repeats = 5)",setup,846e20,51
seed_value <- 58132133,setup,846e20,51
set.seed(seed_value),setup,846e20,51
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",     sep = """"), stringsAsFactors = F)",import,43e21,50
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,     name = ""cl"")",communication,846e20,51
training_set_fraction <- 0.8,setup,846e20,51
test_set_fraction <- 1 - training_set_fraction,setup,846e20,51
"experiment_names <- c(""Four Class Census"", ""Four Class Sample Size 10%"",     ""Four Class Sample Size 20%"")",import,846e20,51
fourclass_popsampled_results <- data.frame(),import,846e20,51
fourclass_popsampled_results_roc <- NULL,import,846e20,51
fourclass_popsampled_results_model <- NULL,import,846e20,51
fourclass_popsampled_results_cm <- NULL,setup,846e20,51
"flog.info(""Starting analysis of Four Class population census data"",     name = ""cl"")",communication,846e20,51
i <- 1,setup,846e20,51
exp_name <- experiment_names[i],setup,846e20,51
"exclude_columns <- c(""simulation_run_id"", ""innovation_rate"")",setup,846e20,51
"model <- train_gbm_classifier(eq3_pop_df, training_set_fraction,     ""model_class_label"", gbm_grid, training_control, exclude_columns, verbose = FALSE)",modeling,846e20,51
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,1.5100000000000001e+22,51
files <- list.files(path = diffdir),setup,1.5100000000000001e+22,51
files[1] <- NA,setup,1.5100000000000001e+22,51
files[8] <- NA,setup,1.5100000000000001e+22,51
files[29] <- NA,import,1.5100000000000001e+22,51
files[30] <- NA,import,1.5100000000000001e+22,51
files[31] <- NA,import,1.5100000000000001e+22,51
files <- files[!is.na(files)],import,1.5100000000000001e+22,51
names <- files,setup,1.5100000000000001e+22,51
"split <- data.frame(strsplit(names, ""_""))",import,1.5100000000000001e+22,51
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",import,1.5100000000000001e+22,51
"mat <- matrix(nrow = dim(split)[2], ncol = 4)",setup,1.5100000000000001e+22,51
library(synapseClient),setup,997e20,52
data = data.frame(mat),import,1.5100000000000001e+22,51
synapseLogin(),setup,997e20,52
"colnames(data) <- c(""strain"", ""timepoint"", ""filename"", ""dir"")",import,1.5100000000000001e+22,51
library(data.table),setup,997e20,52
"for (i in seq(1, (dim(split)[2]))) {",import,1.5100000000000001e+22,51
"data$strain[i] <- as.character(split[1, i])",import,1.5100000000000001e+22,51
"data$dir[i] <- paste(diffdir, filename, sep = ""/"")",import,1.5100000000000001e+22,51
},import,1.5100000000000001e+22,51
"data$timepoint[i] <- as.character(split[4, i])",import,1.5100000000000001e+22,51
"filename <- paste(split[, i], collapse = ""_"")",import,1.5100000000000001e+22,51
data$filename[i] <- filename,import,1.5100000000000001e+22,51
"write.table(data, ""autoanalysisInfo.csv"", sep = "","")",export,1.5100000000000001e+22,51
"dat <- read.csv(""autoanalysisInfo.csv"", header = TRUE, stringsAsFactors = FALSE)",import,1.5100000000000001e+22,51
"estimate <- as.data.frame(t(read.table(synGet(""syn5908274"")@filePath,     output = paste(filename, "".md"", sep = """"), quiet = TRUE)",import,997e20,52
i <- as.numeric(as.character(commandArgs(TRUE)[1])),setup,1.5100000000000001e+22,51
require(ggplot2),setup,997e20,52
filename <- dat$filename[i],import,1.5100000000000001e+22,51
"mgmt_grp <- dlply(spid, .(mgmt_grp))",data cleaning,43e21,50
print(filename),communication,1.5100000000000001e+22,51
print(dat$strain[i]),communication,1.5100000000000001e+22,51
dir.create(filename),not sure,1.5100000000000001e+22,51
setwd(filename),setup,1.5100000000000001e+22,51
mgmt_grp <- mgmt_grp[2:9],exploratory,43e21,50
"knit2html(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/StrainTemplate.Rmd"",     output = paste(filename, "".md"", sep = """"), quiet = TRUE)",export,1.5100000000000001e+22,51
library(knitr),setup,1.5100000000000001e+22,51
"d <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_bldg_size.csv"",     header = TRUE, sep = "","")",import,22e21,53
"patient <- synTableQuery(""select Patient,Length_in_mm,RNASeq,TumorLocation from syn5556216"")@values",import,997e20,52
"d1 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_bldg_psf.csv"",     header = TRUE, sep = "","")",import,22e21,53
"analysisdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/""",setup,1.5100000000000001e+22,51
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,1.5100000000000001e+22,51
"d2 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_land_size.csv"",     header = TRUE, sep = "","")",import,22e21,53
setwd(diffdir),setup,1.5100000000000001e+22,51
files <- list.files(),setup,1.5100000000000001e+22,51
names <- files,setup,1.5100000000000001e+22,51
"d3 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_land_psf.csv"",     header = TRUE, sep = "","")",import,22e21,53
"header = TRUE, sep = "","")",import,22e21,53
library(zoo),setup,2.4199999999999998e+22,51
library(data.table),setup,2.4199999999999998e+22,51
"d <- data.frame(d, d1[, 3], d2[, 3], d3[, 3])",import,22e21,53
library(dplyr),setup,2.4199999999999998e+22,51
library(reshape2),setup,2.4199999999999998e+22,51
"estimate$Patient = as.factor(patient$Patient[match(rownames(estimate),     patient$RNASeq)])",data cleaning,997e20,52
library(jagsUI),setup,2.4199999999999998e+22,51
"community_area <- str_trim(d1[, 1], side = ""both"")",import,22e21,53
"stageSelect = ""none""",setup,2.4199999999999998e+22,51
"source(""analysis/dataPrep.R"")",setup,2.4199999999999998e+22,51
"source(""analysis/model.R"")",setup,2.4199999999999998e+22,51
"estimate$TumorSize = patient$Length_in_mm[match(rownames(estimate),     patient$RNASeq)]",data cleaning,997e20,52
"params <- c(""pMrSigma"", ""pDepSigma"", ""muPMr"", ""muPDep"", ""pMrEps"")",setup,2.4199999999999998e+22,51
"codaOnly <- c(""pMrEps"", ""pDepEps"", ""yearRan"", ""siteRan"", ""eps"")",setup,2.4199999999999998e+22,51
"estimate$Location = patient$TumorLocation[match(rownames(estimate),     patient$RNASeq)]",data cleaning,997e20,52
ni = 20000,setup,2.4199999999999998e+22,51
nb = 10000,setup,2.4199999999999998e+22,51
nt = 5,setup,2.4199999999999998e+22,51
nc = 3,setup,2.4199999999999998e+22,51
na = 2000,setup,2.4199999999999998e+22,51
inits <- function() {,not sure,2.4199999999999998e+22,51
"list(N = data[, sum(count), by = surveyIndex]$V1)",not sure,2.4199999999999998e+22,51
},not sure,2.4199999999999998e+22,51
"r = cor(estimate$ImmuneScore, estimate$StromalScore)",evaluation,997e20,52
start <- Sys.time(),setup,2.4199999999999998e+22,51
"ggplot(estimate) + geom_point(aes(x = StromalScore, y = ImmuneScore,     col = Patient, size = TumorPurity)) + ggtitle(paste(""Stromal-Immune R ="",     format(r, digits = 3)))",visualization,997e20,52
"out <- jags(jagsData, inits = inits, params, ""analysis/model.txt"",     n.chains = nc, n.iter = ni, n.burnin = nb, n.thin = nt, parallel = T,     codaOnly = codaOnly)",modeling,2.4199999999999998e+22,51
"ggsave(""ESTIMATEscoresAcrossSamples.png"")",export,997e20,52
"saveRDS(out, ""results/out.rds"")",export,2.4199999999999998e+22,51
"r = cor(estimate$TumorPurity, estimate$TumorSize)",evaluation,997e20,52
finish <- Sys.time(),export,2.4199999999999998e+22,51
"ggplot(estimate) + geom_point(aes(x = TumorPurity, y = TumorSize,     col = Location)) + ggtitle(paste(""Purity-Size R ="", format(r,     digits = 3)))",visualization,997e20,52
print(finish - start),communication,2.4199999999999998e+22,51
"ggsave(""ESTIMATEpurityscoresAcrossSamplesBySize.png"")",export,997e20,52
"write.table(estimate, file = ""estimateScoresWithOtherTumorData.txt"",     sep = ""\t"", row.names = F, quote = F)",export,997e20,52
siteSize = 2048,setup,2.4199999999999998e+22,51
"treatment = ""Copper""",setup,2.4199999999999998e+22,51
"strand = ""both""",setup,2.4199999999999998e+22,51
window.size = 100,setup,2.4199999999999998e+22,51
numSam = 6,setup,2.4199999999999998e+22,51
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,2.4199999999999998e+22,51
"synStore(File(""estimateScoresWithOtherTumorData.txt"", parentId = ""syn5908270""),     executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-05/formatTumorPurityEstimates.R"")),     used = list(list(entity = ""syn5908274"")))",export,997e20,52
"write.table(data.frame(Sample = rownames(estimate), Purity = estimate$TumorPurity),     file = ""tumorPurityOnly.txt"", row.names = F, quote = F, sep = ""\t"")",export,997e20,52
"synStore(File(""tumorPurityOnly.txt"", parentId = ""syn5908270""),     executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-05/formatTumorPurityEstimates.R"")),     used = list(list(entity = ""syn5908274"")))",export,997e20,52
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,2.4199999999999998e+22,51
load(out.path),import,2.4199999999999998e+22,51
"synStore(File(""ESTIMATEpurityscoresAcrossSamplesBySize.png"",     parentId = ""syn5908270""), executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-05/formatTumorPurityEstimates.R"")),     used = list(list(entity = ""syn5908274"")))",export,997e20,52
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,2.4199999999999998e+22,51
"pdf(""hist.statistic.pval.DESeq2.100.full.discrete.pdf"")",export,2.4199999999999998e+22,51
filter.cut = 0,not sure,2.4199999999999998e+22,51
"synStore(File(""ESTIMATEscoresAcrossSamples.png"", parentId = ""syn5908270""),     executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-05/formatTumorPurityEstimates.R"")),     used = list(list(entity = ""syn5908274"")))",export,997e20,52
pval = pval.deseq.100.0,not sure,2.4199999999999998e+22,51
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.min.pval."",     filter.cut, "".txt""))[, 1])",import,2.4199999999999998e+22,51
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.min.pval."",     filter.cut, "".txt""))[, 1])",import,2.4199999999999998e+22,51
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==     TRUE))",exploratory,2.4199999999999998e+22,51
require(lme4),setup,698e20,52
xmax = 1,not sure,2.4199999999999998e+22,51
xmin = 0,not sure,2.4199999999999998e+22,51
library(ggplot2),visualization,299e19,54
"source(system.file(""utils"", ""allFit.R"", package = ""lme4""))",setup,698e20,52
"par(mfrow = c(3, 1))",visualization,2.4199999999999998e+22,51
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : alt test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : null test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
"hist(pval[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : pvalue [100]"", length(pval) - length(del.ix.deseq)),     xlim = c(xmin, xmax), xlab = ""p=value"")",visualization,2.4199999999999998e+22,51
filter.cut = 0,not sure,2.4199999999999998e+22,51
pval = pval.deseq.full.0,not sure,2.4199999999999998e+22,51
"source(""./analysis/nursery_experiment_inundation/functions/index.R"")",setup,698e20,52
library(lubridate),data cleaning,299e19,54
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.full.pval."",     filter.cut, "".txt""))[, 1])",import,2.4199999999999998e+22,51
"survival_data <- read.table(""./analysis/nursery_experiment_inundation/data/nursery_experiment_data.txt"",     header = TRUE)",import,698e20,52
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",       treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.full.pval."",   filter.cut, "".txt""))[, 1])",import,2.4199999999999998e+22,51
"rm(list = setdiff(ls(), ""base_path""))",not sure,299e19,54
"surv_model <- glmer(surv ~ sp + treat + dia + sp:treat + (1 |     mother) + (1 | block), data = survival_data, family = ""binomial"",     control = glmerControl(optimizer = ""nlminbw""))",modeling,698e20,52
"load(file.path(base_path, ""data"", ""output"", ""manual_puzzles"",     ""clean_manual_puzzles.RData""))",import,299e19,54
"surv_model2 <- update(surv_model, . ~ . - sp:treat)",modeling,698e20,52
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==     TRUE))",data cleaning,2.4199999999999998e+22,51
xmax = 1,not sure,2.4199999999999998e+22,51
xmin = 0,not sure,2.4199999999999998e+22,51
"anova(surv_model, surv_model2)",evaluation,698e20,52
"par(mfrow = c(3, 1))",visualization,2.4199999999999998e+22,51
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : alt test statistic [2048]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : null test statistic [2048]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
"hist(pval[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : pvalue [2048]"", length(pval) - length(del.ix.deseq)),     xlim = c(xmin, xmax), xlab = ""p=value"")",visualization,2.4199999999999998e+22,51
"surv_model1_residuals <- resid(surv_model, type = ""pearson"")",evaluation,698e20,52
dev.off(),visualization,2.4199999999999998e+22,51
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,2.4199999999999998e+22,51
"pdf(""hist.statistic.pval.DESeq2.100.full.discrete.pooling.pdf"")",export,2.4199999999999998e+22,51
"performance <- filter(performance, year(time) != 2016) %>% arrange(time) %>%     mutate(game_nr = 1:nrow(.)) %>% mutate(week = week(time))",data cleaning,299e19,54
filter.cut = 0,not sure,2.4199999999999998e+22,51
surv_model1_fitted <- fitted(surv_model),evaluation,698e20,52
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.all.pval."",     filter.cut, "".txt""))))",import,2.4199999999999998e+22,51
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.all.pval."",     filter.cut, "".txt""))))",import,2.4199999999999998e+22,51
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==     TRUE))",data cleaning,2.4199999999999998e+22,51
xmax = 1,not sure,2.4199999999999998e+22,51
"newbinplot(surv_model1_fitted, surv_model1_residuals)",visualization,698e20,52
xmin = 0,not sure,2.4199999999999998e+22,51
"par(mfrow = c(2, 1))",visualization,2.4199999999999998e+22,51
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : alt test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,     "" : null test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,2.4199999999999998e+22,51
dev.off(),visualization,2.4199999999999998e+22,51
"ranNorm(""mother"", slope = 1, model = surv_model)",visualization,698e20,52
"ranNorm(""block"", slope = 1, model = surv_model)",visualization,698e20,52
library(knitr),setup,2.4199999999999998e+22,51
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,2.4199999999999998e+22,51
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,2.4199999999999998e+22,51
"game_nr_end_of_week <- c(performance$game_nr[which(diff(performance$week) !=     0)], max(performance$game_nr))",exploratory,299e19,54
coef <- fixef(surv_model),evaluation,698e20,52
names(game_nr_end_of_week) <- unique(performance$week),data cleaning,299e19,54
print(strain),export,2.4199999999999998e+22,51
"for (i in seq(1, (dim(mastersheet)[1]))) {",export,2.4199999999999998e+22,51
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,",export,2.4199999999999998e+22,51
"dir <- mastersheet[i, 2]",export,2.4199999999999998e+22,51
"strain <- mastersheet[i, 1]",export,2.4199999999999998e+22,51
print(dir),export,2.4199999999999998e+22,51
""".md"", sep = """"), quiet = TRUE)",export,2.4199999999999998e+22,51
print(dir),export,2.4199999999999998e+22,51
print(strain),export,2.4199999999999998e+22,51
},export,2.4199999999999998e+22,51
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",setup,2.4199999999999998e+22,51
"slope_coef <- data.frame(sp = levels(survival_data$sp), p = c(coef[11],     coef[11] + coef[13:length(coef)]))",communication,698e20,52
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",setup,2.4199999999999998e+22,51
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",setup,2.4199999999999998e+22,51
"write.table(slope_coef, file = ""analysis/nursery_experiment_inundation/data/survival_slope_coef.txt"")",export,698e20,52
"graph_rating_progression <- ggplot(data = performance, aes(x = game_nr,     y = user_rating)) + geom_line(colour = ""grey50"") + geom_vline(xintercept = game_nr_end_of_week) +     annotate(""text"", x = game_nr_end_of_week - 10, y = 1200,         angle = 90, label = paste(""week"", names(game_nr_end_of_week), sep = "" ""))",visualization,299e19,54
"test_master_sheet <- (rbind(test1, test2, test3))",import,2.4199999999999998e+22,51
"for (i in seq(1, (dim(test_master_sheet)[1]))) {",export,2.4199999999999998e+22,51
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,",export,2.4199999999999998e+22,51
print(dir),export,2.4199999999999998e+22,51
"dir <- test_master_sheet[i, 2]",export,2.4199999999999998e+22,51
print(dir),export,2.4199999999999998e+22,51
"strain <- test_master_sheet[i, 1]",export,2.4199999999999998e+22,51
},export,2.4199999999999998e+22,51
""".md"", sep = """"))",export,2.4199999999999998e+22,51
print(strain),export,2.4199999999999998e+22,51
print(strain),export,2.4199999999999998e+22,51
"graphs <- mget(ls()[grep(pattern = ""graph_"", x = ls())])",not sure,299e19,54
library(ggplot2),setup,2.4199999999999998e+22,51
library(reshape2),setup,2.4199999999999998e+22,51
"genomeAvg <- read.csv(""files/speciesCopyNumberAnalysis.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"save_path_graphs <- file.path(base_path, ""analysis"", ""output"")",export,299e19,54
"colnames(genomeAvg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"mapply(ggsave, file = paste0(file.path(save_path_graphs, names(graphs)),     "".png""), plot = graphs)",export,299e19,54
"genomeAvgData <- melt(genomeAvg, id = c(""id""))",import,2.4199999999999998e+22,51
"genomeAvgData$segment <- ""genomeAvg""",import,2.4199999999999998e+22,51
"reusable <- c(""odds_var"", ""td_bookmax"", ""td_low_odds"")",setup,299e19,54
"bg <- read.csv(""files/speciesCopyNumberAnalysis/BG.txt"", sep = ""\t"",     header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"bgData <- melt(bg, id = c(""id""))",import,2.4199999999999998e+22,51
"bgData$segment <- ""bg""",import,2.4199999999999998e+22,51
"save_path_reusable <- file.path(base_path, ""analyse"", ""multiple variables"",     ""exploratory analysis"", ""output exploratory analysis"", ""bookmakers"",     ""reusable data"")",setup,299e19,54
"bl <- read.csv(""files/speciesCopyNumberAnalysis/BL.txt"", sep = ""\t"",     header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"blData <- melt(bl, id = c(""id""))",import,2.4199999999999998e+22,51
"blData$segment <- ""bl""",import,2.4199999999999998e+22,51
"pg <- read.csv(""files/speciesCopyNumberAnalysis/PG.txt"", sep = ""\t"",     header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(pg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"pgData <- melt(pg, id = c(""id""))",import,2.4199999999999998e+22,51
"pgData$segment <- ""pg""",import,2.4199999999999998e+22,51
"pl <- read.csv(""files/speciesCopyNumberAnalysis/PL.txt"", sep = ""\t"",     header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
library(fpp),setup,741e20,55
"colnames(pl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"plData <- melt(pl, id = c(""id""))",import,2.4199999999999998e+22,51
"plData$segment <- ""pl""",import,2.4199999999999998e+22,51
"bgbl <- read.csv(""files/speciesCopyNumberAnalysis/BGBL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bgbl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"bgblData <- melt(bgbl, id = c(""id""))",import,2.4199999999999998e+22,51
"save(list = r, file = paste0(save_path_reusable, ""/"", r,",export,299e19,54
for (r in reusable) {,export,299e19,54
""".RData""))",export,299e19,54
},export,299e19,54
"bgblData$segment <- ""bgbl""",import,2.4199999999999998e+22,51
"bgpg <- read.csv(""files/speciesCopyNumberAnalysis/BGPG.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"clean_as_is_data <- read.csv(""Analysis/data/tidy_as_is_data.csv"")",import,741e20,55
"colnames(bgpg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"bgpgData <- melt(bgpg, id = c(""id""))",import,2.4199999999999998e+22,51
"bgpgData$segment <- ""bgpg""",import,2.4199999999999998e+22,51
"clean_plan_data <- read.csv(""Analysis/data/tidy_plan_data.csv"")",import,741e20,55
"bgpl <- read.csv(""files/speciesCopyNumberAnalysis/BGPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bgpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"clean_indicator_data <- read.csv(""Analysis/data/tidy_indicator_data.csv"")",import,741e20,55
"bgplData <- melt(bgpl, id = c(""id""))",import,2.4199999999999998e+22,51
""".RData""))",not sure,299e19,54
for (r in reusable) {,not sure,299e19,54
"save(list = r, file = paste0(save_path_reusable, ""/"", r,",not sure,299e19,54
},not sure,299e19,54
"bgplData$segment <- ""bgpl""",import,2.4199999999999998e+22,51
"blpg <- read.csv(""files/speciesCopyNumberAnalysis/BLPG.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
colnames(clean_as_is_data),exploratory,741e20,55
"colnames(blpg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,2.4199999999999998e+22,51
"blpgData <- melt(blpg, id = c(""id""))",import,2.4199999999999998e+22,51
"blpgData$segment <- ""blpg""",import,2.4199999999999998e+22,51
"blpl <- read.csv(""files/speciesCopyNumberAnalysis/BLPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
library(ggplot2),setup,299e19,54
library(lubridate),setup,299e19,54
"colnames(blpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"blplData <- melt(blpl, id = c(""id""))",import,2.4199999999999998e+22,51
"blplData$segment <- ""blpl""",import,2.4199999999999998e+22,51
"pgpl <- read.csv(""files/speciesCopyNumberAnalysis/PGPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"rm(list = setdiff(ls(), ""base_path""))",setup,299e19,54
"colnames(pgpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"asis_data <- subset(clean_as_is_data, year <= 2013)",not sure,741e20,55
"pgplData <- melt(pgpl, id = c(""id""))",import,2.4199999999999998e+22,51
"pgplData$segment <- ""pgpl""",import,2.4199999999999998e+22,51
"bgblpg <- read.csv(""files/speciesCopyNumberAnalysis/BGBLPG.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bgblpg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"plan_data <- subset(clean_plan_data, year <= 2013)",not sure,741e20,55
"bgblpgData <- melt(bgblpg, id = c(""id""))",import,2.4199999999999998e+22,51
"bgblpgData$segment <- ""bgblpg""",import,2.4199999999999998e+22,51
"bgblpl <- read.csv(""files/speciesCopyNumberAnalysis/BGBLPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"sapply(asis_data, class)",exploratory,741e20,55
"colnames(bgblpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"bgblplData <- melt(bgblpl, id = c(""id""))",import,2.4199999999999998e+22,51
"bgblplData$segment <- ""bgblpl""",import,2.4199999999999998e+22,51
"bgpgpl <- read.csv(""files/speciesCopyNumberAnalysis/BGPGPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bgpgpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"bgpgplData <- melt(bgpgpl, id = c(""id""))",import,2.4199999999999998e+22,51
"bgpgplData$segment <- ""bgpgpl""",import,2.4199999999999998e+22,51
"blpgpl <- read.csv(""files/speciesCopyNumberAnalysis/BLPGPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(blpgpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"blpgplData <- melt(blpgpl, id = c(""id""))",import,2.4199999999999998e+22,51
"blpgplData$segment <- ""blpgpl""",import,2.4199999999999998e+22,51
"bgblpgpl <- read.csv(""files/speciesCopyNumberAnalysis/BGBLPGPL.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(bgblpgpl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"bgblpgplData <- melt(bgblpgpl, id = c(""id""))",import,2.4199999999999998e+22,51
"bgblpgplData$segment <- ""bgblpgpl""",import,2.4199999999999998e+22,51
"passengers <- rbind(bgpgData, blplData, bgblpgData, bgblplData,     bgpgplData, blpgplData, bgblpgplData)",import,2.4199999999999998e+22,51
"passengers$segment <- ""passengers""",import,2.4199999999999998e+22,51
"solitaries <- read.csv(""files/speciesCopyNumberAnalysis/solitaryNonPassengers.txt"",     sep = ""\t"", header = FALSE, row.names = NULL)",import,2.4199999999999998e+22,51
"colnames(solitaries) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,2.4199999999999998e+22,51
"solitariesData <- melt(solitaries, id = c(""id""))",import,2.4199999999999998e+22,51
"solitariesData$segment <- ""solitaries""",import,2.4199999999999998e+22,51
"total <- rbind(genomeAvgData, bgData, blData, pgData, plData,     bgplData, blpgData, bgblData, pgplData, passengers, solitariesData)",import,2.4199999999999998e+22,51
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,916e20,56
"svg(filename = ""figures/speciesCopyNumber.svg"", width = 9.5,     height = 4, pointsize = 18)",visualization,2.4199999999999998e+22,51
"axis.title.x = element_blank(), legend.position = ""bottom"") +",visualization,2.4199999999999998e+22,51
"ggplot(total, aes(x = factor(segment), y = value, fill = variable,     color = variable)) + geom_point(position = position_jitterdodge(dodge.width = 0.8,     jitter.height = 0.25), size = 0.5) + geom_boxplot(fill = ""white"",     outlier.colour = NA, position = position_dodge(width = 0.8),     notch = TRUE, notchwidth = 0.5) + coord_cartesian(ylim = c(-0.31,     13.31)) + scale_y_continuous(breaks = seq(0, 13, 2)) + scale_color_manual(values = c(""#000000"",     ""#009c73"", ""#e69f00""), name = ""Status"", limits = c(""onetoone"",     ""dup"", ""noortho""), labels = c(""Unchanged"", ""Duplicated"",     ""No ortholog"")) + scale_fill_manual(values = c(""#000000"",     ""#009c73"", ""#e69f00""), name = ""Status"", limits = c(""onetoone"",      ""solitaries"", ""pg"", ""pl"", ""pgpl"", ""bg"", ""bl"", ""bgbl"", ""bgpl"",     ""blpg"", ""passengers""))",visualization,2.4199999999999998e+22,51
dev.off(),visualization,2.4199999999999998e+22,51
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,916e20,56
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,916e20,56
library(ncdf4),not sure,916e20,56
library(here),import,916e20,56
library(ggplot2),setup,526e20,57
library(tidyverse),data cleaning,916e20,56
library(plyr),setup,526e20,57
library(stringr),data cleaning,916e20,56
library(stringr),setup,526e20,57
library(reshape2),setup,526e20,57
require(rstanarm),setup,445e20,58
options(mc.cores = parallel::detectCores()),setup,445e20,58
"load(""analysis/rdata-tmp/britdat.RData"")",import,445e20,58
"rtdat <- subset(britdat, Voice == ""ACT"" & NVerb %in% c(""PROMISE"",     ""GIVE"") & IO == ""Recipient Noun"" & DO == ""Theme Noun"" & isDatAcc == 1)",data cleaning,445e20,58
"rtcomponent <- data.frame(Year = rtdat$year, Val = rtdat$isTo,     Type = ""I gave to recipient theme"")",data cleaning,445e20,58
"heavy <- read.csv(""analysis/data/Heavy.dat"", sep = ""\t"")",import,445e20,58
heavy$isShifted <- heavy$Shifted,data cleaning,445e20,58
"levels(heavy$isShifted) <- c(0, 1, 0, 1, 0, 1)",data cleaning,445e20,58
heavy$isShifted <- as.numeric(as.character(heavy$isShifted)),data cleaning,445e20,58
heavy$type <- heavy$Shifted,data cleaning,445e20,58
"levels(heavy$type) <- c(""Shifted over Adverbs"", ""Shifted over Adverbs"",     ""Shifted over Both Adverbs and PP"", ""Shifted over Both Adverbs and PP"",     ""Shifted over PP"", ""Shifted over PP"")",data cleaning,445e20,58
"hreal <- subset(heavy, ObjType %in% c(""ObjConj"", ""ObjDefinite"",     ""ObjDPronoun"", ""ObjIndefinite"", ""ObjName""))",data cleaning,445e20,58
"heavycomponent <- data.frame(Year = hreal$YoC, Val = hreal$isShifted,     Type = ""Shifted"")",data cleaning,445e20,58
"compdat <- subset(as.data.frame(rbind(rtcomponent, heavycomponent)),     Year >= 1300 & Year <= 1500)",data cleaning,445e20,58
compdat$isShifted <- compdat$Type,data cleaning,445e20,58
"levels(compdat$isShifted) <- c(0, 1)",data cleaning,445e20,58
compdat$isShifted <- as.numeric(as.character(compdat$isShifted)),data cleaning,445e20,58
compdat$zYear <- (compdat$Year - mean(compdat$Year))/sd(compdat$Year),data cleaning,445e20,58
"param <- read.csv(""analysis/parameters/parameters.csv"")",import,445e20,58
"heavymod <- stan_glm(Val ~ zYear * isShifted, data = compdat,",modeling,445e20,58
seed = param$seed),modeling,445e20,58
"scale = param$prior_sd), prior_intercept = cauchy(location = 0,",modeling,445e20,58
"} else if (param$prior_dist == ""normal"") {",modeling,445e20,58
seed = param$seed),modeling,445e20,58
"scale = param$prior_sd), iter = param$iters, chains = param$nchains,",modeling,445e20,58
},modeling,445e20,58
"scale = param$prior_sd), iter = param$iters, chains = param$nchains,",modeling,445e20,58
"family = binomial(link = ""logit""), prior = cauchy(location = 0,",modeling,445e20,58
"if (param$prior_dist == ""cauchy"") {",modeling,445e20,58
"scale = param$prior_sd), prior_intercept = normal(location = 0,",modeling,445e20,58
"heavymod <- stan_glm(Val ~ zYear * isShifted, data = compdat,",modeling,445e20,58
"family = binomial(link = ""logit""), prior = normal(location = 0,",modeling,445e20,58
"saveRDS(heavymod, file = ""analysis/mcmc-runs/heavy.RDS"")",export,445e20,58
numSites = 500,modeling,535e20,59
"source(""../../bin/RNASeqData.R"")",exploratory,646e20,60
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/""",import,535e20,59
"mat <- rnaGencodeKallistoMatrix(byGene = TRUE, useCellNames = T)",import,646e20,60
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/""",import,535e20,59
"write.table(mat, file = ""pnfGencodeKallisto_tpmByGene.tsv"", sep = ""\t"",     row.names = T, col.names = T)",export,646e20,60
"case.name = c(""fullread.6ind.over"", ""2fullread.6ind.over"", ""4fullread.6ind.over"")",import,535e20,59
"synStore(File(""pnfGencodeKallisto_tpmByGene.tsv"", parentId = ""syn5579785""),     executed = ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2016-08-17/reformatRnaSeq.R"",     used = ""syn5580347"")",not sure,646e20,60
library(Biobase),setup,646e20,60
expr <- ExpressionSet(mat),import,646e20,60
"tmp <- reshape(dat, varying = names(dat)[4:ncol(dat)], v.names = ""severity"",     timevar = ""tissue_parasite"", times = names(dat)[4:ncol(dat)],     direction = ""long"")",data cleaning,81e20,1
"annotes = synTableQuery(""SELECT \""Sample Name\"",\""Sample Genotype\"",\""RNA-Seq Data (Gencode)\"" FROM syn5014742 where \""RNA-Seq Data (Gencode)\"" is not null"")@values",exploratory,646e20,60
"tmp$organ <- matrix(unlist(strsplit(tmp$tissue_parasite, ""_"")),     ncol = 2, byrow = TRUE)[, 2]",data cleaning,81e20,1
"tmp$parasite <- matrix(unlist(strsplit(tmp$tissue_parasite, ""_"")),     ncol = 2, byrow = TRUE)[, 1]",data cleaning,81e20,1
tmp$severity <- as.character(tmp$severity),data cleaning,81e20,1
"yy <- unlist(strsplit(tmp$severity, "",""))",data cleaning,81e20,1
"yy[yy == "".""] <- -99",data cleaning,81e20,1
"df <- data.frame(annotes[, 2:3])",data cleaning,646e20,60
"yy <- as.data.frame(matrix(as.numeric(yy), ncol = 3, byrow = TRUE))",data cleaning,81e20,1
"names(yy) <- c(""x1"", ""x2"", ""x3"")",data cleaning,81e20,1
"tmp <- cbind(tmp, yy)",data cleaning,81e20,1
"tmp2 <- tmp[, -c(9, 10)]",data cleaning,81e20,1
tmp2$rep <- 1,data cleaning,81e20,1
"rownames(df) <- annotes[, 1]",data cleaning,646e20,60
"names(tmp2)[8] <- ""sev""",data cleaning,81e20,1
"tmp_app <- tmp[, -c(8, 10)]",data cleaning,81e20,1
tmp_app$rep <- 2,data cleaning,81e20,1
"names(tmp_app)[8] <- ""sev""",data cleaning,81e20,1
"tmp2 <- rbind(tmp2, tmp_app)",data cleaning,81e20,1
"tmp_app <- tmp[, -c(8, 9)]",data cleaning,81e20,1
"colnames(df) <- c(""Genotype"", ""Synapse ID"")",data cleaning,646e20,60
tmp_app$rep <- 3,data cleaning,81e20,1
rm(list = ls()),setup,1.7500000000000001e+22,1
"FTL <- read.csv(""/Volumes/NOAA_Data/CNH/Data/Catch/FTL_2009-2013_2014-03-21.csv"",     as.is = TRUE)",setup,1.7500000000000001e+22,1
"spid_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/remove_spid.csv"",     as.is = TRUE)",import,1.7500000000000001e+22,1
"cmplx_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/cmplx.csv"",     as.is = TRUE)",import,1.7500000000000001e+22,1
"mgmt_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/mgmt_grp.csv"",     as.is = TRUE)",import,1.7500000000000001e+22,1
"species_data <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/spid.csv"",     as.is = TRUE)",import,1.7500000000000001e+22,1
"prop_tripTable <- FTL_cp(FTL, type = ""proportion"", times = 300,     spid_remove, cmplx_remove, mgmt_remove)",import,1.7500000000000001e+22,1
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",     Sys.Date(), "".Rdata"", sep = """"))",exploratory,1.7500000000000001e+22,1
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",     Sys.Date(), "".Rdata"", sep = """"))",export,1.7500000000000001e+22,1
options(stringsAsFactors = FALSE),setup,7.0799999999999996e+22,61
library(ggplot2),setup,1.7500000000000001e+22,1
library(plyr),setup,1.7500000000000001e+22,1
library(stringr),setup,1.7500000000000001e+22,1
library(reshape2),setup,1.7500000000000001e+22,1
"source(""R/utils.R"")",setup,7.0799999999999996e+22,61
"source(""powerAnalysis/lib.R"")",setup,1.7500000000000001e+22,1
library(randomForest),import,941e20,62
"source(""R/FunctionsForRWLAnalysis.R"")",import,7.0799999999999996e+22,61
library(caret),setup,941e20,62
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,2.8199999999999998e+22,63
"library(""lookr"")",import,7.0799999999999996e+22,61
library(doMC),setup,941e20,62
"library(""magrittr"")",import,7.0799999999999996e+22,61
"library(""stringr"")",import,7.0799999999999996e+22,61
library(mmadsenr),setup,941e20,62
"library(""dplyr"", warn.conflicts = FALSE)",import,7.0799999999999996e+22,61
library(futile.logger),setup,941e20,62
library(dplyr),setup,941e20,62
library(ggthemes),setup,941e20,62
"library(""lme4"")",import,7.0799999999999996e+22,61
"library(""yaml"")",import,7.0799999999999996e+22,61
"library(""readr"")",import,7.0799999999999996e+22,61
"analysis_opts <- yaml.load_file(""analysis_options.yaml"")",import,7.0799999999999996e+22,61
"pseu <- read.csv(""analysis/data/pseudopassives-old.csv"")",import,2.8199999999999998e+22,63
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""per-locus-only-classification.log"")",setup,941e20,62
bin_width <- analysis_opts$bin_width,setup,7.0799999999999996e+22,61
pseu$isPas <- factor(pseu$selected),data cleaning,2.8199999999999998e+22,63
"flog.appender(appender.file(log_file), name = ""cl"")",setup,941e20,62
clargs <- commandArgs(trailingOnly = TRUE),setup,941e20,62
"levels(pseu$isPas) <- c(0, 1)",data cleaning,2.8199999999999998e+22,63
good_phon <- analysis_opts$targets_s2$phono,setup,7.0799999999999996e+22,61
pseu$isPas <- as.numeric(as.character(pseu$isPas)),data cleaning,2.8199999999999998e+22,63
good_semy <- analysis_opts$targets_s2$semantic,not sure,7.0799999999999996e+22,61
"pseu.old <- data.frame(Year = pseu$YoC, Val = pseu$isPas)",data cleaning,2.8199999999999998e+22,63
normalize_medu <- function(xs) {,not sure,7.0799999999999996e+22,61
},not sure,7.0799999999999996e+22,61
"substr(xs, 1, 4)",not sure,7.0799999999999996e+22,61
"xs <- ifelse(xs == ""4 year college degree"", ""College"", xs)",not sure,7.0799999999999996e+22,61
"xs <- ifelse(xs == """", ""Declined"", xs)",not sure,7.0799999999999996e+22,61
"save(pseu.old, file = ""analysis/rdata-tmp/old-pseudopassives.RData"")",export,2.8199999999999998e+22,63
},setup,941e20,62
"filename = ""equifinality-3-sampled-data.rda"")",setup,941e20,62
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
"filename = ""equifinality-3-ta-sampled-data.rda"")",setup,941e20,62
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
"filename = ""equifinality-3-population-data.rda"")",setup,941e20,62
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
} else {,setup,941e20,62
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
"filename = ""equifinality-3-population-data.rda"", args = clargs)",setup,941e20,62
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,941e20,62
"filename = ""equifinality-3-sampled-data.rda"", args = clargs)",setup,941e20,62
if (length(clargs) == 0) {,setup,941e20,62
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",setup,941e20,62
"save(pseu.old, file = ""analysis/rdata-tmp/old-pseudopassives.RData"")",export,2.8199999999999998e+22,63
load(pop_data_file),import,941e20,62
load(sampled_data_file),import,941e20,62
load(ta_sampled_data_file),import,941e20,62
"pseu <- read.csv(""analysis/data/pseudopassives-old.csv"")",import,2.8199999999999998e+22,63
pseu$isPas <- factor(pseu$selected),data cleaning,2.8199999999999998e+22,63
"medu_codes <- c(Less = ""low"", GED = ""low"", High = ""low"", Some = ""middle"")",not sure,7.0799999999999996e+22,61
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",communication,941e20,62
"s2_looks <- read_csv(""data/study2/01_looking_data.csv"")",not sure,7.0799999999999996e+22,61
"flog.info(""Loaded data file: %s"", sampled_data_file, name = ""cl"")",communication,941e20,62
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",communication,941e20,62
"flog.info(""Beginning classification analysis of equifinality-3 data sets for per-locus only predictors"",     name = ""cl"")",communication,941e20,62
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,941e20,62
"flog.info(""Number of cores used in analysis: %s"", num_cores,     name = ""cl"")",communication,941e20,62
"s2_infos <- read_csv(""data/study2/00_child_info.csv"") %>% mutate(Dialect = factor(AAE,     levels = c(0, 1), labels = c(""MAE"", ""AAE"")), medu = normalize_medu(medu)) %>%     rename(Subj = Participant_ID) %>% select(-householdIncome,     -pcedu) %>% rename(EVT_standard = EVT_Standard, PPVT_standard = PPVT_Standard)",import,7.0799999999999996e+22,61
registerDoMC(cores = num_cores),setup,941e20,62
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (1:10) *     25, .shrinkage = 0.05)",setup,941e20,62
"training_control <- trainControl(method = ""repeatedcv"", number = 10,     repeats = 5)",setup,941e20,62
s2_infos$medu <- medu_codes[s2_infos$medu],data cleaning,7.0799999999999996e+22,61
seed_value <- 58132133,setup,941e20,62
set.seed(seed_value),setup,941e20,62
"s2_binned <- standard_model_pipeline(s2_looks, bins = bin_width,     draw = TRUE)",not sure,7.0799999999999996e+22,61
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,     name = ""cl"")",communication,941e20,62
training_set_fraction <- 0.8,setup,941e20,62
test_set_fraction <- 1 - training_set_fraction,setup,941e20,62
"stopifnot(setdiff(s2_binned$Subj, s2_infos$Subj) == 0)",modeling,7.0799999999999996e+22,61
"path <- c(getwd(), filepath2)",import,68e21,7
rm(list = ls(all.names = TRUE)),setup,329e20,1
"experiment_names <- c(""Per-Locus Population Census"", ""Per-Locus Sampled 10%"",     ""Per-Locus Sampled 20%"")",setup,941e20,62
"s2 <- make_model_data(s2_binned, s2_infos)",not sure,7.0799999999999996e+22,61
"path <- paste(path, collapse = """")",import,68e21,7
"RigCountByTrajectory <- read.csv(path, header = TRUE, sep = "","",     stringsAsFactors = FALSE)",import,68e21,7
perlocus_results <- data.frame(),setup,941e20,62
"RigCountByTrajectory <- RigCountByTrajectory[, -1]",import,68e21,7
"write_csv(s2, ""data/study2/02_analysis1.csv"")",not sure,7.0799999999999996e+22,61
"s2_bias_dfs <- compute_bias_growth_curves(looks = s2_looks, infos = s2_infos,     bins = 3, phon_set = good_phon, semy_set = good_semy)",export,7.0799999999999996e+22,61
"colnames(RigCountByTrajectory) <- c(""Date"", ""DirRigCount"", ""HorzRigCount"")",data cleaning,68e21,7
oldwd <- getwd(),data cleaning,68e21,7
library(tidyverse),setup,11e21,1
mtcars %>% select(mpg),exploratory,11e21,1
"filepath2 <- ""/Data/""",not sure,68e21,7
"path <- c(getwd(), filepath2)",not sure,68e21,7
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,11e21,1
"path <- paste(path, collapse = """")",not sure,68e21,7
setwd(path),not sure,68e21,7
"write.csv(RigCountByTrajectory, file = ""CleanRigCountByTrajectory.csv"")",not sure,68e21,7
setwd(oldwd),export,68e21,7
setwd(oldwd),not sure,68e21,7
"filepath2 <- ""/Data/RigCountByTrajectory.csv""",import,68e21,7
"sysData <- read.csv(""../Cleaning/CleanCutSysData.csv"")",import,68e21,7
quad <- clean^2,modeling,68e21,7
RMS <- function(vals) {,modeling,68e21,7
clean <- na.omit(vals),modeling,68e21,7
quadMean <- mean(quad),modeling,68e21,7
sqrt(quadMean),modeling,68e21,7
},modeling,68e21,7
"mean <- sapply(sysData[c(1:54)], mean)",modeling,68e21,7
"rms <- sapply(sysData[c(1:54)], RMS)",modeling,68e21,7
rmsDiff <- sqrt(rms^2 - mean^2),modeling,68e21,7
RMSDiff <- function(vals) {,modeling,68e21,7
},modeling,68e21,7
clean <- na.omit(vals),modeling,68e21,7
sqrt(RMS(vals)^2 - mean(vals)^2),modeling,68e21,7
},modeling,68e21,7
sqrt(sum(vals^2)),modeling,68e21,7
clean <- na.omit(vals),modeling,68e21,7
SumQuad <- function(vals) {,modeling,68e21,7
"errColIndices <- grepl(""Err"", colnames(sysData))",modeling,68e21,7
errors <- sysData[errColIndices],not sure,68e21,7
values <- sysData[!errColIndices],not sure,68e21,7
"rmsDiffByStudy <- with(values, aggregate(values, by = list(StudyType,         VarIndex), RMSDiff))",modeling,68e21,7
"maxRMSDiff <- sapply(rmsDiffByStudy[, !colnames(rmsDiffByStudy) %in%     c(""StudyType"", ""Group.1"", ""Group.2"")], max)",modeling,68e21,7
"rmsDiffAll <- sapply(values[!colnames(values) %in% c(""StudyType"")],     RMSDiff)",modeling,68e21,7
"rmsStdDev <- sapply(rmsDiffByStudy[, c(3:29)], RMS)",modeling,68e21,7
"quadStdDev <- sapply(rmsDiffByStudy[, c(3:29)], SumQuad)",modeling,68e21,7
"rmsStdDevOutput <- data.frame(Parameter = names(rmsStdDev), SigmaCut = rmsStdDev)",export,68e21,7
"rmsStdDevOutput$Parameter <- gsub(""LamALam"", ""LA"", rmsStdDevOutput$Parameter)",export,68e21,7
"write.csv(rmsStdDevOutput, ""SystematicsCutVariationErrors.csv"",     row.names = FALSE)",export,68e21,7
library(randomForest),setup,68e21,7
library(caret),setup,68e21,7
library(doMC),setup,68e21,7
library(mmadsenr),setup,68e21,7
library(futile.logger),setup,68e21,7
library(dplyr),setup,68e21,7
library(ggthemes),setup,68e21,7
},data cleaning,68e21,7
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {",data cleaning,68e21,7
"df_tassize_subset <- dplyr::filter(df, sample_size == ssize,",data cleaning,68e21,7
df_tassize_subset,data cleaning,68e21,7
ta_duration == tadur),data cleaning,68e21,7
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,68e21,7
"filename = ""tasampled-classification.log"")",import,68e21,7
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,68e21,7
clargs <- commandArgs(trailingOnly = TRUE),not sure,68e21,7
"filename = ""equifinality-3-ta-sampled-data.rda"")",import,68e21,7
if (length(clargs) == 0) {,import,68e21,7
} else {,import,68e21,7
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,68e21,7
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,68e21,7
},import,68e21,7
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",import,68e21,7
load(ta_sampled_data_file),import,68e21,7
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",import,68e21,7
"flog.info(""Beginning classification analysis of TA sampled equifinality-3 data sets using per-locus predictors only"",     name = ""cl"")",modeling,68e21,7
num_cores <- get_parallel_cores_given_os(dev = TRUE),not sure,68e21,7
library(plyr),setup,736e20,64
library(stringr),setup,736e20,64
library(reshape2),setup,736e20,64
library(xtable),setup,736e20,64
"source(""powerAnalysis/lib.R"")",setup,736e20,64
"trackdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/tracks/""",setup,1.2499999999999999e+22,65
"kInputPath <- ""powerAnalysis/results_design_regressions.RData""",setup,736e20,64
"kLmTablePath <- ""powerAnalysis/tables_design_lm.tex""",import,736e20,64
"kGlmTablePath <- ""powerAnalysis/tables_design_glm.tex""",import,736e20,64
...),import,736e20,64
},import,736e20,64
"xtable(get(name, envir = parent.frame()), caption = title,",import,736e20,64
"BuildXtable <- function(name, title, ...) {",import,736e20,64
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",communication,1.2499999999999999e+22,65
load(kInputPath),import,736e20,64
"names.lms <- ls()[str_detect(ls(), perl(""^lm\\.(?!names)""))]",setup,736e20,64
files <- list.files(path = diffdir),evaluation,1.2499999999999999e+22,65
"titles.lms <- str_replace(names.lms, perl(""lm\\.(.*)""), ""\\1"")",not sure,736e20,64
"names.glms <- ls()[str_detect(ls(), perl(""^glm\\.(?!names)""))]",import,736e20,64
names <- files,export,1.2499999999999999e+22,65
"titles.glms <- str_replace(names.glms, perl(""glm\\.(.*)""), ""\\1"")",exploratory,736e20,64
"split <- data.frame(strsplit(names, ""_""))",communication,1.2499999999999999e+22,65
library(dbscan),setup,6.7599999999999996e+22,64
library(scater),setup,6.7599999999999996e+22,64
library(ggplot2),setup,6.7599999999999996e+22,64
"sce <- readRDS(""Dropbox (Cambridge University)/SST_spermatocytes/Analysis/data/10X_data/SCE_all.rds"")",import,6.7599999999999996e+22,64
"sce <- sce[, colData(sce)$AnnotatedClusters %in% levels(colData(sce)$AnnotatedClusters)[1:22]]",data cleaning,6.7599999999999996e+22,64
sce.B6 <- normalize(sce.B6),import,6.7599999999999996e+22,64
sce.B6 <- runPCA(sce.B6),data cleaning,6.7599999999999996e+22,64
"dbs <- dbscan(reducedDims(sce.B6)$PCA, eps = 1.5)",modeling,6.7599999999999996e+22,64
"ggplot(data.frame(tsne1 = reducedDims(sce.B6)$TSNE[, 1], tsne2 = reducedDims(sce.B6)$TSNE[,     2], clusters = as.factor(dbs$cluster))) + geom_point(aes(tsne1,     tsne2, colour = clusters))",exploratory,6.7599999999999996e+22,64
"sce.B6 <- sce.B6[, dbs$cluster == 1]",visualization,6.7599999999999996e+22,64
"sce.Tc0 <- sce[, colData(sce)$Sample == ""Tc0""]",not sure,6.7599999999999996e+22,64
sce.Tc0 <- normalize(sce.Tc0),not sure,6.7599999999999996e+22,64
sce.Tc0 <- runPCA(sce.Tc0),data cleaning,6.7599999999999996e+22,64
"dbs <- dbscan(reducedDims(sce.Tc0)$PCA, eps = 1.5)",modeling,6.7599999999999996e+22,64
"ggplot(data.frame(tsne1 = reducedDims(sce.Tc0)$TSNE[, 1], tsne2 = reducedDims(sce.Tc0)$TSNE[,     2], clusters = as.factor(dbs$cluster))) + geom_point(aes(tsne1,     tsne2, colour = clusters))",modeling,6.7599999999999996e+22,64
"sce.Tc0 <- sce.Tc0[, dbs$cluster == 1]",visualization,6.7599999999999996e+22,64
"cmp1_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp1_promoters.csv"")",import,435e20,66
"cmp2_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp2_promoters.csv"")",import,435e20,66
"cmp3_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp3_promoters.csv"")",import,435e20,66
"source(""../../../RASPathwaySig/bin/cBioPortalData.R"", chdir = T)",setup,867e20,67
setwd(wd),setup,867e20,67
rm(list = ls()),setup,368e19,68
"source(""../../../dermalNF/bin/dermalNFData.R"")",setup,867e20,67
library(plyr),setup,368e19,68
library(dplyr),setup,368e19,68
library(reshape2),setup,368e19,68
"load(""../../../RASPathwaySig/analysis/2016-08-23/exprData.Rdata"")",setup,867e20,67
tcga.mat <- exprData,import,867e20,67
"codedir <- ""code""",setup,368e19,68
"ramdir <- ""data/ramldb/data""",setup,368e19,68
"outputdir <- ""analysis/ramldb/output""",setup,368e19,68
"tabledir <- ""analysis/ramldb/tables""",setup,368e19,68
"return(rowMeans(tcga.mat[, cols], na.rm = T))",not sure,867e20,67
"tcga.dis.averages <- sapply(setdiff(tcga.cancer.types, c(""lgggbm"",",not sure,867e20,67
}),not sure,867e20,67
"cols <- match(samps, colnames(tcga.mat))",not sure,867e20,67
"""nsclc"")), function(x) {",not sure,867e20,67
"samps <- sapply(samps, function(y) gsub(""-"", ""."", y, fixed = T))",not sure,867e20,67
cols <- cols[!is.na(cols)],not sure,867e20,67
if (length(cols) > 1),not sure,867e20,67
samps <- getSamplesForDisease(x),not sure,867e20,67
"else return(tcga.mat[, cols])",not sure,867e20,67
x))),setup,368e19,68
"sapply(list.files(codedir, "".R""), function(x) source(file.path(codedir,",setup,368e19,68
"load(file.path(outputdir, ""RAMLDB_ricker_sst.Rdata""))",setup,368e19,68
"lhdata <- read.csv(file.path(ramdir, ""ramldb_life_history_data.csv""),     as.is = T)",import,368e19,68
require(synapseClient),not sure,867e20,67
"tstats <- data %>% group_by(stockid) %>% summarize(sst_c_avg = mean(sst_c),     sst_c_trend = freeR::slope(lm(sst_c ~ year)), sst_c_cv = sd(sst_c)/mean(sst_c))",exploratory,368e19,68
synapseLogin(),import,867e20,67
"(x - mean(x, na.rm = T))/sd(x)",import,867e20,67
zscore <- function(x) {,import,867e20,67
x <- unlist(x),import,867e20,67
},import,867e20,67
dermalSamps <- rna_fpkm_matrix(),not sure,867e20,67
"final <- stocks %>% left_join(unique(select(lhdata, -c(species_orig,     species_use, temp_c))), by = ""species"") %>% left_join(tstats,     by = ""stockid"") %>% left_join(results$stock, by = ""stockid"")",exploratory,368e19,68
"normDermData <- apply(dermalSamps, 2, zscore)",not sure,867e20,67
phenoData <- fpkm_annotations(),not sure,867e20,67
"phenoData <- unique(phenoData[, c(1, 2, 5)])",not sure,867e20,67
library(plyr),data cleaning,423e20,69
"if (!require(""pacman"")) install.packages(""pacman"")",import,4.6799999999999996e+22,70
"pats <- paste(""patient"", apply(phenoData[match(colnames(normDermData),     phenoData$sample), c(1, 3)], 1, paste, collapse = "" tumor""))",data cleaning,867e20,67
"p_load(tidyverse, rvest, tabulizer, pdftools, qdap)",import,4.6799999999999996e+22,70
library(gdata),not sure,423e20,69
colnames(normDermData) <- pats,not sure,867e20,67
"loc <- ""./FRAN-reports/ARA 2015.pdf""",setup,4.6799999999999996e+22,70
"tbl2015 <- extract_tables(loc, pages = 18, guess = TRUE, encoding = ""UTF-8"")",setup,4.6799999999999996e+22,70
sessionInfo(),communication,423e20,69
"tbl2015 <- tbl2015[[1]][, 1:7] %>% as_tibble(.)",setup,4.6799999999999996e+22,70
"setwd(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data"")",setup,423e20,69
"comm.genes <- intersect(rownames(tcga.dis.averages), rownames(normDermData))",not sure,867e20,67
"mn <- read.csv(""rollingsales_manhattan.csv"", skip = 4, header = TRUE)",import,423e20,69
head(mn),exploratory,423e20,69
summary(mn),exploratory,423e20,69
str(mn),exploratory,423e20,69
"colnames(tbl2015) <- tbl2015[1, 1:7]",exploratory,4.6799999999999996e+22,70
"mn$SALE.PRICE.N <- as.numeric(gsub(""[^[:digit:]]"", """", mn$SALE.PRICE))",data cleaning,423e20,69
"write.csv(mn, file = ""rollingsales_manhattan_salespriceN.csv"")",export,423e20,69
str(mn),exploratory,423e20,69
str(mn),not sure,423e20,69
library(plyr),data cleaning,423e20,69
library(gdata),not sure,423e20,69
sessionInfo(),communication,423e20,69
"setwd(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data"")",setup,423e20,69
"mn <- read.csv(""rollingsales_manhattan.csv"", skip = 4, header = TRUE)",import,423e20,69
head(mn),exploratory,423e20,69
summary(mn),exploratory,423e20,69
str(mn),exploratory,423e20,69
"mn$SALE.PRICE.N <- as.numeric(gsub(""[^[:digit:]]"", """", mn$SALE.PRICE))",data cleaning,423e20,69
"write.csv(mn, file = ""rollingsales_manhattan_salespriceN.csv"")",export,423e20,69
str(mn),exploratory,423e20,69
str(mn),not sure,423e20,69
"rm(list = setdiff(ls(), ""repository""))",setup,375e20,69
"library(""tidyverse"")",import,686e20,71
"data = read.csv(""crimes_by_category_district_year.csv"", header = TRUE,     stringsAsFactors = FALSE)",setup,375e20,69
"source(""analysis/plot-panels.R"")",import,686e20,71
"source(""analysis/extract-functions.R"")",import,686e20,71
"setwd(paste0(repository, ""analysis/"", ""input""))",import,375e20,69
"source(""analysis/pretty-panels.R"")",import,686e20,71
"source(""analysis/make-handpicked-panel.R"")",import,686e20,71
"data_year_district <- summaryBy(Freq.2002 + Freq.2003 + Freq.2004 +     Freq.2005 + Freq.2006 + Freq.2007 + Freq.2008 + Freq.2009 +     Freq.2015 ~ district, FUN = c(sum), data = data)",setup,375e20,69
data_year = as.data.frame(colSums(data_year_district)),exploratory,375e20,69
"gsub(""FF$"", """", pal)",setup,686e20,71
"pal <- viridisLite::plasma(n, begin = 0.01, end = 0.81, direction = -1)",setup,686e20,71
pal_func <- function(n) {,setup,686e20,71
},setup,686e20,71
"data_year = slice(data_year, 2:15)",exploratory,375e20,69
"years = as.data.frame(matrix(unlist(c(2002:2015)), ncol = 1))",exploratory,375e20,69
"3/2 * gold(), fig_width = 6.5, right_gap = 63)",visualization,686e20,71
"cache_file = ""data/generated/method-models-genetics-grams2.rds"",",visualization,686e20,71
"fig_file = ""figs/methods-models-genetics2.pdf"", fig_height = 6.5 *",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/methods-models-genetics2.csv"",     csv_out = ""data/generated/methods-models-genetics-out.csv"",     fig_file = ""figs/stats-supp.pdf"", fig_height = 3.5 * gold(),",visualization,686e20,71
"csv_out = ""data/generated/methods-models-genetics-out.csv"",",visualization,686e20,71
"fig_file = ""figs/stats-supp.pdf"", fig_height = 3.5 * gold(),",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/stats-supp.csv"", cache_file = ""data/generated/stats-supp.rds"",",visualization,686e20,71
"fig_width = 3.5, right_gap = 45, ncols = 1)",visualization,686e20,71
"cache_file = ""data/generated/genetics-supp.rds"", fig_file = ""figs/genetics-supp.pdf"",",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/genetics-supp.csv"",",visualization,686e20,71
"fig_height = 6.5 * gold() * 1/2, fig_width = 6.5, right_gap = 82)",visualization,686e20,71
"cache_file = ""data/generated/conservation-human-impacts.rds"",",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/conservation-human-impacts.csv"",",visualization,686e20,71
"fig_file = ""figs/conservation-human-impacts.pdf"", fig_height = 6.5 *",visualization,686e20,71
"3/2 * gold(), fig_width = 6.5, right_gap = 38)",visualization,686e20,71
"csv_out = ""data/generated/conservation-human-impacts-out.csv"",",visualization,686e20,71
"data = cbind(years, data_year)",data cleaning,375e20,69
"names(data)[names(data) == ""V1""] <- ""Year""",data cleaning,375e20,69
"names(data)[names(data) == ""colSums(data_year_district)""] <- ""Crimes""",data cleaning,375e20,69
"ggplot(data = data, aes(x = ""Year"", y = ""Crimes"")) + geom_line() +     geom_point()",data cleaning,375e20,69
"ggplot(data = data, aes(x = ""Year"", y = ""Crimes"")) + geom_line() +     geom_point()",visualization,375e20,69
"rm(list = setdiff(ls(), ""repository""))",setup,375e20,69
"gold() * 4/2, fig_width = 6.5, right_gap = 55)",visualization,686e20,71
"fig_file = ""figs/ecology-panels3.pdf"", fig_height = 6.5 *",visualization,686e20,71
"csv_out = ""data/generated/general-ecology-out.csv"", cache_file = ""data/generated/ecology-panels2.rds"",",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/ecology_panels_10_05.csv"",",visualization,686e20,71
siteSize = 2048,setup,375e20,69
"cache_file = ""data/generated/social-science-ngrams3.rds"",",visualization,686e20,71
"make_handpicked_panel(terms_file = ""data/social-ngram.csv"", csv_out = ""data/generated/social-sciences-out.csv"",",visualization,686e20,71
"fig_file = ""figs/social-science-panels3.pdf"", fig_height = 6.5 *",visualization,686e20,71
"2/2 * gold(), fig_width = 6.5, right_gap = 81)",visualization,686e20,71
"treatment = ""Copper""",setup,375e20,69
"if (!require(""pacman"")) install.packages(""pacman"")",import,866e20,72
"strand = ""both""",setup,375e20,69
window.size = 300,setup,375e20,69
numSam = 6,setup,375e20,69
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",data cleaning,375e20,69
"p_load(tidyverse, rvest)",import,866e20,72
"pages <- vector(mode = ""character"", length = 3)",setup,866e20,72
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,375e20,69
load(out.path),setup,375e20,69
"treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete."",",setup,375e20,69
"600, "".Robj"")",setup,375e20,69
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",",setup,375e20,69
for (i in seq_along(pages)) {,setup,866e20,72
i),setup,866e20,72
},setup,866e20,72
"pages[i] <- paste0(""https://data.europa.eu/euodp/en/data/dataset?q=Frontext+Risk+Analysis+Network&ext_boolean=all&sort=&page="",",setup,866e20,72
load(out.path),setup,375e20,69
"frontex <- tibble(title = vector(""list"", length = 3), link = vector(""list"",     length = 3))",setup,866e20,72
"library(""qvalue"")",import,375e20,69
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/pval.ms.wave."",     all.name, "".Robj"")",setup,375e20,69
load(input.path),import,375e20,69
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,375e20,69
load(input.path),import,375e20,69
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete.Robj"")",import,375e20,69
load(input.path),setup,375e20,69
sum(is.na(pval.deseq.600.0)),exploratory,375e20,69
sum(is.na(pval.deseq.100.0)),exploratory,375e20,69
sum(is.na(pval.deseq.100.10)),exploratory,375e20,69
sum(is.na(pval.deseq.3.0)),exploratory,375e20,69
sum(is.na(pval.deseq.3.10)),exploratory,375e20,69
sum(is.na(pval.deseq.full.0)),exploratory,375e20,69
sum(is.na(pval.ms)),exploratory,375e20,69
sum(is.na(pval.wave)),exploratory,375e20,69
length(pval.ms),exploratory,375e20,69
del.ix = NULL,setup,375e20,69
"del.ix = union(del.ix, which(is.na(pval.deseq.100.0) == TRUE))",exploratory,375e20,69
"del.ix = union(del.ix, which(is.na(pval.deseq.3.0) == TRUE))",exploratory,375e20,69
"del.ix = union(del.ix, which(is.na(pval.deseq.600.0) == TRUE))",exploratory,375e20,69
"del.ix = union(del.ix, which(is.na(pval.deseq.full.0) == TRUE))",exploratory,375e20,69
"del.ix = union(del.ix, which(is.na(pval.ms) == TRUE))",exploratory,375e20,69
"del.ix = union(del.ix, which(is.na(pval.wave) == TRUE))",exploratory,375e20,69
length(del.ix),exploratory,375e20,69
qval.wave = qvalue(pval.wave[-del.ix]),exploratory,375e20,69
qval.ms = qvalue(pval.ms[-del.ix]),exploratory,375e20,69
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,698e20,73
qval.deseq.full.0 = qvalue(pval.deseq.full.0[-del.ix]),exploratory,375e20,69
qval.deseq.3.0 = qvalue(pval.deseq.3.0[-del.ix]),exploratory,375e20,69
qval.deseq.100.0 = qvalue(pval.deseq.100.0[-del.ix]),exploratory,375e20,69
qval.deseq.600.0 = qvalue(pval.deseq.600.0[-del.ix]),exploratory,375e20,69
qval.wave$pi0,exploratory,375e20,69
qval.ms$pi0,exploratory,375e20,69
qval.deseq.full.0$pi0,exploratory,375e20,69
qval.deseq.3.0$pi0,exploratory,375e20,69
qval.deseq.100.0$pi0,exploratory,375e20,69
qval.deseq.600.0$pi0,exploratory,375e20,69
"alpha.list = seq(0, 0.2, by = 0.01)",setup,375e20,69
length(alpha.list),exploratory,375e20,69
length(alpha.list)),setup,375e20,69
"num.wave = num.ms = num.deseq.full.0 = num.deseq.3.0 = num.deseq.100.0 = num.deseq.600.0 = rep(NA,",setup,375e20,69
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),data cleaning,375e20,69
num.deseq.600.0[i] = sum(qval.deseq.600.0$qvalues < alpha.list[i]),data cleaning,375e20,69
for (i in 1:length(alpha.list)) {,data cleaning,375e20,69
num.wave[i] = sum(qval.wave$qvalues < alpha.list[i]),data cleaning,375e20,69
num.deseq.100.0[i] = sum(qval.deseq.100.0$qvalues < alpha.list[i]),data cleaning,375e20,69
num.deseq.full.0[i] = sum(qval.deseq.full.0$qvalues < alpha.list[i]),data cleaning,375e20,69
num.deseq.3.0[i] = sum(qval.deseq.3.0$qvalues < alpha.list[i]),data cleaning,375e20,69
},data cleaning,375e20,69
"pdf(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/code_fig/RECOMB_2014/fig/FDR.pdf"")",export,375e20,69
library(knitr),setup,822e19,74
"pandoc(""analysis_results.md"", format = ""html"")",export,822e19,74
"pandoc(""analysis_results.md"", format = ""html"")",export,822e19,74
library(knitr),setup,822e19,74
"pandoc(""analysis_results.md"", format = ""html"")",export,822e19,74
"pandoc(""analysis_results.md"", format = ""html"")",not sure,822e19,74
library(knitr),setup,822e19,74
library(readxl),setup,727e20,10
library(openxlsx),setup,727e20,10
library(tidyverse),setup,727e20,10
library(lubridate),setup,727e20,10
library(here),setup,727e20,10
"rm(data, df)",setup,727e20,10
date <- as.character(today() - wday(today() + 1)),exploratory,727e20,10
"csv_file_path <- file.path(""analysis"", ""data_original"", ""csv"")",import,727e20,10
"target_filename <- paste0(file.path(csv_file_path, date), ""_results-survey431953.csv"")",import,727e20,10
df <- read_csv(target_filename),import,727e20,10
library(shiny),communication,945e19,75
"request_types = c(""Bulky Items"", ""Dead Animal Removal"", ""Graffiti Removal"")",not sure,945e19,75
"df$A3 <- str_pad(as.character(df$A3), 4, pad = ""0"")",data cleaning,727e20,10
"selectInput(inputId = ""types"", label = ""Request Types: "",",visualization,945e19,75
"choices = request_types, multiple = TRUE, selectize = TRUE),",visualization,945e19,75
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Zipcode Level Analysis"",",visualization,945e19,75
"start = ""2015-08-01"", end = ""2016-11-30"", min = ""2015-08-01"",",visualization,945e19,75
"sidebarLayout(sidebarPanel(dateRangeInput(""daterange"", ""Time Period: "",",visualization,945e19,75
"width = 4), mainPanel(plotOutput(outputId = ""plot"", click = ""plot_click"")))))",visualization,945e19,75
"actionButton(inputId = ""button_geo"", label = ""Submit""),",visualization,945e19,75
"max = ""2016-11-30"", format = ""mm/dd/yy"", separator = "" - ""),",visualization,945e19,75
"save_path <- here(""analysis"", ""data"")",export,727e20,10
"save(df, file = paste0(save_path, ""/"", ""df.RData""))",export,727e20,10
save.image(),export,727e20,10
"start = ""2015-08-01"", end = ""2016-11-30"", min = ""2015-08-01"",",visualization,945e19,75
"sidebarLayout(sidebarPanel(dateRangeInput(""daterange"", ""Time Period: "",",visualization,945e19,75
"selectInput(inputId = ""types"", label = ""Request Types: "",",visualization,945e19,75
"max = ""2016-11-30"", format = ""mm/dd/yy"", separator = "" - ""),",visualization,945e19,75
"choices = request_types, multiple = TRUE, selectize = TRUE),",visualization,945e19,75
"width = 4), mainPanel(plotOutput(outputId = ""plot"", click = ""plot_click"")))))",visualization,945e19,75
"actionButton(inputId = ""button_geo"", label = ""Submit""),",visualization,945e19,75
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Zipcode Level Analysis"",",visualization,945e19,75
"unlink(paste0(save_path, ""df.RData""))",not sure,727e20,10
suppressPackageStartupMessages(library(strucchange)),setup,997e20,76
suppressPackageStartupMessages(library(optparse)),setup,997e20,76
"option_list <- list(make_option(c(""-b"", ""--breakpoints""), type = ""character""))",not sure,997e20,76
opt <- parse_args(OptionParser(option_list = option_list)),modeling,997e20,76
"dataSetOri <- read_excel(""SecondaryAnalysisData2018.03.25.xlsx"",     sheet = ""Data_prop_reporting_PA"")",import,316e20,1
dataSetOri <- as.data.frame(dataSetOri),data cleaning,316e20,1
dataSet <- dataSetOri,data cleaning,316e20,1
years <- dataSet$YearsStudied,data cleaning,316e20,1
medianYear <- as.numeric(years),data cleaning,316e20,1
"minYear <- unlist(strsplit(years[i], ""-""))[1]",data cleaning,316e20,1
"""-""))[2])))) {",data cleaning,316e20,1
"maxYear <- unlist(strsplit(years[i], ""-""))[2]",data cleaning,316e20,1
"if ((is.na(as.numeric(years)[i])) && (!is.na(as.numeric(unlist(strsplit(years[i],",data cleaning,316e20,1
medianYear[i] <- median(yearRange),data cleaning,316e20,1
yearRange <- (minYear:maxYear),data cleaning,316e20,1
for (i in 1:length(years)) {,data cleaning,316e20,1
},data cleaning,316e20,1
},data cleaning,316e20,1
dataSet$medianYear <- medianYear,data cleaning,316e20,1
args <- commandArgs(trailingOnly = TRUE),setup,368e20,77
idx <- as.numeric(args[1]),setup,368e20,77
print(idx),setup,368e20,77
"req <- c(""rstan"")",setup,368e20,77
"lapply(req, library, character.only = TRUE)",data cleaning,368e20,77
"library(""data.table"")",setup,502e20,1
"library(""dplyr"")",setup,502e20,1
"library(""jsonlite"")",setup,502e20,1
"library(""textcat"")",setup,502e20,1
"con <- file.path(""./data/all_participants_all_data_2002_2014_2.json"")",setup,502e20,1
data <- fromJSON(con),data cleaning,502e20,1
rm(req),data cleaning,368e20,77
mello_data <- as_data_frame(data),data cleaning,502e20,1
mello_data <- tbl_dt(mello_data),data cleaning,502e20,1
"mello_data[language == """" & lyrics != """", `:=`(language, textcat(lyrics))]",data cleaning,502e20,1
"mello_data[language == ""scots"", `:=`(language, ""english"")]",data cleaning,502e20,1
set.seed(3749),setup,368e20,77
mello_data <- tbl_df(mello_data),data cleaning,502e20,1
sessionInfo(),setup,368e20,77
"source(""analysis/lovecount.R"")",setup,502e20,1
"losers <- file.path(""data/losers.json"")",import,502e20,1
"load(""./data/d00_ci5.Rdta"")",import,368e20,77
"winners <- file.path(""data/winners.json"")",import,502e20,1
"wl <- bind_rows(fromJSON(losers) %>% mutate(winner = 0), fromJSON(winners) %>%     mutate(winner = 1))",data cleaning,502e20,1
library(ggbiplot),setup,502e20,1
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,682e20,78
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,682e20,78
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,682e20,78
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,682e20,78
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,682e20,78
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,682e20,78
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,682e20,78
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,682e20,78
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,682e20,78
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,682e20,78
rm(list = ls()),setup,682e20,78
siteSize = 2048,not sure,41e21,79
gc(),setup,682e20,78
set.seed(132),setup,682e20,78
ncores = 40,setup,682e20,78
"source(""bergan_cole_analysis.R"")",setup,682e20,78
"source(""bergan_tables.R"")",setup,682e20,78
"treatment = ""Copper""",setup,41e21,79
"source(""bergan_tables.R"")",setup,682e20,78
"strand = ""both""",setup,41e21,79
window.size = 300,visualization,41e21,79
numSam = 6,setup,41e21,79
library(knitr),setup,755e20,80
"setwd(""/home/ali/doc/code/IGT_net/analysis/script"")",setup,347e20,81
"source(""./igt_analysis.r"")",setup,347e20,81
"library(""abind"")",setup,347e20,81
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,41e21,79
"library(""dtw"")",setup,347e20,81
"igt_path <<- ""~/doc/ms/thesis/all_in_one/data/payam/""",setup,347e20,81
names(groups) = unlist(groups),not sure,347e20,81
"feature_ts_gr = lapply(groups, function(gr) {",not sure,347e20,81
dat = load_exec_data(igt_path),not sure,347e20,81
return(feature_ts_gr),not sure,347e20,81
"apply(subg, c(1, 2), function(x) {",not sure,347e20,81
"sub_exp_map = read.csv(paste(igt_path, group_fname, sep = ""/""))",not sure,347e20,81
sub_in_gr = which(sub_exp_map == gr),not sure,347e20,81
sub_names = rownames(sub_exp_map)[sub_in_gr],not sure,347e20,81
"groups = lapply(summary(sub_exp_map), function(x) {",not sure,347e20,81
},not sure,347e20,81
"group_fname = ""sub_exp_map""",not sure,347e20,81
}),not sure,347e20,81
feature_dat = read.csv(load_path),not sure,347e20,81
}),not sure,347e20,81
"bn_feature_visualizer <- function(load_path = ""/tmp/outcome.csv"") {",not sure,347e20,81
as.numeric(x),not sure,347e20,81
"subg = subset(feature_dat, id %in% sub_names)",not sure,347e20,81
"subg = subg[, !names(subg) %in% c(""id"")]",not sure,347e20,81
"unlist(strsplit(x, "":""))[1]",not sure,347e20,81
}),not sure,347e20,81
"layout(matrix(seq(3), nrow = 3))",not sure,347e20,81
run_bn_vis <- function() {,not sure,347e20,81
"colmeans_gr = lapply(groups, function(gr) {",not sure,347e20,81
"legend(""bottomleft"", colnames(agr), fill = 1:3)",not sure,347e20,81
}),not sure,347e20,81
dev.off(),not sure,347e20,81
print(f),not sure,347e20,81
"agr = abind(colmeans_gr, along = 2)",not sure,347e20,81
"features = c(""outcome"", ""gain"", ""loss"")",not sure,347e20,81
"png(""/tmp/bn.png"", width = 800, height = 1000)",not sure,347e20,81
colMeans(feature_ts_gr[[gr]]),not sure,347e20,81
f)),not sure,347e20,81
}),not sure,347e20,81
feature_ts_gr = bn_feature_visualizer(fn),not sure,347e20,81
"matplot(agr, type = ""l"", lwd = 4, ylab = sprintf(""%s Based Behavior Avg"",",not sure,347e20,81
par(cex = 1.2),not sure,347e20,81
"lapply(features, function(f) {",not sure,347e20,81
names(features) = features,not sure,347e20,81
"fn = sprintf(""%s%s.csv"", igt_path, f)",not sure,347e20,81
},not sure,347e20,81
"df_limesurvey <- df %>% select(c(A3, 1:7, 359:511))",data cleaning,727e20,10
data <- df %>% select(c(8:358)),data cleaning,727e20,10
names(df_limesurvey),exploratory,727e20,10
library(tidyverse),setup,855e20,82
mtcars %>% select(mpg),exploratory,855e20,82
"ggplot(mtcars, aes(mpg)) + geom_histogram()",exploratory,855e20,82
summarize_all(df_limesurvey),not sure,727e20,10
"df_limesurvey %>% summarize_at(vars(9:161), mean, na.rm = TRUE) %>%     data.frame()",exploratory,727e20,10
"sub_data <- data[, 9:161]",data cleaning,727e20,10
library(tidyverse),setup,162e20,83
mtcars %>% select(mpg),exploratory,162e20,83
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,162e20,83
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,162e20,83
library(tidyverse),visualization,162e20,83
library(tidyverse),setup,252e20,84
library(tidyverse),setup,8.5600000000000008e+22,85
mtcars %>% select(mpg),data cleaning,8.5600000000000008e+22,85
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,885e20,86
"aid_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_WorldBank/data/locations.csv"")",import,1.7299999999999999e+22,87
"aid_loc <- aid_loc[grepl(""Africa"", aid_loc$gazetteer_adm_name),     ]",import,1.7299999999999999e+22,87
library(tidyverse),setup,866e20,88
mtcars %>% select(mpg),data cleaning,866e20,88
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,866e20,88
"source(""https://bioconductor.org/biocLite.R"")",setup,885e20,86
"biocLite(""GenomicFeatures"")",setup,885e20,86
"biocLite(""GenomicRanges"")",setup,885e20,86
"aid_loc$longitude[i] <- aid_loc$longitude[i] + max(min(rnorm(1)/100,",modeling,1.7299999999999999e+22,87
"0.5), -0.5)",modeling,1.7299999999999999e+22,87
if (aid_loc$longitude[i]%%0.5 == 0) {,modeling,1.7299999999999999e+22,87
},modeling,1.7299999999999999e+22,87
"aid_loc$latitude[i] <- aid_loc$latitude[i] + max(min(rnorm(1)/100,",modeling,1.7299999999999999e+22,87
for (i in 1:nrow(aid_loc)) {,modeling,1.7299999999999999e+22,87
},modeling,1.7299999999999999e+22,87
},modeling,1.7299999999999999e+22,87
"0.5), -0.5)",modeling,1.7299999999999999e+22,87
if (aid_loc$latitude[i]%%0.5 == 0) {,modeling,1.7299999999999999e+22,87
rm(list = ls(all = TRUE)),setup,691e20,89
"biocLite(""SummarizedExperiment"")",exploratory,885e20,86
"aid_loc_China <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_China/locations.csv"",     sep = "";"")",export,1.7299999999999999e+22,87
"aid_loc_China$latitude <- as.numeric(gsub(""\\,"", ""."", aid_loc_China$latitude))",import,1.7299999999999999e+22,87
"aid_loc_China$longitude <- as.numeric(gsub(""\\,"", ""."", aid_loc_China$longitude))",data cleaning,1.7299999999999999e+22,87
aid_loc_China$latitude[i] <- aid_loc_China$latitude[i] +,data cleaning,1.7299999999999999e+22,87
for (i in 1:nrow(aid_loc_China)) {,data cleaning,1.7299999999999999e+22,87
aid_loc_China$longitude[i] <- aid_loc_China$longitude[i] +,data cleaning,1.7299999999999999e+22,87
"max(min(rnorm(1)/100, 0.5), -0.5)",data cleaning,1.7299999999999999e+22,87
},data cleaning,1.7299999999999999e+22,87
"max(min(rnorm(1)/100, 0.5), -0.5)",data cleaning,1.7299999999999999e+22,87
if (aid_loc_China$latitude[i]%%0.5 == 0) {,data cleaning,1.7299999999999999e+22,87
},data cleaning,1.7299999999999999e+22,87
},data cleaning,1.7299999999999999e+22,87
if (aid_loc_China$longitude[i]%%0.5 == 0) {,data cleaning,1.7299999999999999e+22,87
"base::source(""./scripts/graphing/graph-presets.R"")",setup,691e20,89
library(magrittr),exploratory,691e20,89
library(ggplot2),exploratory,691e20,89
"write.csv(aid_loc_China, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_China/locations_perturbed.csv"",     row.names = FALSE)",not sure,1.7299999999999999e+22,87
"write.csv(aid_loc_China, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_China/locations_perturbed.csv"",     row.names = FALSE)",export,1.7299999999999999e+22,87
"aid_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_WorldBank/data/locations.csv"")",not sure,1.7299999999999999e+22,87
library(magrittr),setup,112e20,13
library(ggplot2),setup,112e20,13
"aid_loc <- aid_loc[grepl(""Africa"", aid_loc$gazetteer_adm_name),     ]",import,1.7299999999999999e+22,87
"path_out <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis""",setup,112e20,13
"path_script <- ""/data/liucj/github/autophagy-in-cancer/analysis/23-gene-set-enrichment-analysis""",setup,112e20,13
"path_gmt <- file.path(path_out, ""GSEA-collections-gmt"")",import,112e20,13
for (i in 1:nrow(aid_loc)) {,exploratory,1.7299999999999999e+22,87
},exploratory,1.7299999999999999e+22,87
},exploratory,1.7299999999999999e+22,87
"0.5), -0.5)",exploratory,1.7299999999999999e+22,87
},exploratory,1.7299999999999999e+22,87
"aid_loc$latitude[i] <- aid_loc$latitude[i] + max(min(rnorm(1)/100,",exploratory,1.7299999999999999e+22,87
"0.5), -0.5)",exploratory,1.7299999999999999e+22,87
if (aid_loc$latitude[i]%%0.5 == 0) {,exploratory,1.7299999999999999e+22,87
if (aid_loc$longitude[i]%%0.5 == 0) {,exploratory,1.7299999999999999e+22,87
"aid_loc$longitude[i] <- aid_loc$longitude[i] + max(min(rnorm(1)/100,",exploratory,1.7299999999999999e+22,87
dir.create(path_gmt),setup,112e20,13
"rda_filename <- file.path(""/data/liucj/project/06-autophagy/20-rda"",     ""01-autophagy-and-hallmarks-expresson.rda"")",setup,112e20,13
load(file = rda_filename),import,112e20,13
library(tidyverse),setup,779e20,90
mtcars %>% select(mpg),modeling,779e20,90
siteSize = 2048,setup,188e20,91
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,918e20,92
numIND = 10,import,918e20,92
library(tidyverse),setup,602e19,93
mtcars %>% select(mpg),exploratory,602e19,93
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,602e19,93
rm(list = ls()),setup,736e20,94
"load(""~/Desktop/vote_analysis/read/analysis_data.Rdata"")",import,736e20,94
library(smacof),setup,736e20,94
"keep <- !indieners %in% c(""NOT KNOWN"", ""NOT APPLICABLE"", """")",data cleaning,736e20,94
"results <- results[keep, ]",data cleaning,736e20,94
indieners <- indieners[keep],data cleaning,736e20,94
vote.id <- vote.id[keep],data cleaning,736e20,94
dist.mat <- dist(t(results)),evaluation,736e20,94
"mds.sol <- mds(dist.mat, ndim = 2, type = ""mspline"")",modeling,736e20,94
mds.sol,evaluation,736e20,94
"plot(mds.sol, ""Shepard"")",visualization,736e20,94
"dir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs/WT_Adult_Male_v_Female_balanced/""",setup,285e20,95
"GTF <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/annotation/mm10_gencode_vM2_with_lncRNAs_and_LacZ.gtf""",setup,285e20,95
summary(mds.sol),evaluation,736e20,94
"party.points <- data.frame(party.name = colnames(results), mds.sol$conf)",not sure,736e20,94
"genome <- ""mm10""",setup,285e20,95
library(cummeRbund),setup,285e20,95
library(ggplot2),setup,736e20,94
"cuff <- readCufflinks(dir = dir, gtfFile = ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/annotation/mm10_gencode_vM2_with_lncRNAs_and_LacZ.gtf"",     genome = genome)",import,285e20,95
"sig <- getSig(cuff, alpha = 0.05)",data cleaning,285e20,95
"ggplot(data = party.points, aes(D1, D2, label = party.name)) +     geom_label(aes(fill = party.name), colour = ""white"", fontface = ""bold"")",communication,736e20,94
"ggsave(""political_spectrum.png"", device = ""png"")",export,736e20,94
rm(list = ls()),setup,534e20,96
rm(list = ls()),setup,5.2400000000000004e+22,97
"source(""0-useful.R"")",setup,5.2400000000000004e+22,97
"source(""0-helper.R"")",setup,5.2400000000000004e+22,97
"source(""0-find.transitions.R"")",setup,5.2400000000000004e+22,97
library(randomForest),setup,958e20,98
library(caret),setup,958e20,98
library(plotrix),setup,651e20,51
library(RColorBrewer),setup,651e20,51
"raw.data.path <- ""tracker_data/""",not sure,5.2400000000000004e+22,97
"root <- ""~/selection/counts/all""",setup,651e20,51
library(doMC),setup,958e20,98
"info.path <- ""info/""",not sure,5.2400000000000004e+22,97
"processed.data.path <- ""processed_data/""",not sure,5.2400000000000004e+22,97
library(mmadsenr),setup,958e20,98
"readmefile <- ""~/selection/analysis/series/figure2.readme""",setup,651e20,51
"out <- ""~/selection/analysis/series/""",setup,651e20,51
library(futile.logger),setup,958e20,98
ang <- 20,setup,651e20,51
"ylim <- c(0, 1)",setup,651e20,51
"vid.info <- read.csv(paste(info.path, ""VideoSegmentInfo.csv"",     sep = """"))",import,5.2400000000000004e+22,97
"turn.info <- read.csv(paste(info.path, ""TurnInfo.csv"", sep = """"))",import,5.2400000000000004e+22,97
"pp <- read.table(""~/selection/analysis/series/polypop_list.txt"",     as.is = TRUE)",import,651e20,51
"subject.info <- read.csv(paste(info.path, ""SubjectInfo.csv"",     sep = """"))",import,5.2400000000000004e+22,97
"pp[, 1] <- gsub(""_"", "" "", pp[, 1])",data cleaning,651e20,51
library(dplyr),data cleaning,958e20,98
"gap.info <- read.csv(paste(info.path, ""GapInfo.csv"", sep = """"))",import,5.2400000000000004e+22,97
"snpname <- ""rs12913832""",data cleaning,651e20,51
flip <- TRUE,setup,651e20,51
"outname <- ""herc2series.pdf""",setup,651e20,51
"data <- read.table(""~/selection/counts/all.reads.freq"", as.is = TRUE,     header = TRUE)",import,651e20,51
library(ggthemes),visualization,958e20,98
rm(list = ls()),setup,6.2799999999999996e+22,99
"freq <- data[, 6:NCOL(data)]",import,651e20,51
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,1.1900000000000001e+22,100
"data <- data[, 1:5]",import,651e20,51
"setwd(""~/Dropbox/Albert Xue/Research/Deployment/SHAPE-Seq_event_detector/"")",setup,6.2799999999999996e+22,99
"rownames(freq) <- data[, 1]",import,651e20,51
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,1.1900000000000001e+22,100
"uci <- read.table(""~/selection/counts/all.reads.highCI.freq"",     as.is = TRUE, header = TRUE)",import,651e20,51
"uci <- unlist(uci[uci[, 1] == snpname, 6:NCOL(uci)])",import,651e20,51
"lci <- read.table(""~/selection/counts/all.reads.lowCI.freq"",     as.is = TRUE, header = TRUE)",import,651e20,51
"lci <- unlist(lci[lci[, 1] == snpname, 6:NCOL(lci)])",import,651e20,51
"pops <- unique(pp[, 1])",import,651e20,51
"ff <- freq[snpname, ]",import,651e20,51
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""per-locus-only-classification.log"")",import,958e20,98
"source(""support_functions/ShapeSeq_events.R"")",import,6.2799999999999996e+22,99
"setwd(""/Users/t-rex-Box/Desktop/work/nba-predictor/"")",setup,1.1900000000000001e+22,100
if (flip) {,data cleaning,651e20,51
tmp1 <- 1 - uci,data cleaning,651e20,51
},data cleaning,651e20,51
lci <- tmp1,data cleaning,651e20,51
uci <- 1 - lci,data cleaning,651e20,51
ff <- 1 - ff,data cleaning,651e20,51
"pp$f <- unlist(ff[pp[, 2]])",data cleaning,651e20,51
"source(""support_functions/find_concurrent_events.R"")",import,6.2799999999999996e+22,99
"pp$lci <- unlist(lci[pp[, 2]])",data cleaning,651e20,51
"pp$uci <- unlist(uci[pp[, 2]])",data cleaning,651e20,51
"source(""analysis/util.R"")",import,1.1900000000000001e+22,100
"source(""support_functions/plotting/make_visual.R"")",import,6.2799999999999996e+22,99
"source(""support_functions/load_data.R"")",import,6.2799999999999996e+22,99
"source(""analysis/prepare_features.R"")",import,1.1900000000000001e+22,100
"cols <- brewer.pal(length(pops), ""Set1"")",visualization,651e20,51
"flog.appender(appender.file(log_file), name = ""cl"")",data cleaning,958e20,98
"cols[6] <- ""darkgrey""",visualization,651e20,51
"train.glm <- glm(ScoreDiff ~ Team1_win_last_6 + Team2_win_last_6 +     Team1_away_win_percentage_10 + Team2_away_win_percentage_10 +     Team1_avg_pnt_top_3_players_6 + Team2_avg_pnt_top_3_players_6,     data = train)",modeling,1.1900000000000001e+22,100
"data_mat = load_data(""example_data/other_data/F_subtract.txt"")",import,6.2799999999999996e+22,99
"pdf(paste0(out, outname), width = 12, height = 6)",export,651e20,51
summary(train.glm),exploratory,1.1900000000000001e+22,100
"plot(0, 0, col = ""white"", xlim = c(-8000, 0), ylim = ylim, bty = ""n"",     xlab = ""Years before present"", ylab = ""HERC2 allele frequency"", xaxt=""n"")",visualization,651e20,51
"event_locations1 = read.csv(""analysis/F_subtract/replicates/F_subtract_1.csv"")",import,6.2799999999999996e+22,99
"event_locations2 = read.csv(""analysis/F_subtract/replicates/F_subtract_2.csv"")",import,6.2799999999999996e+22,99
"event_locations3 = read.csv(""analysis/F_subtract/replicates/F_subtract_3.csv"")",import,6.2799999999999996e+22,99
"p.hats <- predict.glm(train.glm, newdata = test, type = ""response"")",modeling,1.1900000000000001e+22,100
clargs <- commandArgs(trailingOnly = TRUE),not sure,958e20,98
ln <- length(int.ends),exploratory,651e20,51
if (i == 3) {,exploratory,651e20,51
for (i in 1:length(pops)) {,exploratory,651e20,51
int.mids <- 0.5 * (int.starts + int.ends),exploratory,651e20,51
"lc[inc.dn], col = cols[i], lwd = 2)",exploratory,651e20,51
"uc <- pp[pp[, 1] == pop, ""uci""]",exploratory,651e20,51
"uc[inc.up], col = cols[i], lwd = 2)",exploratory,651e20,51
},exploratory,651e20,51
},exploratory,651e20,51
},exploratory,651e20,51
pop <- pops[i],exploratory,651e20,51
int.mids[1] <- int.mids[1] + 20,exploratory,651e20,51
"segments(-int.mids[inc.up], af[inc.up] + 0.02, -int.mids[inc.up],",exploratory,651e20,51
"af[2:ln], col = cols[i], lwd = 2)",exploratory,651e20,51
"rect(-int.starts, af - 0.02, -int.ends, af + 0.02, col = cols[i],",exploratory,651e20,51
inc.dn <- af > 0.02,exploratory,651e20,51
"lc <- pp[pp[, 1] == pop, ""lci""]",exploratory,651e20,51
"int.ends <- pp[pp[, 1] == pop, 4]",exploratory,651e20,51
"int.starts <- pp[pp[, 1] == pop, 3]",exploratory,651e20,51
if (ln > 1) {,exploratory,651e20,51
"segments(-int.ends[1:(ln - 1)], af[1:(ln - 1)], -int.starts[2:ln],",exploratory,651e20,51
},exploratory,651e20,51
"af <- pp[pp[, 1] == pop, ""f""]",exploratory,651e20,51
},exploratory,651e20,51
"density = 20, angle = ang * i, border = cols[i])",exploratory,651e20,51
inc.up <- af < 0.98,exploratory,651e20,51
if (sum(inc.up)) {,exploratory,651e20,51
if (sum(inc.dn)) {,exploratory,651e20,51
"segments(-int.mids[inc.dn], af[inc.dn] - 0.02, -int.mids[inc.dn],",exploratory,651e20,51
as.numeric(p.hats > 0),evaluation,1.1900000000000001e+22,100
"legend(""bottomright"", pops, col = cols, lwd = 2, bty = ""n"")",visualization,651e20,51
} else {,import,958e20,98
"filename = ""equifinality-3-population-data.rda"", args = clargs)",import,958e20,98
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",import,958e20,98
if (length(clargs) == 0) {,import,958e20,98
"filename = ""equifinality-3-sampled-data.rda"")",import,958e20,98
"filename = ""equifinality-3-sampled-data.rda"", args = clargs)",import,958e20,98
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
"filename = ""equifinality-3-ta-sampled-data.rda"")",import,958e20,98
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
"filename = ""equifinality-3-population-data.rda"")",import,958e20,98
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,958e20,98
},import,958e20,98
"axis(1, at = -seq(8, 0, -2) * 1000, labels = format(seq(8, 0,",visualization,651e20,51
"-2) * 1000, big.mark = "",""))",visualization,651e20,51
dev.off(),visualization,651e20,51
load(pop_data_file),import,958e20,98
i] %in% event_group)),setup,6.2799999999999996e+22,99
},setup,6.2799999999999996e+22,99
"get_event_group <- function(event_locations_temp, event_group) {",setup,6.2799999999999996e+22,99
"return(sapply(1:ncol(event_locations_temp), function(i) event_locations_temp[,",setup,6.2799999999999996e+22,99
load(sampled_data_file),import,958e20,98
"mean((p.hats > 0) == test$Result, na.rm = TRUE)",evaluation,1.1900000000000001e+22,100
load(ta_sampled_data_file),import,958e20,98
prts <- unique(vessel_landings$pcgroup),not sure,651e20,51
colnames(ports) <- tolower(colnames(ports)),not sure,651e20,51
port_df$m_delta <- port_df$m_post - port_df$m,not sure,651e20,51
"ic$m[i] <- modularity(g, membership(wtc))",not sure,651e20,51
"na.rm = T), lat = mean(lat, na.rm = T))",not sure,651e20,51
"source(""Analysis/new_analysis/participation_networks/participation_networks_fun.R"")",not sure,651e20,51
"port_list[[p]] <- participation_network(year_choose = 2009:2010,",not sure,651e20,51
"pcid_choose = prts[p], filter = TRUE, tickets = vessel_landings)",not sure,651e20,51
ic_post$m_post <- NA,not sure,651e20,51
},not sure,651e20,51
},not sure,651e20,51
ic_post$ld_post[i] = length(E(g))/length(V(g)),not sure,651e20,51
"2011, ""before"", ""after"")) %>% group_by(pcgroup, period) %>%",not sure,651e20,51
for (i in 1:length(port_list)) {,not sure,651e20,51
"port_df <- port_df[complete.cases(port_df), ]",not sure,651e20,51
"before), na.rm = T)) %>% rename(before.nves = before,",not sure,651e20,51
"period, drvid) %>% distinct() %>% group_by(pcgroup, period) %>%",not sure,651e20,51
"summarize(n.ves = length(drvid)) %>% spread(period, n.ves) %>%",not sure,651e20,51
after.nves = after),not sure,651e20,51
"stringsAsFactors = FALSE) %>% left_join(unique(vessel_landings[,",not sure,651e20,51
if (any(is.na(port_post))) {,not sure,651e20,51
},not sure,651e20,51
for (i in 1:length(port_post)) {,not sure,651e20,51
"ports <- read.csv(""processedData/spatial/ports/all_ports.csv"",",not sure,651e20,51
"wtc <- cluster_walktrap(g, weights = E(g)$weight)",not sure,651e20,51
library(tidyr),not sure,651e20,51
library(igraph),not sure,651e20,51
library(dplyr),not sure,651e20,51
g <- port_list[[i]],not sure,651e20,51
calc_port_df <- function() {,not sure,651e20,51
port_list <- port_list[-which(is.na(port_list))],not sure,651e20,51
ic$ld <- NA,not sure,651e20,51
"ic_post <- data.frame(pcgroup = names(port_post), stringsAsFactors = FALSE)",not sure,651e20,51
"group_by(pcgroup) %>% mutate(overall_nves = mean(c(after,",not sure,651e20,51
rev.ves = vessel_landings %>% mutate(period = ifelse(year <,not sure,651e20,51
"port_post[[p]] <- participation_network(year_choose = 2012:2013,",not sure,651e20,51
"summarize(revenue = sum(adj_revenue, na.rm = T)) %>%",not sure,651e20,51
names(port_list) <- prts,not sure,651e20,51
ic$m <- NA,not sure,651e20,51
"pcid_choose = prts[p], filter = TRUE, tickets = vessel_landings)",not sure,651e20,51
port_post <- port_post[-which(is.na(port_post))],not sure,651e20,51
ic_post$ld_post <- NA,not sure,651e20,51
for (p in 1:length(prts)) {,not sure,651e20,51
"2011, ""before"", ""after"")) %>% dplyr::select(pcgroup,",not sure,651e20,51
library(reshape2),not sure,651e20,51
},not sure,651e20,51
"vessel_landings <- readRDS(""Analysis/new_analysis/catch_shares/Analysis/vessel_landings_data.RDS"")",not sure,651e20,51
for (p in 1:length(prts)) {,not sure,651e20,51
"wtc <- cluster_walktrap(g, weights = E(g)$weight)",not sure,651e20,51
names(port_post) <- prts,not sure,651e20,51
},not sure,651e20,51
port_df$ld_delta <- port_df$ld_post - port_df$ld,not sure,651e20,51
"c(""pcid"", ""pcgroup"")]), by = c(Pcid = ""pcid""))",not sure,651e20,51
"ports <- ports %>% group_by(pcgroup, state) %>% summarize(lon = mean(lon,",not sure,651e20,51
if (any(is.na(port_list))) {,not sure,651e20,51
},not sure,651e20,51
g <- port_post[[i]],not sure,651e20,51
n.ves = vessel_landings %>% mutate(period = ifelse(year <,not sure,651e20,51
port_list <- list(),not sure,651e20,51
"ic <- data.frame(pcgroup = names(port_list), stringsAsFactors = FALSE)",not sure,651e20,51
ic$ld[i] = length(E(g))/length(V(g)),not sure,651e20,51
port_post <- list(),not sure,651e20,51
"ic_post$m_post[i] <- modularity(g, membership(wtc))",not sure,651e20,51
"port_df <- full_join(ic, ic_post)",not sure,651e20,51
left_join(lbs.ves) %>% left_join(trips.ves) %>% left_join(ports),not sure,651e20,51
"lbs) %>% group_by(pcgroup) %>% mutate(overall_lbs = mean(c(after,",not sure,651e20,51
twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & twl_partip$itq_post ==,not sure,651e20,51
twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & twl_partip$itq_post ==,not sure,651e20,51
"0)] = ""general landing entrant""",not sure,651e20,51
"quota_post = vessel_landings %>% dplyr::select(trip_id, pcgroup,",not sure,651e20,51
after.lbs = after),not sure,651e20,51
"spread(period, revenue) %>% group_by(pcgroup) %>% mutate(overall_rev = mean(c(after,",not sure,651e20,51
"period, trip_id) %>% distinct() %>% group_by(pcgroup,",not sure,651e20,51
group_by(pcgroup) %>% summarize(itq_post = ifelse(any(fleet ==,not sure,651e20,51
"spread(period, ntrips) %>% group_by(pcgroup) %>% mutate(overall_trips = mean(c(after,",not sure,651e20,51
after.rev = after),not sure,651e20,51
port_stats <- port_df %>% left_join(n.ves) %>% left_join(rev.ves) %>%,not sure,651e20,51
return(port_df),not sure,651e20,51
trips.ves = vessel_landings %>% mutate(period = ifelse(year <,not sure,651e20,51
"2011, ""before"", ""after"")) %>% dplyr::select(pcgroup,",not sure,651e20,51
"1)] = ""itq entrant""",not sure,651e20,51
"fleet, year) %>% distinct() %>% filter(year > 2011) %>%",not sure,651e20,51
"0)] = ""LE gf exit, still landings""",not sure,651e20,51
"2011, ""before"", ""after"")) %>% group_by(pcgroup, period) %>%",not sure,651e20,51
"before), na.rm = T)) %>% rename(before.lbs = before,",not sure,651e20,51
group_by(pcgroup) %>% summarize(twl_prior = ifelse(any(metier.2010 %in%,not sure,651e20,51
"twl_partip = full_join(twl_prior, quota_post)",not sure,651e20,51
twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & twl_partip$itq_post ==,not sure,651e20,51
twl_partip$ifq_flag = NA,not sure,651e20,51
"twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & is.na(twl_partip$itq_post))] = ""LE gf total exit""",not sure,651e20,51
twl_partip$ifq_flag[which(is.na(twl_partip$twl_prior) & twl_partip$itq_post ==,not sure,651e20,51
port_df <- port_stats %>% left_join(twl_partip),not sure,651e20,51
period) %>% summarize(ntrips = length(unique(trip_id))) %>%,not sure,651e20,51
"c(""TWL_1"", ""TWL_5"", ""TWL_7"", ""TWL_8"", ""TWL_9"", ""TWL_10"",",not sure,651e20,51
"1)] = ""itq entrant: general landings""",not sure,651e20,51
twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & twl_partip$itq_post ==,not sure,651e20,51
"saveRDS(port_list, file = ""Analysis/new_analysis/catch_shares/Analysis/port_pre2011_networks.RDS"")",not sure,651e20,51
"twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & is.na(twl_partip$itq_post))] = ""unaffected exit""",not sure,651e20,51
after.trips = after),not sure,651e20,51
"1)] = ""itq stay on""",not sure,651e20,51
"saveRDS(port_df, file = ""Analysis/new_analysis/catch_shares/Analysis/port_stats.RDS"")",not sure,651e20,51
"before), na.rm = T)) %>% rename(before.trips = before,",not sure,651e20,51
"twl_partip <- dplyr::select(twl_partip, pcgroup, ifq_flag)",not sure,651e20,51
"twl_prior = vessel_landings %>% dplyr::select(trip_id, pcgroup,",not sure,651e20,51
"""LE""), 1, 0))",not sure,651e20,51
"0)] = ""unaffected""",not sure,651e20,51
"saveRDS(port_post, file = ""Analysis/new_analysis/catch_shares/Analysis/port_post2011_networks.RDS"")",not sure,651e20,51
"before), na.rm = T)) %>% rename(before.rev = before,",not sure,651e20,51
"""TWL_11"", ""TWL_12"", ""TWL_13"")), 1, 0))",not sure,651e20,51
lbs.ves = vessel_landings %>% mutate(period = ifelse(year <,not sure,651e20,51
"summarize(lbs = sum(pounds, na.rm = T)) %>% spread(period,",not sure,651e20,51
"metier.2010, year) %>% distinct() %>% filter(year < 2011) %>%",not sure,651e20,51
twl_partip$ifq_flag[which(is.na(twl_partip$twl_prior) & twl_partip$itq_post ==,not sure,651e20,51
},not sure,651e20,51
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",import,958e20,98
"flog.info(""Loaded data file: %s"", sampled_data_file, name = ""cl"")",import,958e20,98
library(gplots),setup,651e20,51
},setup,651e20,51
"if (!require(""gplots"")) {",setup,651e20,51
"install.packages(""gplots"", dependencies = TRUE)",setup,651e20,51
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",import,958e20,98
"install.packages(""RColorBrewer"", dependencies = TRUE)",setup,651e20,51
"if (!require(""RColorBrewer"")) {",setup,651e20,51
library(RColorBrewer),setup,651e20,51
},setup,651e20,51
"flog.info(""Beginning classification analysis of equifinality-3 data sets for per-locus only predictors"",     name = ""cl"")",import,958e20,98
"install.packages(""cluster"", dependencies = TRUE)",setup,651e20,51
"if (!require(""cluster"")) {",setup,651e20,51
},setup,651e20,51
library(cluster),setup,651e20,51
"if (!require(""tidyverse"")) {",setup,651e20,51
library(tidyverse),setup,651e20,51
},setup,651e20,51
"install.packages(""tidyverse"", dependencies = TRUE)",setup,651e20,51
"source(""./analysis/wood_density_distribution/organisation.R"")",import,982e20,101
library(reshape2),setup,651e20,51
},setup,651e20,51
"if (!require(""reshape2"")) {",setup,651e20,51
"install.packages(""reshape2"", dependencies = TRUE)",setup,651e20,51
"source(""./packages.R"")",not sure,982e20,101
"d897 <- read.csv(""analysis/clustering/kmeans/data/897_motor_nms.csv"",     comment.char = ""#"")",import,651e20,51
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,958e20,98
"source(""./analysis/wood_density_distribution/function_index.R"")",not sure,982e20,101
d897_nms_domains9 = d897[68:76],import,651e20,51
"ggplot(wood_density_data_178ha, aes(x = d, y = e)) + geom_point(aes(color = fd)) +     stat_smooth(method = lm) + theme_bw()",visualization,982e20,101
"model1 <- lm(e ~ d, data = wood_density_data_178ha)",modeling,982e20,101
"flog.info(""Number of cores used in analysis: %s"", num_cores,     name = ""cl"")",communication,958e20,98
"plot(model1, which = 1)",visualization,982e20,101
"kmeans_nms_domains_models = vector(""list"", 11)",setup,651e20,51
"save(model2, file = ""./analysis/wood_density_distribution/models/lm_models/model1.R"")",export,982e20,101
},exploratory,651e20,51
"kmeans_nms_domains_models[[i]] = kmeans(x = d897_nms_domains9,",exploratory,651e20,51
for (i in 1:length(kmeans_nms_domains_models)) {,exploratory,651e20,51
"centers = i + 1, iter.max = 30, nstart = 20)",exploratory,651e20,51
registerDoMC(cores = num_cores),setup,958e20,98
"filtered_d897_nms_domains = d897[c(68:76, 3:7, 82, 33, 81)]",exploratory,651e20,51
"model2 <- gls(e ~ d, data = wood_density_data_178ha, weights = varIdent(form = ~1 |     fd))",modeling,982e20,101
"filtered_d897_nms_domains_withClusters = vector(""list"", 11)",exploratory,651e20,51
summary(model2),evaluation,982e20,101
plot(model2),visualization,982e20,101
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (1:10) *",modeling,958e20,98
"25, .shrinkage = 0.05)",modeling,958e20,98
filtered_d897_nms_domains_withClusters[[i]] = kmeans_nms_domains_models[[i]]$cluster,exploratory,651e20,51
},exploratory,651e20,51
for (i in 1:length(filtered_d897_nms_domains_withClusters)) {,exploratory,651e20,51
"save(model2, file = ""./analysis/wood_density_distribution/models/gls_models/model2.R"")",export,982e20,101
"nms_heatmaps = vector(""list"", 11)",exploratory,651e20,51
"load(""./analysis/wood_density_distribution/bootstrapped/coef_CI_gls_wooddensity_VS_elevation.R"")",import,982e20,101
"lapply(1:NCOL(only_nms_domains_centers_data), function(i) only_nms_domains_centers_data[,",exploratory,651e20,51
"nms_heatmaps[[i]] = ggplot(data = melted_heat_map_data, aes(x = Clusters,",exploratory,651e20,51
"high = ""red"")",exploratory,651e20,51
"value = ""value"")",exploratory,651e20,51
only_nms_domains_centers_data = kmeans_nms_domains_models[[i]]$centers,exploratory,651e20,51
rownames(ordered_heat_map_data) = 1:nrow(ordered_heat_map_data),exploratory,651e20,51
for (i in 1:length(kmeans_nms_domains_models)) {,exploratory,651e20,51
"geom_text(aes(label = round(value, 1))) + scale_fill_gradient(low = ""white"",",exploratory,651e20,51
"names(melted_heat_map_data) = c(Var1 = ""Clusters"", Var2 = ""NMS_domains"",",exploratory,651e20,51
"i])), ]",exploratory,651e20,51
},exploratory,651e20,51
"ordered_heat_map_data = only_nms_domains_centers_data[do.call(order,",exploratory,651e20,51
melted_heat_map_data = melt(ordered_heat_map_data),exploratory,651e20,51
"y = NMS_domains, fill = value)) + geom_tile(aes(fill = value)) +",exploratory,651e20,51
coef_CI,evaluation,982e20,101
"training_control <- trainControl(method = ""repeatedcv"", number = 10,     repeats = 5)",data cleaning,958e20,98
"booter(model2, data = wood_density_data_178ha, )",not sure,982e20,101
seed_value <- 58132133,setup,958e20,98
"if (!require(""gplots"")) {",setup,651e20,51
},setup,651e20,51
library(gplots),setup,651e20,51
"install.packages(""gplots"", dependencies = TRUE)",setup,651e20,51
set.seed(seed_value),setup,958e20,98
"sap_dden_data <- read.csv(""./data/wood_density_saplings .csv"")",import,651e20,51
"seedling_data <- read.table(""./data/data.txt"", header = TRUE)",import,651e20,51
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,     name = ""cl"")",communication,958e20,98
training_set_fraction <- 0.8,modeling,958e20,98
head(seedling_data),exploratory,651e20,51
"data <- data.frame(sap_dden = with(sap_dden_data, tapply(bottom_density,     mean)), rr = riskratio$diff_mort, elev = riskratio$elev,     Sp, mean)), adult_dden = with(riskratio, tapply(dden, sp,     sp = levels(as.factor(seedling_data$sp)))",data cleaning,651e20,51
"summary(lm(sap_dden ~ adult_dden, data))",exploratory,651e20,51
"ggplot(data, aes(x = log(sap_dden), y = log(adult_dden))) + geom_point() +     geom_abline(intercept = 0, slope = 1) + geom_text(aes(label = sp))",visualization,651e20,51
"geom_abline(intercept = 0, slope = 1) + geom_text(aes(label = sp))",visualization,651e20,51
"model <- (lm(log(rr) ~ log(sap_dden), data))",modeling,651e20,51
"source(""./functions/booter.R"")",setup,651e20,51
"booter(model, coef = TRUE, n = 5000, data = data)",modeling,651e20,51
"write.table(data, file = ""./analysis/inundation_wooddensity_relationship/data/data_sap_adult_rr_density.txt"")",export,651e20,51
test_set_fraction <- 1 - training_set_fraction,data cleaning,958e20,98
"experiment_names <- c(""Per-Locus Population Census"", ""Per-Locus Sampled 10%"",     ""Per-Locus Sampled 20%"")",data cleaning,958e20,98
perlocus_results <- data.frame(),not sure,958e20,98
perlocus_results_roc <- NULL,not sure,958e20,98
perlocus_results_model <- NULL,not sure,958e20,98
perlocus_results_cm <- NULL,not sure,958e20,98
"flog.info(""Starting analysis of population data without per-locus values only"",     name = ""cl"")",import,958e20,98
i <- 1,setup,958e20,98
exp_name <- experiment_names[i],setup,958e20,98
"eq3_pop_df$two_class_label <- factor(ifelse(eq3_pop_df$model_class_label ==     ""allneutral"", ""neutral"", ""biased""))",data cleaning,958e20,98
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",     ""innovation_rate"", ""configuration_slatkin"", ""num_trait_configurations"")",data cleaning,958e20,98
"model <- train_gbm_classifier(eq3_pop_df, training_set_fraction,     ""two_class_label"", gbm_grid, training_control, exclude_columns,     verbose = FALSE)",modeling,958e20,98
"perlocus_results_model[[""perlocus_pop""]] <- model$tunedmodel",modeling,958e20,98
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,958e20,98
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",modeling,958e20,98
results <- get_parsed_binary_confusion_matrix_stats(cm),evaluation,958e20,98
results$experiments <- exp_name,data cleaning,958e20,98
results$elapsed <- model$elapsed,evaluation,958e20,98
"perlocus_results_cm[[""perlocus_pop""]] <- cm",evaluation,958e20,98
results$sample_size <- 0,evaluation,958e20,98
results$ta_duration <- 0,evaluation,958e20,98
"perlocus_pop_roc <- calculate_roc_binary_classifier(model$tunedmodel,     model$test_data, ""two_class_label"", exp_name)",evaluation,958e20,98
"setwd(""/Users/caryn/Box Sync/Projects/GOmaize/"")",setup,681e20,102
results$auc <- unlist(perlocus_pop_roc$auc@y.values),data cleaning,958e20,98
library(dplyr),import,681e20,102
library(topGO),import,681e20,102
"perlocus_results_roc[[""perlocus_pop""]] <- perlocus_pop_roc",data cleaning,958e20,98
"perlocus_results <- rbind(perlocus_results, results)",data cleaning,958e20,98
"genesv3 <- readRDS(""analysis/BSFG_12092017/modules_09122017.rds"")",import,681e20,102
"flog.info(""Starting analysis of sampled data without per-locus values only"",     name = ""cl"")",evaluation,958e20,98
i <- 2,setup,958e20,98
exp_name <- experiment_names[i],setup,958e20,98
"Ngenes <- n_distinct(genesv3[, 1])",data cleaning,681e20,102
"eq3_sampled_10 <- dplyr::filter(eq3_sampled_df, sample_size ==     10)",evaluation,958e20,98
"eq3_sampled_10$two_class_label <- factor(ifelse(eq3_sampled_10$model_class_label ==     ""allneutral"", ""neutral"", ""biased""))",data cleaning,958e20,98
"maize.db <- read.table(""db/maize.agrigo.f.db"", sep = ""\t"", header = F)",import,681e20,102
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"")",data cleaning,958e20,98
"model <- train_gbm_classifier(eq3_sampled_10, training_set_fraction,     verbose = FALSE)",modeling,958e20,98
"agrigo <- read.table(""db/maize_v3.agrigo.f.db"", header = F, sep = ""\t"")",import,681e20,102
"argot <- read.table(""db/maize_v3.argot2.f.db"", header = F, sep = ""\t"")",import,681e20,102
"analysisDir <- ""BSFG_12092017""",setup,681e20,102
"perlocus_results_model[[""perlocus_sampled_10""]] <- model$tunedmodel",evaluation,958e20,98
"genes.in.db <- maize.db[maize.db$V1 %in% genesv3$genes, ]",data cleaning,681e20,102
n.genes.in.db <- n_distinct(genes.in.db$V1),data cleaning,681e20,102
percent_N_go_analysis <- n.genes.in.db/Ngenes,modeling,681e20,102
"maize.gene2GO <- readMappings(file = ""db/maize.agrigo.all.f.db"")",import,681e20,102
"agrigo.gene2GO <- readMappings(file = ""db/maize_v3.agrigo.f.db"")",import,681e20,102
"argot.gene2GO <- readMappings(file = ""db/maize_v3.argot2.f.db"")",import,681e20,102
return((thresh < -0.2) | (thresh > 0.2)),modeling,681e20,102
},modeling,681e20,102
goi <- function(thresh) {,modeling,681e20,102
n_modules <- n_distinct(genesv3$factor),data cleaning,681e20,102
module_GO_1 <- list(),not sure,681e20,102
mlist <- list(),not sure,681e20,102
names(geneList) <- maize.db.m$V1,not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
"lostGenes <- maize.db.m[is.na(maize.db.m$V2), ]",not sure,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",not sure,681e20,102
"result_fisher <- runTest(GOdata_BP, algorithm = ""classic"",",not sure,681e20,102
module_GO_1[[m]] <- mlist,not sure,681e20,102
maize.db.m[is.na(maize.db.m)] <- 0,not sure,681e20,102
"result_KS_elim <- runTest(GOdata_MF, algorithm = ""elim"",",not sure,681e20,102
"result_KS_elim <- runTest(GOdata_BP, algorithm = ""elim"",",not sure,681e20,102
},not sure,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",not sure,681e20,102
"result_KS_classic <- runTest(GOdata_MF, algorithm = ""classic"",",not sure,681e20,102
"allRes_MF <- GenTable(GOdata_MF, classicFisher = result_fisher,",not sure,681e20,102
topNodes = 100),not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
geneList <- maize.db.m$value,not sure,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",not sure,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",not sure,681e20,102
"mlist <- list(genes, lostGenes, maize.db.m, geneList, GOdata_MF,",not sure,681e20,102
for (m in 1:n_modules) {,not sure,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",not sure,681e20,102
"maize.db.m <- maize.db.m[!is.na(maize.db.m$V2), ]",not sure,681e20,102
"GOdata_BP <- new(""topGOdata"", ontology = ""BP"", allGenes = geneList,",not sure,681e20,102
"maize.db.m <- full_join(maize.db, genes, by = c(V1 = ""genes""))",not sure,681e20,102
"genes <- filter(genesv3, factor == m)",not sure,681e20,102
"result_fisher <- runTest(GOdata_MF, algorithm = ""classic"",",not sure,681e20,102
"statistic = ""fisher"")",not sure,681e20,102
"allRes_BP <- GenTable(GOdata_BP, classicFisher = result_fisher,",not sure,681e20,102
gene2GO = maize.gene2GO),not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
gene2GO = maize.gene2GO),not sure,681e20,102
"GOdata_MF <- new(""topGOdata"", ontology = ""MF"", allGenes = geneList,",not sure,681e20,102
"statistic = ""fisher"")",not sure,681e20,102
"result_KS_classic <- runTest(GOdata_BP, algorithm = ""classic"",",not sure,681e20,102
topNodes = 100),not sure,681e20,102
"allRes_MF, GOdata_BP, allRes_BP)",not sure,681e20,102
module_GO_2 <- list(),data cleaning,681e20,102
"allRes_MF <- GenTable(GOdata_MF, classicFisher = result_fisher,",modeling,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",modeling,681e20,102
geneList <- agrigo.m$value,modeling,681e20,102
"GOdata_MF <- new(""topGOdata"", ontology = ""MF"", allGenes = geneList,",modeling,681e20,102
"statistic = ""ks"")",modeling,681e20,102
"result_KS_elim <- runTest(GOdata_MF, algorithm = ""elim"",",modeling,681e20,102
"statistic = ""ks"")",modeling,681e20,102
topNodes = 100),modeling,681e20,102
gene2GO = maize.gene2GO),modeling,681e20,102
"statistic = ""fisher"")",modeling,681e20,102
for (m in 1:n_modules) {,modeling,681e20,102
mlist <- list(),modeling,681e20,102
gene2GO = maize.gene2GO),modeling,681e20,102
"lostGenes <- agrigo.m[is.na(agrigo.m$V2), ]",modeling,681e20,102
"result_KS_classic <- runTest(GOdata_BP, algorithm = ""classic"",",modeling,681e20,102
module_GO_2[[m]] <- mlist,modeling,681e20,102
"genes <- filter(genesv3, factor == m)",modeling,681e20,102
"agrigo.m <- agrigo.m[!is.na(agrigo.m$V2), ]",modeling,681e20,102
"result_fisher <- runTest(GOdata_MF, algorithm = ""classic"",",modeling,681e20,102
"result_KS_classic <- runTest(GOdata_MF, algorithm = ""classic"",",modeling,681e20,102
"result_KS_elim <- runTest(GOdata_BP, algorithm = ""elim"",",modeling,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",modeling,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",modeling,681e20,102
names(geneList) <- agrigo.m$V1,modeling,681e20,102
"allRes_BP <- GenTable(GOdata_BP, classicFisher = result_fisher,",modeling,681e20,102
},modeling,681e20,102
"statistic = ""fisher"")",modeling,681e20,102
topNodes = 100),modeling,681e20,102
"result_fisher <- runTest(GOdata_BP, algorithm = ""classic"",",modeling,681e20,102
"agrigo.m <- full_join(agrigo, genes, by = c(V1 = ""genes""))",modeling,681e20,102
"GOdata_BP <- new(""topGOdata"", ontology = ""BP"", allGenes = geneList,",modeling,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",modeling,681e20,102
"mlist <- list(genes, lostGenes, agrigo.m, geneList, GOdata_MF,",modeling,681e20,102
"statistic = ""ks"")",modeling,681e20,102
agrigo.m[is.na(agrigo.m)] <- 0,modeling,681e20,102
"statistic = ""ks"")",modeling,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",modeling,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",modeling,681e20,102
"allRes_MF, GOdata_BP, allRes_BP)",modeling,681e20,102
module_GO_1 <- list(),data cleaning,681e20,102
"GOdata_MF <- new(""topGOdata"", ontology = ""MF"", allGenes = geneList,",not sure,681e20,102
geneList <- maize.db.m$value,not sure,681e20,102
"maize.db.m <- full_join(maize.db, genes, by = c(V1 = ""genes""))",not sure,681e20,102
gene2GO = maize.gene2GO),not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
"result_fisher <- runTest(GOdata_BP, algorithm = ""classic"",",not sure,681e20,102
mlist <- list(),not sure,681e20,102
},not sure,681e20,102
for (m in 1:n_modules) {,not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
module_GO_1[[m]] <- mlist,not sure,681e20,102
"allRes_MF <- GenTable(GOdata_MF, classicFisher = result_fisher,",not sure,681e20,102
"genes <- filter(genesv3, factor == m)",not sure,681e20,102
"result_fisher <- runTest(GOdata_MF, algorithm = ""classic"",",not sure,681e20,102
names(geneList) <- maize.db.m$V1,not sure,681e20,102
"lostGenes <- maize.db.m[is.na(maize.db.m$V2), ]",not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",not sure,681e20,102
gene2GO = maize.gene2GO),not sure,681e20,102
"statistic = ""fisher"")",not sure,681e20,102
"result_KS_classic <- runTest(GOdata_MF, algorithm = ""classic"",",not sure,681e20,102
"result_KS_classic <- runTest(GOdata_BP, algorithm = ""classic"",",not sure,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",not sure,681e20,102
topNodes = 100),not sure,681e20,102
"allRes_BP <- GenTable(GOdata_BP, classicFisher = result_fisher,",not sure,681e20,102
"classicKS = result_KS_classic, elimKS = result_KS_elim,",not sure,681e20,102
maize.db.m[is.na(maize.db.m)] <- 0,not sure,681e20,102
"statistic = ""fisher"")",not sure,681e20,102
"maize.db.m <- maize.db.m[!is.na(maize.db.m$V2), ]",not sure,681e20,102
"GOdata_BP <- new(""topGOdata"", ontology = ""BP"", allGenes = geneList,",not sure,681e20,102
"result_KS_elim <- runTest(GOdata_BP, algorithm = ""elim"",",not sure,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",not sure,681e20,102
topNodes = 100),not sure,681e20,102
"allRes_MF, GOdata_BP, allRes_BP)",not sure,681e20,102
"statistic = ""ks"")",not sure,681e20,102
"result_KS_elim <- runTest(GOdata_MF, algorithm = ""elim"",",not sure,681e20,102
"geneSel = goi, nodeSize = 5, annotationFun = annFUN.gene2GO,",not sure,681e20,102
"mlist <- list(genes, lostGenes, maize.db.m, geneList, GOdata_MF,",not sure,681e20,102
"orderBy = ""classicFisher"", ranksOf = ""classicFisher"",",not sure,681e20,102
"save(module_GO, file = paste(paste(""analysis/"", analysisDir,     sep = """"), paste(analysisDir, "".RData"", sep = """"), sep = ""/""))",export,681e20,102
"sep = """"), paste(analysisDir, "".RData"", sep = """"), sep = ""/""))",export,681e20,102
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,289e19,103
library(mmadsenr),import,289e19,103
library(caret),import,289e19,103
library(doMC),import,289e19,103
library(futile.logger),import,289e19,103
library(dplyr),import,289e19,103
library(ggthemes),import,289e19,103
ptm <- proc.time(),not sure,289e19,103
"gbm_grid <- expand.grid(interaction.depth = (1:6) * 2, n.trees = (2:10) *     50, shrinkage = 0.05, n.minobsinnode = 10)",visualization,289e19,103
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,4.9999999999999996e+22,104
"setwd(""/Users/t-rex-Box/Desktop/work/nba-predictor/"")",setup,965e20,105
"source(""analysis/util.R"")",setup,965e20,105
"source(""analysis/prepare_features.R"")",data cleaning,965e20,105
train.glm <- glm(ScoreDiff ~ Team1_win_last_6 + Team2_win_last_6 +     Team1_away_win_percentage_10 + Team2_away_win_percentage_10 +     data = train),modeling,965e20,105
data = train),modeling,965e20,105
summary(train.glm),visualization,965e20,105
"p.hats <- predict.glm(train.glm, newdata = test, type = ""response"")",modeling,965e20,105
as.numeric(p.hats > 0),evaluation,965e20,105
"mean((p.hats > 0) == test$Result, na.rm = TRUE)",evaluation,965e20,105
library(dplyr),setup,965e20,105
library(viridis),setup,965e20,105
library(ggplot2),setup,965e20,105
library(reshape2),setup,965e20,105
library(cowplot),setup,965e20,105
library(ogbox),setup,965e20,105
library(homologene),setup,965e20,105
library(scales),setup,965e20,105
library(gplots),setup,965e20,105
library(stringr),setup,965e20,105
library(magrittr),setup,965e20,105
library(pheatmap),setup,965e20,105
"source(""R/cellColors.R"")",setup,965e20,105
"source(""R/puristOut.R"")",setup,965e20,105
"source(""R/heatmap.3.R"")",setup,965e20,105
"source(""R/regionize.R"")",setup,965e20,105
"root = ""~/ANALYSIS""",setup,154e20,106
d_threshold = 0.8,evaluation,154e20,106
"Plot_title = ""Perseids (EDMOND dataset: 2001 to 2015)""",visualization,154e20,106
Binsize = 0.002,visualization,154e20,106
"order = read.design(""data/meltedDesign.tsv"") %>% arrange(MajorType,     Neurotransmitter1, PyramidalDeep) %>% filter(!is.na(PyramidalDeep)) %>%     .$PyramidalDeep %>% unique",not sure,965e20,105
"D_Type = ""DD""",visualization,154e20,106
options(stringsAsFactors = FALSE),setup,407e20,107
"source(""./R/FunctionsForRWLAnalysis.R"")",setup,407e20,107
"analysis_opts <- yaml.load_file(""./analysis_options.yaml"")",import,407e20,107
"list[geneDat, exp] = read.exp(""data/finalExp.csv"") %>% sepExpr",import,965e20,105
"design = read.design(""data/meltedDesign.tsv"")",import,965e20,105
bin_width <- analysis_opts$bin_width,setup,407e20,107
"dpylrFriendly = cbind(design, t(exp))",setup,965e20,105
"dpylrFriendly %<>% arrange(MajorType, Neurotransmitter1, PyramidalDeep) %>%     filter(!is.na(PyramidalDeep))",setup,965e20,105
"regionSamples = regionize(design = dpylrFriendly, regionNames = ""Region"",     groupNames = ""PyramidalDeep"")",not sure,965e20,105
"regionSamples = c(regionSamples, list(All = dpylrFriendly$PyramidalDeep))",not sure,965e20,105
"names(regionSamples) = gsub(""_.*"", """", names(regionSamples))",data cleaning,965e20,105
"list[design, exp] = dpylrFriendly %>% sepExpr",setup,965e20,105
colors = cellColors(),setup,965e20,105
"dir.create(""analysis/09.Plots/GenePlots"")",export,965e20,105
library(tsensembler),setup,17e21,108
library(ggplot2),exploratory,17e21,108
"source(""sources/src-analysis-plots.R"")",exploratory,17e21,108
"x[!grepl(""\\|"", x)]",export,965e20,105
for (i in 1:len(regionSamples)) {,export,965e20,105
genes = genes[regionSamples[[i]] %>% unique %>% trimNAs],export,965e20,105
"relExp = apply(relExp, 2, scale01)",export,965e20,105
"heatCols = toColor(design$PyramidalDeep[!is.na(regionSamples[[i]])],",export,965e20,105
rownames(anotRow) = rownames(t(relExp)),export,965e20,105
"annotation_colors = list(Samples = heatCols$palette,",export,965e20,105
"genes = puristOut(paste0(""analysis/01.Gene Selection/FinalGenes/PyramidalDeep/"",",export,965e20,105
rownames(anotCol) = colnames(t(relExp)),export,965e20,105
"anotRow = data.frame(`Specific Genes` = geneCellTypes, check.names = F)",export,965e20,105
"show_colnames = FALSE, annotation_col = anotCol, annotation_row = anotRow,",export,965e20,105
"png(paste0(""analysis/09.Plots/GenePlots/"", names(regionSamples)[i],",export,965e20,105
"relGene = geneDat[match(unlist(genes), geneDat$Gene.Symbol),",export,965e20,105
"relExp = exp[!is.na(regionSamples[[i]]), match(unlist(genes),",export,965e20,105
names(regionSamples)[i])),export,965e20,105
dev.off(),export,965e20,105
"geneCols = toColor(geneCellTypes, colors)",export,965e20,105
},export,965e20,105
geneDat$Gene.Symbol)],export,965e20,105
anotCol = data.frame(Samples = design$PyramidalDeep[!is.na(regionSamples[[i]])]),export,965e20,105
}),export,965e20,105
"pheatmap(t(relExp), fontsize = 30, show_rownames = FALSE,",export,965e20,105
"geneCellTypes = str_extract(names(unlist(genes)), regexMerge(cellTypes))",export,965e20,105
genes %<>% lapply(function(x) {,export,965e20,105
cellTypes = regionSamples[[i]] %>% trimNAs %>% unique(),export,965e20,105
"""marker gene expression""), color = viridis(20))",export,965e20,105
colors),export,965e20,105
"cluster_rows = F, cluster_cols = F, main = paste(names(regionSamples[i]),",export,965e20,105
],export,965e20,105
""".png""), height = 1000, width = 1500)",export,965e20,105
"`Specific Genes` = geneCols$palette), annotation_legend = T,",export,965e20,105
"genes = list.dirs(""analysis/01.Gene Selection/FinalGenes/PyramidalDeep/"")",import,965e20,105
"LAMBDA <- c(3, 5, 10, 15, 25, 50, 60, 75, 100, 150, 300, 450,     600)",import,17e21,108
genes = genes[-1],data cleaning,965e20,105
"OMEGA <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)",import,17e21,108
names = basename(genes),data cleaning,965e20,105
"genes = lapply(genes, puristOut)",data cleaning,965e20,105
names(genes) = names,data cleaning,965e20,105
"dat <- read.csv(""autoanalysisInfo.csv"", header = TRUE, stringsAsFactors = FALSE)",not sure,9.3500000000000005e+21,109
"component1 = """"",not sure,965e20,105
component2 = names(genes[[i]][j]),not sure,965e20,105
"lapply(1:len(genes[[i]]), function(j) {",not sure,965e20,105
component1 = names(genes[i]),not sure,965e20,105
"genes = lapply(1:len(genes), function(i) {",not sure,965e20,105
"print(paste(i, j))",not sure,965e20,105
"if (component1 == ""All_"") {",not sure,965e20,105
]$V1 %>% unlist %>% as.char,not sure,965e20,105
"component1 = paste0(component1, ""_"")",not sure,965e20,105
}),not sure,965e20,105
},not sure,965e20,105
"component1, ""PyramidalDeep/"", component2))",not sure,965e20,105
"scores = read.table(paste0(""analysis/01.Gene Selection/Fold/Relax/"",",not sure,965e20,105
"(scores %>% filter(V1 %in% genes[[i]][[j]] & V3 > 0.6))[1:5,",not sure,965e20,105
}),not sure,965e20,105
library(knitr),communication,9.3500000000000005e+21,109
names(genes) = names,data cleaning,965e20,105
}),data cleaning,965e20,105
"genes = lapply(genes, function(x) {",data cleaning,965e20,105
"lapply(x, trimNAs)",data cleaning,965e20,105
toPlot = genes$Cortex %>% unlist %>% unique,visualization,965e20,105
i <- as.numeric((commandArgs(TRUE)[1])),data cleaning,9.3500000000000005e+21,109
"list[geneDat, exp] = read.exp(""data/finalExp.csv"") %>% sepExpr",import,965e20,105
"design = read.design(""data/meltedDesign.tsv"")",import,965e20,105
filename <- dat$filename[i],data cleaning,9.3500000000000005e+21,109
print(filename),exploratory,9.3500000000000005e+21,109
"dpylrFriendly = cbind(design, t(exp))",not sure,965e20,105
print(dat$strain[i]),exploratory,9.3500000000000005e+21,109
dir.create(filename),setup,9.3500000000000005e+21,109
setwd(filename),setup,9.3500000000000005e+21,109
cellTypes = sort(trimNAs(unique(dpylrFriendly$PyramidalDeep))),not sure,965e20,105
strain <- dat$strain[i],not sure,9.3500000000000005e+21,109
"dpylrFriendly$JustPyra = factor(dpylrFriendly$PyramidalDeep,        levels = c(""Astrocyte"", ""Microglia"", ""Oligo"", cellTypes[!cellTypes %in%      c(""Astrocyte"", ""Microglia"", ""Oligo"")]))",not sure,965e20,105
dpylrFriendly = dpylrFriendly %>% filter(!is.na(JustPyra)) %>%     arrange(JustPyra),data cleaning,965e20,105
"list[design, exp] = dpylrFriendly %>% sepExpr",not sure,965e20,105
cellTypes = unique(design$PyramidalDeep),not sure,965e20,105
"genes = allPuristOut(""analysis/01.Gene Selection/FinalGenes/PyramidalDeep/"")",import,965e20,105
"files = list.files(""analysis/01.Gene Selection//RotSel/Marker/"",     recursive = T, full.names = T)",import,965e20,105
"files = files[grepl(""PyramidalDeep"", files)]",import,965e20,105
read.table(x)$V1,not sure,965e20,105
"genes = lapply(files, function(x) {",not sure,965e20,105
}),not sure,965e20,105
}),not sure,965e20,105
try({,not sure,965e20,105
names(genes) = basename(files),import,965e20,105
"lapply(unique(names(genes)), function(x) {",not sure,965e20,105
}),not sure,965e20,105
colors = cellColors(),not sure,965e20,105
colors = colors[cellTypes],not sure,965e20,105
}),data cleaning,965e20,105
"geneCellTypes = sapply(names(unlist(genes)), function(x) {",data cleaning,965e20,105
"str_split(x, ""\\."")[[1]][2]",data cleaning,965e20,105
"geneCellTypes = str_extract(geneCellTypes, regexMerge(cellTypes))",data cleaning,965e20,105
a = unique(unlist(genes)[geneCellTypes %in% x]),data cleaning,965e20,105
}),data cleaning,965e20,105
"cellTypeGenes = lapply(cellTypes, function(x) {",data cleaning,965e20,105
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,16e21,110
names(cellTypeGenes) = cellTypes,data cleaning,965e20,105
"setwd(""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/segregation_analysis"")",setup,16e21,110
"geneCellTypes = str_extract(names(unlist(cellTypeGenes)), regexMerge(cellTypes))",not sure,965e20,105
"relExp = exp[, match(unlist(cellTypeGenes), geneDat$Gene.Symbol)]",data cleaning,965e20,105
"relGene = geneDat[match(unlist(cellTypeGenes), geneDat$Gene.Symbol),     ]",data cleaning,965e20,105
"relExp = apply(relExp, 2, scale01)",data cleaning,965e20,105
"heatCols = toColor(design$PyramidalDeep, colors)",visualization,965e20,105
"geneCols = toColor(geneCellTypes, colors)",visualization,965e20,105
"png(""analysis/09.Plots/markerGenes.png"", height = 1000, width = 1000)",visualization,965e20,105
"heatmap.2(t(relExp), Rowv = F, Colv = F, trace = ""none"", col = viridis(20),      ColSideColors = heatCols$cols, RowSideColors = geneCols$cols,    labRow = """", labCol = """")",visualization,965e20,105
"legend(title = ""Cell Types"", ""bottomleft"", legend = names(heatCols$palette),     fill = heatCols$palette)",visualization,965e20,105
dev.off(),visualization,965e20,105
"simuProbs = read.table(""analysis/02.Mouse Single Cell/Output/NoTresholdNoDub0.3333/simuProbs"",     header = TRUE)",import,965e20,105
"pVals = read.table(""analysis/02.Mouse Single Cell/Output/NoTresholdNoDub0.3333/realProbs"",     header = TRUE)",import,965e20,105
sigMarks = signifMarker(pVals$ps),not sure,965e20,105
"allFiles = list.files(""analysis/02.Mouse Single Cell/Output/NoTresholdNoDub0.3333/"",     full.names = TRUE)",import,965e20,105
"allFiles = allFiles[!grepl(""(simuProbs)|(realProbs)"", allFiles)]",import,965e20,105
"existanceMatri = lapply(allFiles, function(x) {",import,965e20,105
"read.table(x, skip = 1)",import,965e20,105
}),import,965e20,105
names(existanceMatri) = basename(allFiles),import,965e20,105
"existanceMatri = existanceMatri[c(""Astrocyte"", ""Oligo"", ""Microglia"",     names(existanceMatri)[!names(existanceMatri) %in% c(""Astrocyte"",         ""Oligo"", ""Microglia"")])]",data cleaning,965e20,105
"pVals = pVals[c(""Astrocyte"", ""Oligo"", ""Microglia"", names(existanceMatri)[!names(existanceMatri) %in%     c(""Astrocyte"", ""Oligo"", ""Microglia"")]), ]",data cleaning,965e20,105
sigMarks = signifMarker(pVals$ps),not sure,965e20,105
frame = existanceMatri[[i]] %>% (reshape2::melt),visualization,965e20,105
"ylab(""Marker genes"") + xlab(""Cells"") + ggtitle(bquote(~.(names(existanceMatri)[[i]])^.(sigMarks[i])))",visualization,965e20,105
set.seed(1),visualization,965e20,105
"p = frame %>% ggplot(aes(y = V1, x = variable)) + geom_tile(aes(fill = value)) +",visualization,965e20,105
labels,visualization,965e20,105
"frame$V1 = factor(frame$V1, levels = GeneOrder)",visualization,965e20,105
return(p),visualization,965e20,105
t %>% dist %>% hclust %>% as.dendrogram %>% reorder(colMeans(existanceMatri[[i]][2:ncol(existanceMatri[[i]])])) %>%,visualization,965e20,105
set.seed(1),visualization,965e20,105
"frame$variable = factor(frame$variable, levels = cellOrder)",visualization,965e20,105
"plots = lapply(1:len(existanceMatri), function(i) {",visualization,965e20,105
dist %>% hclust %>% as.dendrogram %>% reorder(rowMeans(existanceMatri[[i]][2:ncol(existanceMatri[[i]])])) %>%,visualization,965e20,105
"panel.grid.minor = element_blank(), axis.ticks.x = element_blank(),",visualization,965e20,105
GeneOrder = existanceMatri[[i]][existanceMatri[[i]][2:ncol(existanceMatri[[i]])] %>%,visualization,965e20,105
cellOrder = existanceMatri[[i]][2:ncol(existanceMatri[[i]])] %>%,visualization,965e20,105
"theme_bw() + theme(panel.grid.major = element_blank(),",visualization,965e20,105
"legend.position = ""none"", plot.title = element_text(size = 22)) +",visualization,965e20,105
}),visualization,965e20,105
"axis.text.x = element_blank(), axis.text.y = element_blank(),",visualization,965e20,105
"labels, 1]",visualization,965e20,105
"scale_fill_gradient(low = ""white"", high = muted(""blue"")) +",visualization,965e20,105
"plot = plot_grid(plotlist = plots, ncol = 5, labels = letters[1:10])",visualization,965e20,105
"save_plot(""analysis//09.Plots/singleMouseCellPlot.png"", plot,     base_height = 10, base_aspect_ratio = 2)",export,965e20,105
"simuProbs = read.table(""analysis/03.Human Single Cell/Output/NoTreshold0.3333/simuProbs"",     header = TRUE)",import,965e20,105
"pVals = read.table(""analysis/03.Human Single Cell/Output/NoTreshold0.3333/realProbs"",     header = TRUE)",import,965e20,105
"allFiles = list.files(""analysis/03.Human Single Cell/Output/NoTreshold0.3333/"",     full.names = TRUE)",import,965e20,105
"allFiles = allFiles[!grepl(""(simuProbs)|(realProbs)"", allFiles)]",import,965e20,105
"existanceMatri = lapply(allFiles, function(x) {",import,965e20,105
}),import,965e20,105
"read.table(x, skip = 1)",import,965e20,105
names(existanceMatri) = basename(allFiles),setup,965e20,105
"existanceMatri = existanceMatri[c(""Astrocyte"", ""Oligo"", ""Microglia"",     names(existanceMatri)[!names(existanceMatri) %in% c(""Astrocyte"",         ""Oligo"", ""Microglia"")])]",data cleaning,965e20,105
"pVals = pVals[c(""Astrocyte"", ""Oligo"", ""Microglia"", names(existanceMatri)[!names(existanceMatri) %in%     c(""Astrocyte"", ""Oligo"", ""Microglia"")]), ]",data cleaning,965e20,105
sigMarks = signifMarker(pVals$ps),not sure,965e20,105
"plots = lapply(1:len(existanceMatri), function(i) {",visualization,965e20,105
"frame$variable = factor(frame$variable, levels = cellOrder)",visualization,965e20,105
"p = frame %>% ggplot(aes(y = V1, x = variable)) + geom_tile(aes(fill = value)) +",visualization,965e20,105
"panel.grid.minor = element_blank(), axis.ticks.x = element_blank(),",visualization,965e20,105
cellOrder = existanceMatri[[i]][2:ncol(existanceMatri[[i]])] %>%,visualization,965e20,105
set.seed(1),visualization,965e20,105
t %>% dist %>% hclust %>% as.dendrogram %>% reorder(colMeans(existanceMatri[[i]][2:ncol(existanceMatri[[i]])])) %>%,visualization,965e20,105
GeneOrder = existanceMatri[[i]][existanceMatri[[i]][2:ncol(existanceMatri[[i]])] %>%,visualization,965e20,105
dist %>% hclust %>% as.dendrogram %>% reorder(rowMeans(existanceMatri[[i]][2:ncol(existanceMatri[[i]])])) %>%,visualization,965e20,105
}),visualization,965e20,105
"labels, 1]",visualization,965e20,105
return(p),visualization,965e20,105
"scale_fill_gradient(low = ""white"", high = muted(""blue"")) +",visualization,965e20,105
frame = existanceMatri[[i]] %>% (reshape2::melt),visualization,965e20,105
"ylab(""Marker genes"") + xlab(""Cells"") + ggtitle(bquote(~.(names(existanceMatri)[[i]])^.(sigMarks[i])))",visualization,965e20,105
set.seed(1),visualization,965e20,105
"frame$V1 = factor(frame$V1, levels = GeneOrder)",visualization,965e20,105
"axis.text.x = element_blank(), axis.text.y = element_blank(),",visualization,965e20,105
labels,visualization,965e20,105
"legend.position = ""none"", plot.title = element_text(size = 22)) +",visualization,965e20,105
"theme_bw() + theme(panel.grid.major = element_blank(),",visualization,965e20,105
"plot = plot_grid(plotlist = plots, ncol = 5, labels = letters[11:20])",visualization,965e20,105
"save_plot(""analysis//09.Plots/singleHumanCellPlot.png"", plot,     base_height = 10, base_aspect_ratio = 2)",export,965e20,105
set.seed(1),setup,965e20,105
"crappyGenesAstro = existanceMatri$Astrocyte[, 2:ncol(existanceMatri$Astrocyte)] %>%     as.matrix %>% heatmap.2(trace = ""none"") %$% rowDendrogram[[2]][[2]][[1]] %>%     labels %>% existanceMatri$Astrocyte[., 1]",data cleaning,965e20,105
set.seed(1),setup,965e20,105
"req <- c(""mvtnorm"", ""ggplot2"", ""reshape2"", ""foreign"", ""Hmisc"",     ""scales"", ""splines"", ""Cairo"", ""lubridate"", ""gridExtra"", ""gtable"",     ""plyr"", ""lmtest"", ""survival"", ""data.table"")",setup,166e20,111
"crappyGenesOligo = existanceMatri$Oligo[, 2:ncol(existanceMatri$Oligo)] %>%     as.matrix %>% heatmap.2(trace = ""none"") %$% rowDendrogram[[2]][[2]][[1]] %>%     labels %>% existanceMatri$Oligo[., 1]",data cleaning,965e20,105
"as.matrix %>% heatmap.2(trace = ""none"") %$% rowDendrogram[[2]][[2]][[1]] %>%",data cleaning,965e20,105
set.seed(1),setup,965e20,105
"crappyGenesMicroglia = existanceMatri$Microglia[, 2:ncol(existanceMatri$Microglia)] %>%     as.matrix %>% heatmap.2(trace = ""none"") %$% rowDendrogram[[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]][[2]] %>%     labels %>% existanceMatri$Microglia[., 1]",data cleaning,965e20,105
"lapply(req, library, character.only = TRUE)",setup,166e20,111
"crappyGenes = list(Astrocyte = crappyGenesAstro, Oligo = crappyGenesOligo,     Microglia = crappyGenesMicroglia)",data cleaning,965e20,105
set.seed(753892375),setup,166e20,111
"dir.create(""analysis//09.Plots/crappyGenesHumanCoexp"")",export,965e20,105
nsamples <- 1000,exploratory,166e20,111
"analysis <- read.dta(""data/d01_cacoh_stset_barlow.dta"", convert.underscore = TRUE)",import,166e20,111
isCrappy = colnames(coexpression) %in% crappyGenes[[i]],import,965e20,105
""".png""), width = 800, height = 800)",import,965e20,105
"coexpression = coexpression[, 2:ncol(coexpression)]",import,965e20,105
names(crappyGenes)[i])),import,965e20,105
for (i in 1:len(crappyGenes)) {,import,965e20,105
"heatmap.2(coexpression %>% as.matrix, trace = ""none"", col = viridis(20),",import,965e20,105
"png(paste0(""analysis//09.Plots/crappyGenesHumanCoexp/"", names(crappyGenes)[i],",import,965e20,105
"dendrogram = ""column"", ColSideColors = colors, main = names(crappyGenes)[i],",import,965e20,105
"colors = toColor(isCrappy, c(`FALSE` = ""white"", `TRUE` = muted(""red"")))$cols",import,965e20,105
"labRow = """")",import,965e20,105
dev.off(),import,965e20,105
"coexpression = read.csv(paste0(""analysis/04.Human Coexpression/intraGroup/singleData/cortex/"",",import,965e20,105
},import,965e20,105
analysis_stata <- analysis,not sure,166e20,111
"files = list.files(""analysis/04.Human Coexpression/coexpData"",",import,965e20,105
"full.names = T, recursive = T)",import,965e20,105
"files = files[grepl(pattern = ""RData"", files)]",import,965e20,105
"files = files[grepl(pattern = ""spear"", files)]",import,965e20,105
varlab = attributes(analysis_stata)$var.labels),data cleaning,166e20,111
"varlabs <- data.frame(varname = attributes(analysis_stata)$names,",data cleaning,166e20,111
"return(list(coexpressions = lapply(coexpressions, sort),",import,965e20,105
"plotOut = plotOut, regionsIn = regionsIn))",import,965e20,105
}),import,965e20,105
"coexpData = lapply(files, function(x) {",import,965e20,105
load(x),import,965e20,105
"daCorvec = sort(daCorvec), subFolderName = subFolderName,",import,965e20,105
"files = list.files(""analysis/04.Human Coexpression/coexpData"",     full.names = T, recursive = T)",import,965e20,105
"files = files[grepl(pattern = ""pVals"", files)]",import,965e20,105
"files = files[grepl(pattern = ""spear"", files)]",import,965e20,105
varlabs <- data.table(varlabs),not sure,166e20,111
vec = tb$V2,import,965e20,105
}),import,965e20,105
"pVals = lapply(files, function(x) {",import,965e20,105
tb = read.table(x),import,965e20,105
names(vec) = tb$V1,import,965e20,105
return(vec),import,965e20,105
analysis <- data.table(analysis),not sure,166e20,111
analysis$stage.imputed <- factor(analysis$stage.imputed),not sure,166e20,111
analysis$sex <- factor(analysis$sex),not sure,166e20,111
analysis <- analysis[.st == 1],not sure,166e20,111
"""Pyramidal_Glt_25d2"", ""Pyramidal_Thy1"")]",data cleaning,965e20,105
"""Pyramidal_Thy1"")]",data cleaning,965e20,105
},data cleaning,965e20,105
"c(""Astrocyte"", ""Microglia"", ""Oligo"", ""GabaRelnCalb"",",data cleaning,965e20,105
coexpData[[i]]$coexpressions = coexpData[[i]]$coexpressions[!names(coexpData[[i]]$coexpressions) %in%,data cleaning,965e20,105
"""Microglia"", ""Oligo"", ""GabaRelnCalb"", ""Pyramidal_Glt_25d2"",",data cleaning,965e20,105
for (i in 2:len(pVals)) {,data cleaning,965e20,105
"pVals[[i]] = pVals[[i]][!names(pVals[[i]]) %in% c(""Astrocyte"",",data cleaning,965e20,105
skeleton = pVals),data cleaning,965e20,105
"pAdjusted = relist(flesh = p.adjust(unlist(pVals), method = ""fdr""),",data cleaning,965e20,105
"knts3 <- quantile(analysis$vd3.h, probs = c(0.3, 0.5, 0.7), na.rm = TRUE)",not sure,166e20,111
"knts2 <- quantile(analysis$vd3.h, probs = c(0.33, 0.67), na.rm = TRUE)",not sure,166e20,111
"knts1 <- quantile(analysis$vd3.h, probs = c(0.5), na.rm = TRUE)",not sure,166e20,111
"bknts <- quantile(analysis$vd3.h, probs = c(0.1, 0.9), na.rm = TRUE)",not sure,166e20,111
"relevantsFull = rbind(all, relevants)",visualization,965e20,105
"ps), maxY = yMax, size = 3) + ggtitle(name)",visualization,965e20,105
"list(geom_violin(color = ""#C4C4C4"", fill = ""#C4C4C4""),",visualization,965e20,105
"axis.text.y = element_text(size = 4)) + geom_signif(c(1,",visualization,965e20,105
cellTypes = unique(relevants$L1),visualization,965e20,105
"theme_bw() + scale_y_continuous(name = ""Gene to gene correlations"") +",visualization,965e20,105
"geom_boxplot(width = 0.2, fill = ""lightblue"", outlier.size = 0.5)) +",visualization,965e20,105
"size = 6), title = element_text(vjust = 0.5, size = 6),",visualization,965e20,105
"tail(relevantsFull$value[relevantsFull$L1 %in% x], n = 1)",visualization,965e20,105
"plotVioBox = function(relevants, ps, all, name) {",visualization,965e20,105
"scale_x_discrete(name = """") + theme(axis.text.x = element_text(size = 4.5,",visualization,965e20,105
"yMax = sapply(unique(relevantsFull$L1), function(x) {",visualization,965e20,105
},visualization,965e20,105
"angle = 45, hjust = 1), axis.title.y = element_text(vjust = 0.5,",visualization,965e20,105
"plot = ggplot(relevantsFull, aes(x = L1, y = value, group = L1)) +",visualization,965e20,105
}),visualization,965e20,105
return(plot),visualization,965e20,105
knts <- knts2,not sure,166e20,111
set.seed(1),setup,965e20,105
"minlist <- c(""age.recruitment"", ""sex"", ""stage.imputed"", ""sin1.recr.day"",",not sure,166e20,111
"""cos1.recr.day"")",not sure,166e20,111
}),data cleaning,965e20,105
"names(pAdjusted) = sapply(coexpData, function(x) {",data cleaning,965e20,105
basename(x$plotOut),data cleaning,965e20,105
"fullformula <- paste(minlist, collapse = "" + "")",not sure,166e20,111
"names(pAdjusted)[1] = ""All Regions""",data cleaning,965e20,105
"fullformula <- paste(fullformula, ""+ strata(country)"")",not sure,166e20,111
"all = data.frame(value = allTemp, L1 = ""all"")",visualization,965e20,105
"plot = plotVioBox(relevants, ps, all, names(pAdjusted)[i])",visualization,965e20,105
relevants = melt(relevants),visualization,965e20,105
ps = pAdjusted[[i]],visualization,965e20,105
"plots = mclapply(1:len(coexpData), function(i) {",visualization,965e20,105
relevants = coexpData[[i]]$coexpressions,visualization,965e20,105
"allTemp = sample(coexpData[[i]]$daCorvec, size = 2000)",visualization,965e20,105
"}, mc.cores = len(coexpData))",visualization,965e20,105
"lhsstr <- ""Surv(time=.t0, time2=.t, event=.d) ~ """,not sure,166e20,111
"xstr <- ""ns(vd3.h, knots=knts, Boundary.knots=bknts)""",not sure,166e20,111
"plot = plot_grid(plotlist = plots, ncol = 2)",visualization,965e20,105
"save_plot(""analysis//09.Plots/humanCoexpressionPlot.png"", plot,     base_height = 4, base_aspect_ratio = 1.3)",export,965e20,105
"coxnull <- coxph(as.formula(paste(lhsstr, xstr)), weights = wgt.stratified,     robust = TRUE, data = analysis)",modeling,166e20,111
"estims = read.table(""analysis/05.Brain Estimations/estimations/cortex_white/estimations"",     header = T, sep = ""\t"")",import,965e20,105
"estims[1:(ncol(estims) - 1)] = apply(estims[1:(ncol(estims) -     1)], 2, scale01)",data cleaning,965e20,105
"coxfull <- coxph(as.formula(paste(lhsstr, xstr, ""+"", fullformula)),     weights = wgt.stratified, robust = TRUE, data = analysis, model = TRUE)",modeling,166e20,111
frame = melt(estims),data cleaning,965e20,105
"names(frame) = c(""brainRegions"", ""cellType"", ""estimation"")",data cleaning,965e20,105
"frame$cellType = factor(frame$cellType, levels = order) %>% droplevels",data cleaning,965e20,105
frame = frame %>% group_by(cellType),data cleaning,965e20,105
maxY = frame %>% summarise(max(estimation)),data cleaning,965e20,105
"coxref <- coxph(as.formula(paste(lhsstr, fullformula)), weights = wgt.stratified,",modeling,166e20,111
"robust = TRUE, data = analysis, model = TRUE)",modeling,166e20,111
}),data cleaning,965e20,105
"a2 = x %>% filter(brainRegions == ""white matter"") %>% select(estimation) %>%",data cleaning,965e20,105
"wilcox.test(a1, a2)$p.value",data cleaning,965e20,105
unlist,data cleaning,965e20,105
unlist,data cleaning,965e20,105
"a1 = x %>% filter(brainRegions == ""frontal cortex"") %>% select(estimation) %>%",data cleaning,965e20,105
"ps = by(frame, frame$cellType, function(x) {",data cleaning,965e20,105
ps = p.adjust(ps),data cleaning,965e20,105
markers = signifMarker(ps),data cleaning,965e20,105
"vitd <- seq(5, 100, by = 1)",setup,166e20,111
"signifFrame = data.frame(markers, x = 1.5, y = 1, cellType = names(ps))",data cleaning,965e20,105
"p = frame %>% ggplot(aes(x = brainRegions, y = estimation)) +       facet_wrap(~cellType) + geom_violin(color = ""#C4C4C4"", fill = ""#C4C4C4"") +   geom_boxplot(width = 0.1, fill = ""lightblue"") + theme(axis.text.x = element_text(angle = 45,     hjust = 1), strip.text.x = element_text(size = 16)) + geom_text(data = signifFrame,  aes(x = x, y = y, label = markers), size = 10) + coord_cartesian(ylim = c(-0.1, 1.1))",visualization,965e20,105
"ggsave(filename = ""analysis//09.Plots/cortex_WhiteMatterEstimations.png"",     p, width = 11, height = 10)",export,965e20,105
"estims = read.table(""analysis/05.Brain Estimations/estimations/parkinsonMale/estimations"",     header = T, sep = ""\t"")",import,965e20,105
"estims[1:(ncol(estims) - 1)] = apply(estims[1:(ncol(estims) -     1)], 2, scale01)",data cleaning,965e20,105
frame = melt(estims),data cleaning,965e20,105
"ns_vitd <- as.matrix(ns(vitd, knots = knts, Boundary.knots = bknts))",not sure,166e20,111
b <- coef(coxfull)[1:ncol(ns_vitd)],setup,166e20,111
"V <- vcov(coxfull)[1:ncol(ns_vitd), 1:ncol(ns_vitd)]",setup,166e20,111
subtract_ref <- function(x) (x - x[vitd == 50]),setup,166e20,111
"ns_vitd50 <- t(aaply(ns_vitd, 2, subtract_ref))",not sure,166e20,111
pred_ml <- ns_vitd50 %*% b,modeling,166e20,111
se_ml <- sqrt(diag(ns_vitd50 %*% V %*% t(ns_vitd50))),data cleaning,166e20,111
hr_ml <- exp(pred_ml),data cleaning,166e20,111
library(ggbiplot),not sure,6.6800000000000004e+22,112
"source(""../../bin/ncatsSingleAgentScreens.R"")",not sure,6.6800000000000004e+22,112
"source(""../../bin/RNASeqData.R"")",not sure,6.6800000000000004e+22,112
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,459e20,113
"cat(""\f"")",communication,459e20,113
rm(list = ls(all = TRUE)),setup,459e20,113
library(BGLR),setup,459e20,113
library(doParallel),setup,459e20,113
library(gdata),not sure,459e20,113
library(knitr),modeling,87e21,114
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",modeling,87e21,114
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,87e21,114
"NSAF.avg <- read.csv(""Documents/robertslab/labnotebook/data/NSAF/silo3and9_nozerovals_AVGs.csv"")",import,897e20,1
"rownames(NSAF.avg) <- paste(""D"", NSAF.avg$day, ""T"", NSAF.avg$temp,     sep = """")",data cleaning,897e20,1
NSAF.avg <- t(NSAF.avg),data cleaning,897e20,1
"NSAF.avg <- subset(NSAF.avg, grepl(paste(""CHOYP"", collapse = ""|""),     rownames(NSAF.avg)))",data cleaning,897e20,1
NSAF.trans <- data.frame(NSAF.avg),data cleaning,897e20,1
"NSAF.fil <- read.csv(""Documents/robertslab/labnotebook/data/NSAF/silo3and9_nozerovals_noincnstprot.csv"")",data cleaning,897e20,1
"rownames(NSAF.fil) <- paste(""D"", NSAF.fil$day, ""T"", NSAF.fil$temp,     sep = """")",import,897e20,1
NSAF.fil <- t(NSAF.fil),data cleaning,897e20,1
"NSAF.fil <- subset(NSAF.fil, grepl(paste(""CHOYP"", collapse = ""|""),     rownames(NSAF.fil)))",data cleaning,897e20,1
"which(grepl(""ALBU_BOVIN"", rownames(NSAF.fil)))",data cleaning,897e20,1
NSAF.trans <- data.frame(NSAF.fil),exploratory,897e20,1
"annotations <- read.csv(""Documents/robertslab/labnotebook/data/allsilos-tag_and_annot.csv"")",data cleaning,897e20,1
"annotations <- annotations[, c(1, 67)]",import,897e20,1
"annotations$Protein.ID <- sub(""\\|"", ""."", annotations$Protein.ID)",data cleaning,897e20,1
"merge <- merge(NSAF.trans, annotations, by.x = ""row.names"", by.y = ""Protein.ID"",     all.x = TRUE)",data cleaning,897e20,1
merge$Gene.names <- as.character(unlist(merge$Gene.names)),data cleaning,897e20,1
class(merge$Gene.names),data cleaning,897e20,1
"merge$Names <- ifelse(merge$Gene.names == """", yes = merge$Row.names,     no = merge$Names)",data cleaning,897e20,1
"merge$Names <- ifelse(merge$Names == ""None"", yes = merge$Row.names,     no = merge$Names)",data cleaning,897e20,1
"merge$Names <- ifelse(is.na(merge$Names) == TRUE, yes = merge$Row.names,     no = merge$Names)",data cleaning,897e20,1
any(is.na(merge$Names)),data cleaning,897e20,1
"s3 <- merge[, c(15, 2, 4, 6, 8, 10, 12)]",data cleaning,897e20,1
"s9 <- merge[, c(15, 3, 5, 7, 9, 11, 13)]",data cleaning,897e20,1
NSAF.trans$Names <- rownames(NSAF.trans),data cleaning,897e20,1
rownames(NSAF.trans) <- NULL,data cleaning,897e20,1
"silo3 <- NSAF.trans[, c(grepl(""23"", colnames(NSAF.trans)))]",data cleaning,897e20,1
silo3$Names <- NSAF.trans$Names,data cleaning,897e20,1
"silo9 <- NSAF.trans[, c(grepl(""29"", colnames(NSAF.trans)))]",data cleaning,897e20,1
silo9$Names <- NSAF.trans$Names,data cleaning,897e20,1
"silo3$Names <- sub(""^"", ""3_"", silo3$Names)",data cleaning,897e20,1
"silo9$Names <- sub(""^"", ""9_"", silo9$Names)",data cleaning,897e20,1
"colnames(silo3) <- sub(""T.*"", """", colnames(silo3))",data cleaning,897e20,1
"colnames(silo9) <- sub(""T.*"", """", colnames(silo9))",data cleaning,897e20,1
"silo3.9 <- rbind(silo3, silo9)",data cleaning,897e20,1
rownames(silo3.9) <- silo3.9$Names,data cleaning,897e20,1
"silo3.9 <- silo3.9[, -c(7)]",data cleaning,897e20,1
silo3.9$D0 <- NSAF.trans$D0T16,data cleaning,897e20,1
library(dplyr),data cleaning,897e20,1
"silo3.9 <- silo3.9 %>% select(""D0"", everything())",setup,897e20,1
"source(""Documents/robertslab/labnotebook/analysis/scripts/biostats.R"")",setup,897e20,1
library(vegan),setup,897e20,1
"nsaf.euc <- vegdist(silo3.9, method = ""euclidean"")",setup,897e20,1
library(cluster),modeling,897e20,1
"clust.avg <- hclust(nsaf.euc, method = ""average"")",setup,897e20,1
coef.hclust(clust.avg),modeling,897e20,1
"cor(nsaf.euc, cophenetic(clust.avg))",modeling,897e20,1
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/scree.jpeg"",     width = 1000, height = 1000)",modeling,897e20,1
hclus.scree(clust.avg),visualization,897e20,1
dev.off(),modeling,897e20,1
plot(clust.avg),visualization,897e20,1
"rect.hclust(clust.avg, h = 250)",visualization,897e20,1
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/dendrogram.jpeg"",     width = 1000, height = 1000)",visualization,897e20,1
plot(clust.avg),visualization,897e20,1
"rect.hclust(clust.avg, h = 250)",visualization,897e20,1
dev.off(),visualization,897e20,1
"clust.class <- cutree(clust.avg, h = 250)",visualization,897e20,1
max(clust.class),modeling,897e20,1
silo3_9.freq <- data.frame(table(clust.class)),modeling,897e20,1
"write.csv(silo3_9.freq, file = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/freq.csv"",     row.names = FALSE)",communication,897e20,1
silo3_9.clus <- data.frame(clust.class),export,897e20,1
names <- rownames(silo3_9.clus),modeling,897e20,1
"silo3_9.clus <- cbind(names, silo3_9.clus)",data cleaning,897e20,1
rownames(silo3_9.clus) <- NULL,data cleaning,897e20,1
"colnames(silo3_9.clus)[1] <- ""ID""",data cleaning,897e20,1
"colnames(silo3_9.clus)[2] <- ""Cluster""",data cleaning,897e20,1
"silo3_9.all <- merge(silo3_9.clus, silo3.9, by.x = ""ID"", by.y = ""row.names"")",data cleaning,897e20,1
library(ggthemes),data cleaning,897e20,1
library(reshape),setup,897e20,1
library(ggplot2),setup,897e20,1
"melted_all_s3_9 <- melt(silo3_9.all, id.vars = c(""ID"", ""Cluster""))",setup,897e20,1
"silo <- substr(melted_all_s3_9$ID, 0, 1)",data cleaning,897e20,1
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/lineplot-allprot.jpeg"",     width = 1000, height = 1000)",data cleaning,897e20,1
"ggplot(melted_all_s3_9, aes(x = variable, y = value, group = ID,     color = silo)) + geom_line(alpha = 0.8) + theme_bw() + facet_wrap(~Cluster,     scales = ""free_y"") + labs(x = ""Time Point"", y = ""Normalized Spectral Abundance Factor"")",visualization,897e20,1
dev.off(),visualization,897e20,1
silo3_9.edit <- silo3_9.all,visualization,897e20,1
"silo3_9.edit$Silo <- substr(silo3_9.edit$ID, 1, 1)",not sure,897e20,1
class(silo3_9.edit$ID),data cleaning,897e20,1
silo3_9.edit$ID <- as.character(unlist(silo3_9.edit$ID)),exploratory,897e20,1
"silo3_9.edit$ID <- substr(silo3_9.edit$ID, 3, nchar(silo3_9.edit$ID))",data cleaning,897e20,1
library(dplyr),data cleaning,897e20,1
"silo3_9.edit <- silo3_9.edit %>% select(Silo, everything())",setup,897e20,1
"silo3_9.edit <- silo3_9.edit %>% select(Cluster, everything())",exploratory,897e20,1
"silo3_9.annot <- merge(silo3_9.edit, annotations, by.x = ""ID"",",exploratory,897e20,1
"write.csv(silo3_9.annot, file = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/all-prot-anno.csv"",     row.names = FALSE)",data cleaning,897e20,1
library(data.table),export,897e20,1
"unique.prot <- silo3_9.edit[!(duplicated(silo3_9.edit[c(""ID"",     ""Cluster"")]) | duplicated(silo3_9.edit[c(""ID"", ""Cluster"")],     fromLast = TRUE)), ]",setup,897e20,1
"anyDuplicated(silo3_9.edit[, c(""ID"", ""Cluster"")])",data cleaning,897e20,1
"anyDuplicated(unique.prot[, c(""ID"", ""Cluster"")])",exploratory,897e20,1
"final.unique.prot <- merge(unique.prot, annotations, by.x = ""ID"",     by.y = ""Protein.ID"")",exploratory,897e20,1
"sum(final.unique.prot$Silo == ""3"")",data cleaning,897e20,1
"sum(final.unique.prot$Silo == ""9"")",modeling,897e20,1
"write.csv(final.unique.prot, file = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/unq-prot-anno.csv"",     row.names = FALSE)",modeling,897e20,1
plot.unq <- unique.prot,export,897e20,1
"plot.unq$S.ID <- paste(plot.unq$Silo, plot.unq$ID, sep = ""_"")",visualization,897e20,1
"plot.unq <- plot.unq[, -c(2:3)]",visualization,897e20,1
"unq_melted_all_s3_9 <- melt(plot.unq, id.vars = c(""S.ID"", ""Cluster""))",visualization,897e20,1
"silo <- substr(unq_melted_all_s3_9$S.ID, 0, 1)",data cleaning,897e20,1
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/lineplots-unq-prot.jpeg"",     width = 1000, height = 1000)",data cleaning,897e20,1
"color = silo)) + geom_line(alpha = 0.8) + theme_bw() + facet_wrap(~Cluster,",visualization,897e20,1
"scales = ""free_y"") + labs(x = ""Time Point"", y = ""Normalized Spectral Abundance Factor"")",visualization,897e20,1
"ggplot(unq_melted_all_s3_9, aes(x = variable, y = value, group = S.ID,",visualization,897e20,1
dev.off(),visualization,897e20,1
"annotations <- read.csv(""Documents/robertslab/labnotebook/data/allsilos-tag_and_annot.csv"")",visualization,897e20,1
"annotations <- annotations[, c(1, 63)]",import,897e20,1
"annotations$Protein.ID <- sub(""\\|"", ""."", annotations$Protein.ID)",data cleaning,897e20,1
"unq.anno <- merge(unique.prot, annotations, by.x = ""ID"", by.y = ""Protein.ID"")",data cleaning,897e20,1
"write.csv(unq.anno, ""Documents/robertslab/labnotebook/analysis/clustering/NSAF-s3s9/unqprot-travg-anno.csv"")",data cleaning,897e20,1
library(dplyr),export,897e20,1
"count(unq.anno, Entry)",setup,897e20,1
"count(unq.anno, Entry)",exploratory,897e20,1
"library(""rjson"")",import,568e20,115
"source(file = ""Research_1/VersionClassifier/Analysis/analysisScript1.R"")",not sure,568e20,115
"mobileJsonCyc = getFiledata(""CyclesMobile.json"")",import,568e20,115
"desktopJsonCyc = getFiledata(""CyclesDesktop.json"")",import,568e20,115
"siblingJsonCyc = getFiledata(""CyclesSibling.json"")",import,568e20,115
"sibMobJsonCyc = getFiledata(""CyclesSibMob.json"")",import,568e20,115
"sibDeskJsonCyc = getFiledata(""CyclesSibDesk.json"")",import,568e20,115
mobileCyc = mobileJsonCyc$Cycle$Data,exploratory,568e20,115
desktopCyc = desktopJsonCyc$Cycle$Data,exploratory,568e20,115
siblingCyc = siblingJsonCyc$Cycle$Data,exploratory,568e20,115
sibMobCyc = sibMobJsonCyc$Cycle$Data,exploratory,568e20,115
sibDesktCyc = sibDeskJsonCyc$Cycle$Data,exploratory,568e20,115
RunAnalysis <- function() {},not sure,568e20,115
"setwd(""~/Desktop/gitHub/protracted_sp/"")",setup,634e20,116
library(ggplot2),setup,634e20,116
library(parallel),import,634e20,116
library(geiger),import,634e20,116
"source(""analysis/R/auxiliary_functions.R"")",import,634e20,116
"birds = read.csv(file = ""analysis/data/Botero14_plus_taxonomy.csv"",     as.is = TRUE)",import,634e20,116
"order = get_prop(""Order"", type = ""latitude"")",data cleaning,634e20,116
"order2gg = plot_prop(order, minimum = 30, type = ""latitude"")",visualization,634e20,116
"ggsave(order2gg, filename = ""analysis/output/Botero14_proportion_Lat.range_order.pdf"")",export,634e20,116
"family = get_prop(""Family.name"", type = ""latitude"")",not sure,634e20,116
"family2gg = plot_prop(family, minimum = 30, type = ""latitude"")",not sure,634e20,116
"ggsave(family2gg, filename = ""analysis/output/Botero14_proportion_Lat.range_family.pdf"")",export,634e20,116
"genus = get_prop(""Genus"", type = ""latitude"")",not sure,634e20,116
"if (!require(""pacman"")) install.packages(""pacman"")",setup,26e21,117
"genus2gg = plot_prop(genus, minimum = 30, type = ""latitude"")",visualization,634e20,116
"ggsave(genus2gg, filename = ""analysis/output/Botero14_proportion_Lat.range_genus.pdf"")",export,634e20,116
"pacman::p_install_gh(""kahaaga/tstools"")",setup,26e21,117
"orderH = get_prop(""Order"", type = ""harshness"")",data cleaning,634e20,116
"pacman::p_load(dplyr, dtplyr, data.table)",setup,26e21,117
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,1.9399999999999998e+22,118
"combos <- expand.grid(threshold = seq(0, 500, 25), latitude = seq(-90,     90, 1))",not sure,26e21,117
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.9399999999999998e+22,118
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.9399999999999998e+22,118
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.9399999999999998e+22,118
"window.sizes = seq(12, 1, -1)",setup,26e21,117
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.9399999999999998e+22,118
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,1.9399999999999998e+22,118
"source(""../../bin/sigSurvAnalysis.R"", chdir = T)",setup,4e22,119
"gene = ""NF1""",evaluation,4e22,119
for (dis in tcga.cancer.types) {,exploratory,4e22,119
"mut.sig <- survivalAnalysisByMutation(dis, c(gene))",exploratory,4e22,119
"expr.sig <- survivalAnalysisByExpression(dis, c(gene))",exploratory,4e22,119
"print(paste(""Significance of"", gene, ""in"", dis, ""is"", expr.sig$pval,",exploratory,4e22,119
},exploratory,4e22,119
"""(expression) and"", mut.sig$pval, ""(mutation)""))",exploratory,4e22,119
"gene = ""CREBBP""",evaluation,4e22,119
library(dplyr),import,584e20,120
"expr.sig <- survivalAnalysisByExpression(dis, c(gene))",exploratory,4e22,119
for (dis in tcga.cancer.types) {,exploratory,4e22,119
"print(paste(""Significance of"", gene, ""in"", dis, ""is"", expr.sig$pval,",exploratory,4e22,119
},exploratory,4e22,119
"mut.sig <- survivalAnalysisByMutation(dis, c(gene))",exploratory,4e22,119
"""(expression) and"", mut.sig$pval, ""(mutation)""))",exploratory,4e22,119
"gene = ""CDC27""",evaluation,4e22,119
library(MASS),import,584e20,120
"expr.sig <- survivalAnalysisByExpression(dis, c(gene))",exploratory,4e22,119
for (dis in tcga.cancer.types) {,exploratory,4e22,119
"print(paste(""Significance of"", gene, ""in"", dis, ""is"", expr.sig$pval,",exploratory,4e22,119
"mut.sig <- survivalAnalysisByMutation(dis, c(gene))",exploratory,4e22,119
"""(expression) and"", mut.sig$pval, ""(mutation)""))",exploratory,4e22,119
},exploratory,4e22,119
"gene = c(""CREBBP"", ""CDC27"", ""NF1"")",evaluation,4e22,119
"mut.sig <- survivalAnalysisByMutation(dis, c(gene))",exploratory,4e22,119
for (dis in tcga.cancer.types) {,exploratory,4e22,119
"""(mutation)""))",exploratory,4e22,119
},exploratory,4e22,119
"""in"", dis, ""is"", expr.sig$pval, ""(expression) and"", mut.sig$pval,",exploratory,4e22,119
"print(paste(""Significance of"", paste(gene, collapse = ""_""),",exploratory,4e22,119
"expr.sig <- survivalAnalysisByExpression(dis, c(gene))",exploratory,4e22,119
library(ggplot2),visualization,584e20,120
"gene = ""NF2""",evaluation,4e22,119
"""(expression) and"", mut.sig$pval, ""(mutation)""))",exploratory,4e22,119
"print(paste(""Significance of"", gene, ""in"", dis, ""is"", expr.sig$pval,",exploratory,4e22,119
"mut.sig <- survivalAnalysisByMutation(dis, c(gene))",exploratory,4e22,119
for (dis in tcga.cancer.types) {,exploratory,4e22,119
"expr.sig <- survivalAnalysisByExpression(dis, c(gene))",exploratory,4e22,119
},exploratory,4e22,119
"source(""./source/data_processing.R"")",import,584e20,120
"source(""../../bin/singleDrugAnalysis.R"")",import,481e20,121
"cor_matrix <- cor(analysis_df %>% mutate(Attrition = as.numeric(Attrition ==     ""Yes"")) %>% select_if(is.numeric))",modeling,584e20,120
"source(""analysis/utils.R"")",setup,364e19,122
max(cor_matrix[cor_matrix < 1 & cor_matrix > -1]),evaluation,584e20,120
require(reshape2),setup,7.5500000000000005e+21,123
"source(""analysis/analysis.R"")",setup,364e19,122
require(plyr),setup,7.5500000000000005e+21,123
require(ggplot2),setup,7.5500000000000005e+21,123
"source(""../../bin/ctrpSingleAgentScreens.R"")",not sure,481e20,121
corrplot::corrplot(cor_matrix),visualization,584e20,120
"source(""../../bin/ncatsSingleAgentScreens.R"")",not sure,481e20,121
"x <- lapply(analysis_df %>% select_if(is.factor), function(x) min(prop.table(table(x))))",data cleaning,584e20,120
x[x < 0.05],data cleaning,584e20,120
summarize_analyses <- function(analyses) {,setup,364e19,122
"list(promise_type_distribution = promise_type_distribution,",setup,364e19,122
group_by(promise_type) %>% summarize(count = sum(count)),setup,364e19,122
"group_by(promise_type, promise_expression_type) %>% summarize(count = sum(count))",setup,364e19,122
promise_type_distribution <- analyses$`promise-type` %>%,setup,364e19,122
promise_expression_type_distribution <- analyses$`promise-type` %>%,setup,364e19,122
},setup,364e19,122
promise_expression_type_distribution = promise_expression_type_distribution),setup,364e19,122
"fs = synapseQuery(""select name,id from entity where parentId=='syn5674273'"")",import,481e20,121
model_df[curVar] <- analysis_df[[curVar]],modeling,584e20,120
"summary(glm(formula(paste(""y ~ "", curVar)), model_df, family = binomial(link = ""logit"")))",modeling,584e20,120
"uni_models_list <- lapply(names(analysis_df[, -1]), function(curVar) {",modeling,584e20,120
"model_df <- data.frame(y = analysis_df$Attrition == ""Yes"")",modeling,584e20,120
}),modeling,584e20,120
"y = ""PROMISE COUNT"")",visualization,364e19,122
mode_expression_type <- analyses$promise_expression_type_distribution %>%,visualization,364e19,122
"geom_bar(position = ""stack"") + theme(axis.text.x = element_text(angle = 90,",visualization,364e19,122
"ggplot(aes(promise_expression_type, weight = count, fill = promise_type)) +",visualization,364e19,122
"list(mode_total = mode_total, promise_expression_type = promise_expression_type,",visualization,364e19,122
mode_total <- analyses$promise_expression_type_distribution %>%,visualization,364e19,122
promise_expression_type <- analyses$promise_expression_type_distribution %>%,visualization,364e19,122
"vjust = 0.5)) + labs(title = ""Promise mode distribution by expression slot type"",",visualization,364e19,122
"y = ""PROMISE COUNT + 1 (log10 scale)"")",visualization,364e19,122
visualize_analyses <- function(analyses) {,visualization,364e19,122
"fill = reorder(promise_expression_type, count))) +",visualization,364e19,122
"ggplot(aes(promise_type, weight = count, fill = reorder(promise_expression_type,",visualization,364e19,122
"count))) + geom_bar(position = ""fill"") + labs(title = ""Promise count"",",visualization,364e19,122
"ggplot(aes(promise_expression_type_classification, weight = count,",visualization,364e19,122
mode_expression_type = mode_expression_type),visualization,364e19,122
mutate(promise_expression_type_classification = classify_type(promise_expression_type)) %>%,visualization,364e19,122
"vjust = 0.5)) + labs(title = ""Promise mode distribution by expression slot type"",",visualization,364e19,122
"geom_bar(position = ""fill"") + theme(axis.text.x = element_text(angle = 90,",visualization,364e19,122
},visualization,364e19,122
"y = ""PROMISE COUNT + 1 (log10 scale)"")",visualization,364e19,122
"names(uni_models_list) <- names(analysis_df[, -1])",data cleaning,584e20,120
list(),communication,364e19,122
},communication,364e19,122
latex_analyses <- function(analyses) {,communication,364e19,122
uni_models_list,evaluation,584e20,120
"top_logit <- sort(sapply(uni_models_list, function(x) x$aic))",evaluation,584e20,120
},communication,364e19,122
"summarize_analyses, visualize_analyses, latex_analyses)",communication,364e19,122
"analyzer <- create_analyzer(""Argument Promise Mode"", combine_analyses,",communication,364e19,122
main <- function() {,communication,364e19,122
drive_analysis(analyzer),communication,364e19,122
"top_logit <- names(head(top_logit, 5))",exploratory,584e20,120
main(),not sure,364e19,122
library(ggplot2),setup,573e20,124
warnings(),exploratory,364e19,122
"source(""config.worldbank.R"", local = TRUE)",setup,573e20,124
"tbl <- table(analysis_df[[curVar]], analysis_df$Attrition)",evaluation,584e20,120
function(curVar) {,evaluation,584e20,120
}),evaluation,584e20,120
print(curVar),evaluation,584e20,120
"chi_sq_list <- lapply(names(analysis_df[, -1] %>% select_if(is.factor)),",evaluation,584e20,120
chisq.test(tbl),evaluation,584e20,120
print(tbl),evaluation,584e20,120
"datasets <- read.csv(paste0(metaPath, ""worldbank.metadata."",     refPeriod, "".csv""), header = T)",import,573e20,124
"cat(paste(""datasetX"", ""datasetY"", ""correlation"", ""pValue"", ""n"",     sep = "",""), file = paste0(summaryPath, ""correlation"", ""."",     refPeriod, "".csv""), sep = ""\n"")",export,573e20,124
"bdir = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/data_integration""",setup,364e19,122
setwd(bdir),setup,364e19,122
"names(chi_sq_list) <- names(analysis_df[, -1] %>% select_if(is.factor))",communication,584e20,120
library(reshape2),import,364e19,122
"cat(paste(""dataset"", ""time"", sep = "",""), file = paste0(summaryPath,     ""metadata"", ""."", refPeriod, "".csv""), sep = ""\n"")",export,573e20,124
"source(""../global_aes_out.R"")",setup,364e19,122
chi_sq_list,communication,584e20,120
"top_chi <- sort(sapply(chi_sq_list, function(x) x$p.value))",communication,584e20,120
"var_fn = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/pathogenic_variants/charged.PCA.r1.TCGAbarcode.merge.exon.ALL.vcf.samples.cleaned.expanded.AFcorrected.lowAF.sele.labeled.rare.cancer.pass.tsv""",setup,364e19,122
"top_chi <- names(head(top_chi, 5))",communication,584e20,120
datasetLength <- nrow(datasets),exploratory,573e20,124
"var = read.table(sep = ""\t"", header = T, quote = """", file = var_fn,     stringsAsFactors = FALSE)",import,364e19,122
"multi_logit <- glm(paste(""Attrition ~"", paste(unique(top_chi,     top_logit), collapse = "" + "")), data = analysis_df %>% mutate(Attrition = Attrition ==     ""Yes""), family = binomial(link = ""logit""))",modeling,584e20,120
"var$HGVSp_short = gsub("".*:"", """", var$HGVSp)",data cleaning,364e19,122
"var$HGVSp_short[var$HGVSp_short == ""p.""] = NA",data cleaning,364e19,122
summary(multi_logit),communication,584e20,120
"stepAIC(multi_logit, direction = ""both"")",not sure,584e20,120
"result_list <- mclapply(1, function(n) source(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis/Code/MacArthur_Analysis.R""))",modeling,593e20,125
"cat(""Starting out with matrix size dimension:"", ""\n"")",communication,364e19,122
library(gbm),import,584e20,120
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,3.1800000000000002e+22,126
dim(var),communication,364e19,122
"gbm_model <- gbm.fit(as.data.frame(analysis_df[, -1]), analysis_df$Attrition ==     ""Yes"")",modeling,584e20,120
"assoc_fn = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/association_test/assoc_results/PCA.pathVar.ExAC.r1.sites.vep.biallelic.combine.fisher.anno.v2.tsv""",import,364e19,122
"assoc_f = read.table(sep = ""\t"", header = T, file = assoc_fn,     fill = T, stringsAsFactors = FALSE)",import,364e19,122
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,3.1800000000000002e+22,126
"gbm_plot_data <- data.frame(Var = summary(gbm_model)$var, Influence = summary(gbm_model)$rel.inf)",evaluation,584e20,120
"assoc_f = assoc_f[assoc_f$ExAC_AC < 61, ]",data cleaning,364e19,122
"gbm_plot_data$Var <- factor(gbm_plot_data$Var, gbm_plot_data$Var[order(gbm_plot_data$Influence)])",visualization,584e20,120
"assoc_f = assoc_f[order(assoc_f$P, decreasing = F), ]",data cleaning,364e19,122
"assoc_f = assoc_f[!duplicated(assoc_f$HGVSg), ]",data cleaning,364e19,122
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,208e20,126
if (i == 1) {,import,593e20,125
results.all.df <- result_list[[1]]$value,import,593e20,125
for (i in 1:length(result_list)) {,import,593e20,125
},import,593e20,125
},import,593e20,125
"results.all.df <- rbind(results.all.df, result_list[[1]]$value)",import,593e20,125
else {,import,593e20,125
},import,593e20,125
"ggplot(gbm_plot_data) + geom_bar(aes(Var, Influence), stat = ""identity"") +     xlab("""") + ylab(""Rel Influence"") + coord_flip()",visualization,584e20,120
"assoc_f_brief = assoc_f[, c(""HGVSg"", ""Var"", ""OR"", ""P"")]",data cleaning,364e19,122
"colnames(assoc_f_brief) = paste(""ExAC_assoc"", colnames(assoc_f_brief),     sep = ""_"")",data cleaning,364e19,122
"colnames(assoc_f_brief)[1] = ""HGVSg""",data cleaning,364e19,122
args = (commandArgs(TRUE)),setup,803e20,127
"var_assoc = merge(var, assoc_f_brief, by = ""HGVSg"", all.x = T,     all.y = F)",data cleaning,364e19,122
"cat(""After merging association:"", ""\n"")",communication,364e19,122
dim(var_assoc),communication,364e19,122
"exp_score_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/expression_effect/2016-06-21_KH_pancan_exp_log2RSEM_all_uniq.tsv.gz""",setup,364e19,122
"exp_score = read.table(sep = ""\t"", header = F, file = gzfile(exp_score_f),     stringsAsFactors = FALSE)",import,364e19,122
"exp_quantile_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/expression_effect/2016-06-21_KH_pancan_exp_quantile_all_uniq.tsv.gz""",setup,364e19,122
"exp_quantile = read.table(sep = ""\t"", header = F, file = gzfile(exp_quantile_f),     stringsAsFactors = FALSE)",import,364e19,122
},modeling,208e20,126
"tune.svm3 <- function(trainset, groupingvar) {",modeling,208e20,126
R = min(objR$performances$error),modeling,208e20,126
"cost = 4^(-5:5), tune.control(sampling = ""cross""), kernel = ""radial"")",modeling,208e20,126
L = min(objL$performances$error),modeling,208e20,126
"objR <- tune.svm(groupingvar ~ ., data = trainset, gamma = 4^(-5:5),",modeling,208e20,126
"objL <- tune.svm(groupingvar ~ ., data = trainset, gamma = 4^(-5:5),",modeling,208e20,126
"cost = 4^(-5:5), tune.control(sampling = ""cross""), kernel = ""linear"")",modeling,208e20,126
"return(c(""radial"", objR, ""linear"", objL))",modeling,208e20,126
"""log2RSEM"", ""cancer"")",data cleaning,364e19,122
"colnames(exp_score) = c(""HUGO_Symbol"", ""bcr_patient_barcode"",",data cleaning,364e19,122
"setwd(""analysis"")",setup,208e20,126
library(glmpath),import,208e20,126
library(randomForest),import,208e20,126
"colnames(exp_quantile) = c(""HUGO_Symbol"", ""bcr_patient_barcode"",     ""expressionQuantile"", ""cancer"")",data cleaning,364e19,122
library(ica),import,208e20,126
"var_assoc_exp = merge(var_assoc, exp_score, by = c(""HUGO_Symbol"",     ""bcr_patient_barcode"", ""cancer""), all.x = T, all.y = F)",data cleaning,364e19,122
"var_assoc_exp_q = merge(var_assoc_exp, exp_quantile, by = c(""HUGO_Symbol"",     ""bcr_patient_barcode"", ""cancer""), all.x = T, all.y = F)",data cleaning,364e19,122
library(e1071),import,208e20,126
require(Hmisc),import,208e20,126
"cat(""After merging expression:"", ""\n"")",communication,364e19,122
library(osfr),import,208e20,126
library(tidyverse),import,208e20,126
library(stringr),import,208e20,126
dim(var_assoc_exp_q),communication,364e19,122
library(gridExtra),import,208e20,126
"var_assoc_exp_q$transcript_name = gsub("":.*"", """", var_assoc_exp_q$HGVSc)",data cleaning,364e19,122
library(RGraphics),import,208e20,126
"transcript_l_f = ""/Users/khuang/Box Sync/PhD/germline/pan8000_germline_clinical/reference_files/gene_transcript_length""",setup,364e19,122
"transcript_l = read.table(header = F, quote = """", sep = ""\t"",     fill = T, file = transcript_l_f, stringsAsFactors = FALSE)",import,364e19,122
"colnames(transcript_l) = c(""HUGO_Symbol"", ""transcript_name"",     ""transcript length"")",data cleaning,364e19,122
"var_assoc_exp_q_t = merge(var_assoc_exp_q, transcript_l, by = c(""HUGO_Symbol"",     ""transcript_name""), all.x = T, all.y = F)",data cleaning,364e19,122
"source(""Rcode/functions.r"")",import,208e20,126
"cat(""After merging transcript length:"", ""\n"")",communication,364e19,122
dim(var_assoc_exp_q_t),communication,364e19,122
"ai_missense_fn = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/LOH/LOH.missense.out.tsv""",setup,364e19,122
"ai_missense = read.table(sep = ""\t"", header = T, file = ai_missense_fn,     stringsAsFactors = FALSE)",import,364e19,122
"PMeta = osfr::path_file(""myxcv"")",import,208e20,126
"ai_truncation_fn = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/LOH/LOH.truncation.out.tsv""",setup,364e19,122
"ai_truncation = read.table(sep = ""\t"", header = T, file = ai_truncation_fn,     stringsAsFactors = FALSE)",import,364e19,122
RECREATEMINFILE = F,setup,208e20,126
"ai_truncation$binary_type = ""Truncation""",data cleaning,364e19,122
"groupingby = ""MITsoft""",data cleaning,208e20,126
"ai_missense$binary_type = ""Missense""",data cleaning,364e19,122
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,235e20,128
"ai_f = rbind(ai_missense, ai_truncation)",data cleaning,364e19,122
Npermutation = 250,setup,208e20,126
ai_f$TumorByNormalVAF = ai_f$TumorVAF/ai_f$NormalVAF,data cleaning,364e19,122
"ai_f_brief = ai_f[, c(3, 14:21)]",data cleaning,364e19,122
"colnames(ai_f_brief)[1] = ""Start""",data cleaning,364e19,122
"Name_project = ""Ro_testdata""",setup,208e20,126
siteSize = 2048,setup,235e20,128
"colnames(ai_f_brief)[3:7] = paste(""LOH"", colnames(ai_f_brief)[3:7],     sep = ""_"")",data cleaning,364e19,122
"source(""Rcode/inputdata.r"")",setup,208e20,126
"treatment = ""Copper""",setup,235e20,128
"var_assoc_exp_q_t_ai = merge(var_assoc_exp_q_t, ai_f_brief, by = c(""Sample"",     ""Start""), all.x = T, all.y = F)",data cleaning,364e19,122
"strand = ""both""",setup,235e20,128
"cat(""After merging LOH:"", ""\n"")",communication,364e19,122
dim(var_assoc_exp_q_t_ai),communication,364e19,122
"Outputs = paste(WD, Projects_metadata$Folder_path, ""Routputs"",     sep = ""/"")",export,208e20,126
"clin_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/TCGA_data/clinical/PanCan_ClinicalData_V4_wAIM.txt""",setup,364e19,122
"clin = read.table(header = T, quote = """", sep = ""\t"", fill = T,     file = clin_f, stringsAsFactors = FALSE)",import,364e19,122
onlinemin = Outputs,export,208e20,126
op <- options(digits.secs = 3),data cleaning,593e20,125
"if (WD == ""https:/"") Outputs = paste(""../Routputs"", Projects_metadata$Folder_path,     sep = ""/"")",setup,208e20,126
"dir.create(Outputs, recursive = TRUE)",export,208e20,126
randN <- Sys.time(),data cleaning,593e20,125
plot.path = Outputs,export,208e20,126
"randN <- gsub(""-"", """", randN, fixed = TRUE)",setup,593e20,125
"source(""Rcode/checkmetadata.r"")",setup,208e20,126
"source(""Rcode/animal_groups.r"")",import,208e20,126
"source(""Rcode/create_minfile.r"")",setup,208e20,126
"metadata$Exclude_data[is.na(metadata$Exclude_data)] <- ""include""",data cleaning,208e20,126
"metadata = metadata %>% filter(Exclude_data != ""exclude"")",data cleaning,208e20,126
"randN <- gsub("" "", """", randN, fixed = TRUE)",data cleaning,593e20,125
MIN_data = MIN_data %>% filter(ID %in% metadata$ID),data cleaning,208e20,126
"randN <- gsub("":"", """", randN, fixed = TRUE)",data cleaning,593e20,125
"source(""Rcode/multidimensional_analysis_prep.R"")",import,208e20,126
"randN <- gsub(""."", """", randN, fixed = TRUE)",setup,593e20,125
Multi_datainput_m$groupingvar = as.numeric(Multi_datainput_m$groupingvar),data cleaning,208e20,126
"save(results, file = paste(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis/Results/McArthur_MC_"",     randN, "".Rda"", sep = """"))",data cleaning,593e20,125
RF_selec = Multi_datainput_m,setup,208e20,126
"save(results, file = paste(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis/Results/McArthur_MC_"",     randN, "".Rda"", sep = """"))",export,593e20,125
"clin = clin[, -c(38:39)]",data cleaning,364e19,122
colnames(clin)[colnames(clin) %in% colnames(var_assoc_exp_q_t_ai)],data cleaning,364e19,122
"colnames(clin)[2] = ""cancer""",data cleaning,364e19,122
"RF_selec = RF_selec[order(RF_selec$groupingvar), ]",data cleaning,208e20,126
"colnames(clin)[38] = ""AIM_ethnicity""",data cleaning,364e19,122
"germ_clin = merge(var_assoc_exp_q_t_ai, clin, by = c(""bcr_patient_barcode"",     ""cancer""), all.x = T, all.y = F)",data cleaning,364e19,122
temp = RF_selec %>% select(-groupingvar),data cleaning,208e20,126
"cat(""After merging clinical data:"", ""\n"")",communication,364e19,122
dim(germ_clin),communication,364e19,122
"truncation_f_PCGP = paste(""/Users/khuang/Box Sync/PhD/germline/pan8000_germline_clinical/CharGer_analysis/pan8000/05_07_2016/05_07_2016_pan8000_MAF0.05_truncation_charger_PCGP.txt"",    sep = """")",setup,364e19,122
cfreq <- colSums(temp),exploratory,208e20,126
library(parallel),setup,593e20,125
"E1 = names(temp[, cfreq == 0])",data cleaning,208e20,126
"missense_f_PCGP = paste(""/Users/khuang/Box Sync/PhD/germline/pan8000_germline_clinical/CharGer_analysis/pan8000/05_07_2016/05_07_2016_pan8000_MAF0.05_missense_charger_PCGP.txt"",     sep = """")",setup,364e19,122
"trun_PCGP = read.table(header = T, quote = """", sep = ""\t"", fill = T,     file = truncation_f_PCGP)",import,364e19,122
"RF_selec = RF_selec[, !names(RF_selec) %in% c(E1)]",data cleaning,208e20,126
"miss_PCGP = read.table(header = T, quote = """", sep = ""\t"", fill = T,     file = missense_f_PCGP)",import,364e19,122
set.seed(66),setup,208e20,126
germ_clin$PCGP = FALSE,data cleaning,364e19,122
"germ_clin[germ_clin$HGVSg %in% trun_PCGP$HGVSg, ]$PCGP = TRUE",data cleaning,364e19,122
"germ_clin[germ_clin$HGVSg %in% miss_PCGP$HGVSg, ]$PCGP = TRUE",data cleaning,364e19,122
xx = as.matrix(RF_selec %>% select(-groupingvar)),data cleaning,208e20,126
"cat(""After merging PCGP:"", ""\n"")",communication,364e19,122
dim(germ_clin),communication,364e19,122
yy = as.numeric(RF_selec$groupingvar) - 1,data cleaning,208e20,126
"pp <- rep(NA, length(yy))",setup,208e20,126
library(readr),setup,261e20,129
"ppsvm <- rep(NA, length(yy))",setup,208e20,126
"ppsvm_L <- rep(NA, length(yy))",setup,208e20,126
"sgd_64 <- read_csv(""~/Documents/Projects/fish/analysis/training/detect_batch_sgd_64.csv"",     col_names = FALSE)",import,261e20,129
num_per_class <- nrow(RF_selec)/2,setup,208e20,126
before <- Sys.time(),setup,208e20,126
best.parameters = bestk[[2]],evaluation,208e20,126
best.parameters_L = bestk[[11]],evaluation,208e20,126
bestdex <- 2,evaluation,208e20,126
kernel = bestk[[1]]),evaluation,208e20,126
"pred <- predict(fit, newx = xx[hold_out, ], s = bestlambda,",evaluation,208e20,126
"fit <- glmpath::glmpath(x = xx[-hold_out, ], y = yy[-hold_out],",evaluation,208e20,126
"hold_out = c(k, k + num_per_class)",evaluation,208e20,126
"kernel = ""linear"")",evaluation,208e20,126
},evaluation,208e20,126
"type = ""link"", mode = ""lambda"")",evaluation,208e20,126
bestdex <- which.min(fit$bic),evaluation,208e20,126
},evaluation,208e20,126
"family = binomial, max.arclength = 1)",evaluation,208e20,126
"], cost = best.parameters_L$cost, gamma = best.parameters_L$gamma,",evaluation,208e20,126
bestlambda <- fit$lambda[bestdex],evaluation,208e20,126
"svm.model <- svm(yy[-hold_out] ~ ., data = xx[-hold_out,",evaluation,208e20,126
"ppsvm_L[hold_out] = predict(svm.model_L, xx[hold_out, ])",evaluation,208e20,126
for (k in 1:num_per_class) {,evaluation,208e20,126
"bestk = tune.svm3(RF_selec[-hold_out], as.data.frame(yy[-hold_out]))",evaluation,208e20,126
"ppsvm[hold_out] = predict(svm.model, xx[hold_out, ])",evaluation,208e20,126
pp[hold_out] = pred,evaluation,208e20,126
"], cost = best.parameters$cost, gamma = best.parameters$gamma,",evaluation,208e20,126
"svm.model_L <- svm(yy[-hold_out] ~ ., data = xx[-hold_out,",evaluation,208e20,126
if (bestdex == 1) {,evaluation,208e20,126
duration = Sys.time() - before,evaluation,208e20,126
true_class <- sign(yy - 0.5),modeling,208e20,126
pred_class <- sign(pp),evaluation,208e20,126
pred_classsvm <- sign(ppsvm),evaluation,208e20,126
pred_classsvm_L <- sign(ppsvm_L),evaluation,208e20,126
library(dplyr),setup,478e20,130
"prediction_res1 = table(true_class, pred_class)",modeling,208e20,126
"prediction_res2 = table(true_class, pred_classsvm)",evaluation,208e20,126
library(quantreg),setup,478e20,130
"prediction_res3 = table(true_class, pred_classsvm_L)",evaluation,208e20,126
library(ggplot2),setup,478e20,130
ACURRACY = NA,setup,208e20,126
args <- commandArgs(trailingOnly = TRUE),setup,478e20,130
temp = classAgreement(prediction_res1),evaluation,208e20,126
"data_dir <- ""../../data/ideology_analysis/""",import,478e20,130
"ACURRACY = c(ACURRACY, temp$kappa)",modeling,208e20,126
temp = classAgreement(prediction_res2),evaluation,208e20,126
"ACURRACY = c(ACURRACY, temp$kappa)",evaluation,208e20,126
"somatic_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/TCGA_data/somatic/mc3.v0.2.8.PUBLIC.maf.gene_vclass_HGVSp_sample.gz""",setup,364e19,122
temp = classAgreement(prediction_res3),evaluation,208e20,126
"somatic = read.table(header = T, quote = """", sep = ""\t"", file = gzfile(somatic_f),     stringsAsFactors = FALSE)",import,364e19,122
"ACURRACY = c(ACURRACY, temp$kappa)",evaluation,208e20,126
ACURRACYreal <- ACURRACY,evaluation,208e20,126
"colnames(somatic) = c(""HUGO_Symbol"", ""Somatic_Variant_Classification"",     ""TumorSample"", ""Somatic_HGVSp"")",data cleaning,364e19,122
"res_dir <- paste0(data_dir, ""bootstrap_results/"")",setup,478e20,130
"Acc_sampled = c(""log_regr"", ""svm_radial"")",setup,208e20,126
"somatic$bcr_patient_barcode = gsub(""(^TCGA-[A-Z0-9][A-Z0-9]-[A-Z0-9][A-Z0-9][A-Z0-9][A-Z0-9])-.*"",     ""\\1"", somatic$TumorSample)",data cleaning,364e19,122
"somatic = somatic[somatic$Somatic_Variant_Classification %in%     c(""Frame_Shift_Del"", ""Frame_Shift_Ins"", ""In_Frame_Del"", ""In_Frame_Ins"")]",data cleaning,364e19,122
"somatic_class_agg = aggregate(somatic[c(""Somatic_Variant_Classification"",     ""Somatic_HGVSp"")], by = somatic[c(""TumorSample"", ""HUGO_Symbol"",     ""bcr_patient_barcode"")], paste, collapse = "","")",data cleaning,364e19,122
"germ_clin_so = merge(germ_clin, somatic_class_agg, by = c(""bcr_patient_barcode"",     ""HUGO_Symbol""), all.x = T, all.y = F)",data cleaning,364e19,122
Npermutation = 2,communication,208e20,126
"cat(""After merging somatic mutation:"", ""\n"")",communication,364e19,122
dim(germ_clin_so),communication,364e19,122
"quantiles <- c(seq(0.5, 0.9, by = 0.1), seq(0.91, 0.97, by = 0.01))",setup,478e20,130
before <- Sys.time(),setup,208e20,126
bestlambda <- fit$lambda[bestdex],setup,208e20,126
groupingvar = as.data.frame(yy[-hold_out]),setup,208e20,126
xx = as.matrix(RF_selec %>% select(-groupingvar)),setup,208e20,126
yy = as.numeric(RF_selec$groupingvar) - 1,setup,208e20,126
"ppsvm_L <- rep(NA, length(yy))",setup,208e20,126
bestdex <- 2,setup,208e20,126
"type = ""link"", mode = ""lambda"")",setup,208e20,126
temp = classAgreement(prediction_res3),setup,208e20,126
best.parameters_L = objL$best.parameters,setup,208e20,126
"ppsvm_L[hold_out] = predict(svm.model_L, xx[hold_out,",setup,208e20,126
pred_class <- sign(pp),setup,208e20,126
temp = classAgreement(prediction_res1),setup,208e20,126
"ACURRACY = c(ACURRACY, temp$kappa)",setup,208e20,126
for (i in 1:Npermutation) {,setup,208e20,126
Multi_datainput_m$groupingvar = as.numeric(sample(Multi_datainput_m$groupingvar)),setup,208e20,126
for (k in 1:num_per_class) {,setup,208e20,126
if (bestdex == 1) {,setup,208e20,126
"svm.model_L <- svm(yy[-hold_out] ~ ., data = xx[-hold_out,",setup,208e20,126
"pp <- rep(NA, length(yy))",setup,208e20,126
num_per_class <- nrow(RF_selec)/2,setup,208e20,126
RF_selec = Multi_datainput_m,setup,208e20,126
before <- Sys.time(),setup,208e20,126
"prediction_res3 = table(true_class, pred_classsvm_L)",setup,208e20,126
},setup,208e20,126
bestdex <- which.min(fit$bic),setup,208e20,126
"gamma = 4^(-5:5), cost = 4^(-5:5), tune.control(sampling = ""cross""),",setup,208e20,126
"], cost = best.parameters_L$cost, gamma = best.parameters_L$gamma,",setup,208e20,126
ACURRACY = NA,setup,208e20,126
print(i),setup,208e20,126
"kernel = ""radial"")",setup,208e20,126
},setup,208e20,126
true_class <- sign(yy - 0.5),setup,208e20,126
]),setup,208e20,126
"objL <- tune.svm(groupingvar ~ ., data = RF_selec[-hold_out],",setup,208e20,126
"RF_selec = RF_selec[order(RF_selec$groupingvar), ]",setup,208e20,126
"hold_out = c(k, k + num_per_class)",setup,208e20,126
"pred <- predict(fit, newx = xx[hold_out, ], s = bestlambda,",setup,208e20,126
"ACURRACY = c(ACURRACY, temp$kappa)",setup,208e20,126
"Acc_sampled = rbind(Acc_sampled, ACURRACY[-1])",setup,208e20,126
pred_classsvm_L <- sign(ppsvm_L),setup,208e20,126
"fit <- glmpath::glmpath(x = xx[-hold_out, ], y = yy[-hold_out],",setup,208e20,126
pp[hold_out] = pred,setup,208e20,126
},setup,208e20,126
"prediction_res1 = table(true_class, pred_class)",setup,208e20,126
"kernel = ""linear"")",setup,208e20,126
duration = Sys.time() - before,setup,208e20,126
"family = binomial, max.arclength = 1)",setup,208e20,126
"germ_clin_so$var = paste(germ_clin_so$HUGO_Symbol, germ_clin_so$HGVSp_short)",data cleaning,364e19,122
"somatic_colocalized_var = somatic[paste(somatic$HUGO_Symbol,     somatic$Somatic_HGVSp) %in% germ_clin_so$var, ]",data cleaning,364e19,122
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,1.7900000000000001e+22,131
"somatic_occurence = data.frame(table(paste(somatic_colocalized_var$HUGO_Symbol,     somatic_colocalized_var$Somatic_HGVSp)))",data cleaning,364e19,122
beepr::beep(),modeling,208e20,126
"colnames(somatic_occurence) = c(""var"", ""colocalized_somatic_mutation_count"")",data cleaning,364e19,122
"germ_clin_so = merge(germ_clin_so, somatic_occurence, by = ""var"",     all.x = T, all.y = F)",data cleaning,364e19,122
germ_clin_so$colocalized_somatic_mutation_count[is.na(germ_clin_so$colocalized_somatic_mutation_count)] = 0,data cleaning,364e19,122
"germ_clin_so = germ_clin_so[, -which(colnames(germ_clin_so) ==     ""var"")]",data cleaning,364e19,122
"print(""time to perform the analysis:"")",communication,208e20,126
"cat(""Ending with matrix size dimension:"", ""\n"")",communication,364e19,122
print(Sys.time() - b),communication,208e20,126
dim(germ_clin_so),communication,364e19,122
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.7900000000000001e+22,131
"hist(as.numeric(Acc_sampled[-1, 1]), breaks = (c(-11:10)/21 +",communication,208e20,126
"0.5/21) * 2, main = ""Jhuang_6smallwindows_L1regLregression"")",communication,208e20,126
"cat(""Loading data...\n"")",not sure,478e20,130
out[[i]] <- mods,not sure,478e20,130
"if (args[1] == ""base"") {",not sure,478e20,130
"load(""../../data/ideology_analysis/ideology_analysis_input.RData"")",not sure,478e20,130
"dat <- filter(df, is.element(left_id, sc))",not sure,478e20,130
i <- 1,not sure,478e20,130
for (file in out_files) {,not sure,478e20,130
"quant_reg <- function(q, dat) {",not sure,478e20,130
"mods <- lapply(mods, coef)",not sure,478e20,130
else {,not sure,478e20,130
"print(paste(""Processed"", file))",not sure,478e20,130
"save(out, file = paste0(data_dir, ""regression_results.RData""))",not sure,478e20,130
"else if (args[1] == ""bootstrap"") {",not sure,478e20,130
"cat(paste0(""Finished iteration "", i, ""\n""))",not sure,478e20,130
"cat(paste0(""Size: "", nrow(dat), ""\n""))",not sure,478e20,130
"tau = q, method = ""pfn"")",not sure,478e20,130
"cat(paste0(""Done with "", q, ""\n""))",not sure,478e20,130
},not sure,478e20,130
"mods <- lapply(mods, coef)",not sure,478e20,130
"load(paste0(res_dir, file))",not sure,478e20,130
},not sure,478e20,130
"final_out <- do.call(cbind, outputs)",not sure,478e20,130
if (length(args) > 0) {,not sure,478e20,130
"sc <- sample(clusters, nc, replace = TRUE)",not sure,478e20,130
print(length(out_files)),not sure,478e20,130
},not sure,478e20,130
nc <- length(clusters),not sure,478e20,130
"outputs <- vector(mode = ""list"", length = length(out_files))",not sure,478e20,130
"load(paste0(res_dir, ""quantreg_mods.RData""))",not sure,478e20,130
B <- as.integer(args[3]),not sure,478e20,130
return(mod),not sure,478e20,130
},not sure,478e20,130
"mods <- lapply(quantiles, quant_reg, dat = df)",not sure,478e20,130
"out <- vector(mode = ""list"", length = B)",not sure,478e20,130
for (i in 1:B) {,not sure,478e20,130
"save(mods, file = paste0(res_dir, ""quantreg_mods.RData""))",not sure,478e20,130
},not sure,478e20,130
"out <- list(bootstrap_results = final_out, base_model = base_model_coefs)",not sure,478e20,130
no <- as.integer(args[2]),not sure,478e20,130
i <- i + 1,not sure,478e20,130
},not sure,478e20,130
"base_model_coefs <- sapply(mods, function(x) x[2])",not sure,478e20,130
},not sure,478e20,130
clusters <- unique(df$left_id),not sure,478e20,130
"save(out, file = paste0(res_dir, ""bs_out_"", no, "".RData""))",not sure,478e20,130
outputs[[i]] <- op,not sure,478e20,130
"mod <- rq(adjusted_alignment_score ~ ideology_dist, data = dat,",not sure,478e20,130
"op <- sapply(out, function(x) do.call(cbind, x)[2, ])",not sure,478e20,130
print(dim(final_out)),not sure,478e20,130
"mods <- lapply(quantiles, quant_reg, dat = dat)",not sure,478e20,130
"stop(""Invalid mode argument"")",not sure,478e20,130
} else {,not sure,478e20,130
"out_files <- list.files(path = res_dir, pattern = ""bs_out_"")",not sure,478e20,130
"fn = ""out/PCA_pathVar_integrated.tsv""",setup,364e19,122
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.7900000000000001e+22,131
INTERACTIVE = FALSE,setup,478e20,130
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.7900000000000001e+22,131
"write.table(germ_clin_so, quote = F, sep = ""\t"", file = fn, row.names = F)",export,364e19,122
"abline(v = ACURRACYreal[2], col = ""Red"")",visualization,208e20,126
"abline(v = 0, col = ""blue"")",visualization,208e20,126
"hist(as.numeric(Acc_sampled[-1, 2]), breaks = (c(-11:10)/21 +",visualization,208e20,126
"0.5/21) * 2, main = ""Jhuang_6smallwindows_SVMlin"")",visualization,208e20,126
duplicated_sample = germ_clin_so$bcr_patient_barcode[duplicated(germ_clin_so$bcr_patient_barcode)],data cleaning,364e19,122
"mutate(quantile_fctr = as.factor(quantile), significant = as.factor(ifelse(upper <",not sure,478e20,130
if (INTERACTIVE) {,not sure,478e20,130
"ggplot(filter(pdat, quantile < 0.98)) + geom_segment(aes(x = quantile_fctr,",not sure,478e20,130
"0, 1, 0)))",not sure,478e20,130
"upper = apply(out$bootstrap_results, 1, quantile, 0.975),",not sure,478e20,130
"load(paste0(data_dir, ""regression_results.RData""))",not sure,478e20,130
"scale_color_manual(values = c(cbPalette[1], ""black"")) +",not sure,478e20,130
"guides(color = FALSE) + geom_hline(aes(yintercept = 0),",not sure,478e20,130
"xlab(""Quantile"") + plot_theme",not sure,478e20,130
"ggsave(""../../paper/figures/quantile_regression.png"", width = p_width,",not sure,478e20,130
"lower = apply(out$bootstrap_results, 1, quantile, 0.025))) %>%",not sure,478e20,130
},not sure,478e20,130
"linetype = 2, color = ""grey"") + coord_flip() + ylab(""Quantile Regression Coefficient"") +",not sure,478e20,130
"pdat <- tbl_df(data.frame(coefs = out$base_model, quantile = quantiles,         height = 0.8 * p_width)",not sure,478e20,130
"geom_point(aes(x = quantile_fctr, y = coefs), size = 3) +",not sure,478e20,130
"source(""../plot_theme.R"")",not sure,478e20,130
"xend = quantile_fctr, y = lower, yend = upper), size = 1) +",not sure,478e20,130
"abline(v = ACURRACYreal[4], col = ""Red"")",visualization,208e20,126
"germ_clin_so_ds = germ_clin_so[germ_clin_so$bcr_patient_barcode %in%     duplicated_sample, ]",data cleaning,364e19,122
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.7900000000000001e+22,131
"abline(v = 0, col = ""blue"")",visualization,208e20,126
"k1 <- sum(as.numeric(Acc_sampled[-1, 1]) >= ACURRACYreal[2])",visualization,208e20,126
"fn = ""out/PCA_pathVar_integrated_multi-var_carrier.tsv""",setup,364e19,122
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,1.7900000000000001e+22,131
"write.table(germ_clin_so_ds, quote = F, sep = ""\t"", file = fn,     row.names = F)",export,364e19,122
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,1.7900000000000001e+22,131
"k2 <- sum(as.numeric(Acc_sampled[-1, 2]) >= ACURRACYreal[4])",evaluation,208e20,126
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,1.7900000000000001e+22,131
"print(zapsmall(binconf(k1, nrow(Acc_sampled) - 1, method = ""all"")))",evaluation,208e20,126
"print(zapsmall(binconf(k2, nrow(Acc_sampled) - 1, method = ""all"")))",communication,208e20,126
"print(zapsmall(binconf(k2, nrow(Acc_sampled) - 1, method = ""all"")))",communication,208e20,126
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,1.7900000000000001e+22,131
duplicated_HGVSg = germ_clin_so$HGVSg[duplicated(germ_clin_so$HGVSg)],data cleaning,364e19,122
"germ_clin_so_dv = germ_clin_so[germ_clin_so$HGVSg %in% duplicated_HGVSg, ]",data cleaning,364e19,122
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,1.7900000000000001e+22,131
"fn = ""out/PCA_pathVar_integrated_multi-carrier_var.tsv""",setup,364e19,122
"write.table(germ_clin_so_dv, quote = F, sep = ""\t"", file = fn,     row.names = F)",export,364e19,122
"germ_clin_so_ComHet = germ_clin_so[!is.na(germ_clin_so$Somatic_Variant_Classification), ]",data cleaning,364e19,122
rm(list = ls()),data cleaning,1.7900000000000001e+22,131
"fn = ""out/PCA_pathVar_integrated_comHet.tsv""",setup,364e19,122
"write.table(germ_clin_so_ComHet, quote = F, sep = ""\t"", file = fn,     row.names = F)",export,364e19,122
"objR <- tune.svm(groupingvar ~ ., data = trainset, gamma = 4^(-5:5),",modeling,208e20,126
"cost = 4^(-5:5), tune.control(sampling = ""cross""), kernel = ""linear"")",modeling,208e20,126
"objL <- tune.svm(groupingvar ~ ., data = trainset, gamma = 4^(-5:5),",modeling,208e20,126
R = min(objR$performances$error),modeling,208e20,126
"return(c(""radial"", objR, ""linear"", objL))",modeling,208e20,126
},modeling,208e20,126
L = min(objL$performances$error),modeling,208e20,126
"tune.svm3 <- function(trainset, groupingvar) {",modeling,208e20,126
"cost = 4^(-5:5), tune.control(sampling = ""cross""), kernel = ""radial"")",modeling,208e20,126
gc(),data cleaning,1.7900000000000001e+22,131
set.seed(231),setup,1.7900000000000001e+22,131
"kpg <- keggPathwayGraphs(""eco"", relPercThresh = 0, updateCache = TRUE,     verbose = TRUE)",communication,208e20,126
ncores = 40,setup,1.7900000000000001e+22,131
"kpg <- setEdgeWeights(kpg, edgeTypeAttr = ""subtype"", edgeWeightByType = list(activation = 1,     inhibition = -1, expression = 1, repression = -1), defaultWeight = 0)",modeling,208e20,126
"core <- read.csv(""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/best_strains_DEseq.csv"",     header = TRUE)",import,208e20,126
"source(""butler_nickerson_analysis.R"")",setup,1.7900000000000001e+22,131
"source(""butler_tables.R"")",setup,1.7900000000000001e+22,131
"colnames(core)[1] <- ""bnum""",data cleaning,208e20,126
"core <- core[complete.cases(core), ]",data cleaning,208e20,126
"kpn <- keggPathwayNames(""eco"")",modeling,208e20,126
fc <- core$log2FoldChange[core$padj <= 0.01],evaluation,208e20,126
"names(fc) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",communication,208e20,126
pv <- core$padj[core$padj <= 0.01],evaluation,208e20,126
"names(pv) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",communication,208e20,126
"kpg <- setNodeWeights(kpg, weights = alphaMLG(pv), defaultWeight = 1)",modeling,208e20,126
"ref <- paste0(""eco:"", core$bnum)",communication,208e20,126
"peRes <- pe(x = fc, graphs = kpg, ref = ref, nboot = 200, verbose = TRUE)",modeling,208e20,126
"s <- Summary(peRes, pathNames = kpn, totalAcc = FALSE, totalPert = FALSE,     pAcc = FALSE, order.by = ""pPert"")",communication,208e20,126
library(ncdf4),import,2.3800000000000002e+22,132
library(here),import,2.3800000000000002e+22,132
library(tidyverse),import,2.3800000000000002e+22,132
"p <- peRes@pathways[[""path:eco00650""]]",communication,208e20,126
library(stringr),import,2.3800000000000002e+22,132
"g <- layoutGraph(p@map, layoutType = ""dot"")",visualization,208e20,126
graphRenderInfo(g) <- list(fixedsize = FALSE),visualization,208e20,126
edgeRenderInfo(g) <- peEdgeRenderInfo(p),visualization,208e20,126
nodeRenderInfo(g) <- peNodeRenderInfo(p),visualization,208e20,126
renderGraph(g),visualization,208e20,126
"txx = nc_open(here(""analysis"", ""data"", ""index-ts"", ""txx.nc""))",import,2.3800000000000002e+22,132
"library(""topGO"")",import,208e20,126
"gt37 = nc_open(here(""analysis"", ""data"", ""days-above-T"", ""Number_of_days_above_37degC.nc""),     write = TRUE)",import,2.3800000000000002e+22,132
"library(""org.EcK12.eg.db"")",import,208e20,126
"results <- ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/""",setup,208e20,126
"goDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/gene_association.ecocyc.csv"",     row.names = 1, stringsAsFactors = F)",import,208e20,126
"myDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/media_all_genes_edited.csv"",     row.names = 1, stringsAsFactors = F)",import,208e20,126
"txx_timevals = ncvar_get(txx, varid = ""time"") %>% as.character()",data cleaning,2.3800000000000002e+22,132
FCok <- which(abs(myDat$log2FoldChange) > 2),data cleaning,208e20,126
"str_sub(txx_timevals, start = 7, end = 8) = ""15""",data cleaning,2.3800000000000002e+22,132
txx_timevals = txx_timevals %>% as.numeric(),data cleaning,2.3800000000000002e+22,132
"gt37_time = ncvar_def(""time"", ""day as %Y%m%d.%f"", gt37$dim$time,     missval = NA, longname = ""Time"")",data cleaning,2.3800000000000002e+22,132
FDRok <- which(myDat$padj < 0.05),evaluation,208e20,126
"gt37 = ncvar_add(gt37, gt37_time)",data cleaning,2.3800000000000002e+22,132
"DE <- intersect(FDRok, FCok)",evaluation,208e20,126
"ncvar_put(gt37, varid = ""time"", txx_timevals, start = 1, count = -1)",data cleaning,2.3800000000000002e+22,132
geneNam <- as.vector(myDat$Name),communication,208e20,126
DEgeneNam <- as.vector(myDat$Name[DE]),communication,208e20,126
geneNam2 <- geneNam[which(geneNam %in% goDat$Symbol)],data cleaning,208e20,126
DEgeneNam2 <- DEgeneNam[which(DEgeneNam %in% goDat$Symbol)],data cleaning,208e20,126
"goDat2 <- goDat[which(goDat$Symbol %in% geneNam2), ]",data cleaning,208e20,126
"EcoliGenes <- rep(0, length(geneNam2))",setup,208e20,126
"source(""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/global_aes_out.R"")",setup,2.3800000000000002e+22,132
EcoliGenes[which(geneNam2 %in% DEgeneNam2)] <- 1,data cleaning,208e20,126
"source(""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/dependency_files.R"")",setup,2.3800000000000002e+22,132
names(EcoliGenes) <- geneNam2,data cleaning,208e20,126
"fit = glm(formula = model, data = z, family = binomial(link = ""logit""))",modeling,2.3800000000000002e+22,132
if (is.na(covar) | is.null(covar) | nchar(covar) == 0) {,modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
fit,modeling,2.3800000000000002e+22,132
"if (ytype == ""B"")",modeling,2.3800000000000002e+22,132
"fit = glm(formula = model, data = z, family = gaussian(link = ""identity""))",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
"model = formula(paste(trait, ""~"", variant, ""+"", covar))",modeling,2.3800000000000002e+22,132
"myglm = function(z, trait, variant, covar = NA, ytype) {",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
else {,modeling,2.3800000000000002e+22,132
"if (ytype == ""Q"")",modeling,2.3800000000000002e+22,132
"model = formula(paste(trait, ""~"", variant))",modeling,2.3800000000000002e+22,132
DEcoli <- names(EcoliGenes)[which(EcoliGenes == 1)],data cleaning,208e20,126
"p = p + geom_violin(aes_string(x = xi, y = yi, fill = xi),",visualization,2.3800000000000002e+22,132
"p = p + labs(x = paste(xi, ""pathVarPline Variant""), y = yi) +",visualization,2.3800000000000002e+22,132
"alpha = 0.5) + guides(fill = FALSE, color = FALSE)",visualization,2.3800000000000002e+22,132
"p = p + facet_grid(as.formula(paste("". ~"", covi)))",visualization,2.3800000000000002e+22,132
theme_bw(),visualization,2.3800000000000002e+22,132
"plot_violin = function(y, yi, xi, covi) {",visualization,2.3800000000000002e+22,132
"axis.text.x = element_text(colour = ""black"", size = 14),",visualization,2.3800000000000002e+22,132
"axis.text.y = element_text(colour = ""black"", size = 14),",visualization,2.3800000000000002e+22,132
"p = p + theme(text = element_text(colour = ""black"", size = 16),",visualization,2.3800000000000002e+22,132
p,visualization,2.3800000000000002e+22,132
"p = p + guides(fill = FALSE, color = FALSE)",visualization,2.3800000000000002e+22,132
},visualization,2.3800000000000002e+22,132
"ggsave(file = fn, width = n_facet, useDingbats = FALSE)",visualization,2.3800000000000002e+22,132
"dat = y[, c(yi, xi, covi)]",visualization,2.3800000000000002e+22,132
"p = p + geom_jitter(aes_string(x = xi, y = yi, color = xi),",visualization,2.3800000000000002e+22,132
"strip.text = element_text(size = 8, angle = 90))",visualization,2.3800000000000002e+22,132
p = ggplot(data = dat),visualization,2.3800000000000002e+22,132
"sep = ""_"")",visualization,2.3800000000000002e+22,132
"fn = paste(pd, yi, ""by"", xi, ""cross"", covi, ""violin.pdf"",",visualization,2.3800000000000002e+22,132
"dat[, 1] = as.numeric(dat[, 1])",visualization,2.3800000000000002e+22,132
"n_facet = length(unique(dat[, covi]))",visualization,2.3800000000000002e+22,132
alpha = 0.2),visualization,2.3800000000000002e+22,132
FacGenes <- as.factor(EcoliGenes),data cleaning,208e20,126
"goBP <- goDat2[which(goDat2$category == ""P""), ]",data cleaning,208e20,126
"goMF <- goDat2[which(goDat2$category == ""F""), ]",data cleaning,208e20,126
},modeling,2.3800000000000002e+22,132
"xi = ""Freq""",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
"run_glm = function(data = NULL, covi = """") {",modeling,2.3800000000000002e+22,132
if (xi %in% rownames(fit)),modeling,2.3800000000000002e+22,132
"glm = try(myglm(data_g, yi, xi, covi, ytype))",modeling,2.3800000000000002e+22,132
row_stat = NULL,modeling,2.3800000000000002e+22,132
else {,modeling,2.3800000000000002e+22,132
coeff = coefficients(glm)[[2]],modeling,2.3800000000000002e+22,132
return(row_stat),modeling,2.3800000000000002e+22,132
"test = ""Chisq""",modeling,2.3800000000000002e+22,132
"])), coeff, covi))",modeling,2.3800000000000002e+22,132
"else if (ytype == ""B"") {",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
next,modeling,2.3800000000000002e+22,132
"(row_stat = cbind(yi, ytype, xi, as.data.frame(t(fit[xi,",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
"yi = ""Contribution""",modeling,2.3800000000000002e+22,132
data_g = data,modeling,2.3800000000000002e+22,132
"ytype = ""Q""",modeling,2.3800000000000002e+22,132
"test = ""F""",modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
fit = as.matrix(fit),modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
""" xi ="", xi, "" covi ="", covi, ""\n""))",modeling,2.3800000000000002e+22,132
else {,modeling,2.3800000000000002e+22,132
"if (class(glm)[1] == ""try-error"") {",modeling,2.3800000000000002e+22,132
"fit <- try(anova(glm, test = test))",modeling,2.3800000000000002e+22,132
"if (ytype == ""Q"") {",modeling,2.3800000000000002e+22,132
coeff = NA,modeling,2.3800000000000002e+22,132
"if (class(fit)[1] != ""try-error"") {",modeling,2.3800000000000002e+22,132
covi = covi,modeling,2.3800000000000002e+22,132
if (length(names(coefficients(glm))) > 1) {,modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
},modeling,2.3800000000000002e+22,132
"stop(""Unknown model ytype "", ytype)",modeling,2.3800000000000002e+22,132
"cat(paste(""    Error caught, continuing.  yi ="", yi,",modeling,2.3800000000000002e+22,132
"goCC <- goDat2[which(goDat2$category == ""C""), ]",data cleaning,208e20,126
BPterms <- unique(goBP$GO),exploratory,208e20,126
MFterms <- unique(goMF$GO),exploratory,208e20,126
CCterms <- unique(goCC$GO),exploratory,208e20,126
"somaticDriver299_f = ""/Users/khuang/Box Sync/HuangLab/reference/Driver_BaileyCell2018/299driverGene.txt""",import,2.3800000000000002e+22,132
BPlist <- list(),setup,208e20,126
"somaticDriver299 = as.vector(t(read.table(header = F, quote = """",     sep = ""\t"", file = somaticDriver299_f, stringsAsFactors = FALSE)))",import,2.3800000000000002e+22,132
"somatic_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/TCGA_data/somatic/mc3.v0.2.8.PUBLIC.maf.gene_vclass_HGVSp_sample.gz""",import,2.3800000000000002e+22,132
"somatic = read.table(header = T, quote = """", sep = ""\t"", file = gzfile(somatic_f),     stringsAsFactors = FALSE)",import,2.3800000000000002e+22,132
"somatic$bcr_patient_barcode = gsub(""(^TCGA-[A-Z0-9][A-Z0-9]-[A-Z0-9][A-Z0-9][A-Z0-9][A-Z0-9])-.*"",     ""\\1"", somatic$Tumor_Sample_Barcode)",data cleaning,2.3800000000000002e+22,132
genes <- unique(goBP$Symbol[which(goBP$GO == term)]),exploratory,208e20,126
},exploratory,208e20,126
for (ii in 1:length(BPterms)) {,exploratory,208e20,126
BPlist[[ii]] <- genes,exploratory,208e20,126
term <- BPterms[ii],exploratory,208e20,126
somatic_mut_count = data.frame(table(somatic$bcr_patient_barcode)),import,2.3800000000000002e+22,132
names(BPlist) <- BPterms,data cleaning,208e20,126
"colnames(somatic_mut_count) = c(""bcr_patient_barcode"", ""MutationCount"")",data cleaning,2.3800000000000002e+22,132
MFlist <- list(),setup,208e20,126
table(somatic$Variant_Classification),exploratory,2.3800000000000002e+22,132
genes <- unique(goMF$Symbol[which(goMF$GO == term)]),data cleaning,208e20,126
MFlist[[ii]] <- genes,data cleaning,208e20,126
for (ii in 1:length(MFterms)) {,data cleaning,208e20,126
},data cleaning,208e20,126
term <- MFterms[ii],data cleaning,208e20,126
names(MFlist) <- MFterms,setup,208e20,126
CClist <- list(),setup,208e20,126
"""In_Frame_Del"", ""In_Frame_Ins"", ""Missense_Mutation"", ""Nonsense_Mutation"",",setup,2.3800000000000002e+22,132
"likelyFunctionalTypes = c(""Frame_Shift_Del"", ""Frame_Shift_Ins"",",setup,2.3800000000000002e+22,132
"""Splice_Site"", ""Translation_Start_Site"")",setup,2.3800000000000002e+22,132
"try(setwd(""U:/Pragmatics/New/Analysis/""))",setup,887e20,133
term <- CCterms[ii],data cleaning,208e20,126
},data cleaning,208e20,126
CClist[[ii]] <- genes,data cleaning,208e20,126
genes <- unique(goCC$Symbol[which(goCC$GO == term)]),data cleaning,208e20,126
for (ii in 1:length(CCterms)) {,data cleaning,208e20,126
],data cleaning,2.3800000000000002e+22,132
"somaticDriver299) & somatic$Variant_Classification %in% likelyFunctionalTypes,",data cleaning,2.3800000000000002e+22,132
"somatic_likelyfunctional = somatic[somatic$Hugo_Symbol %in% c(pathVar$HUGO_Symbol,",data cleaning,2.3800000000000002e+22,132
names(CClist) <- CCterms,data cleaning,208e20,126
"gene_sample = data.frame(table(somatic_likelyfunctional$Hugo_Symbol,     somatic_likelyfunctional$bcr_patient_barcode))",data cleaning,2.3800000000000002e+22,132
"directory <- ""~/Dropbox/github/stat215b-final-project/analysis""",setup,3.1000000000000002e+22,134
"topBP <- new(""topGOdata"", description = ""Ecoli BP"", ontology = ""BP"",     allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,     GO2genes = BPlist)",data cleaning,208e20,126
"colnames(gene_sample) = c(""Gene"", ""bcr_patient_barcode"", ""Freq"")",data cleaning,2.3800000000000002e+22,132
run.source <- FALSE,setup,3.1000000000000002e+22,134
"gene_sample_m = merge(gene_sample, somatic_mut_count, by = ""bcr_patient_barcode"")",data cleaning,2.3800000000000002e+22,132
"topMF <- new(""topGOdata"", description = ""Ecoli MF"", ontology = ""MF"",     allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,     GO2genes = MFlist)",data cleaning,208e20,126
"mut_signature_f = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/TCGA_data/signature_profile_sample.txt.gz""",import,2.3800000000000002e+22,132
GO2genes = CClist),data cleaning,208e20,126
"topCC <- new(""topGOdata"", description = ""Ecoli CC"", ontology = ""CC"",",data cleaning,208e20,126
"allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,",data cleaning,208e20,126
"source(file.path(directory, ""prepare-analysis.R""))",setup,3.1000000000000002e+22,134
},setup,3.1000000000000002e+22,134
if (run.source) {,setup,3.1000000000000002e+22,134
"save.image(file.path(directory, ""prepare-analysis.Rdata""))",setup,3.1000000000000002e+22,134
"mut_signature = read.table(sep = ""\t"", header = T, file = gzfile(mut_signature_f),     stringsAsFactors = FALSE)",import,2.3800000000000002e+22,132
"load(file.path(directory, ""prepare-analysis.Rdata""))",setup,3.1000000000000002e+22,134
"mut_signature_tcga = mut_signature[mut_signature$Country == ""United States"", ]",data cleaning,2.3800000000000002e+22,132
"X.ohie <- na.omit(data.frame(n.hh, gender, age.19to49, age.50to64,     white, black, hisp, diabetes, asthma, bp, heart, education, income))",data cleaning,3.1000000000000002e+22,134
"mut_signature_tcga$cancer = gsub(""-US"", """", mut_signature_tcga$project_code)",data cleaning,2.3800000000000002e+22,132
"mut_signature_tcga$Signature = gsub(""\\."", ""-"", mut_signature_tcga$Signature)",data cleaning,2.3800000000000002e+22,132
"mut_signature_tcga$bcr_patient_barcode = gsub(""\\."", ""-"", mut_signature_tcga$Tumor_Sample_Barcode)",data cleaning,2.3800000000000002e+22,132
BP.genes <- genesInTerm(topBP),data cleaning,208e20,126
"mut_signature_tcga_brief = mut_signature_tcga[, c(""cancer"", ""Signature"",      ""Contribution"", ""bcr_patient_barcode"")]",data cleaning,2.3800000000000002e+22,132
MF.genes <- genesInTerm(topMF),data cleaning,208e20,126
CC.genes <- genesInTerm(topCC),data cleaning,208e20,126
cancers = unique(pathVarP$cancer),data cleaning,2.3800000000000002e+22,132
genes = unique(pathVarP$HUGO_Symbol),data cleaning,2.3800000000000002e+22,132
"BP.Fisher.elim <- runTest(topBP, algorithm = ""elim"", statistic = ""fisher"")",modeling,208e20,126
tt = NULL,not sure,2.3800000000000002e+22,132
"BP.Fisher.elim.Table <- GenTable(topBP, elimFisher = BP.Fisher.elim,",evaluation,208e20,126
topNodes = 1000),evaluation,208e20,126
for (cancer in cancers) {,data cleaning,2.3800000000000002e+22,132
wWstat = w$statistic,data cleaning,2.3800000000000002e+22,132
wP = w$p.value,data cleaning,2.3800000000000002e+22,132
"var_exp_g = merge(mut_signature_tcga_brief, gene_sample_g,",data cleaning,2.3800000000000002e+22,132
"var_exp_g_c = var_exp_g[var_exp_g$cancer %in% cancer,",data cleaning,2.3800000000000002e+22,132
for (signature in unique(var_exp_g_c$Signature)) {,data cleaning,2.3800000000000002e+22,132
"full_cancer_gene_stat = cbind(cancer, gene, signature,",data cleaning,2.3800000000000002e+22,132
"cancer_gene_stat = run_glm(var_exp_g_c_s, covi = ""MutationCount"")",data cleaning,2.3800000000000002e+22,132
w = wilcox.test(var_exp_g_c_s$Contribution[var_exp_g_c_s$Freq ==,data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
"""Signature-1""])",data cleaning,2.3800000000000002e+22,132
"by = ""bcr_patient_barcode"", all.x = T)",data cleaning,2.3800000000000002e+22,132
gene_path_count = sum(var_exp_g_c$Freq[var_exp_g_c$Signature ==,data cleaning,2.3800000000000002e+22,132
var_exp_g_c_s = var_exp_g_c[var_exp_g_c$Signature ==,data cleaning,2.3800000000000002e+22,132
"gene_path_count, wP, wWstat, cancer_gene_stat)",data cleaning,2.3800000000000002e+22,132
"signature, ]",data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
"0], var_exp_g_c_s$Contribution[var_exp_g_c_s$Freq !=",data cleaning,2.3800000000000002e+22,132
var_exp_g$Freq[is.na(var_exp_g$Freq)] = 0,data cleaning,2.3800000000000002e+22,132
],data cleaning,2.3800000000000002e+22,132
if (gene_path_count > 2) {,data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
for (gene in genes) {,data cleaning,2.3800000000000002e+22,132
"tt = rbind(tt, full_cancer_gene_stat)",data cleaning,2.3800000000000002e+22,132
"gene_sample_g = gene_sample_m[gene_sample_m$Gene == gene,",data cleaning,2.3800000000000002e+22,132
var_exp_g$Freq[var_exp_g$Freq != 0] = 1,data cleaning,2.3800000000000002e+22,132
0]),data cleaning,2.3800000000000002e+22,132
],data cleaning,2.3800000000000002e+22,132
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[which(BP.Fisher.elim.Table$elimFisher <     0.05), ]",evaluation,208e20,126
"colnames(tt) = c(""cancer"", ""gene"", ""signature"", ""gene_path_count"")",data cleaning,2.3800000000000002e+22,132
"tt$FDR = p.adjust(tt[, ""p-value""], method = ""fdr"")",modeling,2.3800000000000002e+22,132
"tt$wilcoxFDR = p.adjust(tt[, ""wilcoxP""], method = ""fdr"")",modeling,2.3800000000000002e+22,132
"tt = tt[order(tt$FDR, decreasing = FALSE), ]",modeling,2.3800000000000002e+22,132
"c(""Term""))]",communication,208e20,126
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(BP.Fisher.elim.Table) %in%",communication,208e20,126
"tn = ""out/somaticMutMutsigAssoc.txt""",export,2.3800000000000002e+22,132
"write.table(tt, quote = F, sep = ""\t"", file = tn, row.names = F)",export,2.3800000000000002e+22,132
"x)]], DEgeneNam1), collapse = "",""))",export,208e20,126
"aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)",export,208e20,126
"genesInTerm <- sapply(goIDs, function(x) paste(BP.genes[[which(names(BP.genes) ==",export,208e20,126
"bDF <- cbind(BP.Fisher.elim.Table, aDF)",export,208e20,126
"write.csv(bDF, file = paste0(results, ""media_pathway_analysis_BP.csv""))",export,208e20,126
"x)]], collapse = "",""))",export,208e20,126
goIDs <- BP.Fisher.elim.Table$GO.ID,export,208e20,126
},export,208e20,126
if (nrow(BP.Fisher.elim.Table) > 0) {,export,208e20,126
"DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(BP.genes[[which(names(BP.genes) ==",export,208e20,126
"Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))",export,208e20,126
"try(setwd(""U:/Pragmatics/New/Analysis/""))",setup,2.3800000000000002e+22,132
"try(setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis""))",setup,2.3800000000000002e+22,132
"MF.Fisher.elim <- runTest(topMF, algorithm = ""elim"", statistic = ""fisher"")",modeling,208e20,126
"detect.d = read.csv(""../Results/SimplifiedPhonology/Detectability/RandomConcepts/detectability_randomConcepts_firstSegments.csv"",     stringsAsFactors = F)",import,2.3800000000000002e+22,132
mean(detect.d$z),exploratory,2.3800000000000002e+22,132
sum(detect.d$z < 0),exploratory,2.3800000000000002e+22,132
"MF.Fisher.elim.Table <- GenTable(topMF, elimFisher = MF.Fisher.elim,     topNodes = 1000)",evaluation,208e20,126
sum(detect.d$z < 0)/nrow(detect.d),exploratory,2.3800000000000002e+22,132
mean(detect.d$z),exploratory,2.3800000000000002e+22,132
sum(detect.d$p > 0.95 & detect.d$z < 0),exploratory,2.3800000000000002e+22,132
sum(detect.d$p > 0.95 & detect.d$z < 0)/nrow(detect.d),exploratory,2.3800000000000002e+22,132
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[which(MF.Fisher.elim.Table$elimFisher <     0.05), ]",evaluation,208e20,126
args = (commandArgs(TRUE)),setup,2.3800000000000002e+22,132
"c(""Term""))]",communication,208e20,126
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[, !(names(MF.Fisher.elim.Table) %in%",communication,208e20,126
goIDs <- MF.Fisher.elim.Table$GO.ID,export,208e20,126
"genesInTerm <- sapply(goIDs, function(x) paste(MF.genes[[which(names(MF.genes) ==",export,208e20,126
"aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)",export,208e20,126
if (nrow(MF.Fisher.elim.Table) > 0) {,export,208e20,126
"DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(MF.genes[[which(names(MF.genes) ==",export,208e20,126
},export,208e20,126
"x)]], DEgeneNam1), collapse = "",""))",export,208e20,126
"Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))",export,208e20,126
"x)]], collapse = "",""))",export,208e20,126
"write.csv(bDF, paste0(results, ""media_pathway_analysis_MF.csv""))",export,208e20,126
"bDF <- cbind(MF.Fisher.elim.Table, aDF)",export,208e20,126
eval(parse(text = args[[1]])),import,2.3800000000000002e+22,132
"CC.Fisher.elim <- runTest(topCC, algorithm = ""elim"", statistic = ""fisher"")",modeling,208e20,126
"setwd(""~/WaveQTL/R"")",setup,2.3800000000000002e+22,132
"Wmat_1024 = read.table(""../data/DWT/Wmat_1024"", as.is = TRUE)",import,2.3800000000000002e+22,132
"CC.Fisher.elim.Table <- GenTable(topCC, elimFisher = CC.Fisher.elim,     topNodes = 200)",evaluation,208e20,126
W2mat_1024 = Wmat_1024 * Wmat_1024,data cleaning,2.3800000000000002e+22,132
"WaveQTL.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/WaveQTL/""",import,2.3800000000000002e+22,132
"wd.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/prepareData/""",import,2.3800000000000002e+22,132
"CC.Fisher.elim.Table <- CC.Fisher.elim.Table[which(CC.Fisher.elim.Table$elimFisher <     0.05), ]",communication,208e20,126
setwd(wd.path),setup,2.3800000000000002e+22,132
"CC.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(CC.Fisher.elim.Table) %in%",communication,208e20,126
"c(""Term""))]",communication,208e20,126
"path.fig = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/fig/ES/""",import,2.3800000000000002e+22,132
"path.output = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/data/""",import,2.3800000000000002e+22,132
"path.data = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/""",import,2.3800000000000002e+22,132
"bDF <- cbind(CC.Fisher.elim.Table, aDF)",export,208e20,126
"x)]], collapse = "",""))",export,208e20,126
goIDs <- CC.Fisher.elim.Table$GO.ID,export,208e20,126
},export,208e20,126
"DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(CC.genes[[which(names(CC.genes) ==",export,208e20,126
"x)]], DEgeneNam1), collapse = "",""))",export,208e20,126
"Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))",export,208e20,126
"write.csv(bDF, paste0(results, ""media_pathway_analysis_CC.csv""))",export,208e20,126
"aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)",export,208e20,126
if (nrow(CC.Fisher.elim.Table) > 0) {,export,208e20,126
"genesInTerm <- sapply(goIDs, function(x) paste(CC.genes[[which(names(CC.genes) ==",export,208e20,126
"phenoD = as.matrix(read.table(paste0(path.data, ""pheno.dat."",     ss), as.is = TRUE))",data cleaning,2.3800000000000002e+22,132
"genoD = scan(paste0(path.data, ""orig.geno.dat."", ss), what = double())",import,2.3800000000000002e+22,132
genoR = as.numeric(round(genoD)),data cleaning,2.3800000000000002e+22,132
wh0 = which(genoR == 0),data cleaning,2.3800000000000002e+22,132
wh1 = which(genoR == 1),data cleaning,2.3800000000000002e+22,132
wh2 = which(genoR == 2),data cleaning,2.3800000000000002e+22,132
sel_geno_IX = 1,data cleaning,2.3800000000000002e+22,132
raw.data = phenoD,data cleaning,2.3800000000000002e+22,132
"beta_var_dataS = as.vector(matrix(data = beta_var, nr = 1,",data cleaning,2.3800000000000002e+22,132
WaveQTL.mean.sig2[wh] = 0,data cleaning,2.3800000000000002e+22,132
library(wavethresh),data cleaning,2.3800000000000002e+22,132
numBPs = 1024,data cleaning,2.3800000000000002e+22,132
sig1.smooth[wh.zero] = 1/70,data cleaning,2.3800000000000002e+22,132
"beta_mean = as.numeric(read.table(beta_mean_path)[sel_geno_IX,",data cleaning,2.3800000000000002e+22,132
if ((length(wh0) > 2) & (length(wh1) > 2)) {,data cleaning,2.3800000000000002e+22,132
if (length(wh.zero) > 0) {,data cleaning,2.3800000000000002e+22,132
if (length(wh.zero) > 0) {,data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
"beta_dataS = as.vector(-matrix(data = beta_mean, nr = 1,",data cleaning,2.3800000000000002e+22,132
WaveQTL.mean.sig2 = WaveQTL.mean,data cleaning,2.3800000000000002e+22,132
xmin = 1,data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
2:1025]),data cleaning,2.3800000000000002e+22,132
"this.path = paste0(path.output, ""smooth.ratio.3."", ss)",data cleaning,2.3800000000000002e+22,132
sig0.smooth = sig.all.smooth[1:1024],data cleaning,2.3800000000000002e+22,132
sig1.smooth = sig.all.smooth[1025:2048],data cleaning,2.3800000000000002e+22,132
WaveQTL.mean.sig3 = WaveQTL.mean,data cleaning,2.3800000000000002e+22,132
wh = which(raw.data.T == 0),data cleaning,2.3800000000000002e+22,132
res = 1 + 70 * WaveQTL.mean.sig3/raw.data.T,data cleaning,2.3800000000000002e+22,132
xval = xmin:xmax,data cleaning,2.3800000000000002e+22,132
""".fph.mean.txt"")",data cleaning,2.3800000000000002e+22,132
"sig1 = apply(phenoD[wh1, ], 2, mean)",data cleaning,2.3800000000000002e+22,132
sig.all.smooth = BAYES.THR(sig.all),data cleaning,2.3800000000000002e+22,132
"width = 7, units = ""in"", res = 300)",data cleaning,2.3800000000000002e+22,132
"sig.all = c(sig0, sig1)",data cleaning,2.3800000000000002e+22,132
xmax = numBPs,data cleaning,2.3800000000000002e+22,132
"ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)",data cleaning,2.3800000000000002e+22,132
wh = which(abs(WaveQTL.mean) < 2 * WaveQTL.sd),data cleaning,2.3800000000000002e+22,132
"this.path = paste0(path.output, ""smooth.ratio.2."", ss)",data cleaning,2.3800000000000002e+22,132
cut.thresh = val/70,data cleaning,2.3800000000000002e+22,132
"sig0 = apply(phenoD[wh0, ], 2, mean)",data cleaning,2.3800000000000002e+22,132
"beta_var_path = paste0(WaveQTL.path, ""output/res."", ss, "".fph.var.txt"")",data cleaning,2.3800000000000002e+22,132
"beta_var = as.numeric(read.table(beta_var_path)[sel_geno_IX,",data cleaning,2.3800000000000002e+22,132
nc = 1024) %*% as.matrix(W2mat_1024)),data cleaning,2.3800000000000002e+22,132
quote = FALSE),data cleaning,2.3800000000000002e+22,132
delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh),data cleaning,2.3800000000000002e+22,132
"beta_mean_path = paste0(WaveQTL.path, ""output/res."", ss,",data cleaning,2.3800000000000002e+22,132
sig1.smooth[delix] = sig0.smooth[delix],data cleaning,2.3800000000000002e+22,132
wh.zero = which(sig1.smooth <= 1/70),data cleaning,2.3800000000000002e+22,132
WaveQTL.mean = beta_dataS,data cleaning,2.3800000000000002e+22,132
quote = FALSE),data cleaning,2.3800000000000002e+22,132
"nf <- layout(matrix(1:3, 3, 1, byrow = TRUE))",data cleaning,2.3800000000000002e+22,132
"par(mar = c(3, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
nc = 1024) %*% as.matrix(Wmat_1024)),data cleaning,2.3800000000000002e+22,132
wh = which(abs(WaveQTL.mean) < 3 * WaveQTL.sd),data cleaning,2.3800000000000002e+22,132
"write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,",data cleaning,2.3800000000000002e+22,132
res[wh] = 1,data cleaning,2.3800000000000002e+22,132
"write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,",data cleaning,2.3800000000000002e+22,132
wh.zero = which(sig0.smooth <= 1/70),data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
WaveQTL.mean.sig3[wh] = 0,data cleaning,2.3800000000000002e+22,132
"raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))",data cleaning,2.3800000000000002e+22,132
res[wh] = 1,data cleaning,2.3800000000000002e+22,132
"png(paste0(path.fig, ""ESWaveQTL"", ss, "".png""), height = 4,",data cleaning,2.3800000000000002e+22,132
val = 6,data cleaning,2.3800000000000002e+22,132
sig0.smooth[wh.zero] = 1/70,data cleaning,2.3800000000000002e+22,132
2:1025]),data cleaning,2.3800000000000002e+22,132
beta_sd_dataS = sqrt(beta_var_dataS),data cleaning,2.3800000000000002e+22,132
WaveQTL.sd = beta_sd_dataS,data cleaning,2.3800000000000002e+22,132
res = 1 + 70 * WaveQTL.mean.sig2/raw.data.T,data cleaning,2.3800000000000002e+22,132
"ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)",data cleaning,2.3800000000000002e+22,132
"par(mar = c(3, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
raw.data = phenoD,data cleaning,2.3800000000000002e+22,132
"lines(xval, sig0, type = ""l"", col = ""orange"")",data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
wh = which(sig1.WaveQTL < 0),data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(0, ymax), axes = FALSE, main = ""Raw data"")",data cleaning,2.3800000000000002e+22,132
ymax = max(sig1 - sig0),data cleaning,2.3800000000000002e+22,132
"lines(xval, log(sig1) - log(sig0), type = ""l"", col = ""green"")",data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Major Homozygotes - Heterozygotes, effect size from WaveQTL (0, 2, 3 sd)"")",data cleaning,2.3800000000000002e+22,132
"ymin = min(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,",data cleaning,2.3800000000000002e+22,132
sig0.WaveQTL = mu0.sig * raw.data.T,data cleaning,2.3800000000000002e+22,132
"width = 7, units = ""in"", res = 300)",data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
abline(h = 0),data cleaning,2.3800000000000002e+22,132
"nf <- layout(matrix(1:4, 4, 1, byrow = TRUE))",data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
"ymax = max(sig0, sig1)",data cleaning,2.3800000000000002e+22,132
"par(mar = c(1, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
dev.off(),data cleaning,2.3800000000000002e+22,132
} else {,data cleaning,2.3800000000000002e+22,132
sig1 = sig1.WaveQTL,data cleaning,2.3800000000000002e+22,132
ymax = max(raw.data.T),data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
sig0[wh0] = min.val,data cleaning,2.3800000000000002e+22,132
ymin = min(log(sig1) - log(sig0)),data cleaning,2.3800000000000002e+22,132
dev.off(),data cleaning,2.3800000000000002e+22,132
"mu0.sig = rep(1/70, 1024)",data cleaning,2.3800000000000002e+22,132
sig1.WaveQTL[wh] = 0,data cleaning,2.3800000000000002e+22,132
"lines(xval, sig1, type = ""l"", col = ""blue"")",data cleaning,2.3800000000000002e+22,132
"par(mar = c(1, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
abline(h = 0),data cleaning,2.3800000000000002e+22,132
WaveQTL.mean),data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
"lines(xval, sig1 - sig0, type = ""l"", col = ""green"")",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
"raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
"par(mar = c(1, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
abline(h = 0),data cleaning,2.3800000000000002e+22,132
"lines(xval, sig0.smooth, type = ""l"", col = ""red"")",data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(0, ymax), axes = FALSE, main = ""Major Homozygotes, dark green from multiseq"")",data cleaning,2.3800000000000002e+22,132
"lines(xval, sig1, type = ""l"", col = ""skyblue"")",data cleaning,2.3800000000000002e+22,132
"par(mar = c(3, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
sig1.WaveQTL = sig0.WaveQTL - WaveQTL.mean.sig3,data cleaning,2.3800000000000002e+22,132
"par(mar = c(1, 3, 1, 1))",data cleaning,2.3800000000000002e+22,132
ymin = min(sig1 - sig0),data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected difference (g1 - g0) [WaveQTL]"")",data cleaning,2.3800000000000002e+22,132
sig1[wh1] = min.val,data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected log ratio (log(g1) - log(g0)) [WaveQTL]"")",data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(0, ymax), axes = FALSE, main = ""Heterozygotes"")",data cleaning,2.3800000000000002e+22,132
"lines(xval, sig1.smooth, type = ""l"", col = ""blue"")",data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
"lines(xval, sig1.smooth - sig0.smooth, type = ""l"", col = ""green"")",data cleaning,2.3800000000000002e+22,132
"lines(xval, WaveQTL.mean, type = ""l"", col = ""orange"")",data cleaning,2.3800000000000002e+22,132
"lines(xval, sig0, type = ""l"", col = ""red"")",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
ymax = max(log(sig1) - log(sig0)),data cleaning,2.3800000000000002e+22,132
"lines(xval, WaveQTL.mean.sig2, type = ""l"", col = ""red"")",data cleaning,2.3800000000000002e+22,132
"lines(xval, WaveQTL.mean.sig3, type = ""l"", col = ""blue"")",data cleaning,2.3800000000000002e+22,132
sig0 = sig0.WaveQTL,data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
WaveQTL.mean),data cleaning,2.3800000000000002e+22,132
"png(paste0(path.fig, ""ESsimuWaveQTL"", ss, "".png""), height = 4,",data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
wh0 = which(sig0 == 0),data cleaning,2.3800000000000002e+22,132
"min.val = min(sig1[-wh1], sig0[-wh0])",data cleaning,2.3800000000000002e+22,132
"ymax = max(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,",data cleaning,2.3800000000000002e+22,132
"cat("""", file = paste0(path.fig, ""NG."", ss))",data cleaning,2.3800000000000002e+22,132
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,",data cleaning,2.3800000000000002e+22,132
"lines(xval, raw.data.T, type = ""l"", col = ""black"")",data cleaning,2.3800000000000002e+22,132
"xmax), ylim = c(0, ymax), axes = FALSE, main = ""Expected mean g0: red g1: blue [WaveQTL]"")",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
wh1 = which(sig1 == 0),data cleaning,2.3800000000000002e+22,132
"axis(2, font = 2)",data cleaning,2.3800000000000002e+22,132
box(),data cleaning,2.3800000000000002e+22,132
header = TRUE),import,2.3800000000000002e+22,132
"large_plot_data <- read.table(""./analysis/inundation_predicts_species_distributions/data/forestplot_160_spatial_data_UPDATE.txt"",",import,2.3800000000000002e+22,132
str(large_plot_data),exploratory,2.3800000000000002e+22,132
"source(""https://bioconductor.org/biocLite.R"")",import,2.3800000000000002e+22,132
library(RnBeads),import,2.3800000000000002e+22,132
library(hexbin),import,2.3800000000000002e+22,132
library(wordcloud),import,2.3800000000000002e+22,132
"raw.data.dir = ""../../data/raw/Breakefield_HBMVEC_450k/""",import,2.3800000000000002e+22,132
"analysis.dir = ""./RnBeads/analysis""",import,2.3800000000000002e+22,132
"report.dir = file.path(analysis.dir, ""GetDMRs_9comps_SVAbe_July19_2016"")",import,2.3800000000000002e+22,132
"rnb.options(analysis.name = ""Breakefield450k"", assembly = ""hg19"")",import,2.3800000000000002e+22,132
"source(""./MapPRESSTOenh_prom_sym.R"")",import,2.3800000000000002e+22,132
for (enh.prof in names(my.mapped.ehnancer.annots)) {,data cleaning,2.3800000000000002e+22,132
"rnb.set.annotation(type = enh.prof, description = enh.prof,",data cleaning,2.3800000000000002e+22,132
"6)], assembly = ""hg19"")",data cleaning,2.3800000000000002e+22,132
"regions = my.mapped.ehnancer.annots[[enh.prof]][c(1:3,",data cleaning,2.3800000000000002e+22,132
},data cleaning,2.3800000000000002e+22,132
"rnb.options(region.types = c(""genes"", ""promoters"", names(my.mapped.ehnancer.annots)))",data cleaning,2.3800000000000002e+22,132
"rnb.getOption(""region.types"")",setup,2.3800000000000002e+22,132
"breakefield450K = readRDS(paste(raw.data.dir, ""bkfld450k.rda"",     sep = """"))",import,2.3800000000000002e+22,132
"colnames(breakefield450K) = gsub(""_zappulliMGH1_[ABCDEF][1234]"",     """", colnames(breakefield450K))",data cleaning,2.3800000000000002e+22,132
"colnames(breakefield450K) = gsub("".."", ""."", colnames(breakefield450K),     fixed = T)",data cleaning,2.3800000000000002e+22,132
"breakefield450K = breakefield450K[, order(colnames(breakefield450K))]",data cleaning,2.3800000000000002e+22,132
"betas = breakefield450K[, c(as.numeric(grep(""AVG_Beta"", colnames(breakefield450K))))]",data cleaning,2.3800000000000002e+22,132
rownames(betas) = breakefield450K$TargetID,data cleaning,2.3800000000000002e+22,132
"p.vals = breakefield450K[, c(as.numeric(grep(""Detection.Pval"",     colnames(breakefield450K))))]",data cleaning,2.3800000000000002e+22,132
"my.pheno <- read.csv(file = ""./input/my.pheno.txt"", header = T,     sep = "","", quote = """", na.strings = ""NA"")",import,2.3800000000000002e+22,132
my.pheno = as.data.frame(my.pheno),data cleaning,2.3800000000000002e+22,132
betas = as.matrix(betas),data cleaning,2.3800000000000002e+22,132
p.vals = as.matrix(p.vals),data cleaning,2.3800000000000002e+22,132
dim(my.pheno),exploratory,2.3800000000000002e+22,132
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/cleaning"")",setup,817e20,135
my.range = c(1:24),data cleaning,2.3800000000000002e+22,132
"my.pheno = my.pheno[my.range, ]",data cleaning,2.3800000000000002e+22,132
"betas = betas[, my.range]",data cleaning,2.3800000000000002e+22,132
"p.vals = p.vals[, my.range]",data cleaning,2.3800000000000002e+22,132
my.diff.comps <- colnames(my.pheno)[5:13],data cleaning,2.3800000000000002e+22,132
"source(""standardize_feature.R"")",exploratory,817e20,135
rnb.initialize.reports(report.dir),setup,2.3800000000000002e+22,132
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/ch1 discrimination/plots"")",setup,817e20,135
"my.rnb.set <- RnBeadSet(pheno = my.pheno, betas = betas, probes = rownames(betas),     useff = FALSE, p.values = p.vals, platform = ""450k"")",evaluation,2.3800000000000002e+22,132
"source(""correlation.R"")",exploratory,817e20,135
"any.bad.p.val = apply(dpval(my.rnb.set) > 0.01, 1, any)",data cleaning,2.3800000000000002e+22,132
"my.rnb.set = remove.sites(my.rnb.set, any.bad.p.val)",data cleaning,2.3800000000000002e+22,132
"rnb.sample.groups(annotations = my.pheno, columns = NULL, columns.pairs = NULL,     min.group.size = rnb.getOption(""min.group.size""), max.group.count = rnb.getOption(""max.group.count""))",data cleaning,2.3800000000000002e+22,132
"rnb.sample.replicates(my.rnb.set, ""Replicate"")",data cleaning,2.3800000000000002e+22,132
rnb.options(qc = TRUE),data cleaning,2.3800000000000002e+22,132
wd = getwd(),setup,855e20,136
"subsets_wvictims <- list(Robbery = robbery_data_with_victim,     `Simple Assault` = simple_assault_data_with_victim, Intimidation = intimidation_data_with_victim)",data cleaning,817e20,135
"source(""../../../RASPathwaySig/bin/cBioPortalData.R"", chdir = T)",setup,855e20,136
setwd(wd),setup,855e20,136
"source(""../../../dermalNF/bin/dermalNFData.R"")",import,855e20,136
"subset_names <- c(""Robbery"", ""Aggravated Assault"", ""Simple Assault"",     ""Intimidation"")",data cleaning,817e20,135
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,     2)))",data cleaning,817e20,135
"load(""../../../RASPathwaySig/analysis/2016-08-23/exprData.Rdata"")",import,855e20,136
"ivs <- c(""black_not_white"", ""victim_analyzing_black_not_white"")",data cleaning,817e20,135
rm(list = ls()),setup,803e20,137
"continuous_ivs <- c(""agency_offenders_count"", ""mean_inc"")",data cleaning,817e20,135
"ivs_string <- paste0(ivs, "" + "", collapse = """")",data cleaning,817e20,135
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/FTL_cp.R"")",import,803e20,137
"FTL <- read.csv(""/Volumes/NOAA_Data/CNH/Data/Catch/FTL_2009-2013_2014-03-21.csv"",     as.is = TRUE)",import,803e20,137
"spid_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/remove_spid.csv"",     as.is = TRUE)",import,803e20,137
"iv_names <- c(""Constant"", ""Offender Black (ref = White)"", ""Victim Black (ref = White)"")",visualization,817e20,135
"cmplx_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/cmplx.csv"",     as.is = TRUE)",import,803e20,137
"mgmt_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/mgmt_grp.csv"",     as.is = TRUE)",import,803e20,137
"species_data <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/spid.csv"",     as.is = TRUE)",import,803e20,137
"prop_tripTable <- FTL_cp(FTL, type = ""proportion"", times = 300,     spid_remove, cmplx_remove, mgmt_remove)",exploratory,803e20,137
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",",export,803e20,137
"Sys.Date(), "".Rdata"", sep = """"))",export,803e20,137
tcga.mat <- exprData,not sure,855e20,136
"""nsclc"")), function(x) {",data cleaning,855e20,136
if (length(cols) > 1),data cleaning,855e20,136
cols <- cols[!is.na(cols)],data cleaning,855e20,136
"samps <- sapply(samps, function(y) gsub(""-"", ""."", y, fixed = T))",data cleaning,855e20,136
}),data cleaning,855e20,136
"tcga.dis.averages <- sapply(setdiff(tcga.cancer.types, c(""lgggbm"",",data cleaning,855e20,136
samps <- getSamplesForDisease(x),data cleaning,855e20,136
"else return(tcga.mat[, cols])",data cleaning,855e20,136
"cols <- match(samps, colnames(tcga.mat))",data cleaning,855e20,136
"return(rowMeans(tcga.mat[, cols], na.rm = T))",data cleaning,855e20,136
require(synapseClient),setup,855e20,136
synapseLogin(),setup,855e20,136
zscore <- function(x) {,modeling,855e20,136
"(x - mean(x, na.rm = T))/sd(x)",modeling,855e20,136
x <- unlist(x),modeling,855e20,136
},modeling,855e20,136
dermalSamps <- rna_fpkm_matrix(),modeling,855e20,136
"normDermData <- apply(dermalSamps, 2, zscore)",modeling,855e20,136
phenoData <- fpkm_annotations(),not sure,855e20,136
"phenoData <- unique(phenoData[, c(1, 2, 5)])",data cleaning,855e20,136
"pats <- paste(""patient"", apply(phenoData[match(colnames(normDermData),     phenoData$sample), c(1, 3)], 1, paste, collapse = "" tumor""))",data cleaning,855e20,136
colnames(normDermData) <- pats,data cleaning,855e20,136
"comm.genes <- intersect(rownames(tcga.dis.averages), rownames(normDermData))",data cleaning,855e20,136
library(pheatmap),setup,855e20,136
"cmat <- cbind(normDermData[comm.genes, ], tcga.dis.averages[comm.genes,     ])",data cleaning,855e20,136
"png(""tcga_dermal_dendrogram.png"", width = 800)",export,855e20,136
"plot(hclust(dist(t(cmat))), main = ""TCGA Samples with dermal NF data"")",visualization,855e20,136
"mod_lw2 <- with(data, lm(log(Wgt) ~ log(STL)))",modeling,1.4499999999999999e+22,138
"anova_lw <- anova(mod_lw, mod_lw2)",modeling,1.4499999999999999e+22,138
library(dplyr),import,193e20,139
"lw_m <- filter(data, Sex == ""Male"") %>% len_weight()",modeling,1.4499999999999999e+22,138
library(ogbox),import,193e20,139
library(homologene),import,193e20,139
"APIData <- read.table(""Analysis/Data/APIData"", sep = "","", stringsAsFactors = FALSE)",import,4.0399999999999996e+22,140
"source(""R/mostVariable.R"")",import,193e20,139
"lw_f <- filter(data, Sex == ""Female"") %>% len_weight()",data cleaning,1.4499999999999999e+22,138
"source(""R/puristOut.R"")",import,193e20,139
"AddressData <- read.table(""Analysis/Data/AddressData"", sep = "","",     stringsAsFactors = FALSE)",import,4.0399999999999996e+22,140
"source(""R/cellColors.R"")",import,193e20,139
"source(""R/heatmap.3.R"")",import,193e20,139
"ZillowDataSet6 <- read.table(""Analysis/Data/ZillowDataSet6"",     sep = "","", stringsAsFactors = FALSE)",import,4.0399999999999996e+22,140
"source(""analysis//12.Allen Brain//regionAnalysis.R"")",import,193e20,139
"MainData2 <- data.frame(MainData, APIData)",import,4.0399999999999996e+22,140
library(tidyr),import,193e20,139
"lw_both <- len_weight(mutate(data, facet = ""(a) Female + Male""))",data cleaning,1.4499999999999999e+22,138
library(cowplot),import,193e20,139
"MainData2 <- MainData2[!duplicated(MainData[, 1]), ]",data cleaning,4.0399999999999996e+22,140
library(memoise),import,193e20,139
"MainData3 <- data.frame(MainData2, AddressData)",data cleaning,4.0399999999999996e+22,140
memoMedian = memoise(median),import,193e20,139
"MainData4 <- data.frame(MainData3, ZillowDataSet6)",data cleaning,4.0399999999999996e+22,140
"write.table(MainData4, file = ""Analysis/Data/EnrichedData"", sep = "","")",data cleaning,4.0399999999999996e+22,140
lw_abt <- filter(data_abt) %>% len_weight(),data cleaning,1.4499999999999999e+22,138
memoMatrix = memoise(as.matrix),not sure,193e20,139
"write.table(MainData4, file = ""Analysis/Data/EnrichedData"", sep = "","")",export,4.0399999999999996e+22,140
memoMostVariable = memoise(mostVariable),not sure,193e20,139
"lw_results <- as_data_frame(rbind(lw_m$results, lw_f$results,     lw_both$results)) %>% signif(4) %>% mutate(Sex = c(""Male"",     ""Female"", ""Both"")) %>% select(Sex, everything())",data cleaning,1.4499999999999999e+22,138
"ontology = fread(""data/allenBrain/H0351.1009/Ontology.csv"", data.table = F)",not sure,193e20,139
"write_rds(mod_lw, ""data/len_weight/mod_lw.rds"")",data cleaning,1.4499999999999999e+22,138
"MainData <- read.table(""Analysis/Data/MainData"", sep = "","", stringsAsFactors = FALSE)",import,4.0399999999999996e+22,140
"write_rds(mod_lw2, ""data/len_weight/mod_lw2.rds"")",export,1.4499999999999999e+22,138
"source(""C:\\Users\\Kitsune\\Documents\\GitHub\\VersionClassifier\\Analysis\\analysisScript1.R"")",import,4.0399999999999996e+22,140
"write_rds(anova_lw, ""data/len_weight/anova_lw.rds"")",export,1.4499999999999999e+22,138
"mobileJsonCyc = getFiledata(""CyclesMobile.json"")",import,4.0399999999999996e+22,140
"write_rds(lw_m, ""data/len_weight/lw_m.rds"")",export,1.4499999999999999e+22,138
"desktopJsonCyc = getFiledata(""CyclesDesktop.json"")",import,4.0399999999999996e+22,140
"write_rds(lw_f, ""data/len_weight/lw_f.rds"")",export,1.4499999999999999e+22,138
"siblingJsonCyc = getFiledata(""CyclesSibling.json"")",import,4.0399999999999996e+22,140
"write_rds(lw_both, ""data/len_weight/lw_both.rds"")",export,1.4499999999999999e+22,138
"write_rds(lw_abt, ""data/len_weight/lw_abt.rds"")",export,1.4499999999999999e+22,138
"sibMobJsonCyc = getFiledata(""CyclesSibMob.json"")",import,4.0399999999999996e+22,140
"write_rds(lw_results, ""data/len_weight/lw_results.rds"")",export,1.4499999999999999e+22,138
"sibDeskJsonCyc = getFiledata(""CyclesSibDesk.json"")",import,4.0399999999999996e+22,140
"write_rds(lw_results, ""data/len_weight/lw_results.rds"")",export,1.4499999999999999e+22,138
mobileCyc = mobileJsonCyc$Cycle$Data,data cleaning,4.0399999999999996e+22,140
desktopCyc = desktopJsonCyc$Cycle$Data,data cleaning,4.0399999999999996e+22,140
siblingCyc = siblingJsonCyc$Cycle$Data,data cleaning,4.0399999999999996e+22,140
sibMobCyc = sibMobJsonCyc$Cycle$Data,data cleaning,4.0399999999999996e+22,140
sibDesktCyc = sibDeskJsonCyc$Cycle$Data,data cleaning,4.0399999999999996e+22,140
"library(""countrycode"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,1.4499999999999999e+22,138
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,1.4499999999999999e+22,138
siblingCyc = siblingCyc[-which(siblingCyc %in% c(max(siblingCyc)))],data cleaning,4.0399999999999996e+22,140
"aid <- read.csv(file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/grid_ids_aid.csv"")",import,1.4499999999999999e+22,138
"opt_loc <- merge(opt_loc, aid, by = ""ID"")",data cleaning,1.4499999999999999e+22,138
var.equal = FALSE)),modeling,4.0399999999999996e+22,140
RunAnalysis <- function() {,modeling,4.0399999999999996e+22,140
},modeling,4.0399999999999996e+22,140
"print(t.test(mobileCyc, desktopCyc, alternative = ""two.sided"",",modeling,4.0399999999999996e+22,140
opt_loc$wb_num_oth <- opt_loc$wb_num - opt_loc$wb_num_transp,data cleaning,1.4499999999999999e+22,138
"source(""./R/VAR_functions.R"")",setup,4.0399999999999996e+22,140
rm(list = ls()),setup,349e20,141
"country <- ""Argentina""",setup,4.0399999999999996e+22,140
forecast_exercise_year <- 2018,setup,4.0399999999999996e+22,140
forecast_exercise_number <- 2,setup,4.0399999999999996e+22,140
"countryset <- opt_loc[opt_loc$country == country, ]",data cleaning,1.4499999999999999e+22,138
for (i in 1:nrow(countryset)) {,data cleaning,1.4499999999999999e+22,138
},data cleaning,1.4499999999999999e+22,138
"countryset$ID[i], ""wb_num_oth""]/total_country_other_projects",data cleaning,1.4499999999999999e+22,138
total_country_other_projects <- sum(countryset$wb_num_oth),data cleaning,1.4499999999999999e+22,138
"opt_loc[opt_loc$ID == countryset$ID[i], ""projectfraction""] <- opt_loc[opt_loc$ID ==",data cleaning,1.4499999999999999e+22,138
},data cleaning,1.4499999999999999e+22,138
for (country in unique(opt_loc$country)) {,data cleaning,1.4499999999999999e+22,138
"source(""./R/helper/00_helper_lib_load.R"")",setup,349e20,141
"output_path <- paste0(""./analysis/VAR_output/edd_exercises/"",     ""/"")",setup,4.0399999999999996e+22,140
"opt_loc[is.na(opt_loc$projectfraction), ""projectfraction""] <- 0",data cleaning,1.4499999999999999e+22,138
"opt_loc$wbcode <- countrycode(opt_loc$country, origin = ""country.name"",     destination = ""wb"")",data cleaning,1.4499999999999999e+22,138
"country <- c(""Angola"", ""Cameroon"", ""Congo, DR"", ""Djibouti"", ""Egypt"")",data cleaning,1.4499999999999999e+22,138
"crossing <- c(2005, 2008, 2006, 2007, 1995, 1998, 2009, 2008)",data cleaning,1.4499999999999999e+22,138
"source(""~/selection/code/lib/readlib.R"")",import,196e20,142
"df <- data.frame(country, crossing)",data cleaning,1.4499999999999999e+22,138
"df$wbcode <- countrycode(df$country, origin = ""country.name"",     destination = ""wb"")",data cleaning,1.4499999999999999e+22,138
library(randomForest),import,531e20,143
"opt_loc <- merge(opt_loc, df[, c(""wbcode"", ""crossing"")], by = ""wbcode"",     all.x = T)",data cleaning,1.4499999999999999e+22,138
library(caret),import,531e20,143
library(doMC),import,531e20,143
opt_loc$years_crossed <- 2017 - opt_loc$crossing,data cleaning,1.4499999999999999e+22,138
library(mmadsenr),import,531e20,143
library(futile.logger),import,531e20,143
library(dplyr),import,531e20,143
library(ggthemes),import,531e20,143
"folder <- ""Mutation""",setup,735e20,144
version = NA,not sure,196e20,142
opt_loc$iv_ida <- opt_loc$projectfraction * opt_loc$years_crossed,data cleaning,1.4499999999999999e+22,138
if (!file.exists(folder)) {      dir.create(folder))},setup,735e20,144
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,531e20,143
"write.csv(opt_loc[, c(""ID"", ""iv_ida"")], file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/ID_iv_ida.csv"",     row.names = FALSE)",export,1.4499999999999999e+22,138
"scripts.dir <- paste(""/extraspace/yye1/analysis/Hypoxia/PSM/"",     folder, sep = """")",setup,735e20,144
setwd(scripts.dir),setup,735e20,144
size4_vbls_old <- var_res_old %>% filter(var_size == 4) %>%,exploratory,4.0399999999999996e+22,140
"print(""Size 5 VARs: variables in new that are not in old:"")",exploratory,4.0399999999999996e+22,140
"model_function = ""new"") %>% dplyr::select(-t_treshold) %>%",exploratory,4.0399999999999996e+22,140
"is_wide = TRUE, h_max = h_max, rank_h_max = rank_h_max)",exploratory,4.0399999999999996e+22,140
"lags, ~make_model_name(.x, .y, remove_base = FALSE)),",exploratory,4.0399999999999996e+22,140
dplyr::select(variables) %>% unlist() %>% unique(),exploratory,4.0399999999999996e+22,140
},exploratory,4.0399999999999996e+22,140
var_res_new <- readRDS(filename_new),exploratory,4.0399999999999996e+22,140
"old_and_new <- stack_models(list(var_res_new, var_res_old))",exploratory,4.0399999999999996e+22,140
rank_h_max = rank_h_max),exploratory,4.0399999999999996e+22,140
"plot_best_consolidated <- single_plot_rmse_all_h(old_and_new,",exploratory,4.0399999999999996e+22,140
print(size4_vbls_new[!size4_vbls_new %in% size4_vbls_old]),exploratory,4.0399999999999996e+22,140
print(size5_vbls_new[!size5_vbls_new %in% size5_vbls_old]),exploratory,4.0399999999999996e+22,140
"size5_vbls_new = size5_vbls_new, size5_vbls_old = size5_vbls_old,",exploratory,4.0399999999999996e+22,140
plot_best_each = plot_best_each)),exploratory,4.0399999999999996e+22,140
"read_compare_var_res <- function(filename_new, filename_old,",exploratory,4.0399999999999996e+22,140
var_res_old <- readRDS(filename_old),exploratory,4.0399999999999996e+22,140
},exploratory,4.0399999999999996e+22,140
dplyr::select(-lag_sel_method),exploratory,4.0399999999999996e+22,140
"selected_two = var_res_old, is_wide = TRUE, h_max = h_max,",exploratory,4.0399999999999996e+22,140
"var_res_old = var_res_old, plot_best_consolidated = plot_best_consolidated,",exploratory,4.0399999999999996e+22,140
"lags, ~make_model_name(.x, .y, remove_base = FALSE)),",exploratory,4.0399999999999996e+22,140
"model_function = ""old"", var_size = map_dbl(variables,",exploratory,4.0399999999999996e+22,140
"print(""Size 4 VARs: variables in old that are not in new:"")",exploratory,4.0399999999999996e+22,140
"plot_best_each <- each_plot_rmse_all_h(selected_one = var_res_new,",exploratory,4.0399999999999996e+22,140
"if (""f_vbls_all_sizes"" %in% names(var_res_new)) {",exploratory,4.0399999999999996e+22,140
size4_vbls_new <- var_res_new %>% filter(var_size == 4) %>%,exploratory,4.0399999999999996e+22,140
"return(list(size4_vbls_new = size4_vbls_new, size4_vbls_old = size4_vbls_old,",exploratory,4.0399999999999996e+22,140
dplyr::select(variables) %>% unlist() %>% unique(),exploratory,4.0399999999999996e+22,140
print(size5_vbls_old[!size5_vbls_old %in% size5_vbls_new]),exploratory,4.0399999999999996e+22,140
length)) %>% dplyr::select(-rmse_8) %>% dplyr::select(-rank_8),exploratory,4.0399999999999996e+22,140
size5_vbls_new <- var_res_new %>% filter(var_size == 5) %>%,exploratory,4.0399999999999996e+22,140
"print(""Size 4 VARs: variables in new that are not in old:"")",exploratory,4.0399999999999996e+22,140
"var_res_new <- var_res_new[[""consolidated_var_res""]]",exploratory,4.0399999999999996e+22,140
size5_vbls_old <- var_res_old %>% filter(var_size == 5) %>%,exploratory,4.0399999999999996e+22,140
dplyr::select(variables) %>% unlist() %>% unique(),exploratory,4.0399999999999996e+22,140
dplyr::select(variables) %>% unlist() %>% unique(),exploratory,4.0399999999999996e+22,140
"var_res_old_and_new = old_and_new, var_res_new = var_res_new,",exploratory,4.0399999999999996e+22,140
print(size4_vbls_old[!size4_vbls_old %in% size4_vbls_new]),exploratory,4.0399999999999996e+22,140
"h_max = 7, rank_h_max = 30) {",exploratory,4.0399999999999996e+22,140
"var_res_new <- var_res_new %>% mutate(short_name = map2(variables,",exploratory,4.0399999999999996e+22,140
"var_res_old <- var_res_old %>% mutate(short_name = map2(variables,",exploratory,4.0399999999999996e+22,140
"print(""Size 5 VARs: variables in old that are not in new:"")",exploratory,4.0399999999999996e+22,140
"analysis = ""myclusters""",setup,735e20,144
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,531e20,143
sum.mutAll <- data.frame(),not sure,735e20,144
"arg_partial_filename_new <- ""var_results_Argentina_sizes_2345_fqlims_nonenone1510_t_2222.rds""",export,4.0399999999999996e+22,140
clargs <- commandArgs(trailingOnly = TRUE),setup,531e20,143
"arg_filename_new <- paste0(output_path, arg_partial_filename_new)",export,4.0399999999999996e+22,140
"arg_filename_old <- ""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Argentina_by_step_12345.rds""",export,4.0399999999999996e+22,140
} else {,setup,531e20,143
"filename = ""equifinality-3-population-data.rda"")",setup,531e20,143
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,531e20,143
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,531e20,143
"filename = ""equifinality-3-population-data.rda"", args = clargs)",setup,531e20,143
},setup,531e20,143
if (length(clargs) == 0) {,setup,531e20,143
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,531e20,143
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,531e20,143
"filename = ""equifinality-3-sampled-data.rda"")",setup,531e20,143
"filename = ""equifinality-3-sampled-data.rda"", args = clargs)",setup,531e20,143
"pattern = "".txt"")",setup,735e20,144
"mut.files.names <- list.files(path = ""/extraspace/TCGA/Mutation/"",",setup,735e20,144
"arg <- read_compare_var_res(arg_filename_new, arg_filename_old)",exploratory,4.0399999999999996e+22,140
"mut.files.Abs <- gsub(""mutation_|.txt"", """", mut.files.names)",setup,735e20,144
load(pop_data_file),import,531e20,143
load(sampled_data_file),import,531e20,143
"clinical.files.names <- list.files(path = ""/extraspace/TCGA/TCGA_clinical/"",     pattern = "".txt"")",setup,735e20,144
"bol_partial_filename_new <- ""var_results_Bolivia_sizes_2345_fqlims_nonenone1510_t_2222.rds""",setup,4.0399999999999996e+22,140
"clinical.files.Abs <- gsub(""_clinical_clean.txt"", """", clinical.files.names)",setup,735e20,144
"stratification.files.names <- list.files(path = ""/extraspace/yye1/analysis/Hypoxia/Stratification.tumor/"",     pattern = ""Hypoxia.stratification.txt"")",setup,735e20,144
"bol_filename_new <- paste0(output_path, bol_partial_filename_new)",setup,4.0399999999999996e+22,140
"bol_filename_old <- ""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Bolivia_by_step_12345.rds""",setup,4.0399999999999996e+22,140
"SampleCount <- read.delim(""/extraspace/yye1/analysis/Hypoxia/Stratification.tumor/Hypoxia and normoxia sample size large than 30.txt"", header = T)",setup,735e20,144
"stratification.files.Abs <- intersect(SampleCount$type, intersect(clinical.files.Abs,     mut.files.Abs))",setup,735e20,144
"bol <- read_compare_var_res(bol_filename_new, bol_filename_old)",import,4.0399999999999996e+22,140
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,3.6600000000000002e+22,145
"source(""./R/helper/00_helper_model_fcts.R"")",not sure,349e20,141
"bra_partial_filename_new <- ""var_results_Brasil_sizes_2345_fqlims_nonenone1510_t_2222.rds""",setup,4.0399999999999996e+22,140
"if (analysis == ""myclusters"") {",not sure,735e20,144
"cancer, ""_clinical_clean.txt"", sep = """")",not sure,735e20,144
"clinical.raw <- merge(stratification, clinical.raw, by = ""barcode"")",not sure,735e20,144
"form <- as.formula(paste(""Z~"", paste(colnames(data.dum)[-exclude.col],",not sure,735e20,144
for (cancer in stratification.files.Abs) {,not sure,735e20,144
"print(paste(""Total clinical samples for"", cancer, "":"", nrow(clinical.raw)))",not sure,735e20,144
"stratification$barcode <- gsub(""\\."", ""\\-"", substr(stratification$SampleID,",not sure,735e20,144
"c(""hypoxic"", ""normoxic"")), c(""myclusters"", ""barcode"")]",not sure,735e20,144
"consider_factors <- intersect(consider_factors, colnames(data))",not sure,735e20,144
"consider_factors <- c(""barcode"", ""myclusters"", ""age_at_initial_pathologic_diagnosis"",",not sure,735e20,144
else {,not sure,735e20,144
"data <- data[, consider_factors]",not sure,735e20,144
],not sure,735e20,144
"1, 0)",not sure,735e20,144
"data.dum$X0 <- rep(1, nrow(data.dum))",not sure,735e20,144
1,not sure,735e20,144
"""gender"", ""race"", ""pathologic_stage"")",not sure,735e20,144
"data <- data[-which(data$race == ""ASIAN"" | is.na(data$race)),",not sure,735e20,144
library(dummies),not sure,735e20,144
if (length(table(data$pathologic_stage)) == 0) {,not sure,735e20,144
},not sure,735e20,144
data <- unique(data),not sure,735e20,144
"dummy.feature <- setdiff(colnames(data), c(""Z"", ""age_at_initial_pathologic_diagnosis""))",not sure,735e20,144
"data.dum <- data.dum[, -rm.col]",not sure,735e20,144
"data$myclusters <- ifelse(data$myclusters == ""hypoxic"",",not sure,735e20,144
},not sure,735e20,144
if (length(which(is.na(data$pathologic_stage))) > 0) {,not sure,735e20,144
],not sure,735e20,144
"colnames(data)[which(colnames(data) == ""myclusters"")] <- ""Z""",not sure,735e20,144
library(foreach),not sure,735e20,144
"data <- data[, consider_factors]",not sure,735e20,144
"data <- data[-which(is.na(data$pathologic_stage)),",not sure,735e20,144
},not sure,735e20,144
"data <- data[, -1]",not sure,735e20,144
},not sure,735e20,144
"analysis <- ""myclusters""",not sure,735e20,144
rm.col <- c(),not sure,735e20,144
"rm.col <- c(rm.col, dummy.list[[i]][length(dummy.list[[i]])])",not sure,735e20,144
"colnames(data.dum) <- gsub("" "", ""."", colnames(data.dum))",not sure,735e20,144
"source(""~/code/cal.R"")",not sure,735e20,144
library(doMC),not sure,735e20,144
"""pathologic_stage"")]",not sure,735e20,144
},not sure,735e20,144
for (i in 1:length(dummy.list)) {,not sure,735e20,144
"clinical.raw <- read.table(clinical.file, header = TRUE,",not sure,735e20,144
"clinical.file <- paste(""/extraspace/TCGA/TCGA_clinical/"",",not sure,735e20,144
stratification <- stratification[which(stratification$myclusters %in%,not sure,735e20,144
if (nrow(clinical.raw) >= 50) {,not sure,735e20,144
"stratification <- read.delim(paste(""/extraspace/yye1/analysis/Hypoxia/Stratification.tumor/"",",not sure,735e20,144
"check.names = FALSE, sep = ""\t"", quote = """", comment.char = """")",not sure,735e20,144
consider_factors <- consider_factors[which(consider_factors !=,not sure,735e20,144
if (length(which(is.na(data$race))) > 0) {,not sure,735e20,144
"rownames(data) <- data[, 1]",not sure,735e20,144
"data.dum <- dummy.data.frame(data, names = dummy.feature)",not sure,735e20,144
"dummy.list <- attr(data.dum, ""dummies"")",not sure,735e20,144
"cancer, "".Hypoxia.stratification.txt"", sep = """"), header = T)",not sure,735e20,144
"data <- clinical.raw[, 1:end.col]",not sure,735e20,144
"exclude.col <- match(c(""Z"", ""X0""), colnames(data.dum))",not sure,735e20,144
"1, 12))",not sure,735e20,144
"end.col <- which(colnames(clinical.raw) == ""os_days"") -",not sure,735e20,144
data$race <- as.vector(data$race),not sure,735e20,144
},not sure,735e20,144
data$race <- factor(data$race),not sure,735e20,144
"collapse = ""+""), sep = """"))",not sure,735e20,144
"write.summary(sum.mut, cancer, analysis, ""mut"")",not sure,735e20,144
},not sure,735e20,144
"mutation.pri <- data.frame(t(mutation[, 2:ncol(mutation)]))",not sure,735e20,144
"weight = ifelse(analysis == ""myclusters"",",not sure,735e20,144
cutoff <- 0.05,not sure,735e20,144
if (FALSE) {,not sure,735e20,144
keep.index <- mut.rate.sort$ix[match(names(which(mut.rate.sort$x >,not sure,735e20,144
sum.mut <- data.frame(sum.mut),not sure,735e20,144
"sum.mut$class <- rep(cancer, times = nrow(sum.mut))",not sure,735e20,144
"cancer, "".txt"", sep = """"), header = T)",not sure,735e20,144
"colnames(mutation.pri) <- as.vector(mutation[, 1])",not sure,735e20,144
"mutation <- read.delim(paste(""/extraspace/TCGA/Mutation/mutation_"",",not sure,735e20,144
top.cutoff <- mut.rate.sort$x[top],not sure,735e20,144
"""myclusters"", ""MW"", ""ATT""), mirror.plot = FALSE,",not sure,735e20,144
"mut.result, print = TRUE)",not sure,735e20,144
seed = seed),not sure,735e20,144
"save(seed, perm.mut.result, file = paste(scripts.dir,",not sure,735e20,144
registerDoMC(15),not sure,735e20,144
mut.rate <- colSums(mutation.pri)/nrow(mutation.pri),not sure,735e20,144
},not sure,735e20,144
mut.cutoff <- 0.05,not sure,735e20,144
"mut.rate.sort <- sort(mut.rate, decreasing = T, index.return = T)",not sure,735e20,144
keep.index <- which(mut.rate >= top.cutoff),not sure,735e20,144
if (!file.exists(folder)) {,not sure,735e20,144
"mutation.pri[, keep.index], is.continuous = FALSE,",not sure,735e20,144
"""mut"", outdir = paste(scripts.dir, ""/"", cancer,",not sure,735e20,144
"""_"", analysis, sep = """"), perm = TRUE,",not sure,735e20,144
"mut.ttest <- myttest(data.dum, mutation.pri,",not sure,735e20,144
else {,not sure,735e20,144
"sep = """"))",not sure,735e20,144
"write.result(mut.result, cancer, analysis, ""mut"")",not sure,735e20,144
{,not sure,735e20,144
"""MW"", ""ATT""), mirror.plot = TRUE, cancer,",not sure,735e20,144
"write(c(seed, perm.sum.mut$n.sig), file = paste(scripts.dir,",not sure,735e20,144
"save(mRNAseq.ttest, file = paste(cancer, ""_mut_ttest.RData"",",not sure,735e20,144
},not sure,735e20,144
"mut.cutoff)), names(mut.rate.sort$x))]",not sure,735e20,144
"folder <- paste(cancer, ""_"", analysis, sep = """")",not sure,735e20,144
if (nrow(sum.mutAll) == 0) {,not sure,735e20,144
top <- 100,not sure,735e20,144
"cancer, ""mut"", outdir = paste(scripts.dir, ""/"", cancer,",not sure,735e20,144
"""_"", analysis, sep = """"), perm = FALSE)",not sure,735e20,144
"print = TRUE, cutoff = 0.05)",not sure,735e20,144
},not sure,735e20,144
"perm.mut.result <- weight.test(data.dum, form,",not sure,735e20,144
sum.mutAll <- sum.mut,not sure,735e20,144
},not sure,735e20,144
},not sure,735e20,144
},not sure,735e20,144
if (length(which(mut.rate > mut.cutoff)) > 100) {,not sure,735e20,144
else {,not sure,735e20,144
"seed, "".txt"", sep = """"), ncolumns = 7)",not sure,735e20,144
seedV <- 1:100,not sure,735e20,144
"cancer, ""mut"")",not sure,735e20,144
},not sure,735e20,144
dir.create(folder),not sure,735e20,144
"perm.cal(cancer, analysis, ""mut"", mutation.pri[,",not sure,735e20,144
},not sure,735e20,144
"mut.result <- weight.test(data.dum, form, mutation.pri[,",not sure,735e20,144
"keep.index], perm.mut.result)",not sure,735e20,144
top.index <- mut.rate.sort$ix[1:top],not sure,735e20,144
if (length(which(mut.result$fdr < 0.05)) > 0) {,not sure,735e20,144
},not sure,735e20,144
"summarize.fdr(mutation.pri[, keep.index], mut.result,",not sure,735e20,144
"sum.mutAll <- rbind(sum.mutAll, sum.mut)",not sure,735e20,144
"perm.sum.mut <- summarize.fdr(mutation.pri[,",not sure,735e20,144
"""/"", cancer, ""_"", analysis, ""/perm_sig_result_"",",not sure,735e20,144
"""/"", cancer, ""_"", analysis, ""/perm_sig_count_"",",not sure,735e20,144
"seed, "".RData"", sep = """"))",not sure,735e20,144
"keep.index], is.continuous = FALSE, weight = ifelse(analysis ==",not sure,735e20,144
"sum.mut <- summarize.fdr(mutation.pri[, keep.index],",not sure,735e20,144
"perm.result <- foreach(seed = 1:100, .combine = ""rbind"") %dopar%",not sure,735e20,144
"keep.index], cutoff = cutoff, seedV = seedV)",not sure,735e20,144
"sum.mut <- summarize.fdr(mutation.pri, mut.ttest)",not sure,735e20,144
"bra_filename_new <- paste0(output_path, bra_partial_filename_new)",setup,4.0399999999999996e+22,140
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,3.6600000000000002e+22,145
"source(""./R/helper/00_helper_simulation_data.R"")",not sure,349e20,141
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,3.6600000000000002e+22,145
"bra_filename_old <- ""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Brasil_by_step_12345.rds""",setup,4.0399999999999996e+22,140
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,3.6600000000000002e+22,145
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,3.6600000000000002e+22,145
"write.table(sum.mutAll, file = ""Mutation.genes.across.cancer.types.txt"",     quote = F, sep = ""\t"", row.names = F)",export,735e20,144
"source(""./R/helper/99_helper_diagnostics.R"")",not sure,349e20,141
"bra <- read_compare_var_res(bra_filename_new, bra_filename_old)",import,4.0399999999999996e+22,140
"source(""./R/helper/01_helper_cBPF_as.R"")",not sure,349e20,141
"source(""./R/helper/02_helper_pgas.R"")",not sure,349e20,141
"source(""./R/01_cBPF_as.R"")",not sure,349e20,141
"MutationCountAll <- c(""Type"", ""Mutation.Num"")",setup,735e20,144
"chl_partial_filename_new <- ""var_results_Chile_sizes_2345_fqlims_nonenone1510_t_2222.rds""",setup,4.0399999999999996e+22,140
"source(""./R/02_pgas.R"")",not sure,349e20,141
"chl_filename_new <- paste0(output_path, chl_partial_filename_new)",setup,4.0399999999999996e+22,140
"mutation <- read.delim(paste(""/extraspace/TCGA/Mutation/mutation_"",",not sure,735e20,144
"cancer, "".txt"", sep = """"), header = T)",not sure,735e20,144
mut.rate <- colSums(mutation.pri)/nrow(mutation.pri),not sure,735e20,144
for (cancer in stratification.files.Abs) {,not sure,735e20,144
"mutation.count <- c(cancer, length(mut.rate[mut.rate > 0.05]))",not sure,735e20,144
"colnames(mutation.pri) <- as.vector(mutation[, 1])",not sure,735e20,144
"MutationCountAll <- rbind(MutationCountAll, mutation.count)",not sure,735e20,144
"mutation.pri <- data.frame(t(mutation[, 2:ncol(mutation)]))",not sure,735e20,144
},not sure,735e20,144
"chl_filename_old <- ""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Chile_by_step_12345.rds""",setup,4.0399999999999996e+22,140
"write.csv(MutationCountAll, file = ""/extraspace/yye1/analysis/Hypoxia/PSM/Mutation/MutationCountAll.csv"",     quote = F, row.names = F)",export,735e20,144
init_at_true <- TRUE,setup,349e20,141
"chl <- read_compare_var_res(chl_filename_new, chl_filename_old)",import,4.0399999999999996e+22,140
pgas_run <- TRUE,setup,349e20,141
set.seed(123),setup,349e20,141
library(ogbox),setup,735e20,144
"chl2_partial_filename_new <- ""var_results_Chile_sizes_2345_fqlims_nonenone1510_t_2222_mr50_mrfq30.rds""",setup,4.0399999999999996e+22,140
library(GOADquery),setup,735e20,144
"chl2_filename_new <- paste0(output_path, chl2_partial_filename_new)",setup,4.0399999999999996e+22,140
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test.R"")",not sure,349e20,141
"chl2 <- read_compare_var_res(chl2_filename_new, chl_filename_old)",setup,4.0399999999999996e+22,140
"req <- c(""rstan"")",setup,7.4800000000000004e+22,140
"lapply(req, library, character.only = TRUE)",setup,7.4800000000000004e+22,140
rm(req),setup,7.4800000000000004e+22,140
set.seed(893749),setup,7.4800000000000004e+22,140
sessionInfo(),setup,7.4800000000000004e+22,140
"poisson_ods_full_centred <- stan_model(""./analysis/m01_poisson_ods_full_centred.stan"",     verbose = TRUE)",setup,7.4800000000000004e+22,140
"save(poisson_ods_full_centred, file = ""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",modeling,7.4800000000000004e+22,140
sink(),export,7.4800000000000004e+22,140
sink(),export,7.4800000000000004e+22,140
"sink(""./analysis/output/l02_compile_model.rlog"", split = TRUE)",setup,7.4800000000000004e+22,140
"setwd(""analysis"")",setup,7.4800000000000004e+22,140
library(e1071),setup,7.4800000000000004e+22,140
require(Hmisc),setup,7.4800000000000004e+22,140
library(osfr),setup,7.4800000000000004e+22,140
library(tidyverse),setup,7.4800000000000004e+22,140
library(stringr),setup,7.4800000000000004e+22,140
library(glmpath),setup,7.4800000000000004e+22,140
"source(""Rcode/functions.r"")",setup,7.4800000000000004e+22,140
"PMeta = ""../data/Projects_metadata.csv""",setup,7.4800000000000004e+22,140
Projects_metadata <- read_csv(PMeta),import,7.4800000000000004e+22,140
RECREATEMINFILE = FALSE,setup,7.4800000000000004e+22,140
STICK = NA,setup,7.4800000000000004e+22,140
"Name_project = ""Ro_testdata""",setup,7.4800000000000004e+22,140
"groupingby = ""MITsoft""",setup,7.4800000000000004e+22,140
"source(""Rcode/get_behav_gp.r"")",setup,7.4800000000000004e+22,140
"source(""Rcode/analysis_for_paper1/multidimensional_analysis_prep_diffTW.R"")",setup,7.4800000000000004e+22,140
six_windowMIT = Multi_datainput_m,setup,7.4800000000000004e+22,140
"input.pca <- prcomp(Multi_datainput_m %>% select(-groupingvar),     center = TRUE, scale. = TRUE)",exploratory,7.4800000000000004e+22,140
Moddata = as.data.frame(input.pca$x),data cleaning,7.4800000000000004e+22,140
Moddata$groupingvar = as.factor(Multi_datainput_m$groupingvar),data cleaning,7.4800000000000004e+22,140
data = Moddata,data cleaning,7.4800000000000004e+22,140
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",import,7.4800000000000004e+22,140
ACURRACY,setup,7.4800000000000004e+22,140
"data = Moddata[, 1:10]",setup,7.4800000000000004e+22,140
data$groupingvar = as.factor(Multi_datainput_m$groupingvar),data cleaning,7.4800000000000004e+22,140
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,7.4800000000000004e+22,140
ACURRACY,setup,7.4800000000000004e+22,140
library(stringr),setup,7.4800000000000004e+22,140
library(vegan),setup,7.4800000000000004e+22,140
library(reshape2),setup,7.4800000000000004e+22,140
library(scales),setup,7.4800000000000004e+22,140
library(plyr),setup,7.4800000000000004e+22,140
library(RColorBrewer),setup,7.4800000000000004e+22,140
rm(list = ls()),setup,691e20,145
library(dplyr),import,691e20,145
"source(""Analysis/new_analysis/catch_shares/Analysis/01_create_vessel_df.R"")",setup,691e20,145
vessel_landings <- create_vessel_landings(),modeling,691e20,145
"source(""Analysis/new_analysis/catch_shares/Analysis/01_vessel_stats.R"")",setup,691e20,145
vessel_stats <- calc_vessel_vars(),modeling,691e20,145
"setwd(""~/Dropbox/Expert Survey/Analysis/csv files"")",setup,816e20,140
NAMES <- dir(),setup,816e20,140
"FILE.NAME <- ""expert survey matrix.csv""",setup,816e20,140
library(maptools),setup,267e20,146
library(sp),setup,267e20,146
library(jsonlite),setup,267e20,146
library(doBy),setup,267e20,146
library(raster),setup,267e20,146
library(plyr),setup,267e20,146
"source(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis/Code/geoSIMEX.R"")",setup,267e20,146
"setwd(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis"")",setup,267e20,146
"data.subset.categories <- list(c(""Burundi"", ""Democratic Republic of the Congo""))",data cleaning,267e20,146
"source(""../../bin/dermalNFData.R"")",setup,743e20,140
require(dplyr),setup,743e20,140
require(ggplot2),setup,743e20,140
data.subset.categories.i <- 3,data cleaning,267e20,146
"all.mutations <- read.table(synGet(""syn5713423"")@filePath, header = T,     sep = ""\t"")",import,743e20,140
library(urca),exploratory,804e20,147
library(vars),exploratory,804e20,147
"source(""data-raw/fetch-raw-data.R"")",exploratory,804e20,147
adf <- list(),exploratory,804e20,147
"adf[[1]] <- ur.df(CZ2016, type = ""drift"", lags = 5)",evaluation,804e20,147
analysis.year.begin <- 2001,modeling,267e20,146
analysis.year.end <- 2013,modeling,267e20,146
"adf[[2]] <- ur.df(SX2016, type = ""drift"", lags = 5)",evaluation,804e20,147
"jct <- ca.jo(cbind(CZ2016, SX2016), type = ""eigen"", K = 5)",evaluation,804e20,147
"lag_selection <- VARselect(cbind(CZ2016, SX2016), lag.max = 8)",evaluation,804e20,147
"var_model <- VAR(cbind(CZ2016, SX2016), p = 1, type = ""const"")",evaluation,804e20,147
"save(adf, jct, lag_selection, var_model, file = ""analysis-output/results.rda"")",evaluation,804e20,147
aid.year.begin <- 2005,modeling,267e20,146
aid.year.end <- 2010,modeling,267e20,146
pre.end <- aid.year.begin - 1,modeling,267e20,146
post.begin <- aid.year.end + 1,modeling,267e20,146
"macArth.level_1a <- read.csv(paste(getwd(), ""/Data/MacArthur_Geocoded_data/level_1a.csv"",     sep = """"))",import,267e20,146
"c(""210"", ""220"", ""230"", ""320""), ]",data cleaning,267e20,146
macArth.inf <- macArth.level_1a[macArth.level_1a$ad_sector_codes %in%,data cleaning,267e20,146
"""Implementation""), ]",data cleaning,267e20,146
"macArth.inf <- macArth.inf[macArth.inf$status %in% c(""Completion"",",data cleaning,267e20,146
macArth.inf <- macArth.inf[(macArth.inf$transactions_end_year >=,data cleaning,267e20,146
"aid.year.begin) & (macArth.inf$transactions_end_year <= aid.year.end),",data cleaning,267e20,146
],data cleaning,267e20,146
macArth.inf$recipients_iso3 <- as.character(macArth.inf$recipients_iso3),data cleaning,267e20,146
"macArth.inf <- macArth.inf[macArth.inf$recipients_iso3 != ""Unspecified"",",data cleaning,267e20,146
],data cleaning,267e20,146
"macArth.inf <- macArth.inf[!is.na(macArth.inf$project_id), ]",data cleaning,267e20,146
},not sure,267e20,146
"][macArth.inf[macArth.inf$recipients_iso3 %in% iso3,",not sure,267e20,146
"if (nrow(macArth.inf[macArth.inf$recipients_iso3 %in% iso3,",not sure,267e20,146
"iso3, ]$precision_code %in% c(6, 8), ]$latitude <- macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
"iso3, ]$precision_code %in% c(6, 8), ]$longitude <- macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
"iso3, ][macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
"]$precision_code %in% c(6, 8), ]) > 0) {",not sure,267e20,146
for (iso3 in names(table(macArth.inf$recipients_iso3))) {,not sure,267e20,146
"macArth.inf[macArth.inf$recipients_iso3 %in% iso3, ][macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
"macArth.inf[macArth.inf$recipients_iso3 %in% iso3, ][macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
},not sure,267e20,146
"iso3, ][macArth.inf[macArth.inf$recipients_iso3 %in%",not sure,267e20,146
"iso3, ]$precision_code %in% c(1), ]$longitude[1]",not sure,267e20,146
"iso3, ]$precision_code %in% c(1), ]$latitude[1]",not sure,267e20,146
library(tidyverse),setup,874e20,140
library(adegenet),setup,874e20,140
library(ReproWorkshop),setup,874e20,140
data(ReproWorkshop),import,874e20,140
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_04.R"",     echo = FALSE)",setup,791e20,148
"dapc.all <- dapc(dat.genind, var.contrib = TRUE, scale = FALSE,     n.pca = 100, n.da = nPop(dat.genind) - 1)",exploratory,874e20,140
"popVector <- substring(indNames(dat.genind), 1, 5)",data cleaning,874e20,140
"dapc.df <- cbind(as.data.frame(dapc.all$ind.coord)[1:2], popVector)",data cleaning,874e20,140
"names(dapc.df) <- c(""A1"", ""A2"", ""pop"")",data cleaning,874e20,140
"dapc.plot <- ggplot(dapc.df, aes(x = A1, y = A2, color = pop)) +     theme_classic(base_size = 18) + theme(legend.position = c(0.88,     0.85)) + theme(legend.background = element_rect(colour = ""black"",     fill = ""white"", linetype = ""solid"")) + NULL",visualization,874e20,140
dapc.plot,visualization,874e20,140
"mn.rentals <- mn.sale[which(grepl(""RENTALS"", mn.sale$building.class.category)), ]",exploratory,791e20,148
mn.rentals$Price.per.gross.sqft <- mn.rentals$sale.price.n/mn.rentals$gross.sqft,exploratory,791e20,148
rm(list = ls()),setup,874e20,140
"analysisDir = normalizePath(""."")",setup,874e20,140
mn.rentals$Price.per.land.sqft <- mn.rentals$sale.price.n/mn.rentals$land.sqft,exploratory,791e20,148
"setwd(""/Users/ereznik/pancanmet_analysis/analysis/"")",setup,874e20,140
"source(""functions/readBigMet.R"")",setup,874e20,140
"source(""functions/multiplot_mod.R"")",setup,874e20,140
"mn.rentals$Price.per.gross.sqft <- replace(mn.rentals$Price.per.gross.sqft,     which(is.na(mn.rentals$Price.per.gross.sqft)), 0)",exploratory,791e20,148
"source(""plottingconventions.R"")",setup,874e20,140
library(ggplot2),setup,874e20,140
"mn.rentals$Price.per.land.sqft <- replace(mn.rentals$Price.per.land.sqft,     which(is.na(mn.rentals$Price.per.land.sqft)), 0)",exploratory,791e20,148
library(xlsx),setup,874e20,140
dim(mn.rentals),exploratory,791e20,148
library(combinat),setup,874e20,140
library(ogbox),data cleaning,152e20,149
study2drop = c(),setup,874e20,140
pthresh = 0.1,setup,874e20,140
metdata = readBigMet(study2drop),import,874e20,140
hist(log10(mn.rentals$sale.price.n)),visualization,791e20,148
met = metdata$met,data cleaning,874e20,140
"summary(mn.rentals[which(mn.rentals$sale.price.n < 1e+05), ])",exploratory,791e20,148
tissuetype = metdata$tissuetype,data cleaning,874e20,140
studytype = metdata$studytype,data cleaning,874e20,140
"source(""R/puristOut.R"")",import,152e20,149
0,exploratory,791e20,148
mn.rentals$outliers <- (log10(mn.rentals$sale.price.n) <= 5) +,exploratory,791e20,148
uqstudy = unique(studytype),data cleaning,874e20,140
"tmap = read.csv(""../data/merged_metabolomics/merged_tissuetypes.csv"",     row.names = 1, header = T)",import,874e20,140
"source(""R/estimate.R"")",modeling,152e20,149
mult = names(which(table(tmap) > 1)),data cleaning,874e20,140
pnames = list(),data cleaning,874e20,140
pctr = 1,setup,874e20,140
"mn.rentals <- mn.rentals[which(mn.rentals$outliers == 0), ]",export,791e20,148
"source(""R/superImpose.R"")",evaluation,152e20,149
library(gtable),visualization,152e20,149
"d = met[, idx]",modeling,874e20,140
"d = d[complete.cases(d), ]",modeling,874e20,140
d = as.matrix(d),modeling,874e20,140
"p[metabolite, s] = wilcox.test(d[metabolite, tumidx],",modeling,874e20,140
},modeling,874e20,140
"sep = """"), sheetName = ""P"", col.names = TRUE, row.names = TRUE,",modeling,874e20,140
"study2 = scombs[2, i]",modeling,874e20,140
"plotdata = fc[, s2plot]",modeling,874e20,140
"sigmets = rownames(padj)[which(p[, study1] < pthresh &",modeling,874e20,140
"tempfc = fcadj[, s2plot]",modeling,874e20,140
idx = which(studytype %in% s2use),modeling,874e20,140
1)),modeling,874e20,140
""".xlsx"", sep = """"), sheetName = ""PAdj"", col.names = TRUE,",modeling,874e20,140
padj = fc,modeling,874e20,140
append = TRUE),modeling,874e20,140
"fignum = ggplot(plotdata, aes(X, Y, color = Significance)) +",modeling,874e20,140
"s2use = rownames(tmap)[which(tmap[, 1] == ttype)]",modeling,874e20,140
"row.names = TRUE, append = TRUE)",modeling,874e20,140
fcadj[p > pthresh] = 0,modeling,874e20,140
pvalue = fisher.test(table(tempfc))$p.value,modeling,874e20,140
"pvalue = round(pvalue, 3)",modeling,874e20,140
normidx])),modeling,874e20,140
p = fc,modeling,874e20,140
"fc[metabolite, s] = log2(mean(d[metabolite, tumidx])/mean(d[metabolite,",modeling,874e20,140
"d[metabolite, normidx])$p.value",modeling,874e20,140
"padj[, s] = p.adjust(p[, s], method = ""BH"")",modeling,874e20,140
"write.xlsx2(p, paste(""../results/sametissue/"", ttype, "".xlsx"",",modeling,874e20,140
scombs = matrix(t(scombs)),modeling,874e20,140
"p[, study2] < pthresh)]",modeling,874e20,140
"tumidx = which(d_study == s & (d_tissue == ""Tumor""))",modeling,874e20,140
for (metabolite in rownames(d)) {,modeling,874e20,140
},modeling,874e20,140
append = FALSE),modeling,874e20,140
"scombs = combn(s2use, 2)",modeling,874e20,140
"plotdata$Significance = ""NS""",modeling,874e20,140
"1], ]",modeling,874e20,140
"tissuecorval = round(tissuecor$estimate, 3)",modeling,874e20,140
"titlestr = paste(ttype, "", Fisher Test P-Value ="", pvalue,",modeling,874e20,140
for (i in 1:dim(scombs)[2]) {,modeling,874e20,140
"""\n"", ""Spearman rho"", tissuecorval, ""P-Value ="",",modeling,874e20,140
"d_tissue = unlist(lapply(strsplit(colnames(d), "":""), `[[`,",modeling,874e20,140
for (ttype in mult) {,modeling,874e20,140
3)),modeling,874e20,140
fcadj = fc,modeling,874e20,140
"tempfc = tempfc[-which(tempfc == 0, arr.ind = TRUE)[,",modeling,874e20,140
"plotdata[sigmets, ""Significance""] = ""Significant""",modeling,874e20,140
for (s in unique(s2use)) {,modeling,874e20,140
colnames(fc) = s2use,modeling,874e20,140
print(ttype),modeling,874e20,140
"sep = """"), sheetName = ""FC"", col.names = TRUE, row.names = TRUE,",modeling,874e20,140
"write.xlsx2(padj, paste(""../results/sametissue/"", ttype,",modeling,874e20,140
if (length(scombs) == 2) {,modeling,874e20,140
tempfc = sign(tempfc),modeling,874e20,140
"d_study = unlist(lapply(strsplit(colnames(d), "":""), `[[`,",modeling,874e20,140
"write.xlsx2(fc, paste(""../results/sametissue/"", ttype, "".xlsx"",",modeling,874e20,140
"s2plot = scombs[, i]",modeling,874e20,140
"tissuecor = cor.test(plotdata$X, plotdata$Y, method = ""spearman"")",modeling,874e20,140
"tissuecorp, sep = "" "")",modeling,874e20,140
"study1 = scombs[1, i]",modeling,874e20,140
"fc = data.frame(matrix(0, dim(d)[1], length(s2use)), row.names = rownames(d))",modeling,874e20,140
},modeling,874e20,140
"colnames(plotdata) = c(""X"", ""Y"")",modeling,874e20,140
"tissuecorp = round(tissuecor$p.value, 3)",modeling,874e20,140
"normidx = which(d_study == s & d_tissue == ""Normal"")",modeling,874e20,140
"scale_color_manual(values = c(NS = ""gray"", Significant = ""red""))",modeling,874e20,140
ylab(names2plot[s2plot[2]]) + geom_vline(xintercept = 0) +,modeling,874e20,140
"pnames = c(pnames, pname)",modeling,874e20,140
print(fignum),modeling,874e20,140
pctr = pctr + 1,modeling,874e20,140
geom_point() + theme_classic() + xlab(names2plot[s2plot[1]]) +,modeling,874e20,140
"pname = paste(""fignum"", pctr, sep = """")",modeling,874e20,140
"assign(pname, fignum)",modeling,874e20,140
},modeling,874e20,140
geom_hline(yintercept = 0) + ggtitle(titlestr) +,modeling,874e20,140
},modeling,874e20,140
library(grid),visualization,152e20,149
pnames = unlist(pnames),data cleaning,874e20,140
library(parallel),setup,152e20,149
"pdf(""../results/sametissue/sametissue.pdf"", height = 10, width = 10)",export,874e20,140
"theirPred = read.table(""data/bloodCellType/lymphomaCounts.tsv"",     sep = ""\t"", header = T)",import,152e20,149
"multiplot_mod(pnames, cols = 2)",visualization,874e20,140
dev.off(),export,874e20,140
"gsmFind(GSE = ""GSE65135"", regex = x)",modeling,152e20,149
"gsms = sapply(theirPred$Sample.ID, function(x) {",modeling,152e20,149
}),modeling,152e20,149
theirPred$Sample.ID = gsms,modeling,152e20,149
"names(theirPred) = c(""Sample.ID"", ""Cell.type"", ""RealCounts"",     ""CibersortPred"")",setup,152e20,149
"source(""https://bioconductor.org/biocLite.R"")",setup,712e20,1
library(RnBeads),setup,712e20,1
library(hexbin),setup,712e20,1
library(wordcloud),setup,712e20,1
"raw.data.dir = ""../../data/raw/Breakefield_HBMVEC_450k/""",import,712e20,1
"analysis.dir = ""./RnBeads/analysis""",import,712e20,1
"report.dir = file.path(analysis.dir, ""GetDMRs_9comps_SVAbe_July19_2016"")",import,712e20,1
"rnb.options(analysis.name = ""Breakefield450k"", assembly = ""hg19"",     disk.dump.big.matrices = FALSE, filtering.sex.chromosomes.removal = TRUE,     import.table.separator = ""\t"", identifiers.column = ""Sample_ID"")",setup,712e20,1
"source(""./MapPRESSTOenh_prom_sym.R"")",setup,712e20,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,383e20,150
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,383e20,150
"rnb.set.annotation(type = enh.prof, description = enh.prof,",setup,712e20,1
"6)], assembly = ""hg19"")",setup,712e20,1
"regions = my.mapped.ehnancer.annots[[enh.prof]][c(1:3,",setup,712e20,1
for (enh.prof in names(my.mapped.ehnancer.annots)) {,setup,712e20,1
},setup,712e20,1
"rnb.options(region.types = c(""genes"", ""promoters"", names(my.mapped.ehnancer.annots)))",setup,712e20,1
"rnb.getOption(""region.types"")",setup,712e20,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,383e20,150
"theirPred = theirPred %>% arrange(Cell.type, Sample.ID)",setup,152e20,149
"breakefield450K = readRDS(paste(raw.data.dir, ""bkfld450k.rda"",     sep = """"))",import,712e20,1
"colnames(breakefield450K) = gsub(""_zappulliMGH1_[ABCDEF][1234]"",   """", colnames(breakefield450K))",data cleaning,712e20,1
"colnames(breakefield450K) = gsub("".."", ""."", colnames(breakefield450K),     fixed = T)",data cleaning,712e20,1
"breakefield450K = breakefield450K[, order(colnames(breakefield450K))]",data cleaning,712e20,1
"betas = breakefield450K[, c(as.numeric(grep(""AVG_Beta"", colnames(breakefield450K))))]",data cleaning,712e20,1
rownames(betas) = breakefield450K$TargetID,data cleaning,712e20,1
"p.vals = breakefield450K[,   colnames(breakefield450K))))]",data cleaning,712e20,1
"my.pheno <- read.csv(file = ""./input/my.pheno.txt"", header = T,     sep = "","", quote = """", na.strings = ""NA"")",import,712e20,1
my.pheno = as.data.frame(my.pheno),data cleaning,712e20,1
betas = as.matrix(betas),data cleaning,712e20,1
p.vals = as.matrix(p.vals),data cleaning,712e20,1
dim(my.pheno),exploratory,712e20,1
my.range = c(1:24),data cleaning,712e20,1
"my.pheno = my.pheno[my.range, ]",data cleaning,712e20,1
"betas = betas[, my.range]",data cleaning,712e20,1
"p.vals = p.vals[, my.range]",data cleaning,712e20,1
my.diff.comps <- colnames(my.pheno)[5:13],data cleaning,712e20,1
rnb.initialize.reports(report.dir),communication,712e20,1
"my.rnb.set <- RnBeadSet(pheno = my.pheno, betas = betas, probes = rownames(betas),     useff = FALSE, p.values = p.vals, platform = ""450k"")",import,712e20,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,1.5900000000000001e+22,151
"any.bad.p.val = apply(dpval(my.rnb.set) > 0.01, 1, any)",data cleaning,712e20,1
"my.rnb.set = remove.sites(my.rnb.set, any.bad.p.val)",data cleaning,712e20,1
library(tsensembler),setup,1.5900000000000001e+22,151
"rnb.sample.groups(annotations = my.pheno, columns = NULL, columns.pairs = NULL,     min.group.size = rnb.getOption(""min.group.size""), max.group.count = rnb.getOption(""max.group.count""))",data cleaning,712e20,1
"rnb.sample.replicates(my.rnb.set, ""Replicate"")",data cleaning,712e20,1
library(reshape2),setup,1.5900000000000001e+22,151
rnb.options(qc = TRUE),modeling,712e20,1
library(ggplot2),setup,1.5900000000000001e+22,151
"rnb.options(qc.boxplots = TRUE, qc.barplots = TRUE, qc.negative.boxplot = FALSE,     qc.sample.batch.size = 50, qc.coverage.plots = FALSE, qc.coverage.threshold.plot = 1:10,     qc.snp.distances = TRUE, qc.snp.boxplot = T, qc.snp.barplot = FALSE,     qc.coverage.histograms = FALSE, qc.coverage.violins = T)",modeling,712e20,1
"setwd(""/Users/vcerqueira/Desktop/ADETK2/ID/"")",setup,1.5900000000000001e+22,151
"if (rnb.getOption(""qc"")) {",modeling,712e20,1
"rnb.run.qc(my.rnb.set, report.dir)",modeling,712e20,1
},modeling,712e20,1
"x <- lapply(list.files(), function(x) {",import,1.5900000000000001e+22,151
rm.null(adddata_analysis),import,1.5900000000000001e+22,151
load(x),import,1.5900000000000001e+22,151
}),import,1.5900000000000001e+22,151
"adddata_analysis <- sapply(x, rm.null)",data cleaning,1.5900000000000001e+22,151
length(adddata_analysis),data cleaning,1.5900000000000001e+22,151
"names(adddata_analysis) <- paste0(""ts_"", 1:14)",data cleaning,1.5900000000000001e+22,151
"5)], 1, rank)))",modeling,1.5900000000000001e+22,151
"ds_rank <- as.data.frame(t(apply(ds_by_arima[, c(1, 2, 3,",modeling,1.5900000000000001e+22,151
ds_by_arima <- as.data.frame(ds),modeling,1.5900000000000001e+22,151
"ds <- Reduce(rbind.data.frame, lapply(x, as.data.frame))",modeling,1.5900000000000001e+22,151
"ds_rank <- roll_mean_matrix(ds_rank, 100)",modeling,1.5900000000000001e+22,151
"res <- lapply(adddata_analysis, function(x) {",modeling,1.5900000000000001e+22,151
"ds_rank <- round(ds_rank, 3)",modeling,1.5900000000000001e+22,151
"as.matrix(head(ds_rank, 2800))",modeling,1.5900000000000001e+22,151
}),modeling,1.5900000000000001e+22,151
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"resf <- apply(simplify2array(res), 1:2, mean)",exploratory,1.5900000000000001e+22,151
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"colnames(resf) <- c(""ADE"", ""ARIMA"", ""Naive"", ""SimpleTrim"")",communication,1.5900000000000001e+22,151
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,558e19,152
df <- melt(resf),data cleaning,1.5900000000000001e+22,151
library(ogbox),setup,558e19,152
"colnames(df) <- c(""Time"", ""Model"", ""AvgRank"")",communication,1.5900000000000001e+22,151
"ggplot(df, aes(x = Time, y = AvgRank, color = Model)) + geom_line(lwd = 0.8) +     theme_minimal() + geom_vline(xintercept = 150) + theme(legend.position = ""top"")",visualization,1.5900000000000001e+22,151
"source(""R/rnaSeqTresh.R"")",setup,558e19,152
"rnaSeq = read.table(""data/linnarsonSingleCell/mouseRNASeq_Zeisel 2015.txt"",     sep = ""\t"", comment.char = """", stringsAsFactors = F)",import,558e19,152
"rnaMeta = rnaSeq[1:10, 3:ncol(rnaSeq)]",exploratory,558e19,152
rnaMeta = as.data.frame(t(rnaMeta)),data cleaning,558e19,152
"colnames(rnaMeta) = rnaSeq[1:10, 2]",data cleaning,558e19,152
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",data cleaning,558e19,152
"rnaExp = apply(rnaExp, 2, as.numeric)",exploratory,558e19,152
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",data cleaning,558e19,152
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",data cleaning,558e19,152
"rnaCelIDs = as.numeric(as.character(rnaSeq[12:nrow(rnaSeq), 2]))",data cleaning,558e19,152
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",data cleaning,558e19,152
"tresh <- rnaSeqTresh(rnaExp, ""analysis/02.Mouse Single Cell/tresholds"",     cores = 16)",not sure,558e19,152
rm(list = ls(all.names = TRUE)),setup,113e19,153
rn(rnaExp),not sure,558e19,152
"if (!suppressMessages(require(plspm))) install.packages(""plspm"")",import,113e19,153
"tresholds = matrix(rep(1, len(rn(rnaExp))))",data cleaning,558e19,152
rownames(tresholds) = rn(rnaExp),data cleaning,558e19,152
"if (!suppressMessages(require(mice))) install.packages(""mice"")",import,113e19,153
"write.table(tresholds, file = ""analysis/02.Mouse Single Cell/noTresh"",     col.names = F, row.names = T, quote = F)",export,558e19,152
"if (!suppressMessages(require(ggplot2))) install.packages(""ggplot2"")",import,113e19,153
"if (!suppressMessages(require(RColorBrewer))) install.packages(""RColorBrewer"")",import,113e19,153
"if (!suppressMessages(require(reshape))) install.packages(""reshape"")",import,113e19,153
"if (!suppressMessages(require(pander))) install.packages(""pander"")",import,113e19,153
"if (!suppressMessages(require(polycor))) install.packages(""polycor"")",import,113e19,153
library(plspm),import,113e19,153
library(mice),import,113e19,153
library(ggplot2),import,113e19,153
library(RColorBrewer),import,113e19,153
library(reshape),import,113e19,153
library(pander),import,113e19,153
library(polycor),import,113e19,153
"PRJ_HOME <- Sys.getenv(""DISS_FLOSS_HOME"")",setup,113e19,153
"source(file.path(PRJ_HOME, ""config/diss-floss-config.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/data.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/platform.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/qgraphtikz.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/factors.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/graphics.R""))",import,113e19,153
"source(file.path(PRJ_HOME, ""utils/knit.R""))",import,113e19,153
LOADINGS_THRESHOLD <- 0.7,setup,113e19,153
"COLOR_PALETTE <- brewer.pal(8, ""Set2"")",setup,113e19,153
GGPLOT2_PALETTE_FILL <- scale_fill_manual(values = COLOR_PALETTE),setup,113e19,153
GGPLOT2_PALETTE_LINE <- scale_color_manual(values = COLOR_PALETTE),setup,113e19,153
library(plyr),import,389e20,154
DEBUG <- FALSE,setup,113e19,153
library(ggplot2),import,389e20,154
library(stringr),import,389e20,154
library(reshape2),import,389e20,154
library(yaml),import,389e20,154
"source(""powerAnalysis/lib.R"")",setup,389e20,154
"kConfigPath <- ""powerAnalysis/powerAnalysis.yml""",setup,389e20,154
"kSep <- "" """,setup,389e20,154
kNRows <- -1,setup,389e20,154
"kVariableRegexp <- ""p_local_concentration.*""",setup,389e20,154
"kQuantiles <- c(0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99,     0.995, 0.999)",setup,389e20,154
"kThresholds <- seq(0.5, 0.95, 0.05)",setup,389e20,154
"kDataPath <- ""powerAnalysis/obs_mcmc_summaries.Rdata""",setup,389e20,154
"kOutputPath <- ""powerAnalysis/obs_distribution_summaries.Rdata""",setup,389e20,154
config <- yaml.load_file(kConfigPath),setup,389e20,154
config <- ParseConfig(config),setup,389e20,154
obs.result.pattern <- config$mcmc_output$summary_pattern,setup,389e20,154
"obs.result.paths <- sprintf(obs.result.pattern, 1:as.integer(config$data$n_chrom))",setup,389e20,154
"obs.result.header <- scan(obs.result.paths[1], character(0),     nlines = 1)",import,389e20,154
"obs.result.columns <- which(str_detect(obs.result.header, kVariableRegexp))",setup,389e20,154
obs.result.colnames <- obs.result.header[obs.result.columns],setup,389e20,154
names(obs.result.columns) <- obs.result.colnames,data cleaning,389e20,154
"obs.results.list <- lapply(obs.result.paths, function(path) data.frame(sapply(obs.result.columns,   function(col) ReadColumnViaPipe(path, col, skip = 1))))",import,389e20,154
library(dplyr),import,1.2300000000000001e+22,155
library(ggplot2),import,1.2300000000000001e+22,155
library(scales),import,1.2300000000000001e+22,155
library(stringr),data cleaning,1.2300000000000001e+22,155
library(tidyr),data cleaning,1.2300000000000001e+22,155
"numberOfCycles = analysis$header$`Number of cycles`,",evaluation,8.0799999999999992e+22,156
"experimentType = analysis$header$`Experiment type`,",evaluation,8.0799999999999992e+22,156
"testCycleDuration = analysis$header$`Duration of each test cycle`,",evaluation,8.0799999999999992e+22,156
return(header_table),evaluation,8.0799999999999992e+22,156
"row.names = F, quote = F)",evaluation,8.0799999999999992e+22,156
"rewardDuration = analysis$header$`Duration of reward cycle`,",evaluation,8.0799999999999992e+22,156
"dir.create(""Computed"")",evaluation,8.0799999999999992e+22,156
header_table = rbindlist(ls),evaluation,8.0799999999999992e+22,156
},evaluation,8.0799999999999992e+22,156
ls[[analysis$name]] = row,evaluation,8.0799999999999992e+22,156
ls = list(),evaluation,8.0799999999999992e+22,156
interTrialTime = analysis$header$`Inter trial time`),evaluation,8.0799999999999992e+22,156
create_header_table = function(ls_analysis) {,evaluation,8.0799999999999992e+22,156
for (analysis in ls_analysis) {,evaluation,8.0799999999999992e+22,156
"rewardType = analysis$header$`Reward type`, rewardNumber = analysis$header$`Reward number`,",evaluation,8.0799999999999992e+22,156
"row = list(name = analysis$name, session = analysis$session,",evaluation,8.0799999999999992e+22,156
"if (!dir.exists(""Computed""))",evaluation,8.0799999999999992e+22,156
"write.table(header_table, ""Computed/header_table.csv"", sep = "";"",",evaluation,8.0799999999999992e+22,156
},evaluation,8.0799999999999992e+22,156
rm(list = ls()),not sure,8.0799999999999992e+22,156
"pacman::p_load(INSP, data.table, dplyr, surveillance, TMB, Matrix,       INLA, rgeos)",not sure,8.0799999999999992e+22,156
"DT <- subset(fread(""~/Documents/MXU5MR/defunciones/outputs/demog.csv""),     EDADV == 1)",import,8.0799999999999992e+22,156
"tiff(filename = ""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Presentation\\Article\\figure\\Figure1.tif"",     width = 6.83, height = 9.19, units = ""in"", res = 300)",import,142e20,157
"DT[, `:=`(GEOID, sprintf(""%05d"", GEOID))]",data cleaning,8.0799999999999992e+22,156
"DT[, `:=`(EDAD, EDADN)]",data cleaning,8.0799999999999992e+22,156
"agedf <- fread(""~/Documents/MXU5MR/nacimientos/outputs/age_groups.csv"")",import,8.0799999999999992e+22,156
"windows(width = 8, height = 12)",setup,142e20,157
summary(DT$DEATHS > DT$POPULATION),evaluation,8.0799999999999992e+22,156
summary(DT$DEATHS > DT$POPULATION2),evaluation,8.0799999999999992e+22,156
"par(mfrow = c(2, 1))",visualization,142e20,157
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,527e20,158
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,527e20,158
"plot(nspm.2mo.tow.count.la, select = 1, shade = T, all.terms = T,     scale = 0, xlab = ""Dissolved Oxygen (mg l ^-1)"", ylab = ""Effect of Dissolved Oxygen"")",visualization,142e20,157
library(ggplot2),visualization,527e20,158
library(plyr),visualization,527e20,158
abline(h = 0),visualization,142e20,157
"text(3, -2, ""A"", cex = 1.5, font = 2)",visualization,142e20,157
library(stringr),exploratory,527e20,158
"plot(nspm.2mo.tow.count.tx, select = 1, shade = T, all.terms = T,     scale = 0, xlab = ""Dissolved Oxygen (mg l^-1"", ylab = """")",visualization,142e20,157
"library(""tidyr"")",setup,201e20,159
abline(h = 0),visualization,142e20,157
library(reshape2),data cleaning,527e20,158
"text(3, -2, ""B"", cex = 1.5, font = 2)",visualization,142e20,157
"Marriages <- read.csv(file = ""Analysis/data/RawData/160-03-4_marriage_2011.csv"",       sep = "";"", na.strings = c(""-"", "".""), nrows = 3150, skip = 9,   header = FALSE, col.names = c(""district"", ""DistrictName"",     ""PersonalStatus"", ""Total"", ""TotalMale"", ""TotalFemale"",         ""TotalGerman"", ""TotalForeigner""))",import,201e20,159
library(grid),visualization,527e20,158
"Marriages$DistrictName <- iconv(Marriages$DistrictName, from = ""latin1"", to = ""UTF-8"")",data cleaning,201e20,159
library(gridExtra),modeling,527e20,158
"Marriages <- Marriages[-c(1:6), ]",data cleaning,201e20,159
"source(""powerAnalysis/lib.R"")",import,527e20,158
"Marriages <- Marriages[, -c(2, 5:8)]",data cleaning,201e20,159
"Marriages[, 1] <- as.numeric(as.character(Marriages[, 1]))",data cleaning,201e20,159
"Marriages[, 3] <- as.numeric(as.character(Marriages[, 3]))",data cleaning,201e20,159
"Marriages <- spread(Marriages, ""PersonalStatus"", ""Total"")",data cleaning,201e20,159
"viewport(layout.pos.row = x, layout.pos.col = y)",visualization,527e20,158
},visualization,527e20,158
"VpLayout <- function(x, y) {",visualization,527e20,158
"Marriages <- Marriages[, c(1, 6)]",data cleaning,201e20,159
"MarriageBerHam <- subset(Marriages, Marriages$district == 2 |     Marriages$district == 11, all(TRUE))",modeling,201e20,159
"Marriages <- Marriages[Marriages$district > 1000, ]",data cleaning,201e20,159
"Marriages <- rbind(Marriages, MarriageBerHam)",data cleaning,201e20,159
rm(MarriageBerHam),not sure,201e20,159
tmp <- ggplot_gtable(ggplot_build(a.gplot)),visualization,527e20,158
GetLegend <- function(a.gplot) {,visualization,527e20,158
legend <- tmp$grobs[[leg]],visualization,527e20,158
"leg <- which(sapply(tmp$grobs, function(x) x$name) == ""guide-box"")",visualization,527e20,158
return(legend),visualization,527e20,158
},visualization,527e20,158
cluster.env <- new.env(),setup,527e20,158
"load(""powerAnalysis/output_cluster_power.RData"", envir = cluster.env)",import,527e20,158
parzen.env <- new.env(),setup,527e20,158
"load(""powerAnalysis/output_parzen_window_power.RData"", envir = parzen.env)",import,527e20,158
normal.env <- new.env(),setup,527e20,158
"normal.env$power.cluster <- read.table(""comparisons/out/NOrMAL.tsv"",     header = TRUE, sep = ""\t"")",import,527e20,158
normal.env$power.cluster$coverage <- as.numeric(as.character(normal.env$power.cluster$coverage)),data cleaning,527e20,158
"cluster.env$power.cluster$Method <- ""Cluster estimand""",data cleaning,527e20,158
"parzen.env$power.cluster$Method <- ""Parzen window""",data cleaning,527e20,158
"normal.env$power.cluster$Method <- ""NOrMAL""",not sure,527e20,158
"p.detected.df <- rbind(cluster.env$power.cluster, parzen.env$power.cluster,     normal.env$power.cluster)",data cleaning,527e20,158
"p.detected.df$coverage <- round(p.detected.df$coverage, 2)",data cleaning,527e20,158
"p.detected.df$se.power <- with(p.detected.df, sqrt(p.detected.primary *     (1 - p.detected.primary)/n))",modeling,527e20,158
"power.by.eff.magnitude <- ddply(p.detected.df, .(Method, eff.magnitude),     summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),     mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",modeling,527e20,158
"sig <- getSig(cuff, alpha = 0.05)",setup,64e21,160
"power.by.offset <- ddply(p.detected.df, .(Method, offset.primary),     summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),     mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",evaluation,527e20,158
"power.by.coverage <- ddply(p.detected.df, .(Method, coverage),     summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),     mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",evaluation,527e20,158
"sigGenes <- getGenes(cuff, sig)",import,64e21,160
annot <- annotation(sigGenes),import,64e21,160
"blank_legend <- theme(legend.key = element_rect(color = ""white""),     legend.text = element_blank(), legend.title = element_blank())",visualization,527e20,158
names <- annot$gene_short_name,data cleaning,64e21,160
panel.list <- list(),setup,527e20,158
"forgmt <- list(""SexDiffs"", ""NA"", names)",data cleaning,64e21,160
forgmt <- unlist(forgmt),data cleaning,64e21,160
"panel.list[[1]] <- qplot(x = eff.magnitude, y = power, ymin = power -     1.96 * se.power, ymax = power + 1.96 * se.power, data = power.by.eff.magnitude,     color = Method, shape = Method, geom = c(""line"", ""point"",             ""errorbar""), ylim = c(0, 1))",visualization,527e20,158
"write(forgmt, file = ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"",     ncolumns = length(forgmt), sep = ""\t"")",export,64e21,160
library(GSA),setup,64e21,160
"test <- GSA.read.gmt(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"")",import,64e21,160
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval.Robj"")",import,64e21,160
"dir.create(file.path(getwd(), ""analysis/support/tools/R_Packages""),     showWarnings = FALSE)",setup,7.3999999999999996e+22,161
".libPaths(file.path(getwd(), ""analysis/support/tools/R_Packages""))",setup,7.3999999999999996e+22,161
"install.packages(""R.utils"", repos = ""http://cran.us.r-project.org"")",setup,7.3999999999999996e+22,161
"if (!file.exists(""analysis/support/tools/R_Packages/.utils.exists"")) {",setup,7.3999999999999996e+22,161
},setup,7.3999999999999996e+22,161
"file.create(""analysis/support/tools/R_Packages/.utils.exists"")",setup,7.3999999999999996e+22,161
library(R.utils),setup,7.3999999999999996e+22,161
"if (!isPackageInstalled(""readr"")) install.packages(""readr"", repos = ""http://cran.us.r-project.org"")",setup,7.3999999999999996e+22,161
"if (!isPackageLoaded(""readr"")) library(readr)",setup,7.3999999999999996e+22,161
"outFile = ""analysis/support/tools/benchmark/benchmark.out""",setup,7.3999999999999996e+22,161
"if (!file.exists(outFile)) file.create(outFile, ""w"")",setup,7.3999999999999996e+22,161
"sink(outFile, append = FALSE, split = FALSE)",setup,7.3999999999999996e+22,161
"benchmark <- read_delim(""analysis/support/tools/benchmark/benchmark.csv"",     ""\t"", escape_double = FALSE, trim_ws = TRUE)",import,7.3999999999999996e+22,161
benchmark$script = as.factor(benchmark$script),data cleaning,7.3999999999999996e+22,161
benchmark$scheduler = as.factor(benchmark$scheduler),data cleaning,7.3999999999999996e+22,161
"factors = split(benchmark, list(benchmark$scheduler, benchmark$script))",data cleaning,7.3999999999999996e+22,161
"clusters <- system(""ls weeder_output"", intern = T)",not sure,41e21,162
"lapply(factors, function(j) {    summary(lm(j$memory_MB ~ j$chans + j$samples))})",modeling,7.3999999999999996e+22,161
"lapply(factors, function(j) {})",modeling,7.3999999999999996e+22,161
cluster.weeder.res <- list(),not sure,41e21,162
"system(""echo '\n--- DONE: generateBenchmark ---\n'"")",communication,7.3999999999999996e+22,161
ind <- 0,not sure,41e21,162
total.motifs <- c(),setup,41e21,162
library(beanplot),setup,482e20,163
library(car),setup,482e20,163
"d <- read.csv(""GambleWalkerPsychologicalScienceData.csv"", sep = ""\t"")",import,482e20,163
screen.draw <- TRUE,setup,482e20,163
"URL <- ""https://www.eia.gov/dnav/pet/xls/PET_PRI_SPT_S1_D.xls""",setup,912e20,164
"filepath <- ""/Data/spotprices.xls""",setup,912e20,164
"path <- c(getwd(), filepath)",not sure,912e20,164
"path <- paste(path, collapse = """")",evaluation,912e20,164
library(ggplot2),setup,156e20,165
"download.file(url = URL, destfile = path, mode = ""wb"")",evaluation,912e20,164
library(devtools),setup,156e20,165
library(data.table),setup,156e20,165
library(reshape2),setup,156e20,165
library(survival),setup,156e20,165
library(Hmisc),setup,156e20,165
library(XLConnect),setup,912e20,164
library(Cairo),setup,156e20,165
version_dcmMisc <- 0.1,setup,156e20,165
version_dcmMisc)),setup,156e20,165
"if (""dcmMisc"" %in% rownames(installed.packages()) == FALSE) {",setup,156e20,165
"install_github(""dcmMisc"", username = ""dcmuller"", ref = paste0(""v"",",setup,156e20,165
},setup,156e20,165
},setup,156e20,165
"warning(paste(""replacing dcmMisc with version"", version_randsurv))",setup,156e20,165
"if (installed.packages()[""dcmMisc"", ""Version""] != version_dcmMisc) {",setup,156e20,165
"install_github(""dcmMisc"", username = ""dcmuller"", ref = paste0(""v"",",setup,156e20,165
version_dcmMisc)),setup,156e20,165
library(dcmMisc),setup,156e20,165
"params <- read.csv(""./analysis/output/o01_params.csv"", stringsAsFactors = FALSE)",import,156e20,165
params <- data.table(params),import,156e20,165
"samples <- read.csv(""./analysis/output/o01_all_samples.csv"",     stringsAsFactors = FALSE)",import,156e20,165
"samples <- rename(samples, c(""X"", ""param""), c(""sim_id"", ""param_type""))",import,156e20,165
samples$sim_id <- floor((samples$sim_id + 1)/2),data cleaning,156e20,165
"samples <- data.table(samples, key = c(""settings"", ""model"", ""param_type""))",import,156e20,165
"samples_long <- melt(samples, id.vars = c(""settings"", ""model"",     ""param_type"", ""sim_id""), measure.vars = c(""intercept"", ""exposure"",     ""log_scale""), value.name = ""estimate"", variable.name = ""param"")",data cleaning,156e20,165
samples_long <- data.table(samples_long),data cleaning,156e20,165
"library(RItools, lib.loc = "".local"")",setup,408e20,166
samples_long$param <- as.character(samples_long$param),data cleaning,156e20,165
"setkey(samples_long, settings, model, param_type, param)",data cleaning,156e20,165
"load(""data/twins.rda"")",setup,408e20,166
"summary_samples <- samples_long[, list(mean = mean(estimate),     sd = sd(estimate), min = min(estimate), max = max(estimate)),     by = c(""settings"", ""model"", ""param"", ""param_type"")]",exploratory,156e20,165
"load(""analysis/balance.rda"")",setup,408e20,166
"setkey(summary_samples, model, param, param_type)",data cleaning,156e20,165
set.seed(20110330),setup,408e20,166
summary_samples,exploratory,156e20,165
samples <- 1000,setup,408e20,166
"additive.model <- function(y, z, b, tau) {    y - as.numeric(z) * tau}",setup,408e20,166
"model1 <- min.max.model(additive.model, lower = 0, upper = 6)",setup,408e20,166
twins$match <- propensity$matching[row.names(twins)],setup,408e20,166
"twins.complete <- twins[twins$ideology.complete & !is.na(twins$match), ]",setup,408e20,166
"analysis.m1 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,     moe = model1, samples = samples, parameters = list(tau = seq(-0.9,     twins.complete$treated * 1, test.stat = mean.difference,         0.3, 0.05)))",setup,408e20,166
"tabcox <- summary_samples[(model == ""coxfull"" | model == ""coxweighted"") &     param == ""exposure"", list(settings, model, param_type, mean, sd)]",exploratory,156e20,165
"tmp <- function(y, z, b, beta) {    round(y/beta^(as.numeric(z)))}",setup,408e20,166
"model2 <- min.max.model(tmp, lower = 0, upper = 6)",setup,408e20,166
tabcox_1 <- tabcox[settings == 1],data cleaning,156e20,165
"analysis.m2 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,     twins.complete$treated * 1, test.stat = mean.difference,     moe = model2, samples = samples, parameters = list(beta = c(8:18)/20))",setup,408e20,166
"tabcox_1[, `:=`(settings, NULL)]",data cleaning,156e20,165
"save(file = ""analysis/randomization-inference.rda"", analysis.m1,     analysis.m2, twins.complete)",setup,408e20,166
"tabcox_1 <- reshape(tabcox_1, v.names = c(""mean"", ""sd""), idvar = ""model"",     direction = ""wide"", timevar = ""param_type"")",data cleaning,156e20,165
tabcox_1 <- data.frame(tabcox_1),data cleaning,156e20,165
options(stringsAsFactors = F),import,408e20,166
tabcox_2 <- tabcox[settings == 2],data cleaning,156e20,165
"setwd(""/Users/winterb/Research/gesture_categorization/new_paper_new_analyses/data/"")",import,408e20,166
"tabcox_2[, `:=`(settings, NULL)]",data cleaning,156e20,165
"xdata <- read.csv(""web_gesture_specification_explicit_question.csv"")",import,408e20,166
"tabcox_2 <- reshape(tabcox_2, v.names = c(""mean"", ""sd""), idvar = ""model"",     direction = ""wide"", timevar = ""param_type"")",data cleaning,156e20,165
library(dplyr),import,408e20,166
tabcox_2 <- data.frame(tabcox_2),data cleaning,156e20,165
library(stringr),import,408e20,166
"tabcox <- rbind.data.frame(tabcox_2, tabcox_1)",data cleaning,156e20,165
"xdata <- rename(xdata, Condition = Display.Order..Block.Randomizer.FL_5,     Control = What.is.4.plus.5.)",import,408e20,166
"rownames(tabcox) <- c(""common disease"", """", ""rare disease"", "" "")",data cleaning,156e20,165
nrow(xdata),import,408e20,166
for (i in 1:ncol(tabcox)) {,data cleaning,156e20,165
"if (is.numeric(tabcox[, i])) {",data cleaning,156e20,165
"tabcox[, i] <- round(tabcox[, i], 3)",data cleaning,156e20,165
},data cleaning,156e20,165
},data cleaning,156e20,165
xdata$ShapeResponse <- NA,import,408e20,166
xdata$HeightResponse <- NA,import,408e20,166
"tabcox[[""model""]] <- ifelse(tabcox[[""model""]] == ""coxfull"", ""Full cohort"",     ""Weighted NCC"")",data cleaning,156e20,165
"shape_colnames <- grep(""shape"", colnames(xdata))",import,408e20,166
"height_colnames <- grep(""height"", colnames(xdata))",import,408e20,166
"colnames(tabcox) <- c(""analysis"", ""mean(log HR)"", ""sd(log HR)"",     ""mean(se(log HR))"", ""sd(se(log HR))"")",data cleaning,156e20,165
"textab <- latex(tabcox, file = ""./analysis/output/t02_cox_full_vs_ncc.tex"",     booktabs = TRUE, rowlabel = """")",export,156e20,165
"samples_weighted <- samples[model == ""weighted"" & param_type ==     ""coef"", ]",data cleaning,156e20,165
samples_weighted$sim <- c(1:nrow(samples_weighted)),data cleaning,156e20,165
"x <- matrix(c(1, -1, 1, 0, 1, 1), nrow = 2)",import,156e20,165
"xb <- as.matrix(samples_weighted[, list(intercept, exposure)]) %*% x",data cleaning,156e20,165
"samples_weighted <- data.frame(samples_weighted, xb)",data cleaning,156e20,165
"samples_weighted <- melt(samples_weighted, id.vars = c(""settings"",     ""model"", ""param_type"", ""sim_id"", ""sim"", ""intercept"", ""exposure"",     ""log_scale""), value.name = ""xb"", variable.name = ""x"")",data cleaning,156e20,165
"t <- seq(30, 80, by = 0.5)",import,156e20,165
"time_mat <- matrix(rep(t, each = nrow(samples_weighted)), nrow = nrow(samples_weighted))",import,156e20,165
"pred <- cbind(samples_weighted, time_mat)",import,156e20,165
"pred_long <- melt(pred, id.vars = c(""settings"", ""model"", ""param_type"",     ""sim_id"", ""sim"", ""intercept"", ""exposure"", ""log_scale"", ""x"",   ""xb""), value.name = ""time"")",data cleaning,156e20,165
pred_long <- data.table(pred_long),data cleaning,156e20,165
pred_long$p <- 1/exp(pred_long$log_scale),data cleaning,156e20,165
pred_long$lambda <- exp(-pred_long$p * pred_long$xb),modeling,156e20,165
pred_long$surv <- exp(-pred_long$lambda * (pred_long$time - 30)^pred_long$p),modeling,156e20,165
pred_long$pr <- 1 - pred_long$surv,modeling,156e20,165
"pred_long$plotgroup <- paste0(pred_long$x, pred_long$sim)",data cleaning,156e20,165
"surv_plot <- ggplot(data = pred_long[settings == 1], aes(x = time,     y = pr, group = plotgroup, colour = x))",visualization,156e20,165
surv_plot <- surv_plot + theme_bw(),visualization,156e20,165
surv_plot <- surv_plot + geom_line(alpha = I(1/sqrt(max(pred_long$sim) *     8))),visualization,156e20,165
"surv_plot <- surv_plot + scale_x_continuous(name = ""Age (years)"")",visualization,156e20,165
"surv_plot <- surv_plot + scale_y_continuous(name = ""Cumulative probability"")",visualization,156e20,165
"hr <- exp(params[1, lhr])",data cleaning,156e20,165
library(plyr),setup,586e20,167
library(dplyr),setup,586e20,167
"origin <- params[1, origin]",data cleaning,156e20,165
library(data.table),setup,586e20,167
"weib_param <- params[1, weib_param1]",data cleaning,156e20,165
library(ggplot2),setup,586e20,167
"lambda0 <- c(1/hr, 1, hr) * params[1, baseline_rate1]",modeling,156e20,165
"lambda0 <- rep(lambda0, each = length(t))",modeling,156e20,165
surv_true <- exp(-lambda0 * (t - origin)^weib_param),modeling,156e20,165
"source(file.path(""./read_egt.R""), chdir = F)",import,586e20,167
"true <- data.frame(time = t, surv = surv_true, lambda = lambda0,     pr = 1 - surv_true, plotgroup = rep(0, length(surv_true)),     x = rep(c(""X1"", ""X2"", ""X3""), each = length(t)))",data cleaning,156e20,165
"FileThreat03Trial01 <- read.egt(""text"")",import,586e20,167
"surv_plot <- surv_plot + geom_line(data = true, aes(x = time,     y = pr, group = x))",visualization,156e20,165
"DataThreat03Trial01 <- FileThreat03Trial01[""results""]",not sure,586e20,167
"RepsThreat03Trial01 <- FileThreat03Trial01[""reps""]",not sure,586e20,167
"gens0302 <- c(1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4)",import,586e20,167
"CairoPDF(file = ""./analysis/output/g02_cumul_risk_rare.pdf"",     width = 6, height = 5)",visualization,156e20,165
surv_plot,visualization,156e20,165
dev.off(),visualization,156e20,165
"xs0302 <- c(5, 5, 1, 2, 4, 5, 5, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1)",import,586e20,167
"ys0302 <- c(4, 5, 2, 2, 5, 4, 5, 2, 1, 2, 4, 5, 4, 5, 4, 5)",import,586e20,167
"cstrats0302 <- as.factor(c(1, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2))",import,586e20,167
"pstrats0302 <- as.factor(c(3, 4, 3, 2, 4, 1, 2, 2, 3, 2, 3, 3))",import,586e20,167
"contTag0302 <- c(0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,     0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,     0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,     1, 1, 0)",import,586e20,167
"library(""data.table"")",data cleaning,343e20,168
"library(""dplyr"")",data cleaning,343e20,168
rm(list = ls()),setup,689e20,169
"library(""jsonlite"")",exploratory,343e20,168
library(ggplot2),setup,689e20,169
"library(""textcat"")",import,343e20,168
library(ggthemes),setup,689e20,169
library(cowplot),setup,689e20,169
"con <- file.path(""./data/all_participants_all_data_2002_2014_2.json"")",setup,343e20,168
data <- fromJSON(con),import,343e20,168
"tickets <- readRDS(""Analysis/new_analysis/catch_shares/Analysis/vessel_landings_data.RDS"")",import,689e20,169
mello_data <- as_data_frame(data),exploratory,343e20,168
mello_data <- tbl_dt(mello_data),data cleaning,343e20,168
"vessel_stats <- readRDS(""Analysis/new_analysis/catch_shares/Analysis/vessel_stats.RDS"")",import,689e20,169
library(dplyr),setup,689e20,169
library(vegan),setup,689e20,169
"ports <- read.csv(""processedData/spatial/ports/all_ports.csv"",     stringsAsFactors = FALSE)",import,689e20,169
library(reshape),setup,1.1100000000000001e+22,170
library(plyr),setup,1.1100000000000001e+22,170
library(pheatmap),setup,1.1100000000000001e+22,170
"mello_data[language == """" & lyrics != """", `:=`(language, textcat(lyrics))]",data cleaning,343e20,168
"mello_data[language == ""scots"", `:=`(language, ""english"")]",data cleaning,343e20,168
"ports <- rename(ports, pcid = Pcid)",data cleaning,689e20,169
mello_data <- tbl_df(mello_data),data cleaning,343e20,168
"sim_matrix = ""/home/vanessa/Documents/Dropbox/Code/Python/brain-behavior/analysis/pubmed/pmc_family_sim_matrix.tsv""",import,1.1100000000000001e+22,170
"sim_matrix = read.csv(sim_matrix, sep = ""\t"", row.names = 1)",import,1.1100000000000001e+22,170
"coastwide <- ggplot(vessel_stats[which(vessel_stats$alaska ==     0 & !is.na(vessel_stats$type)), ], aes(x = type)) + geom_bar() +     ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,689e20,169
"pheatmap(sim_matrix, cluster_cols = FALSE, cluster_rows = FALSE)",visualization,1.1100000000000001e+22,170
"input_data = ""/home/vanessa/Documents/Dropbox/Code/Python/brain-behavior/analysis/pubmed/pmc_family_co-occurrence_filtered_pt2.tsv""",import,1.1100000000000001e+22,170
"source(""analysis/lovecount.R"")",import,343e20,168
"losers <- file.path(""data/losers.json"")",setup,343e20,168
"outdir = ""/home/vanessa/Documents/Dropbox/Code/Python/brain-behavior/analysis/pubmed""",setup,1.1100000000000001e+22,170
"df = read.csv(input_data, sep = ""\t"", row.names = 1)",import,1.1100000000000001e+22,170
"by_zone <- ggplot(vessel_stats[which(vessel_stats$alaska == 0 &     !is.na(vessel_stats$type) & !is.na(vessel_stats$zone)), ],     aes(x = type)) + geom_bar() + facet_wrap(~zone, ncol = 1,     scales = ""free_y"") + ylab(""number of vessels"") + theme_pander() +     theme(panel.grid = element_blank())",visualization,689e20,169
"df = df[which(rowSums(df) != 0), ]",exploratory,1.1100000000000001e+22,170
"winners <- file.path(""data/winners.json"")",setup,343e20,168
"df = df[, which(colSums(df) != 0)]",exploratory,1.1100000000000001e+22,170
"wl <- bind_rows(fromJSON(losers) %>% mutate(winner = 0), fromJSON(winners) %>%     mutate(winner = 1))",modeling,343e20,168
"div_hist <- ggplot(subset(vessel_stats[which(!is.na(vessel_stats$zone) &     vessel_stats$alaska == 0), ], vessel_stats$eff.shannon_2010 >     1), aes(x = eff.shannon_2010)) + geom_histogram(aes(y = ..count..)) +    facet_wrap(~zone, ncol = 1, scales = ""free_y"") + xlab(""effective shannon diversity of revenue"") +    ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,689e20,169
"all_plot <- plot_grid(coastwide, by_zone, div_hist, labels = c(""A"",     ""B"", ""C""), ncol = 3, rel_widths = c(1, 1.2, 1.4))",visualization,689e20,169
"outputfile = paste(outdir, ""/web/filterpt2/co-occurrence.tsv"",     sep = """")",setup,1.1100000000000001e+22,170
"ggplot2::ggsave(""Analysis/new_analysis/catch_shares/Analysis/fig_2.pdf"",     all_plot, width = 11.4, height = 7, units = ""cm"", scale = 2.5, dpi = 300)",export,689e20,169
flat = melt(as.matrix(df)),data cleaning,1.1100000000000001e+22,170
x = c(),not sure,1.1100000000000001e+22,170
"lm1 <- lm(delta.eff.shannon_2010 ~ eff.shannon_2010, subset(vessel_stats,     alaska == 0 & both.periods == 1 & ifq_flag != ""itq entrant: general fleet""))",modeling,689e20,169
y = c(),not sure,1.1100000000000001e+22,170
"lm2 <- lm(delta.eff.shannon_2010 ~ eff.shannon_2010 + ifq_flag,     subset(vessel_stats, alaska == 0 & both.periods == 1 & ifq_flag !=         ""itq entrant: general fleet""))",modeling,689e20,169
library(arm),setup,689e20,169
"lm2.sim <- sim(lm2, n = 10000)",modeling,689e20,169
},setup,1.1100000000000001e+22,170
"x = c(x, dx)",setup,1.1100000000000001e+22,170
for (dx in 1:nrow(df)) {,setup,1.1100000000000001e+22,170
"y = c(y, dy)",setup,1.1100000000000001e+22,170
for (dy in 1:ncol(df)) {,setup,1.1100000000000001e+22,170
},setup,1.1100000000000001e+22,170
coef.lm2.sim <- coef(lm2.sim),modeling,689e20,169
flat$x = x,data cleaning,1.1100000000000001e+22,170
vessel_effects <- as.data.frame(coef.lm2.sim),data cleaning,689e20,169
flat$y = y,data cleaning,1.1100000000000001e+22,170
"colnames(flat) = c(""probof"", ""given"", ""prob"", ""x"", ""y"")",data cleaning,1.1100000000000001e+22,170
"colnames(vessel_effects) <- c(""intercept"", ""eff.shannon_2010"",     ""stay_on"", ""LE_exit"")",data cleaning,689e20,169
"write.table(flat, file = outputfile, sep = ""\t"", row.names = FALSE,     col.names = TRUE, quote = FALSE)",export,1.1100000000000001e+22,170
"ifq_effect <- vessel_effects %>% dplyr::select(-eff.shannon_2010) %>%     mutate(stay_on = stay_on + intercept, LE_exit = LE_exit +         intercept) %>% gather() %>% dplyr::rename(ifq_flag = key, coefficient = value) %>% group_by(ifq_flag) %>% summarize(mean = mean(coefficient),         0.025))",data cleaning,689e20,169
"max_ci = quantile(coefficient, 0.975), min_ci = quantile(coefficient,",data cleaning,689e20,169
"ifq_effect$ifq_flag = factor(ifq_effect$ifq_flag, labels = c(""general\nparticipants"",     ""limited entry\nexit"", ""catch share\nparticipant""), ordered = TRUE)",data cleaning,689e20,169
"ggplot(ifq_effect, aes(x = ifq_flag, y = mean)) + geom_point(size = 7) +     ylim(c(0, 1.32)) + geom_errorbar(aes(ymin = min_ci, ymax = max_ci),     width = 0) + theme_pander() + ylab(expression(paste(Delta,     ""H""))) + xlab("""") + theme(panel.grid = element_blank())",visualization,689e20,169
"ggplot2::ggsave(""Analysis/new_analysis/catch_shares/Analysis/fig5.pdf"",     width = 4, height = 4, units = ""in"", scale = 1)",export,689e20,169
"fp = ""Analysis/new_analysis/catch_shares/Analysis/port_stats.RDS""",setup,689e20,169
port_df <- readRDS(fp),import,689e20,169
"lm_port1 <- lm(ld_delta ~ ld, subset(port_df, ifq_flag != ""itq entrant: general landings""))",modeling,689e20,169
"lm_port <- lm(ld_delta ~ ld + ifq_flag, subset(port_df, ifq_flag !=     ""itq entrant: general landings""))",modeling,689e20,169
"lm3 <- lm(ld_delta ~ lat, subset(port_df, ifq_flag != ""itq entrant: general landings""))",modeling,689e20,169
"lm_port.sim <- sim(lm_port, n = 10000)",modeling,689e20,169
coef.lm_port.sim <- coef(lm_port.sim),modeling,689e20,169
port_effect <- as.data.frame(coef.lm_port.sim),data cleaning,689e20,169
"colnames(port_effect) <- c(""intercept"", ""ld_pre"", ""general_fleet"")",data cleaning,689e20,169
"port_effect <- port_effect %>% dplyr::select(-ld_pre) %>% mutate(general_fleet = general_fleet +     intercept) %>% gather() %>% dplyr::rename(ifq_flag = key,     coefficient = value) %>% group_by(ifq_flag) %>% summarize(mean = mean(coefficient),     max_ci = quantile(coefficient, 0.975), min_ci = quantile(coefficient, 0.025))",data cleaning,689e20,169
"levels(port_effect$ifq_flag) = c(""general fleet"", ""catch share\nparticipant"")",data cleaning,689e20,169
"ggplot(port_effect, aes(x = levels(ifq_flag), y = mean)) + geom_point(size = 7) +          geom_errorbar(aes(ymin = min_ci, ymax = max_ci), width = 0) +   theme_pander() + ylab(expression(paste(Delta, ""C""))) + xlab("""") +  theme(panel.grid = element_blank()) + geom_hline(yintercept = 0)",visualization,689e20,169
"ggplot2::ggsave(""Analysis/new_analysis/catch_shares/Analysis/fig5_port.pdf"",     width = 4, height = 4, units = ""in"", scale = 1)",export,689e20,169
"by_day <- tickets %>% filter(year < 2011) %>% group_by(tdate,     metier.2010) %>% summarize(n.trips = length(unique(trip_id)))",exploratory,689e20,169
"by_day$tdate <- as.Date(by_day$tdate, format = ""%d-%b-%y"")",data cleaning,689e20,169
"numSig = sapply(statistic.alt, function(x, statistic.null) {",setup,256e20,171
return(pval.list),setup,256e20,171
return(sum(statistic.null < x)),setup,256e20,171
"numSig = sapply(statistic.alt, function(x, statistic.null) {",setup,256e20,171
},setup,256e20,171
"}, statistic.null = statistic.null)",setup,256e20,171
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,",setup,256e20,171
"statistic.alt, big.sig = TRUE) {",setup,256e20,171
1),setup,256e20,171
},setup,256e20,171
"numEqual = sapply(statistic.alt, function(x, statistic.null) {",setup,256e20,171
Uval = runif(length(statistic.alt)),setup,256e20,171
return(sum(statistic.null > x)),setup,256e20,171
"}, statistic.null = statistic.null)",setup,256e20,171
return(sum(statistic.null == x)),setup,256e20,171
},setup,256e20,171
if (big.sig) {,setup,256e20,171
numNulltests = length(statistic.null),setup,256e20,171
"}, statistic.null = statistic.null)",setup,256e20,171
else {,setup,256e20,171
pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +,setup,256e20,171
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,256e20,171
siteSize = 2048,setup,256e20,171
"treatment = ""Copper""",setup,256e20,171
null = FALSE,data cleaning,256e20,171
"strand = ""both""",data cleaning,256e20,171
window.size = 100,setup,256e20,171
numSam = 6,data cleaning,256e20,171
setwd(wd.path),setup,256e20,171
filter.cut = 0,data cleaning,256e20,171
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",  treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.min.pval."",     filter.cut, "".txt""))[, 1])",data cleaning,256e20,171
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     filter.cut, "".txt""))[, 1])",data cleaning,256e20,171
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==     TRUE))",data cleaning,256e20,171
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],    statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",evaluation,256e20,171
num.tests = length(deseq.alt),modeling,256e20,171
library(ggplot2),visualization,331e20,172
library(devtools),setup,331e20,172
library(data.table),data cleaning,331e20,172
library(reshape2),data cleaning,331e20,172
library(survival),not sure,331e20,172
library(Hmisc),exploratory,331e20,172
library(ggplot2),setup,216e20,173
"source(""/Documents/GRADUATE_SCHOOL/Ranalysis/useful.R"")",setup,216e20,173
"d_pop <- function(N, d) {",setup,216e20,173
return(d),setup,216e20,173
d = sum(N * d)/sum(N),setup,216e20,173
},setup,216e20,173
samp_error = 4/mean(N) * ((1 + mean(d)^2)/8),setup,216e20,173
"d_error <- function(N, d) {",setup,216e20,173
return(error),setup,216e20,173
across_study_var = sum(N * ((d - mean(d))^2))/sum(N),setup,216e20,173
},setup,216e20,173
error = 1.96 * sqrt(across_study_var - samp_error),setup,216e20,173
"metad = read.csv(""/Documents/GRADUATE_SCHOOL/Projects/ME_meta/Analysis/Disambiguation Meta-Analysis Data - Sheet1.csv"")",import,216e20,173
metad$d_by_t <- metad$t/sqrt(metad$N),data cleaning,216e20,173
metad$d_by_M <- (metad$M_experimental - metad$M_baseline)/metad$SD,data cleaning,216e20,173
"metad$d_calculate <- ifelse(!is.na(metad$d), metad$d, ifelse(!is.na(metad$d_by_t),     metad$d_by_t, ifelse(!is.na(metad$d_by_M), metad$d_by_M,  NA)))",data cleaning,216e20,173
"metad$d_error = ifelse((abs(metad$d_by_t - metad$d_by_M) > 0.1) |     (abs(metad$d - metad$d_by_M) > 0.1) | (abs(metad$d - metad$d_by_t) >   0.1), 1, 0)",data cleaning,216e20,173
"metad[which(metad$d_error == 1), c(""paper_key"", ""t"", ""N"", ""M_experimental"",     ""M_baseline"", ""SD"", ""d"", ""d_by_t"", ""d_by_M"")]",exploratory,216e20,173
"md <- metad[!is.na(metad$d_calculate), ]",not sure,216e20,173
"md <- md[md$include.in.basic.analysis. == 1, ]",data cleaning,216e20,173
"md$notes_short = substr(md$Notes, 1, 40)",data cleaning,216e20,173
"md[, c(""paper_key"", ""notes_short"", ""expt_num"", ""d_calculate"",     ""N"")]",exploratory,216e20,173
"md <- md[order(md$paper_key), ]",data cleaning,216e20,173
"md[order(md$d_calculate), c(""paper_key"", ""notes_short"", ""expt_num"",     ""d_calculate"")]",exploratory,216e20,173
length(unique(metad$paper_key)),exploratory,216e20,173
length(unique(md$paper_key)),exploratory,216e20,173
dim(md)[1],exploratory,216e20,173
"par(mfrow = c(2, 1))",visualization,216e20,173
"xlab = ""Age (months)"") + geom_smooth(method = ""lm"", formula = y ~",visualization,216e20,173
"md$age_mean..months., use = ""complete""), 2)))",visualization,216e20,173
"log(x)) + theme_bw() + theme(axis.title = element_text(face = ""bold"",",visualization,216e20,173
"scale_y_continuous(limits = c(-1, 2.4)) + annotate(""text"",",visualization,216e20,173
"size = 20), axis.text = element_text(vjust = 0.5, size = 16),",visualization,216e20,173
"x = 50, y = -0.5, size = 10, label = paste(""r="", round(cor(md$d_calculate,",visualization,216e20,173
"qplot(age_mean..months., d_calculate, data = md, ylab = ""Cohen's d"",",visualization,216e20,173
"panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +",visualization,216e20,173
"xlab = ""Mean CDI productive vocabulary"") + geom_smooth(method = ""lm"",",visualization,216e20,173
"qplot(CDI_prod_mean, d_calculate, data = md, ylab = ""Cohen's d"",",visualization,216e20,173
"md$CDI_prod_mean, use = ""complete""), 2)))",visualization,216e20,173
"scale_y_continuous(limits = c(-1, 2.4)) + annotate(""text"",",visualization,216e20,173
"panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +",visualization,216e20,173
"formula = y ~ log(x)) + theme_bw() + theme(axis.title = element_text(face = ""bold"",",visualization,216e20,173
"x = 300, y = -0.5, size = 10, label = paste(""r="", round(cor(md$d_calculate,",visualization,216e20,173
"size = 20), axis.text = element_text(vjust = 0.5, size = 16),",visualization,216e20,173
"cor.test(md$d_calculate, md$CDI_prod_mean, use = ""complete.obs"")",exploratory,216e20,173
"m1 = lm(d_calculate ~ CDI_prod_mean + age_mean..months., d = md)",modeling,216e20,173
summary(m1),evaluation,216e20,173
"library(""R6"")",setup,216e20,173
"library(""stringr"")",setup,216e20,173
"self$header = ls[[""header""]]",setup,216e20,173
},setup,216e20,173
self$betterEventTable = create_better_dt_events(self$eventTable),setup,216e20,173
if (!is.null(ls)) {,setup,216e20,173
"}, MakeBetterEventTable = function() {",setup,216e20,173
"session = NA, logTable = NA, eventTable = NA, header = NA,",setup,216e20,173
"TimeAnalysis = R6Class(""TimeAnalysis"", public = list(name = NA,",setup,216e20,173
"self$eventTable = ls[[""events""]]",setup,216e20,173
if (!missing(path)) {,setup,216e20,173
})),setup,216e20,173
self$FillInData(),setup,216e20,173
"self$name = gsub(""(.*[/])"", """", path)",setup,216e20,173
"}, FillInData = function() {",setup,216e20,173
ls = ReadMouseLog(path),setup,216e20,173
"self$session = gsub(""(.*[_])"", """", self$name)",setup,216e20,173
"self$logTable = ls[[""table""]]",setup,216e20,173
},setup,216e20,173
"self$session = as.numeric(str_extract(self$name, ""\\d+""))",setup,216e20,173
"betterEventTable = NA, initialize = function(path) {",setup,216e20,173
"setwd(""C:/Documents and Settings/mcolvin/My Documents/projects/"")",setup,216e20,173
"source(""./src/1_global.R"")",setup,216e20,173
"source(""./src/2_functions.R"")",setup,216e20,173
"source(""./src/3_load.R"")",setup,216e20,173
"source(""./src/4_clean.R"")",setup,216e20,173
"source(""./src/5_tables.R"")",setup,216e20,173
"source(""./src/6_figures.R"")",setup,216e20,173
"source(""./src/7_analysis.R"")",setup,216e20,173
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",communication,216e20,173
"library(""R6"")",setup,216e20,173
"library(""stringr"")",setup,216e20,173
"betterEventTable = NA, initialize = function(path) {",setup,216e20,173
"}, FillInData = function() {",setup,216e20,173
if (!missing(path)) {,setup,216e20,173
if (!is.null(ls)) {,setup,216e20,173
"TimeAnalysis = R6Class(""TimeAnalysis"", public = list(name = NA,",setup,216e20,173
"session = NA, logTable = NA, eventTable = NA, header = NA,",setup,216e20,173
"self$name = gsub(""(.*[/])"", """", path)",setup,216e20,173
"self$session = as.numeric(str_extract(self$name, ""\\d+""))",setup,216e20,173
"self$session = gsub(""(.*[_])"", """", self$name)",setup,216e20,173
},setup,216e20,173
"self$logTable = ls[[""table""]]",setup,216e20,173
"}, MakeBetterEventTable = function() {",setup,216e20,173
},setup,216e20,173
self$FillInData(),setup,216e20,173
"self$eventTable = ls[[""events""]]",setup,216e20,173
ls = ReadMouseLog(path),setup,216e20,173
self$betterEventTable = create_better_dt_events(self$eventTable),setup,216e20,173
})),setup,216e20,173
"self$header = ls[[""header""]]",setup,216e20,173
library(randomForest),setup,216e20,173
library(caret),setup,216e20,173
library(doMC),setup,216e20,173
library(mmadsenr),setup,216e20,173
library(futile.logger),setup,216e20,173
library(dplyr),setup,216e20,173
library(ggthemes),setup,216e20,173
"df_tassize_subset <- dplyr::filter(df, sample_size == ssize,      ta_duration == tadur)",setup,216e20,173
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {",setup,216e20,173
},setup,216e20,173
df_tassize_subset,setup,216e20,173
"filename = ""tasampled-classification.log"")",import,216e20,173
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,216e20,173
"flog.appender(appender.file(log_file), name = ""cl"")",import,216e20,173
clargs <- commandArgs(trailingOnly = TRUE),setup,216e20,173
if (length(clargs) == 0) {,setup,216e20,173
} else {,setup,216e20,173
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",setup,216e20,173
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,216e20,173
"filename = ""equifinality-3-ta-sampled-data.rda"")",setup,216e20,173
},setup,216e20,173
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",setup,216e20,173
load(ta_sampled_data_file),import,216e20,173
"setwd(""/Users/rsimham/Documents/Ramesh/SMU/GitRepos/Case Studies/MSDS-CaseStudy1/Analysis/Data"")",setup,364e20,23
library(repmis),setup,364e20,23
library(plyr),setup,364e20,23
library(ggplot2),setup,364e20,23
"source(""countryGDPrawdata.R"")",not sure,364e20,23
"source(""countryFedStatsrawdata.R"")",not sure,364e20,23
"source(""countryGDPcleandata.R"")",data cleaning,364e20,23
"source(""countryFedStatscleandata.R"")",data cleaning,364e20,23
"source(""countryGDPIncometidydata.R"")",data cleaning,364e20,23
"setwd(""../"")",setup,364e20,23
"source(""caseStudyAnalysis.R"", echo = TRUE)",modeling,364e20,23
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,465e20,174
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,465e20,174
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,472e20,175
ss = 1,setup,465e20,174
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,465e20,174
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",     what = character())",not sure,465e20,174
"WaveQTL.repodir <- scan("".WaveQTL.repodir.txt"", what = character())",import,465e20,174
"wd.path = paste0(multiscale.analysis.repodir, ""/analysis/simulation/sample_size/simulation_578/code/"")",setup,465e20,174
setwd(wd.path),setup,465e20,174
"pdf(paste0(wd.path, ""effectsize_578.pdf""), height = 5, width = 7)",export,465e20,174
"hdf5.data.path = ""/mnt/lustre/data/internal/genome_db/hg18/dnase/""",not sure,465e20,174
library(randomForest),exploratory,49e21,176
"source(""./R/VAR_functions.R"")",import,334e18,177
"new_tbl <- readRDS(""./analysis/VAR_output/edd_exercises/2018_exercise_2/Brasil_s1234_t2.rds"")",import,334e18,177
library(caret),modeling,49e21,176
"new_tbl <- new_tbl %>% dplyr::select(-c(lag_sel_method, t_treshold,  var_size, short_name)) %>% mutate(origin = ""new_code"") %>%     dplyr::select(vars_select(names(.), -starts_with(""rank"")))",data cleaning,334e18,177
library(doMC),not sure,49e21,176
names(new_tbl),exploratory,334e18,177
library(mmadsenr),not sure,49e21,176
"old_tbl <- readRDS(""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Brasil_by_step_12345_to_comp.rds"")",import,334e18,177
library(futile.logger),not sure,49e21,176
library(dplyr),exploratory,49e21,176
"old_tbl <- old_tbl %>% dplyr::select(variables, lags, everything()) %>%    dplyr::select(-c(rank_8, rmse_8)) %>% mutate(origin = ""old_code"") %>% dplyr::select(vars_select(names(.), -starts_with(""rank"")))",exploratory,334e18,177
library(ggthemes),visualization,49e21,176
names(old_tbl),exploratory,334e18,177
"old_and_new <- rbind(new_tbl, old_tbl)",data cleaning,334e18,177
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",     filename = ""biasedmodels-classification.log"")",export,49e21,176
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,49e21,176
clargs <- commandArgs(trailingOnly = TRUE),not sure,49e21,176
"filename = ""equifinality-3-ta-sampled-data.rda"")",import,49e21,176
"filename = ""equifinality-3-sampled-data.rda"")",import,49e21,176
"filename = ""equifinality-3-population-data.rda"")",import,49e21,176
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
"filename = ""equifinality-3-population-data.rda"", args = clargs)",import,49e21,176
"sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
},import,49e21,176
"ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
if (length(clargs) == 0) {,import,49e21,176
"filename = ""equifinality-3-sampled-data.rda"", args = clargs)",import,49e21,176
"pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",",import,49e21,176
"filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs)",import,49e21,176
} else {,import,49e21,176
load(pop_data_file),import,49e21,176
load(sampled_data_file),import,49e21,176
load(ta_sampled_data_file),import,49e21,176
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",export,49e21,176
"flog.info(""Loaded data file: %s"", sampled_data_file, name = ""cl"")",export,49e21,176
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",export,49e21,176
"flog.info(""Beginning classification analysis of biased models from equifinality-3 data sets"",     name = ""cl"")",export,49e21,176
num_cores <- get_parallel_cores_given_os(dev = TRUE),modeling,49e21,176
rm(list = ls()),setup,2.9400000000000002e+22,178
"prototypes <- read.table(""../prototypes_2.txt"")",import,2.9400000000000002e+22,178
"uber.proto <- prototypes[1, 2:length(prototypes[1, ])]",data cleaning,2.9400000000000002e+22,178
no.features <- length(uber.proto),exploratory,2.9400000000000002e+22,178
"no.agents <- length(prototypes[, 1]) - 1",exploratory,2.9400000000000002e+22,178
"d.0 <- read.table(""../history_2.txt"", skip = 2)",import,2.9400000000000002e+22,178
"outputs <- d.0[(no.agents + 1):length(d.0[, 1]), (4 + no.features +     1):(4 + no.features + 1 + no.features - 1)]",not sure,2.9400000000000002e+22,178
csim <- function(x1) {    c <- x %*% y/sqrt(x %*% x * y %*% y)    x <- as.numeric(x1)    y <- as.numeric(uber.proto)    return(c)},setup,2.9400000000000002e+22,178
"d.sim <- apply(outputs, 1, csim)",not sure,2.9400000000000002e+22,178
"pdf(""test_2.pdf"")",export,2.9400000000000002e+22,178
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"",   main = paste(""A="", no.agents, "" F="", no.features, sep = """"))",visualization,2.9400000000000002e+22,178
dev.off(),setup,2.9400000000000002e+22,178
rm(list = ls()),setup,2.9400000000000002e+22,178
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/getmode.R"", echo = FALSE)",setup,2.9400000000000002e+22,178
dim(mn.rentals),exploratory,2.9400000000000002e+22,178
count(is.na(mn.rentals$gross.sqft)),exploratory,2.9400000000000002e+22,178
count(is.na(mn.rentals$land.sqft)),exploratory,2.9400000000000002e+22,178
summary(mn.rentals$sale.price.n),exploratory,2.9400000000000002e+22,178
getmode(mn.rentals$sale.price.n),exploratory,2.9400000000000002e+22,178
hist(log10(mn.rentals$sale.price.n)),exploratory,2.9400000000000002e+22,178
library(ggplot2),setup,2.9400000000000002e+22,178
"source(""/Documents/GRADUATE_SCHOOL/Ranalysis/useful.R"")",setup,2.9400000000000002e+22,178
"d_pop <- function(N, d) {    error = 1.96 * sqrt(across_study_var - samp_error);    samp_error = 4/mean(N) * ((1 + mean(d)^2)/8);    across_study_var = sum(N * ((d - mean(d))^2))/sum(N); d = sum(N * d)/sum(N); return(d)}",setup,2.9400000000000002e+22,178
"d_error <- function(N, d) {return(error)}",setup,2.9400000000000002e+22,178
"metad = read.csv(""/Documents/GRADUATE_SCHOOL/Projects/ME_meta/Analysis/Disambiguation Meta-Analysis Data - Sheet1.csv"")",import,2.9400000000000002e+22,178
"cmp1_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp1_promoters.csv"")",import,192e20,179
"cmp2_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp2_promoters.csv"")",import,192e20,179
"cmp3_promoters <- read.csv(""H:/Dropbox/BRL/proj/bkfld_gbm_ev/analysis/2016_04_13_getDMRs_from_HBMVEC_treatments/RnBeads/analysis/noGBM8_noNegCtrl_w_astro_endo_enhancers/differential_methylation_data/diffMethTable_region_cmp3_promoters.csv"")",import,192e20,179
metad$d_by_t <- metad$t/sqrt(metad$N),data cleaning,2.9400000000000002e+22,178
metad$d_by_M <- (metad$M_experimental - metad$M_baseline)/metad$SD,evaluation,2.9400000000000002e+22,178
numIND = 30,setup,764e20,180
"title.name = c(""half"", ""full"", ""2full"", ""4full"")",setup,764e20,180
"case.name = c(paste0(""halfread."", numIND, ""ind.over""), paste0(""fullread."",  numIND, ""ind.over""), paste0(""2fullread."", numIND, ""ind.over""), paste0(""4fullread."", numIND, ""ind.over""))",setup,764e20,180
"ROC.file.name = paste0(""ROC_RD"", numIND, "".pdf"")",setup,764e20,180
"hist.file.name = paste0(""hist_RD"", numIND, "".pdf"")",setup,764e20,180
"ms.null = vector(""list"", length(case.name))",setup,764e20,180
"ms.alt = vector(""list"", length(case.name))",setup,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",    case.name[1], "".Robj""))",import,764e20,180
pval.alt = as.numeric(pval_list),data cleaning,764e20,180
done.alt = done_res,setup,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",    case.name[1], "".Robj""))",import,764e20,180
pval.null = as.numeric(pval_list),data cleaning,764e20,180
done.null = done_res,setup,764e20,180
sum(done.alt),evaluation,764e20,180
sum(done.null),evaluation,764e20,180
min(pval.alt),evaluation,764e20,180
max(pval.alt),evaluation,764e20,180
min(pval.null),evaluation,764e20,180
max(pval.null),evaluation,764e20,180
ms.null[[1]] = pval.null,data cleaning,764e20,180
ms.alt[[1]] = pval.alt,data cleaning,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",    case.name[2], "".Robj""))",import,764e20,180
pval.alt = as.numeric(pval_list),data cleaning,764e20,180
done.alt = done_res,setup,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",     case.name[2], "".Robj""))",import,764e20,180
pval.null = as.numeric(pval_list),setup,764e20,180
done.null = done_res,setup,764e20,180
sum(done.alt),evaluation,764e20,180
sum(done.null),evaluation,764e20,180
min(pval.alt),evaluation,764e20,180
max(pval.alt),evaluation,764e20,180
min(pval.null),evaluation,764e20,180
max(pval.null),evaluation,764e20,180
ms.null[[2]] = pval.null,data cleaning,764e20,180
ms.alt[[2]] = pval.alt,data cleaning,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",     case.name[3], "".Robj""))",import,764e20,180
pval.alt = as.numeric(pval_list),setup,764e20,180
done.alt = done_res,setup,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",     case.name[3], "".Robj""))",import,764e20,180
pval.null = as.numeric(pval_list),setup,764e20,180
done.null = done_res,setup,764e20,180
sum(done.alt),evaluation,764e20,180
sum(done.null),evaluation,764e20,180
min(pval.alt),evaluation,764e20,180
max(pval.alt),evaluation,764e20,180
min(pval.null),evaluation,764e20,180
max(pval.null),evaluation,764e20,180
ms.null[[3]] = pval.null,data cleaning,764e20,180
ms.alt[[3]] = pval.alt,data cleaning,764e20,180
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",     case.name[4], "".Robj""))",import,764e20,180
"tmp <- reshape(dat, varying = names(dat)[4:ncol(dat)], v.names = ""severity"",   timevar = ""tissue_parasite"", times = names(dat)[4:ncol(dat)], direction = ""long"")",setup,578e20,181
"tmp$organ <- matrix(unlist(strsplit(tmp$tissue_parasite, ""_"")),  ncol = 2, byrow = TRUE)[, 2]",setup,578e20,181
"Treatment = ""Retinoic""",setup,961e20,182
library(dbscan),setup,871e20,183
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,621e20,184
library(randomForest),setup,694e20,185
library(caret),setup,694e20,185
library(doMC),setup,694e20,185
library(mmadsenr),setup,694e20,185
library(futile.logger),setup,694e20,185
library(dplyr),setup,694e20,185
library(ggthemes),setup,694e20,185
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {    df_tassize_subset <- dplyr::filter(df, sample_size == ssize, ta_duration == tadur);     df_tassize_subset}",data cleaning,694e20,185
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",  filename = ""tasampled-classification.log"")",setup,694e20,185
"flog.appender(appender.file(log_file), name = ""cl"")",setup,694e20,185
clargs <- commandArgs(trailingOnly = TRUE),setup,694e20,185
"if (length(clargs) == 0) {    ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",    filename = ""equifinality-5-tasampled-data.rda"")} else {    ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",    filename = ""equifinality-5-tasampled-data.rda"", args = clargs)}",setup,694e20,185
load(ta_sampled_data_file),import,694e20,185
load(BYCHANNEL_RDATA),import,293e20,186
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",communication,694e20,185
library(igraph),setup,998e20,1
library(dplyr),setup,998e20,1
"flog.info(""Beginning classification analysis of TA sampled equifinality-5 data sets"",  name = ""cl"")",communication,694e20,185
library(parallel),setup,998e20,1
load(BYSHOW_RDATA),import,293e20,186
library(purrr),setup,998e20,1
load(BYCHANNEL_DAILY_RDATA),import,293e20,186
library(stringr),setup,998e20,1
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,694e20,185
load(BYSHOW_DAILY_RDATA),import,293e20,186
"source(""Analysis/remove_self_node.R"")",setup,998e20,1
load(BYCHANNEL_WEEKLY_RDATA),import,293e20,186
"source(""Analysis/compute_triplets.R"")",setup,998e20,1
"flog.info(""Number of cores used in analysis: %s"", num_cores,     name = ""cl"")",communication,694e20,185
load(BYSHOW_WEEKLY_RDATA),import,293e20,186
"source(""Analysis/compute_all_triplets.R"")",setup,998e20,1
"source(""Analysis/categorize_all_triplets.R"")",setup,998e20,1
load(BYCHANNEL_DAY_OF_WEEK_RDATA),import,293e20,186
"source(""Analysis/categorize_triplet1.R"")",setup,998e20,1
load(BYSHOW_DAY_OF_WEEK_RDATA),import,293e20,186
registerDoMC(cores = num_cores),setup,694e20,185
source(factor_analysis.R),setup,293e20,186
"coffeeG05 = read_graph(""Data/iGraphs/coffeeG05.gml"", format = ""gml"")",visualization,998e20,1
"gasG05 = read_graph(""Data/iGraphs/gasG05.gml"", format = ""gml"")",visualization,998e20,1
"all_triplets = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",modeling,998e20,1
"gbm_grid <- expand.grid(interaction.depth = (1:6) * 2, n.trees = (2:10) *     50, shrinkage = 0.05, n.minobsinnode = 10)",not sure,694e20,185
"all_triplets_test = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",modeling,998e20,1
"ids = unique(unlist(all_triplets %>% filter(category == ""ABC"") %>%    select(X, Y, Z)))",data cleaning,998e20,1
library(reshape2),setup,293e20,186
"subG = induced_subgraph(coffeeG05, vids = ids)",visualization,998e20,1
library(plyr),setup,293e20,186
library(dplyr),setup,293e20,186
library(scales),setup,293e20,186
"ftl <- read.csv(""/Users/efuller/1/CNH/Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",     stringsAsFactors = F)",import,293e20,186
"ftl$trip_id <- paste0(ftl$ftid, ftl$year)",data cleaning,293e20,186
"melt_ftl <- melt(ftl, id.vars = c(""veid"", ""trip_id"", ""spid"",     ""tdate"", ""grid""), measure.vars = ""landed_wt"")",data cleaning,293e20,186
"cast_ftl <- dcast(melt_ftl, trip_id ~ spid, fun.aggregate = sum)",data cleaning,293e20,186
cast_ftl[cast_ftl == 0] <- NA,data cleaning,293e20,186
"training_control <- trainControl(method = ""repeatedcv"", number = 10, repeats = 5)",modeling,694e20,185
seed_value <- 58132133,modeling,694e20,185
"bymedian <- with(melt_ftl, reorder(spid, -value, median))",exploratory,293e20,186
set.seed(seed_value),modeling,694e20,185
"boxplot(value ~ bymedian, data = melt_ftl, cex = 0.15, pch = 19,     las = 2, col = alpha(""black"", 0.25))",visualization,293e20,186
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value, name = ""cl"")",communication,694e20,185
siteSize = 2048,not sure,521e20,187
"treatment = ""Copper""",not sure,521e20,187
"strand = ""both""",not sure,521e20,187
"num_trips <- sort(table(melt_ftl$spid), decreasing = T)",data cleaning,293e20,186
training_set_fraction <- 0.8,modeling,694e20,185
window.size = 300,not sure,521e20,187
test_set_fraction <- 1 - training_set_fraction,modeling,694e20,185
numSam = 6,not sure,521e20,187
"medians <- rep(NA, length(num_trips))",exploratory,293e20,186
"eq5_ta_sampled_df$two_class_label <- factor(ifelse(eq5_ta_sampled_df$model_class_label ==     ""allneutral"", ""neutral"", ""biased""))",data cleaning,694e20,185
"sd <- rep(NA, length(num_trips))",exploratory,293e20,186
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,521e20,187
sample_sizes <- unique(eq5_ta_sampled_df$sample_size),data cleaning,694e20,185
for (i in 1:length(num_trips)) {  sd[i] <- sd(melt_ftl$value[which(melt_ftl$spid == names(num_trips[i]))]);    medians[i] <- median(melt_ftl$value[which(melt_ftl$spid ==  names(num_trips[i]))]) },exploratory,293e20,186
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,521e20,187
ta_durations <- unique(eq5_ta_sampled_df$ta_dur),data cleaning,694e20,185
load(out.path),import,521e20,187
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete."", 600, "".Robj)",setup,521e20,187
"spdf <- data.frame(spid = names(num_trips), num_trips = num_trips,     median_catch = medians, sd = sd)",exploratory,293e20,186
"tassize_subsets <- expand.grid(sample_size = sample_sizes, ta_duration = ta_durations)",modeling,694e20,185
load(out.path),import,521e20,187
"library(""qvalue"")",setup,521e20,187
"little_spdf <- subset(spdf, num_trips < 100 & median_catch <     100)",data cleaning,293e20,186
"exclude_columns <- c(""simulation_run_id"", ""innovation_rate"",  ""model_class_label"", ""sample_size"", ""ta_duration"")",data cleaning,694e20,185
"with(little_spdf, plot(num_trips, median_catch))",visualization,293e20,186
experiment_names <- character(nrow(tassize_subsets)),data cleaning,694e20,185
"with(little_spdf, arrows(x0 = num_trips, y0 = median_catch -     sd, x1 = num_trips, y1 = median_catch + sd, length = 0))",visualization,293e20,186
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/pval.ms.wave."",     all.name, "".Robj"")",setup,521e20,187
"text(little_spdf$num_trips, little_spdf$median_catch, little_spdf$spid, cex = 0.85)",visualization,293e20,186
load(input.path),import,521e20,187
"saveRDS(little_spdf, file = ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-01/little_spdf.RDS"")",export,293e20,186
"for (i in 1:nrow(tassize_subsets)) {           experiment_names[i] <- paste(""Sample Size: "", tassize_subsets[i,  ""sample_size""], "" Duration: "", tassize_subsets[i, ""ta_duration""])    treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete."",     10, "".Robj"")}",communication,694e20,185
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",",setup,521e20,187
load(input.path),import,521e20,187
tassize_subsets_results <- data.frame(),data cleaning,694e20,185
"filter_trips <- cast_ftl[, !(names(cast_ftl) %in% little_spdf$spid)]",data cleaning,293e20,186
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",     treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,521e20,187
load(input.path),import,521e20,187
"filter_trips <- filter_trips[-which(rowSums(filter_trips[, -1],     na.rm = T) == 0), ]",data cleaning,293e20,186
tassize_subset_roc <- NULL,data cleaning,694e20,185
"filtered_ftl <- subset(ftl, trip_id %in% filter_trips$trip_id)",data cleaning,293e20,186
tassize_subset_roc_ssize_20 <- NULL,setup,694e20,185
tassize_subset_roc_ssize_10 <- NULL,setup,694e20,185
sum(is.na(pval.deseq.100.0)),exploratory,521e20,187
tassize_subset_model <- NULL,setup,694e20,185
"saveRDS(filtered_ftl, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-01/filtered_ftl.RDS"")",export,293e20,186
sum(is.na(pval.deseq.100.10)),exploratory,521e20,187
tassize_subset_cm <- NULL,setup,694e20,185
sum(is.na(pval.deseq.3.0)),exploratory,521e20,187
sum(is.na(pval.deseq.3.10)),exploratory,521e20,187
sum(is.na(pval.deseq.full.0)),exploratory,521e20,187
sum(is.na(pval.ms)),exploratory,521e20,187
sum(is.na(pval.wave)),exploratory,521e20,187
length(pval.ms),exploratory,521e20,187
del.ix = NULL,setup,521e20,187
"del.ix = union(del.ix, which(is.na(pval.deseq.100.10) == TRUE)),     p = 0.02, list = FALSE)",data cleaning,521e20,187
"test_tasampled_indices <- createDataPartition(eq5_ta_sampled_df$two_class_label,",data cleaning,694e20,185
"del.ix = union(del.ix, which(is.na(pval.deseq.3.0) == TRUE))",data cleaning,521e20,187
"del.ix = union(del.ix, which(is.na(pval.deseq.3.10) == TRUE))",data cleaning,521e20,187
"del.ix = union(del.ix, which(is.na(pval.deseq.full.0) == TRUE))",data cleaning,521e20,187
"del.ix = union(del.ix, which(is.na(pval.ms) == TRUE))",data cleaning,521e20,187
"del.ix = union(del.ix, which(is.na(pval.wave) == TRUE))",data cleaning,521e20,187
length(del.ix),exploratory,521e20,187
"filtered_ftl <- readRDS(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-01/filtered_ftl.RDS"")",import,293e20,186
"tls10 <- read.csv(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/metier_lists/TLS2010.csv"",     stringsAsFactors = F)",import,293e20,186
"tls12 <- read.csv(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/metier_lists/TLS2012.csv"",",import,293e20,186
qval.wave = qvalue(pval.wave[-del.ix]),modeling,521e20,187
qval.ms = qvalue(pval.ms[-del.ix]),modeling,521e20,187
tls10$X <- NULL,data cleaning,293e20,186
tls10$year <- 2010,data cleaning,293e20,186
qval.deseq.full.0 = qvalue(pval.deseq.full.0[-del.ix]),modeling,521e20,187
tls12$X <- NULL,data cleaning,293e20,186
tls12$year <- 2012,data cleaning,293e20,186
"ftl_sub <- merge(filtered_ftl, tls10, by = c(""ftid"", ""year""))",data cleaning,293e20,186
qval.deseq.3.0 = qvalue(pval.deseq.3.0[-del.ix]),modeling,521e20,187
qval.deseq.3.10 = qvalue(pval.deseq.3.10[-del.ix]),modeling,521e20,187
"ftl_sub12 <- merge(filtered_ftl, tls12, by = c(""ftid"", ""year""))",data cleaning,293e20,186
qval.deseq.100.0 = qvalue(pval.deseq.100.0[-del.ix]),modeling,521e20,187
"num_vess <- ddply(ftl_sub, .(metier), summarize, ves = length(unique(veid)))",data cleaning,293e20,186
"num_vess12 <- ddply(ftl_sub12, .(metier), summarize, ves = length(unique(veid)))    n <- nrow(dat)    stopifnot(all(props >= 0), which.adjust <= length(props))",data cleaning,293e20,186
"split_data <- function(dat, props = c(0.8, 0.15, 0.05), which.adjust = 1) {    which.group <- sample(ids)    ns[which.adjust] <- n - sum(ns[-which.adjust])    ns <- round(n * props)    props <- props/sum(props)    ids <- rep(1:length(props), ns)    split(dat, which.group)}",data cleaning,293e20,186
"melt_ftl <- select(ftl_sub12, trip_id, spid, landed_wt, metier)",data cleaning,293e20,186
"melt_ftl <- melt(melt_ftl, id.vars = c(""trip_id"", ""spid"", ""metier""),     measure.vars = ""landed_wt"")",data cleaning,293e20,186
"cast_ftl <- dcast(melt_ftl, trip_id ~ spid, fun.aggregate = sum)",data cleaning,293e20,186
rownames(cast_ftl) <- cast_ftl$trip_id,data cleaning,293e20,186
cast_ftl$trip_id <- NULL,data cleaning,293e20,186
"df <- split_data(cast_ftl, props = c(0.6, 0.4))",data cleaning,293e20,186
"ref_metier <- select(melt_ftl, trip_id, metier)",data cleaning,293e20,186
ref_metier <- unique(ref_metier),data cleaning,293e20,186
train <- df[[1]],data cleaning,293e20,186
cl <- melt_ftl$metier[which(ref_metier$trip_id %in% rownames(train))],data cleaning,293e20,186
test <- df[[2]],data cleaning,293e20,186
library(class),setup,293e20,186
"k_try <- knn(train, test, cl, k = 50, prob = TRUE)",modeling,293e20,186
"val_test <- data.frame(trip_id = rownames(test), knn = k_try)",evaluation,293e20,186
"val_test <- merge(val_test, ref_metier, by = ""trip_id"")",data cleaning,293e20,186
val_test$match <- val_test$knn == val_test$metier,data cleaning,293e20,186
table(val_test$match)/nrow(val_test),communication,293e20,186
"table(val_test$match, val_test$metier)",communication,293e20,186
probs <- attributes(k_try)[[3]],modeling,293e20,186
val_test$probs <- probs,data cleaning,293e20,186
"problems <- subset(val_test, metier %in% c(""TLS_3"", ""TLS_4""))",data cleaning,293e20,186
"hist(problems$probs, breaks = 30)",visualization,293e20,186
"fileName <- ""/home/kresimir/Projects/FormatAnalysis/fmts-cleaned.tsv""",setup,619e20,188
"syncFolder <- ""/home/kresimir/Dropbox/formatanalysis (1)/figures and other material/201605 figures and other material/201605251200/models""",setup,619e20,188
"colNames <- c(""server"", ""tika"", ""droid"", ""year"", ""amount"")",data cleaning,619e20,188
"experiments <- c(""ARCHIVE"", ""AUDIO"", ""BMPS"", ""DISTILLER"", ""DOCUMENTS"")",setup,619e20,188
"marketFiles <- c(""Format markets - ARCHIVE.tsv"", ""Format markets - AUDIO.tsv"")",setup,619e20,188
start <- 1994,setup,619e20,188
end <- 2010,setup,619e20,188
"predictionYears <- c(2009, 2010, 2011)",modeling,619e20,188
useMovingAverage <- TRUE,setup,619e20,188
multiplicationFactor <- 1000,setup,619e20,188
"source(""conflictResolution.R"")",import,619e20,188
resolveConflicts <- conflictResolution,setup,619e20,188
afterConflictsResolution <- afterResolution,setup,619e20,188
"conflictCategory <- conflictCategoryDetermination        0, 0, 0), ""mm""), panel.background = element_blank(),     linetype = 2, size = 0.2), axis.text = element_text(size = 9),     axis.line.y = element_line(color = ""black"", size = 0.4))",visualization,619e20,188
"themeMain <- theme(axis.ticks = element_line(color = ""gray"",         size = 0.2), panel.grid.minor = element_blank(), legend.key = element_rect(colour = NA),     axis.title = element_text(size = 9), plot.margin = unit(c(0,     axis.line.x = element_line(color = ""black"", size = 0.4),     panel.grid.major = element_line(color = ""gray"", linetype = 2,     axis.text = element_text(size = 15), panel.background = element_blank())",visualization,619e20,188
rm(list = ls()),not sure,559098346391693e8,189
"library(""EpiModelHIV"")",setup,559098346391693e8,189
"library(""EpiModelHPC"")",setup,559098346391693e8,189
"library(""dplyr"")",setup,559098346391693e8,189
"source(""analysis/fx.R"")",setup,559098346391693e8,189
library(ggplot2),setup,559098346391693e8,189
library(ggridges),setup,559098346391693e8,189
library(gridExtra),setup,559098346391693e8,189
library(tidyverse),setup,445189672056586e8,1
mtcars %>% select(mpg),exploratory,445189672056586e8,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,445189672056586e8,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,89257977809757e9,190
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,89257977809757e9,190
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,89257977809757e9,190
rm(list = ls(all.names = TRUE)),not sure,209564585005864e8,191
"source(""/data/private/GOliath/analysis/GOliath_functions.r"")",not sure,89257977809757e9,190
"source(""/data/private/GOliath/analysis/overrepresentation_test.r"")",not sure,89257977809757e9,190
cmdArgs <- commandArgs(),not sure,89257977809757e9,190
"if (!suppressMessages(require(plspm))) install.packages(""plspm"")",setup,209564585005864e8,191
"if (!suppressMessages(require(mice))) install.packages(""mice"")",setup,209564585005864e8,191
folder.path <- cmdArgs[6],setup,89257977809757e9,190
"if (!suppressMessages(require(ggplot2))) install.packages(""ggplot2"")",setup,209564585005864e8,191
"if (!suppressMessages(require(RColorBrewer))) install.packages(""RColorBrewer"")",setup,209564585005864e8,191
"if (!suppressMessages(require(reshape))) install.packages(""reshape"")",setup,209564585005864e8,191
setwd(folder.path),setup,89257977809757e9,190
"config.info <- read.delim(""config.txt"", header = FALSE, row.names = 1)",import,89257977809757e9,190
"if (!suppressMessages(require(pander))) install.packages(""pander"")",setup,209564585005864e8,191
"type <- config.info[""type"", ]",not sure,89257977809757e9,190
library(plspm),setup,209564585005864e8,191
library(mice),setup,209564585005864e8,191
library(ggplot2),setup,209564585005864e8,191
library(RColorBrewer),setup,209564585005864e8,191
library(reshape),setup,209564585005864e8,191
library(pander),setup,209564585005864e8,191
"selectionBarplot <- ggplot(tidyData, aes(x = fatigue)) + geom_bar(aes(fill = result),      position = ""dodge"") + scale_y_discrete(name = ""Correct selection"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,828424352221191e8,192
"ggsave(""./Data/Selection_Barplot_without_zeros.pdf"", selectionBarplot)",export,828424352221191e8,192
"tab1 <- table(tidyData$fatigue, tidyData$result)",modeling,828424352221191e8,192
"setwd(""/Users/cgarvey/Documents/NBA/test/boxScores/"")",setup,697792581049725e8,193
library(plyr),import,697792581049725e8,193
library(scatterplot3d),import,697792581049725e8,193
"basicdata_raw = read.csv(""basic.csv"")",import,697792581049725e8,193
"advdata_raw = read.csv(""advanced.csv"")",import,697792581049725e8,193
"basicdata = basicdata_raw[!(grepl(""DNP"", basicdata_raw$FG)),      ]",import,697792581049725e8,193
"advdata = advdata_raw[!(grepl(""DNP"", advdata_raw$TS.)), ]",data cleaning,697792581049725e8,193
"for (i in 3:21) {     basicdata[, i] <- as.numeric(as.character(basicdata[, i])) }",data cleaning,697792581049725e8,193
"for (i in 3:14) {     advdata[, i] <- as.numeric(as.character(advdata[, i])) }",data cleaning,697792581049725e8,193
"for (i in c(1:2, 22:ncol(basicdata))) {     basicdata[, i] <- as.character(basicdata[, i]) }",data cleaning,697792581049725e8,193
"source(""./R/VAR_functions.R"")",setup,815239961724728e8,194
"for (i in c(1:2, 15:ncol(advdata))) {     advdata[, i] <- as.character(advdata[, i]) }",data cleaning,697792581049725e8,193
"lapply(advdata, class)",data cleaning,697792581049725e8,193
nrow(advdata),exploratory,697792581049725e8,193
nrow(basicdata),exploratory,697792581049725e8,193
head(basicdata),exploratory,697792581049725e8,193
"tail(advdata[, 2])",exploratory,697792581049725e8,193
"remove_end <- function(time) {     pattern <- ""^([0-5][0-9]:[0-5][0-9])""     short_time = regexpr(pattern, time)     regmatches(time, short_time) }",exploratory,697792581049725e8,193
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,193547811359167e7,195
rm(list = ls(all.names = TRUE)),setup,193547811359167e7,195
"if (!suppressMessages(require(psych))) install.packages(""psych"")",setup,193547811359167e7,195
"if (!suppressMessages(require(GPArotation))) install.packages(""GPArotation"")",setup,193547811359167e7,195
"if (!suppressMessages(require(polycor))) install.packages(""polycor"")",setup,193547811359167e7,195
"if (!suppressMessages(require(ggplot2))) install.packages(""ggplot2"")",setup,193547811359167e7,195
"if (!suppressMessages(require(tables))) install.packages(""tables"")",setup,193547811359167e7,195
"if (!suppressMessages(require(Hmisc))) install.packages(""Hmisc"")",setup,193547811359167e7,195
"if (!suppressMessages(require(qgraph))) install.packages(""qgraph"")",setup,193547811359167e7,195
"if (!suppressMessages(require(RColorBrewer))) install.packages(""RColorBrewer"")",setup,193547811359167e7,195
"if (!suppressMessages(require(mice))) install.packages(""mice"")",setup,193547811359167e7,195
library(psych),setup,193547811359167e7,195
library(GPArotation),setup,193547811359167e7,195
library(polycor),setup,193547811359167e7,195
library(ggplot2),setup,193547811359167e7,195
library(tables),setup,193547811359167e7,195
library(Hmisc),setup,193547811359167e7,195
library(qgraph),setup,193547811359167e7,195
library(RColorBrewer),setup,193547811359167e7,195
library(mice),setup,193547811359167e7,195
"PRJ_HOME <- Sys.getenv(""DISS_FLOSS_HOME"")",setup,193547811359167e7,195
"source(file.path(PRJ_HOME, ""config/diss-floss-config.R""))",setup,193547811359167e7,195
"source(file.path(PRJ_HOME, ""utils/data.R""))",setup,193547811359167e7,195
"source(file.path(PRJ_HOME, ""utils/platform.R""))",setup,193547811359167e7,195
"source(file.path(PRJ_HOME, ""utils/graphics.R""))",setup,193547811359167e7,195
"source(file.path(PRJ_HOME, ""utils/knit.R""))",setup,193547811359167e7,195
"SCREE_PLOT_FILE <- ""screePlot""",setup,193547811359167e7,195
DEBUG <- FALSE,setup,193547811359167e7,195
roundLoadings <- function(fa.obj) {     L <- as.matrix(fa.obj$loadings)     L[abs(L) < 0.3] <- 0     return(L) },setup,193547811359167e7,195
"addHeader <- function(obj, newcol, factorNames) {     a1 <- attr(obj, ""colLabels"")     a2 <- rbind(a1, a1)     a2[1, ] <- newcol     a2[2, ] <- factorNames     attr(a2, ""justification"") <- rbind(attr(a1, ""justification""),          attr(a1, ""justification""))     attr(a2, ""formats"") <- rbind(attr(a1, ""formats""), attr(a1,          ""formats""))     attr(obj, ""colLabels"") <- a2     return(obj) }",setup,193547811359167e7,195
"genEFAresultsTable <- function(label = ""efaResults"", caption = ""EFA results summary"",      digits = 2, numFactors) {     fa.pa <- roundLoadings(fa.pa)     colnames(fa.pa) <- paste0(""fa.pa"", ""_"", colnames(fa.pa))     fa.promax <- roundLoadings(fa.promax)     colnames(fa.promax) <- paste0(""fa.promax"", ""_"", colnames(fa.promax))     fa.bi <- roundLoadings(fa.bi)     colnames(fa.bi) <- paste0(""fa.bi"", ""_"", colnames(fa.bi))     fa.uls <- roundLoadings(fa.uls)     colnames(fa.uls) <- paste0(""fa.uls"", ""_"", colnames(fa.uls))     fa.wls <- roundLoadings(fa.wls)     colnames(fa.wls) <- paste0(""fa.wls"", ""_"", colnames(fa.wls))     efaResultsMatrix <- cbind(fa.pa, fa.promax, fa.bi, fa.uls,          fa.wls)     efaResultsMatrix <- round(efaResultsMatrix, digits)     efaResultsMatrix[efaResultsMatrix == 0] <- """"     efaResultsMatrix[efaResultsMatrix != """"] <- gsub(""(0)(\\..*)"",          ""\\2"", efaResultsMatrix[efaResultsMatrix != """"])     efaResultsTable <- as.tabular(efaResultsMatrix)     format(efaResultsTable, digits)     methods <- c(c(""Principal Axis"", rep(NA, numFactors - 1)),          c(""Promax"", rep(NA, numFactors - 1)), c(""Bi-factor"",              rep(NA, numFactors - 1)), c(""ULS"", rep(NA, numFactors -              1)), c(""WLS"", rep(NA, numFactors - 1)))     factorNames <- rep(as.character(1:numFactors), length(unique(methods)) -          1)     efaResultsTable <- addHeader(efaResultsTable, methods, factorNames)     latexCap <- paste0(""\\caption{"", caption, ""}\\\\"", ""\n"",          ""\\toprule"", ""\\label{tab:"", label, ""}"")     booktabs()     latex(efaResultsTable, options = list(tabular = ""longtable"",          toprule = latexCap)) }",setup,193547811359167e7,195
"getBestEFAmodel <- function(models) {     tli.info <- sapply(models, ""[["", ""TLI"")     chi.info <- sapply(models, ""[["", ""chi"")     fit.info <- sapply(models, ""[["", ""fit"")     tli.best <- which.max(tli.info)     chi.best <- which.min(chi.info)     fit.best <- which.min(fit.info)     results <- round(rbind(tli.info, chi.info, fit.info), digits = 2)     if (DEBUG)          print(results)     if (!KNITR) {         print(""Model comparison results in the following best-fitted model:\n"")         print(summary(models[[fit.best]]))     }     return(models[fit.best]) }",setup,193547811359167e7,195
"genEFAcomparisonTable <- function(label = ""efaResults"", caption = ""EFA results summary"",      digits = 2, numFactors) { }",setup,193547811359167e7,195
"genEFAresultsDiagram <- function(models, best.fit = FALSE, latex = FALSE) {     if (best.fit)          models <- getBestEFAmodel(models)     for (fa.obj in models) {         standAlone <- FALSE         filetype <- ifelse(.Platform$GUI == ""RStudio"", ""x11"",              ""R"")         if (latex)              filetype <- ""tex""         factors <- apply(abs(fa.obj$loadings), 1, which.max)         faGroups <- vector(""list"", length(unique(factors)))         for (i in 1:length(factors)) faGroups[[factors[i]]] <- c(faGroups[[factors[i]]],              i)         colPalette <- brewer.pal(5, ""Pastel1"")[1:length(unique(factors))]         tooltips <- c(""Development Team Size"", ""License Restrictiveness"",              ""Project Age"", ""Project Stage"", ""Software Type"",              ""Factor 1"", ""Factor 2"", ""Factor 3"")         qgraph(fa.obj$loadings, groups = faGroups, edge.labels = TRUE,              colors = colPalette, bg = ""grey90"", filetype = filetype,              standAlone = standAlone, mar = c(2.5, 2.5, 2.5, 2.5))     } }",setup,193547811359167e7,195
"message(""\n\n===== PERFORMING EXPLORATORY FACTOR ANALYSIS (EFA) ====="")",communication,193547811359167e7,195
"fileName <- paste0(READY4EFA_FILE, RDS_EXT)",setup,193547811359167e7,195
"ready4efaFile <- file.path(READY4EFA_DIR, fileName)",setup,193547811359167e7,195
"if (!file.exists(EFA_RESULTS_DIR)) {     dir.create(EFA_RESULTS_DIR, recursive = TRUE, showWarnings = FALSE) }",setup,193547811359167e7,195
"message(""\n\n*** Loading data..."")",communication,193547811359167e7,195
flossData <- loadData(ready4efaFile),import,193547811359167e7,195
"flossData <- mice::complete(flossData, 1)",data cleaning,193547811359167e7,195
"factors4analysis <- c(""License.Category"", ""License.Restrictiveness"",      ""Preferred.Support.Type"", ""Preferred.Support.Resource"", ""Project.Age"",      ""Project.Stage"", ""Development.Team.Size"", ""User.Community.Size"")",data cleaning,193547811359167e7,195
"flossData <- flossData[, factors4analysis]",data cleaning,193547811359167e7,195
datasetName <- deparse(substitute(flossData)),data cleaning,193547811359167e7,195
"message(""\n*** Calculating correlations..."")",communication,193547811359167e7,195
"corr.info <- hetcor(flossData, use = ""pairwise.complete.obs"",      std.err = TRUE)",exploratory,193547811359167e7,195
"if (DEBUG) {     message(""\nCorrelations matrix:"")     message(""--------------------"")     print(corr.info, digits = 2) }",communication,193547811359167e7,195
numObs <- floor(mean(corr.info$n[upper.tri(corr.info$n)])),exploratory,193547811359167e7,195
"message(""\n*** Determining number of factors to extract...\n"")",communication,193547811359167e7,195
"message(""\nParallel Analysis (PA) - Method 1 ('psych'):"")",communication,193547811359167e7,195
"message(""============================================\n"")",communication,193547811359167e7,195
rm(list = ls(all = TRUE)),not sure,267587681068107e8,196
"fa.pa.info <- fa.parallel(corr.info$correlations, n.obs = numObs,      fm = ""pa"")",exploratory,193547811359167e7,195
numFactors <- fa.pa.info$nfact,data cleaning,193547811359167e7,195
"pathLinks <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/Links2011V28.csv""",not sure,267587681068107e8,196
"message(""\nProducing PA scree plot... "", appendLF = FALSE)",communication,193547811359167e7,195
"pathHeight <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/Standardized.csv""",not sure,267587681068107e8,196
"pathOutput <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/DoubleEntered.csv""",not sure,267587681068107e8,196
dsLinks <- read.csv(pathLinks),not sure,267587681068107e8,196
"dsLinksLeftHand <- subset(dsLinks, select = c(""Subject1Tag"",      ""Subject2Tag"", ""R""))",not sure,267587681068107e8,196
"dsLinksRightHand <- subset(dsLinks, select = c(""Subject2Tag"",      ""Subject1Tag"", ""R""))",not sure,267587681068107e8,196
"colnames(dsLinksRightHand) <- c(""Subject1Tag"", ""Subject2Tag"",      ""R"")",not sure,267587681068107e8,196
rm(dsLinks),not sure,267587681068107e8,196
dsHeight <- read.csv(pathHeight),not sure,267587681068107e8,196
"dsHeight1 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst19to25"", ""age_ht""))",not sure,267587681068107e8,196
"screePlotData <- with(fa.pa.info, data.frame(Eigen = c(fa.values,      fa.sim), Data = factor(rep(1:2, each = length(fa.values)),      levels = 1:2, labels = c(""Observed"", ""Simulated"")), Factor = rep(1:length(fa.values))))",data cleaning,193547811359167e7,195
"dsHeight2 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst19to25"", ""age_ht""))",not sure,267587681068107e8,196
"colnames(dsHeight1) <- c(""CID"", ""CRace1"", ""CGender1"", ""HtSt1"",      ""AgeHt1"")",not sure,267587681068107e8,196
"colnames(dsHeight2) <- c(""CID"", ""CRace2"", ""CGender2"", ""HtSt2"",      ""AgeHt2"")",not sure,267587681068107e8,196
rm(dsHeight),not sure,267587681068107e8,196
"dsLeftHand <- merge(x = dsLinksLeftHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",not sure,267587681068107e8,196
"g <- ggplot(screePlotData, aes(x = Factor, y = Eigen, color = Data)) +      geom_line() + xlab(""Factor numbers"") + ylab(""Factor eigenvalues"") +      theme(title = element_text(size = 10), legend.position = ""top"",          plot.margin = unit(c(1, 1, 1, 1), ""mm""))",visualization,193547811359167e7,195
"dsLeftHand <- merge(x = dsLeftHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",not sure,267587681068107e8,196
"dsRightHand <- merge(x = dsRightHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",not sure,267587681068107e8,196
"rm(dsLinksLeftHand, dsLinksRightHand, dsHeight1, dsHeight2)",not sure,267587681068107e8,196
"ds <- rbind(dsLeftHand, dsRightHand)",not sure,267587681068107e8,196
screePlot <- g + theme(aspect.ratio = 1/PHI),visualization,193547811359167e7,195
"rm(dsLeftHand, dsRightHand)",not sure,267587681068107e8,196
"write.csv(ds, pathOutput)",not sure,267587681068107e8,196
ageFloor <- 19,not sure,267587681068107e8,196
"ds <- subset(ds, AgeHt1 >= ageFloor & AgeHt2 >= ageFloor)",not sure,267587681068107e8,196
"ds[is.na(ds$R), ""R""] <- 0.375",not sure,267587681068107e8,196
"if (KNITR) {     screePlot_var <- paste0(""screePlot_"", datasetName)     assign(screePlot_var, screePlot, envir = .GlobalEnv) }",communication,193547811359167e7,195
"if (.Platform$GUI == ""RStudio"") {     print(screePlot) }",communication,193547811359167e7,195
"dygraph(gpg_pauses, xlab = ""Keypress index"", ylab = ""Pause length"",      main = paste0(ID, "" "", file_index, "" "", txt_files[file_index],          "" "", n)) %>% dySeries(""V1"", label = ""Seconds"") %>% dyLegend(show = ""always"",      hideOnMouseOut = FALSE) %>% dyRangeSelector()",setup,655371414730325e8,197
"screePlotFile <- file.path(EFA_RESULTS_DIR, paste0(SCREE_PLOT_FILE,      GRAPHICS_EXT))",export,193547811359167e7,195
"suppressMessages(ggsave(file = screePlotFile, plot = screePlot,      width = 4, height = 4))",export,193547811359167e7,195
"message(""Done."")",communication,193547811359167e7,195
p_threshold <- 8,visualization,655371414730325e8,197
"message(""\n\nVery Simple Structure (VSS) analysis:"")",communication,193547811359167e7,195
"message(""====================================="")",communication,193547811359167e7,195
which(pause > p_threshold),visualization,655371414730325e8,197
which(pause > p_threshold),visualization,655371414730325e8,197
library(dygraphs),setup,655371414730325e8,197
"vss.info <- VSS(corr.info$correlations, n.obs = numObs, plot = FALSE)",exploratory,193547811359167e7,195
library(dplyr),setup,655371414730325e8,197
"if (KNITR) {     vssInfo_var <- paste0(""vssInfo_"", datasetName)     assign(vssInfo_var, vss.info, envir = .GlobalEnv) } else {     vss.summ <- summary(vss.info) }",communication,193547811359167e7,195
"EB1979 <- read_sav(""./Analysis/Data/Eurobarometer/Spring 1979/ZA1036_v1-0-1.sav"")",import,655371414730325e8,197
"message(""\nParallel Analysis (PA) - Method 2 ('pcaPA'):"")",communication,193547811359167e7,195
"message(""============================================\n"")",communication,193547811359167e7,195
"message(""Currently disabled."")",communication,193547811359167e7,195
"EB1979 <- select(EB1979, isocntry, v8, v94, v95)",data cleaning,655371414730325e8,197
"names(EB1979) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1979$year <- 1979,data cleaning,655371414730325e8,197
"EB1984 <- read_sav(""Analysis/Data/Eurobarometer/Spring 1984/ZA1320_v1-0-1.sav"")",import,655371414730325e8,197
"if (FALSE) {     numericPA <- PA(flossData, percentiles = c(0.95, 0.99), nReplicates = 50,          type = ""mixed"", algorithm = ""polycor"", use = ""pairwise.complete.obs"")     print(numericPA)     per99Val <- subset(numericPA$percentiles, typeEigenValues ==          99)$eigenValues     obsOrdEigenVal <- numericPA$observed$orderEigenValues     obsEigenVal <- numericPA$observed$eigenValues     numFactorsPcaPA <- max(obsOrdEigenVal[obsEigenVal > per99Val])     message(""\nNumber of factors, determined by PCA PA: "", numFactorsPcaPA)     message(""\n\nProducing PA scree plot... "", appendLF = FALSE)     screePlot <- plot(numericPA, percentiles = c(0.95, 0.99),          main = ""Parallel analysis scree plot"", xlab = ""Number of factors"",          ylab = ""Eigenvalues"", groupLabel = """")     screePlot <- screePlot + theme(aspect.ratio = 1)     if (.Platform$GUI == ""RStudio"") {         print(screePlot)     }     screePlotFile <- file.path(EFA_RESULTS_DIR, paste0(SCREE_PLOT_FILE,          GRAPHICS_EXT))     suppressMessages(ggsave(file = screePlotFile, plot = screePlot,          width = 5, height = 5))     message(""Done.\n"") }",communication,193547811359167e7,195
"EB1984 <- select(EB1984, isocntry, v5, v189, v190)",data cleaning,655371414730325e8,197
"names(EB1984) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1984$year <- 1984,data cleaning,655371414730325e8,197
"EB1989 <- read_sav(""Analysis/Data/Eurobarometer/Spring 1989/ZA1750_v1-0-1.sav"")",import,655371414730325e8,197
"if (FALSE) {     if (numFactors == numFactorsPcaPA) {         message(""PA, using 'psych' and 'pcaPA' packages, suggest\n"",              ""the same number of factors to be extracted: "", numFactors)     }     else {         message(""Number of factors to be extracted, determined, "",              ""using 'psych' and 'pcaPA' packages, differs:\n"")         message(""'psych': "", numFactors)         message(""'pcaPA': "", numFactorsPcaPA)     } }",communication,193547811359167e7,195
"message(""\n\n*** Performing factor analysis (FA)...\n\n"")",communication,193547811359167e7,195
"EB1989 <- select(EB1989, isocntry, v5, v273, v274)",data cleaning,655371414730325e8,197
"message(""FA, using principal axis method:"")",communication,193547811359167e7,195
"names(EB1989) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
"message(""================================\n"")",communication,193547811359167e7,195
EB1989$year <- 1989,import,655371414730325e8,197
"fa.pa <- fa(corr.info$correlations, n.obs = numObs, nfactors = numFactors,      fm = ""pa"")",exploratory,193547811359167e7,195
"EB1994 <- read_sav(""Analysis/Data/Eurobarometer/Spring 1994/ZA2490_v1-1-0.sav"")",data cleaning,655371414730325e8,197
"EB1994 <- filter(EB1994, v5 != 15)",data cleaning,655371414730325e8,197
"EB1994 <- select(EB1994, isocntry, v5, v61, v62)",data cleaning,655371414730325e8,197
if (DEBUG) print(fa.pa),communication,193547811359167e7,195
"names(EB1994) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1994$year <- 1994,data cleaning,655371414730325e8,197
EB1994$nation[EB1994$nation == 13] <- 4,data cleaning,655371414730325e8,197
"EB1995S <- read_sav(""Analysis/Data/Eurobarometer/Sweden 1995/ZA2690_v1-0-1.sav"")",import,655371414730325e8,197
L <- roundLoadings(fa.pa),not sure,193547811359167e7,195
"EB1995S <- filter(EB1995S, v5 == 16)",data cleaning,655371414730325e8,197
"message(""\nRounded loadings matrix:"")",communication,193547811359167e7,195
"EB1995S <- select(EB1995S, isocntry, v5, v67, v68)",data cleaning,655371414730325e8,197
"message(""------------------------"")",communication,193547811359167e7,195
"names(EB1995S) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1995S$year <- 1995,data cleaning,655371414730325e8,197
print(L),communication,193547811359167e7,195
"if (KNITR) {     faPA_var <- paste0(""faPA_"", datasetName)     assign(faPA_var, fa.pa, envir = .GlobalEnv) }",communication,193547811359167e7,195
EB1995S$nation[EB1995S$nation == 13] <- 4,data cleaning,655371414730325e8,197
"message(""\n\nFA with 'promax' rotation:"")",communication,193547811359167e7,195
"message(""===========================\n"")",communication,193547811359167e7,195
"EB1996AF <- read_sav(""Analysis/Data/Eurobarometer/Austria Finland 1996/ZA2831_v1-0-1.sav"")",import,655371414730325e8,197
"EB1996AF <- filter(EB1996AF, v6 == 17 | v6 == 15)",data cleaning,655371414730325e8,197
"EB1996AF <- select(EB1996AF, isocntry, v6, v39, v40)",data cleaning,655371414730325e8,197
"names(EB1996AF) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1996AF$year <- 1996,data cleaning,655371414730325e8,197
EB1996AF$nation[EB1996AF$nation == 13] <- 4,data cleaning,655371414730325e8,197
"fa.promax <- fa(corr.info$correlations, n.obs = numObs, nfactors = numFactors,      fm = ""pa"", rotate = ""promax"")",not sure,193547811359167e7,195
"EB1999 <- read_sav(""Analysis/Data/Eurobarometer/Spring 1999/ZA3171_v1-0-1.sav"")",import,655371414730325e8,197
"EB1999 <- select(EB1999, isocntry, v6, v104, v105)",data cleaning,655371414730325e8,197
"names(EB1999) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB1999$year <- 1999,data cleaning,655371414730325e8,197
EB1999$nation[EB1999$nation == 13] <- 4,data cleaning,655371414730325e8,197
"EB2004 <- read_sav(""Analysis/Data/Eurobarometer/Fall 2004/ZA4229_v1-1-0.sav"")",import,655371414730325e8,197
if (DEBUG) print(fa.promax),communication,193547811359167e7,195
"EB2004 <- select(EB2004, v7, v6, v98, v99)",import,655371414730325e8,197
L <- roundLoadings(fa.promax),not sure,193547811359167e7,195
"names(EB2004) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
"message(""\nRounded loadings matrix:"")",communication,193547811359167e7,195
EB2004$year <- 2004,data cleaning,655371414730325e8,197
"message(""------------------------"")",communication,193547811359167e7,195
EB2004$nation[EB2004$nation == 10] <- 9,data cleaning,655371414730325e8,197
print(L),communication,193547811359167e7,195
"if (KNITR) {     faPromax_var <- paste0(""faPromax_"", datasetName)     assign(faPromax_var, fa.promax, envir = .GlobalEnv) }",communication,193547811359167e7,195
EB2004$nation[EB2004$nation == 14] <- 4,data cleaning,655371414730325e8,197
"message(""\n\nFA with 'quartimin' rotation:"")",communication,193547811359167e7,195
"message(""=============================\n"")",communication,193547811359167e7,195
"message(""Currently disabled."")",communication,193547811359167e7,195
"message(""\n\nFA, using Schmid-Leiman transformation:"")",communication,193547811359167e7,195
"message(""=======================================\n"")",communication,193547811359167e7,195
"message(""Currently disabled."")",communication,193547811359167e7,195
"message(""\n\nFA with 'bi-factor' rotation:"")",communication,193547811359167e7,195
"message(""============================\n"")",communication,193547811359167e7,195
for (i in 1:nrow(EB2004)) {     if (EB2004$nation[i] >= 11) {         EB2004$nation[i] <- EB2004$nation[i] - 1     }     else {         (next)()     } },data cleaning,655371414730325e8,197
"fa.bi <- fa(corr.info$correlations, n.obs = numObs, nfactors = numFactors,      fm = ""pa"", rotate = ""bifactor"", max.iter = 500)",not sure,193547811359167e7,195
"EB2009 <- read_sav(""Analysis/Data/Eurobarometer/January-February 2009/ZA4971_v4-0-0.sav"")",import,655371414730325e8,197
"if (DEBUG) print(fa.bi, sort = TRUE)",communication,193547811359167e7,195
"EB2009 <- select(EB2009, v7, v6, v181, v182)",data cleaning,655371414730325e8,197
"names(EB2009) <- c(""isocntry"", ""nation"", ""membership"", ""benefit"")",data cleaning,655371414730325e8,197
EB2009$year <- 2009,data cleaning,655371414730325e8,197
L <- roundLoadings(fa.bi),not sure,193547811359167e7,195
EB2009$nation[EB2009$nation == 10] <- 9,data cleaning,655371414730325e8,197
EB2009$nation[EB2009$nation == 14] <- 4,data cleaning,655371414730325e8,197
"if (KNITR) {     faBi_var <- paste0(""faBi_"", datasetName)     assign(faBi_var, fa.bi, envir = .GlobalEnv) }",communication,193547811359167e7,195
for (i in 1:nrow(EB2009)) {     if (EB2009$nation[i] >= 11) {         EB2009$nation[i] <- EB2009$nation[i] - 1     }     else {         (next)()     } },data cleaning,655371414730325e8,197
"message(""\nRounded loadings matrix:"")",communication,193547811359167e7,195
"message(""------------------------"")",communication,193547811359167e7,195
"EBMerge <- rbind(EB1979, EB1984, EB1989, EB1994, EB1995S, EB1996AF,      EB1999, EB2004, EB2009)",data cleaning,655371414730325e8,197
print(L),communication,193547811359167e7,195
"message(""\n\nFA using ULS approach:"")",communication,193547811359167e7,195
"EBMerge$gen.EUS <- ifelse(EBMerge$membership == 3, 1, 0)",data cleaning,655371414730325e8,197
"message(""=====================\n"")",communication,193547811359167e7,195
library(knitr),setup,652330298908055e7,198
library(xml2),setup,652330298908055e7,198
library(rvest),setup,652330298908055e7,198
library(ggplot2),setup,652330298908055e7,198
library(pander),setup,652330298908055e7,198
library(plyr),setup,652330298908055e7,198
"source(""~/CaseStudy2/Analysis/procrastination_data.R"", echo = TRUE)",setup,652330298908055e7,198
"source(""~/CaseStudy2/Analysis/hdi_data.R"", echo = TRUE)",setup,652330298908055e7,198
"source(""~/CaseStudy2/Analysis/merge_data.R"", echo = TRUE)",setup,652330298908055e7,198
"source(""~/CaseStudy2/Analysis/preliminary_analysis.R"", echo = TRUE)",setup,652330298908055e7,198
"source(""~/CaseStudy2/Analysis/analysis_wGraphics.R"", echo = TRUE)",setup,652330298908055e7,198
siteSize = 2048,setup,652330298908055e7,198
"treatment = ""Copper""",setup,652330298908055e7,198
"strand = ""both""",setup,652330298908055e7,198
"alt.name = paste0(treatment, ""."", siteSize, ""."", strand, "".alt"")",setup,652330298908055e7,198
"null.name = paste0(treatment, ""."", siteSize, ""."", strand, "".null"")",setup,652330298908055e7,198
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,652330298908055e7,198
"deseq.100.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/min.pval.txt""))[,      1])",setup,652330298908055e7,198
length(deseq.100.alt),setup,652330298908055e7,198
"deseq.100.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/min.pval.txt""))[,      1])",setup,652330298908055e7,198
length(deseq.100.null),setup,652330298908055e7,198
"deseq.300.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/min.pval.txt""))[,      1])",setup,652330298908055e7,198
length(deseq.300.alt),setup,652330298908055e7,198
"deseq.300.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/min.pval.txt""))[,      1])",setup,652330298908055e7,198
length(deseq.300.null),setup,652330298908055e7,198
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/wave/"",      alt.name, "".run/sum/"", alt.name, "".Robj""))",setup,652330298908055e7,198
wave.alt = unlist(logLR_list),setup,652330298908055e7,198
wave.done.alt = unlist(done_list),setup,652330298908055e7,198
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/wave/"",      null.name, "".run/sum/"", null.name, "".Robj""))",setup,652330298908055e7,198
wave.null = unlist(logLR_list),setup,652330298908055e7,198
wave.done.null = unlist(done_list),setup,652330298908055e7,198
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/multiscale/"",      alt.name, "".sum/"", alt.name, "".Robj""))",setup,652330298908055e7,198
ms.alt = unlist(logLR_list),setup,652330298908055e7,198
ms.done.alt = unlist(done_list),setup,652330298908055e7,198
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/multiscale/"",      null.name, "".sum/"", null.name, "".Robj""))",setup,652330298908055e7,198
ms.null = unlist(logLR_list),setup,652330298908055e7,198
ms.done.null = unlist(done_list),setup,652330298908055e7,198
length(wave.alt),setup,652330298908055e7,198
length(wave.null),setup,652330298908055e7,198
length(wave.done.alt),setup,652330298908055e7,198
length(wave.done.null),setup,652330298908055e7,198
min(wave.alt),setup,652330298908055e7,198
max(wave.alt),setup,652330298908055e7,198
min(wave.null),setup,652330298908055e7,198
max(wave.null),setup,652330298908055e7,198
rm(list = ls()),not sure,287180102430284e8,199
sum(is.na(wave.done.alt)),exploratory,652330298908055e7,198
gc(),not sure,287180102430284e8,199
sum(wave.done.alt),exploratory,652330298908055e7,198
sum(is.na(wave.done.null)),exploratory,652330298908055e7,198
sum(wave.done.null),exploratory,652330298908055e7,198
length(ms.alt),exploratory,652330298908055e7,198
length(ms.null),exploratory,652330298908055e7,198
length(ms.done.alt),exploratory,652330298908055e7,198
library(knitr),setup,287180102430284e8,199
length(ms.done.null),exploratory,652330298908055e7,198
library(data.table),setup,287180102430284e8,199
min(ms.alt),exploratory,652330298908055e7,198
max(ms.alt),exploratory,652330298908055e7,198
min(ms.null),exploratory,652330298908055e7,198
max(ms.null),exploratory,652330298908055e7,198
library(gdata),setup,287180102430284e8,199
sum(is.na(ms.done.alt)),exploratory,652330298908055e7,198
sum(ms.done.alt),exploratory,652330298908055e7,198
sum(is.na(ms.done.null)),exploratory,652330298908055e7,198
sum(ms.done.null),exploratory,652330298908055e7,198
"min(ms.alt, na.rm = TRUE)",exploratory,652330298908055e7,198
library(plyr),setup,287180102430284e8,199
library(dplyr),setup,287180102430284e8,199
"max(ms.alt, na.rm = TRUE)",exploratory,652330298908055e7,198
"min(ms.null, na.rm = TRUE)",exploratory,652330298908055e7,198
options(dplyr.print_min = 100),setup,287180102430284e8,199
"max(ms.null, na.rm = TRUE)",exploratory,652330298908055e7,198
options(dplyr.print_max = 100),setup,287180102430284e8,199
length(deseq.100.alt),exploratory,652330298908055e7,198
length(deseq.300.alt),exploratory,652330298908055e7,198
length(deseq.300.null),exploratory,652330298908055e7,198
library(ggplot2),setup,287180102430284e8,199
sum(is.infinite(deseq.100.alt)),exploratory,652330298908055e7,198
library(magrittr),setup,287180102430284e8,199
sum(is.infinite(deseq.300.alt)),exploratory,652330298908055e7,198
library(tidyr),setup,287180102430284e8,199
library(foreach),setup,287180102430284e8,199
sum(is.infinite(deseq.100.null)),exploratory,652330298908055e7,198
library(doParallel),setup,287180102430284e8,199
sum(is.infinite(deseq.300.null)),exploratory,652330298908055e7,198
deseq.100.alt.inf = which(is.infinite(deseq.100.alt) == TRUE),exploratory,652330298908055e7,198
library(microbenchmark),setup,287180102430284e8,199
library(readxl),setup,287180102430284e8,199
deseq.300.alt.inf = which(is.infinite(deseq.300.alt) == TRUE),exploratory,652330298908055e7,198
library(stringr),setup,287180102430284e8,199
library(zoo),setup,287180102430284e8,199
deseq.100.null.inf = which(is.infinite(deseq.100.null) == TRUE),exploratory,652330298908055e7,198
deseq.300.null.inf = which(is.infinite(deseq.300.null) == TRUE),exploratory,652330298908055e7,198
"library(""readxl"")",setup,287180102430284e8,199
sum(deseq.100.alt.inf != deseq.300.alt.inf),exploratory,652330298908055e7,198
"library(""XLConnect"")",setup,287180102430284e8,199
sum(deseq.100.null.inf != deseq.300.null.inf),exploratory,652330298908055e7,198
"library(""btools"")",setup,287180102430284e8,199
sum(wave.alt[deseq.100.alt.inf]),exploratory,652330298908055e7,198
options(dplyr.print_min = 60),setup,287180102430284e8,199
sum(wave.null[deseq.100.null.inf]),exploratory,652330298908055e7,198
library(grid),setup,287180102430284e8,199
sum(ms.alt[deseq.100.alt.inf]),exploratory,652330298908055e7,198
library(gridExtra),setup,287180102430284e8,199
sum(ms.null[deseq.100.null.inf]),exploratory,652330298908055e7,198
"del.ix = union(union(union(deseq.100.alt.inf, deseq.100.null.inf),      which(is.na(ms.alt) == TRUE)), which(is.na(ms.null) == TRUE))",exploratory,652330298908055e7,198
"source(""Functions.R"")",import,287180102430284e8,199
which(is.na(ms.alt) == TRUE),data cleaning,652330298908055e7,198
"RIG.blue <- ""#003598""",setup,287180102430284e8,199
"RIG.red <- ""#A50021""",setup,287180102430284e8,199
"RIG.green <- ""#009900""",setup,287180102430284e8,199
"RIG.yellow <- ""#FFFF66""",setup,287180102430284e8,199
"RIG.purple <- ""#9966FF""",setup,287180102430284e8,199
which(is.na(ms.null) == TRUE),data cleaning,652330298908055e7,198
"RIG.yellow.dark <- ""#ffc829""",setup,287180102430284e8,199
"RIG.orange <- ""#fc9272""",setup,287180102430284e8,199
wave.a = wave.alt[-del.ix],data cleaning,652330298908055e7,198
wave.n = wave.null[-del.ix],data cleaning,652330298908055e7,198
"demo.color6 <- c(RIG.red, RIG.orange, RIG.purple, RIG.green,      RIG.blue, RIG.yellow.dark)",setup,287180102430284e8,199
ms.a = ms.alt[-del.ix],data cleaning,652330298908055e7,198
ms.n = ms.null[-del.ix],data cleaning,652330298908055e7,198
deseq.100.a = deseq.100.alt[-del.ix],data cleaning,652330298908055e7,198
deseq.300.a = deseq.300.alt[-del.ix],data cleaning,652330298908055e7,198
deseq.100.n = deseq.100.null[-del.ix],data cleaning,652330298908055e7,198
deseq.300.n = deseq.300.null[-del.ix],data cleaning,652330298908055e7,198
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/code/"")",data cleaning,652330298908055e7,198
"pdf(""hist.3.methods.both.pdf"", width = 7, height = 5)",setup,652330298908055e7,198
"xmax = max(wave.a, wave.n)",visualization,652330298908055e7,198
"xmin = min(wave.a, wave.n)",exploratory,652330298908055e7,198
"wave.a.hist = hist(wave.a, plot = FALSE, breaks = 200)",exploratory,652330298908055e7,198
"wave.n.hist = hist(wave.n, plot = FALSE, breaks = 200)",exploratory,652330298908055e7,198
"ymax = max(wave.a.hist$counts, wave.n.hist$counts)",exploratory,652330298908055e7,198
"ymin = min(wave.a.hist$counts, wave.n.hist$counts)",exploratory,652330298908055e7,198
"par(mfrow = c(2, 1))",exploratory,652330298908055e7,198
"hist(wave.n, breaks = 200, main = ""wave null"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"hist(wave.a, breaks = 200, main = ""wave alt"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"xmax = max(ms.a, ms.n)",visualization,652330298908055e7,198
"xmin = min(ms.a, ms.n)",exploratory,652330298908055e7,198
"ms.a.hist = hist(ms.a, plot = FALSE, breaks = 200)",exploratory,652330298908055e7,198
"ms.n.hist = hist(ms.n, plot = FALSE, breaks = 200)",visualization,652330298908055e7,198
"ymax = max(ms.a.hist$counts, ms.n.hist$counts)",visualization,652330298908055e7,198
"ymin = min(ms.a.hist$counts, ms.n.hist$counts)",exploratory,652330298908055e7,198
"par(mfrow = c(2, 1))",exploratory,652330298908055e7,198
"hist(ms.n, breaks = 200, main = ""multiseq null"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"hist(ms.a, breaks = 200, main = ""multiseq alt"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
xmax = 1,visualization,652330298908055e7,198
"RIG.theme <- function() {     theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),          panel.grid.minor.y = element_blank(), panel.grid.major.y = element_line(size = 0.5,              color = ""gray80""), plot.title = element_text(hjust = 0.5),          plot.subtitle = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0,              size = 9)) }",setup,287180102430284e8,199
xmin = 0,exploratory,652330298908055e7,198
"deseq.100.a.hist = hist(deseq.100.a, plot = FALSE, breaks = 200)",exploratory,652330298908055e7,198
"deseq.100.n.hist = hist(deseq.100.n, plot = FALSE, breaks = 200)",visualization,652330298908055e7,198
"ymax = max(deseq.100.a.hist$counts, deseq.100.n.hist$counts)",visualization,652330298908055e7,198
"dir_data_ppd <- ""./Inputs_Data_PPD/""",setup,287180102430284e8,199
"dir_data_std <- ""./Inputs_Data_std/planData_std/""",setup,287180102430284e8,199
"dir_outputs_liab <- ""./Outputs_liab/""",setup,287180102430284e8,199
"dir_outputs_sim <- ""./Outputs_sim/""",setup,287180102430284e8,199
"ymin = min(deseq.100.a.hist$counts, deseq.100.n.hist$counts)",data cleaning,652330298908055e7,198
"par(mfrow = c(2, 1))",data cleaning,652330298908055e7,198
"hist(deseq.100.n, breaks = 200, main = ""DESeq 100 null"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"file_ppd <- ""DataPPD.RData""",import,287180102430284e8,199
"hist(deseq.100.a, breaks = 200, main = ""DESeq 100 alt"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"load(paste0(dir_data_ppd, file_ppd))",import,287180102430284e8,199
xmax = 1,visualization,652330298908055e7,198
ppd_id_all <- PPD_data$ppd_id,exploratory,287180102430284e8,199
xmin = 0,exploratory,652330298908055e7,198
"deseq.300.a.hist = hist(deseq.300.a, plot = FALSE, breaks = 200)",exploratory,652330298908055e7,198
"ppd_id_largePlans <- c(9, 26, 83, 85, 125, 72, 84, 86, 140, 150,      10, 28, 78, 88, 108)",exploratory,287180102430284e8,199
"deseq.300.n.hist = hist(deseq.300.n, plot = FALSE, breaks = 200)",visualization,652330298908055e7,198
"ymax = max(deseq.300.a.hist$counts, deseq.300.n.hist$counts)",visualization,652330298908055e7,198
"ymin = min(deseq.300.a.hist$counts, deseq.300.n.hist$counts)",visualization,652330298908055e7,198
"par(mfrow = c(2, 1))",visualization,652330298908055e7,198
"hist(deseq.300.n, breaks = 200, main = ""DESeq 300 null"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
"hist(deseq.300.a, breaks = 200, main = ""DESeq 300 alt"", xlim = c(xmin,      xmax), ylim = c(ymin, ymax))",visualization,652330298908055e7,198
dev.off(),visualization,652330298908055e7,198
set.seed(1),visualization,652330298908055e7,198
ms.new.a = ms.a,setup,652330298908055e7,198
wh = which(ms.a == 0),exploratory,652330298908055e7,198
length(wh),exploratory,652330298908055e7,198
"ms.new.a[wh] = runif(length(wh), -0.001, 0)",exploratory,652330298908055e7,198
"ppd_id_smallPlans <- setdiff(ppd_id_all, ppd_id_largePlans)",not sure,287180102430284e8,199
ms.new.n = ms.n,exploratory,652330298908055e7,198
wh = which(ms.n == 0),exploratory,652330298908055e7,198
"load(""./Analysis/reportData_A1_return75.RData"")",import,287180102430284e8,199
length(wh),exploratory,652330298908055e7,198
"load(""./Analysis/reportData_A1_planAssumption.RData"")",import,287180102430284e8,199
"ms.new.n[wh] = runif(length(wh), -0.001, 0)",exploratory,652330298908055e7,198
"load(""./Analysis/reportData_A1_lowReturn15y.RData"")",import,287180102430284e8,199
wave.new.a = wave.a,exploratory,652330298908055e7,198
wh = which(wave.a == 0),exploratory,652330298908055e7,198
"load(""./Analysis/reportData_A1_highVol.RData"")",import,287180102430284e8,199
length(wh),exploratory,652330298908055e7,198
"wave.new.a[wh] = runif(length(wh), -0.001, 0)",exploratory,652330298908055e7,198
wave.new.n = wave.n,exploratory,652330298908055e7,198
wh = which(wave.n == 0),exploratory,652330298908055e7,198
length(wh),exploratory,652330298908055e7,198
"wave.new.n[wh] = runif(length(wh), -0.001, 0)",exploratory,652330298908055e7,198
"results_det <- bind_rows(reportData_list_A1_return75$results_det,      reportData_list_A1_lowReturn15y$results_det, reportData_list_A1_highVol$results_det)",data cleaning,287180102430284e8,199
"get.pval.from.empirical.null.dist <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null >= x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null <= x))         }, statistic.null = statistic.null)     }     pval.list = sapply(numSig, function(x, numNulltests) {         return(runif(1, (x + 1)/(numNulltests + 2), (x + 1)/(numNulltests +              1)))     }, numNulltests = numNulltests)     return(pval.list) }",exploratory,652330298908055e7,198
"df_fig_det <- results_det %>% filter(ppd_id == 0, returnScn !=      ""highVol"", year >= 2017, year <= 2046) %>% select(ppd_id,      returnScn, year, AL, MA, AA, ERC, PR) %>% mutate(FR_MA = 100 *      MA/AL, ERC_PR = 100 * ERC/PR, returnScn = factor(returnScn,      levels = c(""return75"", ""lowReturn15y""), labels = c(""Scenario 1\n\""7.5 percent expected return\"""",          ""Scenario 2\n\""15 Years of Low Returns\""""))) %>% select(returnScn,      year, FR_MA, ERC_PR, ERC)",exploratory,287180102430284e8,199
"fig.title <- ""Total market asset value \nas a percentage of total liability""",exploratory,287180102430284e8,199
"fig_FR_det <- df_fig_det %>% ggplot(aes(x = year, y = FR_MA,      color = returnScn, shape = returnScn)) + geom_line() + geom_point(size = 2) +      geom_hline(yintercept = 100, linetype = 2, size = 1) + coord_cartesian(ylim = c(50,      100)) + scale_x_continuous(breaks = c(2017, seq(2020, 2040,      5), 2046), name = NULL) + scale_y_continuous(breaks = seq(0,      100, 10)) + scale_color_manual(values = c(RIG.blue, RIG.red,      ""black""), name = NULL) + scale_shape_manual(values = c(15,      16), name = NULL) + labs(title = fig.title, y = ""Percent"") +      guides(color = guide_legend(keywidth = 1.5, keyheight = 3),          shape = guide_legend(keywidth = 1.5, keyheight = 3)) +      theme_bw() + RIG.theme() + theme(legend.position = ""none"")",visualization,287180102430284e8,199
"fig.title <- ""Total employer contribution \nas a percentage of total payroll""",visualization,287180102430284e8,199
"fig_ERC_PR_det <- df_fig_det %>% ggplot(aes(x = year, y = ERC_PR,      color = returnScn, shape = returnScn)) + geom_line() + geom_point(size = 2) +      coord_cartesian(ylim = c(0, 30)) + scale_x_continuous(breaks = c(2017,      seq(2020, 2040, 5), 2046), name = NULL) + scale_y_continuous(breaks = seq(0,      100, 5)) + scale_color_manual(values = c(RIG.blue, RIG.red),      name = NULL) + scale_shape_manual(values = c(15, 16), name = NULL) +      labs(title = fig.title, y = ""Percent"") + guides(color = guide_legend(keywidth = 1.5,      keyheight = 3), shape = guide_legend(keywidth = 1.5, keyheight = 3)) +      theme_bw() + RIG.theme()",visualization,287180102430284e8,199
"fig.title <- grid.text(""Overall funded ratio and employer contribution rate for 170 large public pension plans\nunder different investment return scenarios"",      just = ""center"", x = 0.45)",visualization,287180102430284e8,199
"fig_det <- grid.arrange(fig_FR_det, fig_ERC_PR_det, ncol = 2,      widths = c(0.75, 1), top = fig.title)",visualization,287180102430284e8,199
fig_det %>% grid.draw(),visualization,287180102430284e8,199
"ggsave(fig_det, file = ""./Analysis/Graphs_report/fig_det.png"",      width = 10, height = 5)",visualization,287180102430284e8,199
library(Hmisc),setup,690483701182529e8,195
library(raster),setup,690483701182529e8,195
library(plyr),setup,690483701182529e8,195
library(dplyr),setup,690483701182529e8,195
"plot.IO <- read.csv(""./Analysis/Cleaned_data/plot_IO_Y2.csv"")",setup,690483701182529e8,195
"maize <- filter(plot.IO, zaocode == ""Maize"")",import,690483701182529e8,195
maize$y2_hhid <- as.character(maize$y2_hhid),data cleaning,690483701182529e8,195
"hhid.reg.zone <- read.csv(""./Analysis/Cleaned_data/hhid_reg_zone_y2.csv"")",data cleaning,690483701182529e8,195
hhid.reg.zone$y2_hhid <- as.character(hhid.reg.zone$y2_hhid),import,690483701182529e8,195
"coords <- read.csv(""./Analysis/Cleaned_data/lon_lat.csv"")",data cleaning,690483701182529e8,195
coords$y2_hhid <- as.character(coords$y2_hhid),import,690483701182529e8,195
"with(coords, plot(lon, lat))",data cleaning,690483701182529e8,195
log <- plot.IO$y2_hhid %in% hhid.reg.zone$y2_hhid,visualization,690483701182529e8,195
table(log),visualization,690483701182529e8,195
log2 <- plot.IO$y2_hhid %in% coords$y2_hhid,communication,690483701182529e8,195
table(log2),visualization,690483701182529e8,195
length(unique(plot.IO$y2_hhid)),communication,690483701182529e8,195
"maize2 <- left_join(maize[, c(""y2_hhid"", ""plotnum"", ""output.kg"")],      hhid.reg.zone)",visualization,690483701182529e8,195
"maize3 <- left_join(maize2, select(coords, y2_hhid, lon, lat))",data cleaning,690483701182529e8,195
"maize3$cats <- cut2(maize3$output.kg, g = 4)",data cleaning,690483701182529e8,195
"maize3.split <- split(maize3, maize3$cats)",data cleaning,690483701182529e8,195
small <- maize3.split[[1]],data cleaning,690483701182529e8,195
big <- maize3.split[[4]],data cleaning,690483701182529e8,195
"with(small, plot(lon, lat))",data cleaning,690483701182529e8,195
table(big$region),visualization,690483701182529e8,195
"TZA_map <- getData(""GADM"", country = ""TZA"", level = 1)",communication,690483701182529e8,195
"TZA_map <- getData(""GADM"", country = ""TZA"", level = 1)",not sure,690483701182529e8,195
library(dplyr),data cleaning,123387326253578e8,200
library(ggplot2),visualization,123387326253578e8,200
"setwd(""C:/Users/morle001/Dropbox/Micro_IPOP"")",setup,690483701182529e8,195
library(lattice),setup,690483701182529e8,195
library(ppcor),setup,690483701182529e8,195
library(ggplot2),setup,690483701182529e8,195
rm(list = ls()),setup,690483701182529e8,195
"data <- read.table(file = ""order2size"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2tran"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2erep"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2domain"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2dist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2expr"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2breadth"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""order2solo"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprtran"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprsize"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprerep"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprbreadth"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprdomain"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""exprdist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadthsize"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadthtran"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadtherep"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadthdomain"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadthexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""breadthdist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizetran"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizeorder_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizerep"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizedom_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizedist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""sizeexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""tranorder_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""tranerep"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""trandom"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""trandist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""tranexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""ordererep_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""orderdom_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""orderdist_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""orderexon_BIEN"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""erepdom"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""erepdist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""erepexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""domdist"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""domexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data <- read.table(file = ""distexon"", header = TRUE, sep = ""\t"")",import,690483701182529e8,195
"data_subset <- subset(data, breadth == ""low"")",data cleaning,690483701182529e8,195
"mod2 = lm(data_subset[[""Ka_pos""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,690483701182529e8,195
"mod2 = lm(data_subset[[""Ka_neg""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"data[[""mutation""]] = factor(data[[""mutation""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""recombination""]] = factor(data[[""recombination""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""order""]] = factor(data[[""order2""]], levels = c(""low"",      ""high""))",data cleaning,690483701182529e8,195
"data[[""size""]] = factor(data[[""size""]], levels = c(""low"", ""medium"",      ""high""))",data cleaning,690483701182529e8,195
"data[[""transcripts""]] = factor(data[[""transcripts""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""distance""]] = factor(data[[""distance""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""exons""]] = factor(data[[""exons""]], levels = c(""low"", ""medium"",      ""high""))",data cleaning,690483701182529e8,195
"data[[""expression""]] = factor(data[[""expression""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""breadth""]] = factor(data[[""breadth""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690483701182529e8,195
"data[[""erep""]] = factor(data[[""erep""]], levels = c(""low"", ""high""))",data cleaning,690483701182529e8,195
"data[[""domain""]] = factor(data[[""domain""]], levels = c(""active"",      ""both"", ""inactive""))",data cleaning,690483701182529e8,195
"data[[""order""]] = factor(data[[""order""]], levels = c(""low"", ""medium"",      ""high"", ""sup""))",data cleaning,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,690483701182529e8,195
summary(mod2),communication,690483701182529e8,195
"Anova(mod2, type = ""2"")",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,690483701182529e8,195
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,690483701182529e8,195
numIND = 70,setup,303722349926829e7,201
"title.name = c(""half"", ""full"", ""2full"", ""4full"")",setup,303722349926829e7,201
"case.name = c(paste0(""halfread."", numIND, ""ind.over""), paste0(""fullread."",      numIND, ""ind.over""), paste0(""2fullread."", numIND, ""ind.over""),      paste0(""4fullread."", numIND, ""ind.over""))",import,303722349926829e7,201
"ROC.file.name = paste0(""logLR_ROC_RD"", numIND, "".pdf"")",import,303722349926829e7,201
"hist.file.name = paste0(""logLR_hist_RD"", numIND, "".pdf"")",import,303722349926829e7,201
"ms.null = vector(""list"", length(case.name))",setup,303722349926829e7,201
print(Sys.getpid()),setup,640528935240582e8,202
"write_bib(""devtools"")",communication,520510130561888e8,203
"source(""../../bin/WGSData.R"")",setup,570968170184642e8,204
"source(""~/selection/code/lib/mh_plot_lib.R"")",exploratory,471683370415121e7,205
"results <- read.table(""~/selection/analysis/s_estimates/ALL_s_estimates.txt"",      as.is = TRUE, header = FALSE)",import,471683370415121e7,205
"colnames(results) <- c(""ID"", ""s.est"", ""p"", ""ci.lower"", ""ci.upper"")",data cleaning,471683370415121e7,205
"data <- read.table(""~/data/v6/use/v61kg_europe2names.snp"", as.is = TRUE)",import,471683370415121e7,205
"data <- data[, c(1, 2, 4)]",exploratory,471683370415121e7,205
"colnames(data) <- c(""ID"", ""CHR"", ""POS"")",exploratory,471683370415121e7,205
"results.tag <- """"",exploratory,471683370415121e7,205
"png(paste0(""~/selection/analysis/s_estimates/qq_plot"", results.tag,      "".png""), width = 800, height = 400)",communication,471683370415121e7,205
qq.exp.pts <- rexp(NROW(results))/log(10),evaluation,471683370415121e7,205
"qqplot(qq.exp.pts, -log10(results$p), pch = 1, col = ""red"", xlab = ""Expected"",      ylab = ""Observed"", bty = ""n"", cex = 0.5)",visualization,471683370415121e7,205
"abline(0, 1, col = ""black"")",visualization,471683370415121e7,205
dev.off(),visualization,471683370415121e7,205
"res <- data.frame(ID = results$ID, PVAL = results$p)",visualization,471683370415121e7,205
"res <- merge(res, data, by = ""ID"")",data cleaning,471683370415121e7,205
"res <- res[order(res$CHR, res$POS), ]",data cleaning,471683370415121e7,205
"res <- res[!is.na(res$PVAL), ]",data cleaning,471683370415121e7,205
"png(paste0(""~/selection/analysis/s_estimates/mh_plot"", results.tag,      "".png""), width = 800, height = 400)",communication,471683370415121e7,205
"par(mar = c(2, 4, 1, 1))",visualization,471683370415121e7,205
MH.plot(res),visualization,471683370415121e7,205
"abline(h = 6.79, col = ""red"", lty = 2)",visualization,471683370415121e7,205
dev.off(),visualization,471683370415121e7,205
library(mmadsenr),import,652954841265455e8,206
library(caret),import,652954841265455e8,206
library(doMC),import,652954841265455e8,206
library(futile.logger),import,652954841265455e8,206
library(dplyr),import,652954841265455e8,206
library(ggthemes),import,652954841265455e8,206
ptm <- proc.time(),import,652954841265455e8,206
"gbm_grid <- expand.grid(interaction.depth = (1:6) * 2, n.trees = (2:10) *      50, shrinkage = 0.05, n.minobsinnode = 10)",setup,652954841265455e8,206
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",setup,652954841265455e8,206
seed_value <- 58132133,setup,652954841265455e8,206
set.seed(seed_value),setup,652954841265455e8,206
training_set_fraction <- 0.8,setup,652954841265455e8,206
test_set_fraction <- 1 - training_set_fraction,setup,652954841265455e8,206
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",setup,652954841265455e8,206
"get_experiment_names <- function(comparison_prefix, tassize_subsets) {     n <- nrow(tassize_subsets)     experiment_names <- character(n)     for (i in 1:n) {         experiment_names[i] <- paste0(comparison_prefix, "": Sample Size: "",              tassize_subsets[i, ""sample_size""], "" Duration: "",              tassize_subsets[i, ""ta_duration""])     }     experiment_names }",setup,652954841265455e8,206
"do_model_fit_and_test <- function(comparison, exp_name, ssize,      ta_dur, target_label, subset_df, gbm_grid, training_control,      exclude_columns) {     results <- NULL     model <- train_gbm_classifier(subset_df, training_set_fraction,          target_label, gbm_grid, training_control, exclude_columns,          verbose = FALSE)     test_data <- model$test_data     predictions <- predict(model$tunedmodel, newdata = test_data)     cm <- confusionMatrix(predictions, test_data[[target_label]])     stats <- get_parsed_binary_confusion_matrix_stats(cm)     roc <- calculate_roc_binary_classifier(model$tunedmodel,          model$test_data, target_label, exp_name)     stats$auc <- unlist(roc$auc@y.values)     stats$sample_size <- ssize     stats$ta_duration <- ta_dur     stats$elapsed <- model$elapsed     stats$experiments <- exp_name     stats$exp_group <- comparison     results$sample_size <- ssize     results$ta_duration <- ta_dur     results$cm <- cm     results$roc <- roc     results$model <- model     results$stats <- stats     results$elapsed <- model$elapsed     results }",setup,652954841265455e8,206
"log_file <- ""/mnt/experiment-ctmixtures/equifinality-5/tasampled-classification.log""",setup,652954841265455e8,206
"flog.appender(appender.file(log_file), name = ""cl"")",setup,652954841265455e8,206
"flog.info(""================ TA and Sampled Classification Analysis ================="",      name = ""cl"")",setup,652954841265455e8,206
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",setup,652954841265455e8,206
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,757027098443359e8,207
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,757027098443359e8,207
rm(list = ls()),setup,500883571570739e8,208
library(dplyr),import,500883571570739e8,208
"source(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/01_create_vessel_df.R"")",import,500883571570739e8,208
vessel_landings <- create_vessel_landings(),not sure,500883571570739e8,208
"source(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/01_vessel_stats.R"")",import,500883571570739e8,208
vessel_stats <- calc_vessel_vars(),exploratory,500883571570739e8,208
"source(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/02_port_stats.R"")",import,500883571570739e8,208
port_stats <- calc_port_df(),exploratory,500883571570739e8,208
library(openxlsx),setup,461707452544942e8,209
vessel_landings %>% dplyr::select(drvid) %>% distinct %>% summarize(n.vessels = n()),exploratory,500883571570739e8,208
"files <- list.files(""Dropbox (Cambridge University)/GammaDelta/Analysis/Clones/Txt_files/"",      full.names = TRUE)",import,461707452544942e8,209
"files.2 <- list.files(""Dropbox (Cambridge University)/GammaDelta/Analysis/Clones/Txt_files/"",      full.names = FALSE)",import,461707452544942e8,209
"for (i in seq(1, length(files), 6)) {     cur_data = list(TRD = read.table(files[i + 4], sep = ""\t"",          header = TRUE), TRG = read.table(files[i + 5], sep = ""\t"",          header = TRUE), TRA = read.table(files[i + 2], sep = ""\t"",          header = TRUE), TRB = read.table(files[i + 3], sep = ""\t"",          header = TRUE), IGH = read.table(files[i], sep = ""\t"",          header = TRUE), IGL = read.table(files[i + 1], sep = ""\t"",          header = TRUE))     file.name <- paste(unlist(strsplit(files.2[i], ""_""))[1:11],          collapse = ""_"")     write.xlsx(cur_data, file = paste(""Dropbox (Cambridge University)/GammaDelta/Analysis/Clones/Xlsx_files/"",          file.name, "".xlsx"", sep = """")) }",import,461707452544942e8,209
library(randomForest),import,461707452544942e8,209
library(caret),setup,461707452544942e8,209
library(doMC),setup,461707452544942e8,209
library(mmadsenr),setup,461707452544942e8,209
library(futile.logger),setup,461707452544942e8,209
library(dplyr),setup,461707452544942e8,209
library(ggthemes),setup,461707452544942e8,209
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""combined-tasampled-classification.log"")",setup,461707452544942e8,209
"flog.appender(appender.file(log_file), name = ""cl"")",setup,461707452544942e8,209
clargs <- commandArgs(trailingOnly = TRUE),setup,461707452544942e8,209
"if (length(clargs) == 0) {     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"") } else {     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"", args = clargs) }",import,461707452544942e8,209
load(ta_sampled_data_file),import,461707452544942e8,209
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",import,461707452544942e8,209
"flog.info(""Beginning classification analysis of equifinality-4 data sets for combined tasampled with hidden duration"",      name = ""cl"")",modeling,461707452544942e8,209
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,461707452544942e8,209
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",setup,461707452544942e8,209
registerDoMC(cores = num_cores),setup,461707452544942e8,209
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (2:10) *      50, .shrinkage = 0.05)",modeling,461707452544942e8,209
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,461707452544942e8,209
seed_value <- 58132133,setup,461707452544942e8,209
set.seed(seed_value),setup,461707452544942e8,209
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",setup,461707452544942e8,209
training_set_fraction <- 0.8,modeling,461707452544942e8,209
test_set_fraction <- 1 - training_set_fraction,modeling,461707452544942e8,209
"experiment_names <- c(""All Sample Sizes and TA Durations"")",modeling,461707452544942e8,209
combined_tassize_results <- data.frame(),modeling,461707452544942e8,209
combined_tassize_results_roc <- NULL,modeling,461707452544942e8,209
combined_tassize_results_model <- NULL,modeling,461707452544942e8,209
combined_tassize_results_cm <- NULL,modeling,461707452544942e8,209
"flog.info(""Starting analysis of combined tasampled data"", name = ""cl"")",modeling,461707452544942e8,209
i <- 1,modeling,461707452544942e8,209
exp_name <- experiment_names[i],modeling,461707452544942e8,209
"sample_rows <- createDataPartition(eq4_ta_sampled_df$model_class_label,      p = 1/8, list = FALSE)",modeling,461707452544942e8,209
"eq4_downsampled_df <- eq4_ta_sampled_df[sample_rows, ]",modeling,461707452544942e8,209
"eq4_downsampled_df$two_class_label <- factor(ifelse(eq4_downsampled_df$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",modeling,461707452544942e8,209
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"", ""ta_duration"")",modeling,461707452544942e8,209
"model <- train_gbm_classifier(eq4_downsampled_df, training_set_fraction,      ""two_class_label"", gbm_grid, training_control, exclude_columns,      verbose = FALSE)",modeling,461707452544942e8,209
"combined_tassize_results_model[[""combined_tassize""]] <- model$tunedmodel",modeling,461707452544942e8,209
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,461707452544942e8,209
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",evaluation,461707452544942e8,209
results <- get_parsed_binary_confusion_matrix_stats(cm),evaluation,461707452544942e8,209
results$experiments <- exp_name,evaluation,461707452544942e8,209
results$elapsed <- model$elapsed,evaluation,461707452544942e8,209
"combined_tassize_results_cm[[""combined_tassize""]] <- cm",evaluation,461707452544942e8,209
results$sample_size <- 0,evaluation,461707452544942e8,209
results$ta_duration <- 0,evaluation,461707452544942e8,209
"combined_tassize_roc <- calculate_roc_binary_classifier(model$tunedmodel,      model$test_data, ""two_class_label"", ""Combined Sample Sizes and Durations"")",evaluation,461707452544942e8,209
results$auc <- unlist(combined_tassize_roc$auc@y.values),evaluation,461707452544942e8,209
"combined_tassize_results_roc[[""combined_tassize""]] <- combined_tassize_roc",evaluation,461707452544942e8,209
"combined_tassize_results <- rbind(combined_tassize_results, results)",evaluation,461707452544942e8,209
require(rstanarm),setup,219358000671491e8,1
options(mc.cores = parallel::detectCores()),setup,219358000671491e8,1
"load(""analysis/rdata-tmp/britdat.RData"")",import,219358000671491e8,1
"britdat$era2 <- cut(britdat$year, breaks = c(700, 1100, 1450,      1750, 2000), labels = c(""Old English"", ""Middle English"",      ""Early Modern English"", ""Late Modern English""))",data cleaning,219358000671491e8,1
britdat$isIOPro <- factor(britdat$IO),data cleaning,219358000671491e8,1
"levels(britdat$isIOPro) <- c(0, 1)",data cleaning,219358000671491e8,1
britdat$isDOPro <- factor(britdat$DO),data cleaning,219358000671491e8,1
"levels(britdat$isDOPro) <- c(0, 1)",data cleaning,219358000671491e8,1
britdat$isDOPro <- as.numeric(as.character(britdat$isDOPro)),data cleaning,219358000671491e8,1
"britdat2 <- subset(britdat, !is.na(isDatAcc) & NVerb != ""NONREC"" &      NVerb != ""SEND"" & era >= 1200)",data cleaning,219358000671491e8,1
britdat2$isPas <- factor(britdat2$Voice),data cleaning,219358000671491e8,1
"levels(britdat2$isPas) <- c(0, 1)",data cleaning,219358000671491e8,1
britdat2$isPas <- as.numeric(as.character(britdat2$isPas)),data cleaning,219358000671491e8,1
britdat2$Order <- factor(britdat2$isDatAcc),data cleaning,219358000671491e8,1
"levels(britdat2$Order) <- c(""Theme-Recipient"", ""Recipient-Theme"")",data cleaning,219358000671491e8,1
"pas <- read.csv(""analysis/data/pas.dat"", sep = ""\t"")",data cleaning,219358000671491e8,1
pas$isPas <- factor(pas$Voice),import,219358000671491e8,1
"levels(pas$isPas) <- c(0, NA, 1, NA)",data cleaning,219358000671491e8,1
pas$isPas <- as.numeric(as.character(pas$isPas)),data cleaning,219358000671491e8,1
"pas <- subset(pas, !is.na(isPas))",data cleaning,219358000671491e8,1
"bdat <- data.frame(year = britdat2$year, Order = britdat2$Order,      isPas = britdat2$isPas)",data cleaning,219358000671491e8,1
"pasdat <- data.frame(year = as.numeric(as.character(pas$YoC)),      Order = ""General"", isPas = pas$isPas)",data cleaning,219358000671491e8,1
"joint <- subset(as.data.frame(rbind(bdat, pasdat)), year >= 1200)",data cleaning,219358000671491e8,1
joint$zYear <- (joint$year - mean(joint$year))/sd(joint$year),data cleaning,219358000671491e8,1
joint$isRT <- factor(joint$Order),data cleaning,219358000671491e8,1
"levels(joint$isRT) <- c(0, 1, 0)",data cleaning,219358000671491e8,1
joint$isRT <- as.numeric(as.character(joint$isRT)),data cleaning,219358000671491e8,1
joint$isTR <- factor(joint$Order),data cleaning,219358000671491e8,1
"levels(joint$isTR) <- c(1, 0, 0)",data cleaning,219358000671491e8,1
joint$isTR <- as.numeric(as.character(joint$isTR)),data cleaning,219358000671491e8,1
"small <- subset(joint, Order != ""General"")",data cleaning,219358000671491e8,1
"param <- read.csv(""analysis/parameters/parameters.csv"")",data cleaning,219358000671491e8,1
"if (param$prior_dist == ""cauchy"") {     pasmod <- stan_glm(isPas ~ zYear * isTR, data = small, family = binomial(link = ""logit""),          prior = cauchy(location = 0, scale = param$prior_sd),          prior_intercept = cauchy(location = 0, scale = param$prior_sd),          iter = param$iters, chains = param$nchains, seed = param$seed) } else if (param$prior_dist == ""normal"") {     pasmod <- stan_glm(isPas ~ zYear * isTR, data = small, family = binomial(link = ""logit""),          prior = normal(location = 0, scale = param$prior_sd),          prior_intercept = normal(location = 0, scale = param$prior_sd),          iter = param$iters, chains = param$nchains, seed = param$seed) }",import,219358000671491e8,1
"saveRDS(pasmod, file = ""analysis/mcmc-runs/pas.RDS"")",modeling,219358000671491e8,1
"saveRDS(pasmod, file = ""analysis/mcmc-runs/pas.RDS"")",export,219358000671491e8,1
require(rstanarm),setup,219358000671491e8,1
library(tidyverse),setup,219358000671491e8,1
library(circular),setup,219358000671491e8,1
library(cowplot),setup,219358000671491e8,1
library(PropCIs),setup,219358000671491e8,1
library(R.utils),setup,219358000671491e8,1
"sourceDirectory(""R"")",setup,219358000671491e8,1
"source(""analysis/graphical_parameters.R"")",setup,219358000671491e8,1
"datpha <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = ""phase"",      session = as.character(1:4))",import,219358000671491e8,1
"datpha$participant <- datpha$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,219358000671491e8,1
"datpha <- datpha %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,219358000671491e8,1
"avpha <- datpha %>% group_by(participant, freq) %>% summarise(n = n(),      k = sum(response)) %>% group_by(participant, freq) %>% do({     m <- .$k/.$n     ci <- exactci(.$k, .$n, 0.05)$conf.int     data.frame(m = m, inf = ci[1], sup = ci[2]) })",modeling,219358000671491e8,1
"dattrack <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = c(""tracking""),      session = as.character(1:4))",import,219358000671491e8,1
"dattrack$participant <- dattrack$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,219358000671491e8,1
"Make.trim.mofo <- function(fn) {     stopifnot(file.exists(fn))     df <- read.csv(fn)     df$db.session <- substr(fn, 1:5)     df$db.participant.id <- substr(fn, 7:10)     drops <- c(""iSess"", """")     df <- df[, 2] }",import,141408019000664e8,210
"fl <- list.files(""analysis/data/csv-bysession"", pattern = ""\\.csv$"",      full.names = TRUE)",not sure,141408019000664e8,210
"if (is.null(fl)) {     stop(""No files in file list."") }",data cleaning,141408019000664e8,210
"dfl <- lapply(fl, Make.trim.mofo)",data cleaning,141408019000664e8,210
"setwd(""C:/Documents and Settings/mcolvin/My Documents/projects/"")",setup,691405900521204e8,211
"source(""./src/1_global.R"")",setup,691405900521204e8,211
"source(""./src/2_functions.R"")",setup,691405900521204e8,211
"source(""./src/3_load.R"")",setup,691405900521204e8,211
"source(""./src/4_clean.R"")",setup,691405900521204e8,211
"source(""./src/5_tables.R"")",setup,691405900521204e8,211
"source(""./src/6_figures.R"")",setup,691405900521204e8,211
"source(""./src/7_analysis.R"")",setup,691405900521204e8,211
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",communication,691405900521204e8,211
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,935717977583408e8,212
library(caret),setup,691405900521204e8,211
library(doMC),setup,691405900521204e8,211
library(mmadsenr),setup,691405900521204e8,211
library(futile.logger),setup,691405900521204e8,211
library(dplyr),setup,691405900521204e8,211
library(ggthemes),setup,691405900521204e8,211
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",data cleaning,691405900521204e8,211
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""tasampled-classification.log"")",export,691405900521204e8,211
"flog.appender(appender.file(log_file), name = ""cl"")",export,691405900521204e8,211
clargs <- commandArgs(trailingOnly = TRUE),import,691405900521204e8,211
"if (length(clargs) == 0) {     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"") } else {     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"", args = clargs) }",import,691405900521204e8,211
load(ta_sampled_data_file),import,691405900521204e8,211
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",export,691405900521204e8,211
"flog.info(""Beginning classification analysis of TA sampled equifinality-4 data sets using per-locus predictors only"",      name = ""cl"")",export,691405900521204e8,211
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,691405900521204e8,211
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",export,691405900521204e8,211
registerDoMC(cores = num_cores),setup,691405900521204e8,211
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (2:10) *      50, .shrinkage = 0.05)",data cleaning,691405900521204e8,211
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,691405900521204e8,211
seed_value <- 58132133,setup,691405900521204e8,211
set.seed(seed_value),setup,691405900521204e8,211
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",export,691405900521204e8,211
training_set_fraction <- 0.8,modeling,691405900521204e8,211
test_set_fraction <- 1 - training_set_fraction,modeling,691405900521204e8,211
"eq4_ta_sampled_df$two_class_label <- factor(ifelse(eq4_ta_sampled_df$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",data cleaning,691405900521204e8,211
sample_sizes <- unique(eq4_ta_sampled_df$sample_size),not sure,691405900521204e8,211
ta_durations <- unique(eq4_ta_sampled_df$ta_dur),not sure,691405900521204e8,211
"tassize_subsets <- expand.grid(sample_size = sample_sizes, ta_duration = ta_durations)",data cleaning,691405900521204e8,211
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"", ""configuration_slatkin"", ""num_trait_configurations"",      ""sample_size"", ""ta_duration"")",data cleaning,691405900521204e8,211
experiment_names <- character(nrow(tassize_subsets)),data cleaning,691405900521204e8,211
"for (i in 1:nrow(tassize_subsets)) {     experiment_names[i] <- paste(""Per-Locus Sample Size: "", tassize_subsets[i,          ""sample_size""], "" Duration: "", tassize_subsets[i, ""ta_duration""]) }",export,691405900521204e8,211
"analysis.dir = ""./RnBeads/analysis""",setup,974827901693061e8,213
"report.dir = file.path(analysis.dir, ""GetDMRs_9comps_July19_2016"")",setup,974827901693061e8,213
"if (!exists(x = ""my.dmr.list"")) {     my.dmr.list <- readRDS(file = paste(report.dir, ""/my.annots.final"",          sep = """"))     print(""loading annotations"") } else {     if (exists(""my.final.annots"")) {         my.dmr.list <- my.final.annots     } }",import,974827901693061e8,213
rankThreshold = 1000,not sure,974827901693061e8,213
comps <- names(my.dmr.list),data cleaning,974827901693061e8,213
regions <- names(my.dmr.list$EBM.EGM),data cleaning,974827901693061e8,213
for (cmp in comps) {     for (rg in regions) {         my.dmr.list[[cmp]][[rg]]$Chromosome         my.dmr.list[[cmp]][[rg]]$Start         my.dmr.list[[cmp]][[rg]]$End     } },exploratory,974827901693061e8,213
library(here),setup,33058297005482e9,214
library(tidyverse),setup,33058297005482e9,214
"list.of.packages <- c(""batchtools"", ""dbscan"", ""ggplot2"", ""microbenchmark"",      ""parallel"", ""reshape2"", ""Rlof"", ""stream"", ""streamgenerator"",      ""tictoc"")",setup,995324636343867e8,215
"new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,      ""Package""])]",setup,995324636343867e8,215
if (length(new.packages)) install.packages(new.packages),setup,995324636343867e8,215
"lapply(list.of.packages, require, character.only = T)",setup,995324636343867e8,215
"plot.all.wp <- function(wp.group = ""P1"", fn = ""analysis/data/wallpapers-on-databrary.csv"") {     source(""analysis/load.wp.R"")     source(""analysis/plot.wp.R"")     cat(""Downloading wallpapers from Databrary"")     wpl <- lapply(as.list(1:20), load.wp, wp.group, fn)     r1 <- cbind(wpl[[1]], wpl[[2]], wpl[[3]], wpl[[4]], wpl[[5]])     r2 <- cbind(wpl[[6]], wpl[[7]], wpl[[8]], wpl[[9]], wpl[[10]])     r3 <- cbind(wpl[[11]], wpl[[12]], wpl[[13]], wpl[[14]], wpl[[15]])     r4 <- cbind(wpl[[16]], wpl[[17]], wpl[[18]], wpl[[19]], wpl[[20]])     cat(""Plotting exemplars in 4 x 5 array"")     m <- rbind(r1, r2, r3, r4)     plot.wp(m, asp.ratio = 4/5) }",visualization,730216740863398e8,216
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,347332875244319e8,217
library(scater),setup,347332875244319e8,217
library(limma),not sure,347332875244319e8,217
library(edgeR),not sure,347332875244319e8,217
library(readr),import,347332875244319e8,217
library(aargh),not sure,347332875244319e8,217
library(magrittr),not sure,347332875244319e8,217
library(dplyr),data cleaning,347332875244319e8,217
"dex_analysis <- function(input_sceset = ""sce.rds"", pseudotime_file = ""pseudotime.csv"",      output_file = ""qvals.csv"") {     interaction_qval <- NULL     sce <- readRDS(input_sceset)     pseudotime_df <- read_csv(pseudotime_file)     if (all(is.na(pseudotime_df$pst))) {         interaction_qval <- rep(NA, nrow(sce))     }     else {         pseudotime <- scale(pseudotime_df$pst)[, 1]         cells_non_na <- which(!is.na(pseudotime))         dmat <- dplyr::select(pData(sce), x) %>% dplyr::mutate(pseudotime)         design <- model.matrix(~x + pseudotime + x:pseudotime,              data = dmat[cells_non_na, ])         dge <- DGEList(counts = counts(sce[, cells_non_na]))         v <- voom(dge, design, plot = FALSE)         fit <- lmFit(v, design)         fit <- eBayes(fit)         interaction_pval <- fit$p.value[, ""x:pseudotime""]         interaction_qval <- p.adjust(interaction_pval, method = ""BH"")     }     output_data_frame <- data_frame(qval = interaction_qval)     write_csv(output_data_frame, output_file) }",modeling,347332875244319e8,217
aargh(dex_analysis),not sure,347332875244319e8,217
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,461669454583898e8,218
library(magrittr),import,461669454583898e8,218
library(plyr),import,461669454583898e8,218
library(dplyr),import,461669454583898e8,218
library(ggplot2),import,461669454583898e8,218
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",import,461669454583898e8,218
"record = read.csv(""Analysis/Parsed Data/pilots_production.csv"")",not sure,461669454583898e8,218
"write_bib(""devtools"")",not sure,535819598706439e8,219
"sink(""analysis/materialforpaper/test.bib"")",not sure,535819598706439e8,219
knitr::write_bib(),communication,535819598706439e8,219
"knitr::write_bib(""devtools"")",communication,535819598706439e8,219
sink(),not sure,535819598706439e8,219
"sink(""analysis/materialforpaper/projectmetadata.tex"")",not sure,535819598706439e8,219
temp = t(Projects_metadata),not sure,535819598706439e8,219
temp = as.data.frame(temp),data cleaning,535819598706439e8,219
library(readr),setup,259833797579631e8,220
"demog <- read_csv(""~/Project/Template2/analysis/data/raw/demog.csv"",      col_types = cols(GENDER = col_factor(levels = c(""M"", ""F"")),          GROUP = col_factor(levels = c(""A"", ""B"", ""C"", ""D""))))",import,259833797579631e8,220
"covariance <- read_csv(""~/Project/Template2/analysis/data/raw/covariance.csv"",      col_types = cols(GROUP = col_factor(levels = c(""A"", ""B"",          ""C"", ""D""))))",import,259833797579631e8,220
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval.Robj"")",import,259833797579631e8,220
pval.null.ms = as.numeric(pval_list),data cleaning,259833797579631e8,220
done.null.ms = done_res,not sure,259833797579631e8,220
sum(done.null.ms),exploratory,259833797579631e8,220
"max(pval.null.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
"min(pval.null.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval.Robj"")",import,259833797579631e8,220
pval.alt.ms = as.numeric(pval_list),data cleaning,259833797579631e8,220
done.alt.ms = done_res,not sure,259833797579631e8,220
sum(done.alt.ms),exploratory,259833797579631e8,220
"max(pval.alt.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
"min(pval.alt.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
library(dplyr),setup,661780807189643e8,221
library(maps),setup,661780807189643e8,221
library(scales),setup,661780807189643e8,221
library(ggplot2),setup,661780807189643e8,221
"load(""processedData/spatial/2_coastline.Rdata"")",import,661780807189643e8,221
"delIX = c(305, 368, 451, 464)",import,259833797579631e8,220
pval.null.ms = pval.null.ms[-delIX],not sure,259833797579631e8,220
pval.alt.ms = pval.alt.ms[-delIX],not sure,259833797579631e8,220
"tickets <- readRDS(""processedData/catch/1_cleaningData/tickets.RDS"")",import,661780807189643e8,221
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",data cleaning,259833797579631e8,220
"disc.ms = c(rep(0, 574), rep(1, 574))",not sure,259833797579631e8,220
rnk.ms = order(pval.ms),data cleaning,259833797579631e8,220
p.ms = pval.ms[rnk.ms],data cleaning,259833797579631e8,220
d.ms = disc.ms[rnk.ms],data cleaning,259833797579631e8,220
fdp.ms = NULL,data cleaning,259833797579631e8,220
sig.ms = NULL,data cleaning,259833797579631e8,220
tpr.ms = NULL,data cleaning,259833797579631e8,220
fpr.ms = NULL,data cleaning,259833797579631e8,220
uni.p.ms = unique(p.ms),not sure,259833797579631e8,220
for (i in 1:length(uni.p.ms)) {     wh = which(p.ms <= uni.p.ms[i])     sig.ms[i] = length(wh)     fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh))     tpr.ms[i] = sum(d.ms[wh])/574     fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/574 },exploratory,259833797579631e8,220
given.FDR = 0.05,data cleaning,259833797579631e8,220
posi = max(which(fdp.ms <= given.FDR)),data cleaning,259833797579631e8,220
tpr.ms[posi],data cleaning,259833797579631e8,220
fdp.ms[posi],data cleaning,259833797579631e8,220
fpr.ms.1000 = fpr.ms,data cleaning,259833797579631e8,220
tpr.ms.1000 = tpr.ms,data cleaning,259833797579631e8,220
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",data cleaning,259833797579631e8,220
"disc.ms = c(rep(0, 574), rep(1, 574))",data cleaning,259833797579631e8,220
rank.ms = rank(pval.ms),exploratory,259833797579631e8,220
rank.ms.1000 = rank.ms,data cleaning,259833797579631e8,220
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum_10000/pval.Robj"")",import,259833797579631e8,220
pval.null.ms = as.numeric(pval_list),data cleaning,259833797579631e8,220
done.null.ms = done_res,data cleaning,259833797579631e8,220
sum(done.null.ms),data cleaning,259833797579631e8,220
"max(pval.null.ms, na.rm = TRUE)",data cleaning,259833797579631e8,220
"min(pval.null.ms, na.rm = TRUE)",data cleaning,259833797579631e8,220
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum_10000/pval.Robj"")",import,259833797579631e8,220
pval.alt.ms = as.numeric(pval_list),data cleaning,259833797579631e8,220
done.alt.ms = done_res,data cleaning,259833797579631e8,220
sum(done.alt.ms),exploratory,259833797579631e8,220
"max(pval.alt.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
"min(pval.alt.ms, na.rm = TRUE)",exploratory,259833797579631e8,220
"delIX = c(305, 368, 451, 464)",data cleaning,259833797579631e8,220
pval.null.ms = pval.null.ms[-delIX],data cleaning,259833797579631e8,220
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",data cleaning,259833797579631e8,220
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,816374628338963e8,222
library(ggplot2),import,816374628338963e8,222
library(plyr),import,816374628338963e8,222
library(stringr),import,816374628338963e8,222
library(reshape2),import,816374628338963e8,222
library(grid),import,816374628338963e8,222
library(gridExtra),import,816374628338963e8,222
"source(""powerAnalysis/lib.R"")",import,816374628338963e8,222
library(lme4),import,846664256649092e8,223
"source(""R/GoogleSpreadsheets.R"")",import,846664256649092e8,223
"source(""R/DataFormat.R"")",setup,846664256649092e8,223
"source(""R/SensitivityAnalysis.R"")",setup,846664256649092e8,223
"if (!dir.exists(""Figures"")) {     dir.create(""Figures"") }",evaluation,846664256649092e8,223
"figure_out <- ""Figures""",export,846664256649092e8,223
"load(""Models/FinalDensityModel.rda"")",import,846664256649092e8,223
"load(""Models/FinalRichnessModel.rda"")",import,846664256649092e8,223
"garden <- read.csv(""data/Wildlife Garden - data collection - Sheet1.csv"")",import,846664256649092e8,223
garden <- prepareGS(garden),import,846664256649092e8,223
"SA_scaled <- Sensitivity_Analysis(density3, reps = 1000, scale.area = TRUE,      pointsize = 11)",import,846664256649092e8,223
"pdf(file.path(figure_out, ""SensitivityAnalysis_scaled.pdf""))",export,846664256649092e8,223
"hist(SA_scaled, xlab = ""% Change"", main = """", cex.lab = 1.2)",exploratory,846664256649092e8,223
abline(v = 0),visualization,846664256649092e8,223
dev.off(),setup,846664256649092e8,223
sum(SA_scaled < 0)/1000 * 100,exploratory,846664256649092e8,223
"SA_notscaled <- Sensitivity_Analysis(density3, reps = 1000, scale.area = FALSE)",modeling,846664256649092e8,223
sum(SA_notscaled < 0)/1000 * 100,evaluation,846664256649092e8,223
"SA_richness <- Sensitivity_Analysis(richness2, reps = 1000, scale.area = FALSE)",modeling,846664256649092e8,223
sum(SA_richness < 0)/1000 * 100,communication,846664256649092e8,223
library(plyr),setup,592246771324426e8,224
"pdf(file.path(figure_out, ""SensitivityAnalysis_notscaled.pdf""),      width = 8)",export,846664256649092e8,223
library(stringr),setup,592246771324426e8,224
library(reshape2),import,592246771324426e8,224
library(Rcpp),import,592246771324426e8,224
library(RcppCNPy),import,592246771324426e8,224
"par(mfrow = c(1, 2))",exploratory,846664256649092e8,223
"par(mar = c(4, 4, 2, 0))",exploratory,846664256649092e8,223
"source(""powerAnalysis/lib.R"")",import,592246771324426e8,224
"hist(SA_notscaled, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200), breaks = 20)",visualization,846664256649092e8,223
"sourceCpp(""reproducibility/lib.cpp"")",import,592246771324426e8,224
"mtext(""(a)"", side = 3, line = 0, at = 0)",visualization,846664256649092e8,223
"kRegionPath <- ""powerAnalysis/data/simChrom_regions.txt""",not sure,592246771324426e8,224
"kCoefPath <- ""powerAnalysis/data/simChrom_b.npy""",not sure,592246771324426e8,224
"hist(SA_richness, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200))",visualization,846664256649092e8,223
"mtext(""(b)"", side = 3, line = 0, at = 0)",visualization,846664256649092e8,223
kGeneLength <- 3501,setup,592246771324426e8,224
kPromoterLength <- 1000,communication,592246771324426e8,224
"kGroundtruthPath <- ""powerAnalysis/data/simChrom_groundtruth.txt""",communication,592246771324426e8,224
kReplicates <- 1:10,setup,592246771324426e8,224
kClusterWidth <- 147,setup,592246771324426e8,224
kStructureAdj <- 0,setup,592246771324426e8,224
kQuantileSparsity <- 0.9,setup,592246771324426e8,224
"mtext(""Frequency"", side = 2, outer = TRUE, line = -1.5, las = 0,      at = 0.55)",visualization,846664256649092e8,223
"kOutputPath <- ""powerAnalysis/output_cluster_summaries_groundtruth.RData""",setup,592246771324426e8,224
"mtext(""% Change"", side = 1, outer = TRUE, line = -1.5, las = 0)",visualization,846664256649092e8,223
b.matrix <- npyLoad(kCoefPath),modeling,592246771324426e8,224
groundtruth <- read.csv(kGroundtruthPath),import,592246771324426e8,224
dev.off(),setup,846664256649092e8,223
groundtruth$rep <- groundtruth$rep + 1,data cleaning,592246771324426e8,224
"groundtruth <- groundtruth[order(groundtruth$rep, groundtruth$pos),      ]",data cleaning,592246771324426e8,224
"primaries <- groundtruth[groundtruth$type == 0, ]",data cleaning,592246771324426e8,224
"clusters <- primaries[, c(""rep"", ""pos"", ""coverage"", ""eff.magnitude"",      ""magnitude"", ""offset"")]",data cleaning,592246771324426e8,224
"source(""../../../RASPathwaySig/bin/cBioPortalData.R"")",setup,846664256649092e8,223
"names(clusters)[2] <- colnames(clusters)[2] <- ""center""",data cleaning,592246771324426e8,224
"clusters <- clusters[order(clusters$rep, clusters$center), ]",data cleaning,592246771324426e8,224
stat.list <- list(),setup,592246771324426e8,224
"ccle.mat <- getCcleExpressionData("""", getZscores = TRUE)",import,846664256649092e8,223
"for (replicate in unique(clusters$rep)) {     subset.clusters.replicate <- which(clusters$rep == replicate)     stat.list[[replicate]] <- ComputeClusterIndices(clusters$center[subset.clusters.replicate],          b[replicate, ], w = as.integer(kClusterWidth%/%2), adj = kStructureAdj,          q = kQuantileSparsity)     stat.list[[replicate]]$rep <- replicate }",modeling,592246771324426e8,224
"clusters <- join(clusters, Reduce(rbind, stat.list), type = ""left"")",data cleaning,592246771324426e8,224
"save(clusters, file = kOutputPath)",export,592246771324426e8,224
"all.tiss <- unique(sapply(colnames(ccle.mat), function(x) paste(unlist(strsplit(x,      split = ""_""))[-1], collapse = ""_"")))",data cleaning,846664256649092e8,223
"ccle.tiss.averages <- sapply(all.tiss, function(x) {     cols = grep(x, colnames(ccle.mat))     if (length(cols) > 1)          return(rowMeans(ccle.mat[, cols], na.rm = T))     else return(ccle.mat[, cols]) })",evaluation,846664256649092e8,223
require(synapseClient),setup,846664256649092e8,223
synapseLogin(),setup,846664256649092e8,223
"tpm.vals <- read.table(synGet(""syn5580347"")@filePath, sep = ""\t"",      header = T)",import,846664256649092e8,223
"genes <- unique(sapply(rownames(tpm.vals), function(x) unlist(strsplit(x,      split = ""."", fixed = T))[1]))",data cleaning,846664256649092e8,223
"per.gene.vals <- t(sapply(genes, function(x) {     vals <- grep(paste(x, ""."", sep = """"), rownames(tpm.vals),          fixed = T)     if (length(vals) > 1)          return(colSums(tpm.vals[vals, ], na.rm = T))     else return(tpm.vals[vals, ]) }))",evaluation,846664256649092e8,223
"zscore <- function(x) {     x <- unlist(x)     (x - mean(x, na.rm = T))/sd(x) }",modeling,846664256649092e8,223
"z.score.gene <- apply(per.gene.vals, 2, zscore)",modeling,846664256649092e8,223
"cell.line.names <- synTableQuery(""SELECT \""Sample Name\"",\""RNA-Seq Data (Gencode)\"" FROM syn5014742 where \""RNA-Seq Data (Gencode)\"" is not NULL"")@values",import,846664256649092e8,223
"idx <- match(colnames(z.score.gene), cell.line.names$`RNA-Seq Data (Gencode)`)",import,846664256649092e8,223
colnames(z.score.gene) <- cell.line.names$`Sample Name`[idx],import,846664256649092e8,223
"comm.genes <- intersect(rownames(ccle.tiss.averages), rownames(z.score.gene))",import,846664256649092e8,223
library(pheatmap),import,846664256649092e8,223
"cmat <- cbind(z.score.gene[comm.genes, ], ccle.tiss.averages[comm.genes,      ])",data cleaning,846664256649092e8,223
"pdf(""ccle_pnf_dendrogram.pdf"")",export,846664256649092e8,223
"plot(hclust(dist(t(cmat))), main = ""CCLE Cell lines with pNF cell lines"")",visualization,846664256649092e8,223
dev.off(),setup,846664256649092e8,223
"synStore(File(""ccle_pnf_dendrogram.pdf"", parentId = ""syn5594111""),      executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2016-08-12/clusterCellLinesByExpression.R"")),      used = list(list(entity = ""syn5580347"")))",import,846664256649092e8,223
"pdf(""ccle_pnf_cor_dendrogram.pdf"")",export,846664256649092e8,223
"plot(hclust(as.dist(1 - cor(cmat, use = ""pairwise.complete.obs""))),      main = ""CCLE Cell lines with pNF cell lines"")",visualization,846664256649092e8,223
dev.off(),setup,846664256649092e8,223
"synStore(File(""ccle_pnf_dendrogram.pdf"", parentId = ""syn5594111""),      executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2016-08-12/clusterCellLinesByExpression.R"")),      used = list(list(entity = ""syn5580347"")))",communication,846664256649092e8,223
"synStore(File(""ccle_pnf_cor_dendrogram.pdf"", parentId = ""syn5594111""),      executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2016-08-12/clusterCellLinesByExpression.R"")),      used = list(list(entity = ""syn5580347"")))",communication,846664256649092e8,223
"create_analyses_list = function(path) {     files = list.files(path, full.names = T, include.dirs = F)     timeAnalyses = list()     for (file in files) {         print(file)         analysis = TimeAnalysis$new(file)         timeAnalyses[[analysis$name]] = analysis     }     if (!dir.exists(""Computed""))          dir.create(""Computed"")     save(timeAnalyses, file = ""Computed/timeAnalyses.RData"")     return(timeAnalyses) }",exploratory,7036748228129e10,225
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,383625529706478e8,226
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,558044002391398e8,227
rm(list = ls()),setup,7036748228129e10,225
"library(""plyr"")",exploratory,383625529706478e8,226
"setwd(""/home/I864741/TCC/Analysis/"")",setup,383625529706478e8,226
"source(""./R/helper/00_helper_lib_load.R"")",setup,7036748228129e10,225
"hgcn.nomenclature <- read.delim(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/HGCN_completeSet.txt"",      stringsAsFactors = FALSE)",export,383625529706478e8,226
"source(""./R/helper/00_helper_model_fcts.R"")",not sure,7036748228129e10,225
genename.map <- NULL,not sure,383625529706478e8,226
"source(""./R/helper/00_helper_simulation_data.R"")",import,7036748228129e10,225
"source(""./R/helper/99_helper_diagnostics.R"")",exploratory,7036748228129e10,225
names <- NULL,not sure,383625529706478e8,226
"source(""./R/helper/01_helper_cBPF_as.R"")",evaluation,7036748228129e10,225
"for (ii in 1:dim(hgcn.nomenclature)[1]) {     temp <- hgcn.nomenclature[ii, ""alias_symbol""]     if (temp != """") {         x <- unlist(strsplit(temp, ""\\|""))         names <- c(names, x)         genename.map <- c(genename.map, rep(hgcn.nomenclature[ii,              ""symbol""], length(x)))     }     names <- c(names, hgcn.nomenclature[ii, ""symbol""])     genename.map <- c(genename.map, hgcn.nomenclature[ii, ""symbol""])     temp <- hgcn.nomenclature[ii, ""prev_symbol""]     if (temp != """") {         x <- unlist(strsplit(temp, ""\\|""))         names <- c(names, x)         genename.map <- c(genename.map, rep(hgcn.nomenclature[ii,              ""symbol""], length(x)))     } }",not sure,383625529706478e8,226
names(genename.map) <- names,not sure,383625529706478e8,226
"manualfix <- read.csv(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/HGCN_symbols_included.csv"",      stringsAsFactors = FALSE, header = FALSE)",import,383625529706478e8,226
"names <- manualfix[, 1]",data cleaning,383625529706478e8,226
"temp <- manualfix[, 2]",modeling,383625529706478e8,226
"library(""dplyr"")",setup,385310970945284e8,228
"library(""cqn"")",setup,385310970945284e8,228
names(temp) <- names,import,383625529706478e8,226
"library(""readr"")",setup,385310970945284e8,228
"library(""devtools"")",setup,385310970945284e8,228
"library(""SummarizedExperiment"")",setup,385310970945284e8,228
"load_all(""../seqUtils/"")",import,385310970945284e8,228
"genename.map <- c(genename.map, temp)",not sure,383625529706478e8,226
"load_all(""analysis/housekeeping/"")",import,385310970945284e8,228
"standardizeGeneSymbols <- function(geneList, mapFunction, uppercase = FALSE) {     if (uppercase) {         geneList <- toupper(geneList)     }     temp <- mapFunction[as.character(geneList)]     temp <- as.character(temp)     return(temp) }",not sure,383625529706478e8,226
"sample_names = read.table(""analysis/data/sample_lists/acLDL_names_all.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = FALSE)[,      1]",import,385310970945284e8,228
"design_matrix = constructDesignMatrix_acLDL(sample_names) %>%      dplyr::filter(!(donor %in% c(""mijn"", ""xegx""))) %>% dplyr::arrange(donor,      condition) %>% dplyr::filter(!(condition %in% c(""LAL"", ""LAL_AcLDL"")))",setup,385310970945284e8,228
"count_matrix = loadCounts(""processed/acLDL/featureCounts/"", design_matrix$sample_id,      sub_dir = FALSE, counts_suffix = "".featureCounts.txt"")",import,385310970945284e8,228
"transcript_data = tbl_df(readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.transcript_data.rds"")) %>%      dplyr::rename(gene_id = ensembl_gene_id, transcript_id = ensembl_transcript_id,          gene_name = external_gene_name, chr = chromosome_name)",import,385310970945284e8,228
"valid_chromosomes = c(""1"", ""10"", ""11"", ""12"", ""13"", ""14"", ""15"",      ""16"", ""17"", ""18"", ""19"", ""2"", ""20"", ""21"", ""22"", ""3"", ""4"",      ""5"", ""6"", ""7"", ""8"", ""9"", ""MT"", ""X"", ""Y"")",setup,385310970945284e8,228
"valid_gene_biotypes = c(""lincRNA"", ""protein_coding"", ""IG_C_gene"",      ""IG_D_gene"", ""IG_J_gene"", ""IG_V_gene"", ""TR_C_gene"", ""TR_D_gene"",      ""TR_J_gene"", ""TR_V_gene"", ""3prime_overlapping_ncrna"", ""known_ncrna"",      ""processed_transcript"", ""antisense"", ""sense_intronic"", ""sense_overlapping"")",setup,385310970945284e8,228
"filtered_tx_data = dplyr::filter(transcript_data, gene_biotype %in%      valid_gene_biotypes, chr %in% valid_chromosomes)",setup,385310970945284e8,228
"length_df = dplyr::select(count_matrix, gene_id, length)",setup,385310970945284e8,228
"gene_metadata = filtered_tx_data %>% dplyr::group_by(gene_id) %>%      dplyr::mutate(start = min(transcript_start), end = max(transcript_end)) %>%      dplyr::select(gene_id, gene_biotype, chr, start, end, gene_name,          strand, percentage_gc_content) %>% dplyr::left_join(length_df,      by = ""gene_id"") %>% unique() %>% dplyr::ungroup() %>% as.data.frame()",setup,385310970945284e8,228
rownames(gene_metadata) = gene_metadata$gene_id,setup,385310970945284e8,228
"filtered_data = dplyr::filter(count_matrix, gene_id %in% gene_metadata$gene_id)",setup,385310970945284e8,228
"counts = dplyr::select(filtered_data, -gene_id, -length)",setup,385310970945284e8,228
rownames(counts) = filtered_data$gene_id,setup,385310970945284e8,228
"counts = counts[gene_metadata$gene_id, ]",setup,385310970945284e8,228
"cqn_matrix = calculateCQN(counts, gene_metadata)",setup,385310970945284e8,228
"sample_metadata = readRDS(""analysis/data/covariates/compiled_acLDL_metadata.rds"")",import,385310970945284e8,228
library(plyr),setup,107703006127849e8,229
library(ggplot2),setup,107703006127849e8,229
library(stringr),setup,107703006127849e8,229
library(reshape2),setup,107703006127849e8,229
library(yaml),setup,107703006127849e8,229
"source(""powerAnalysis/lib.R"")",setup,107703006127849e8,229
"kConfigPath <- ""powerAnalysis/powerAnalysis.yml""",setup,107703006127849e8,229
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,898155648028478e8,230
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,898155648028478e8,230
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,898155648028478e8,230
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,898155648028478e8,230
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,898155648028478e8,230
country_table <- as.data.frame(table(opt_loc$country)),import,898155648028478e8,230
"country_names <- paste(country_table[country_table$Freq != 0,      ""Var1""])",setup,898155648028478e8,230
national_zeta <- data.frame(),setup,898155648028478e8,230
i = 1,setup,898155648028478e8,230
"source(""analysis/utils.R"")",setup,335329463239759e8,231
"for (country in country_names) {     df <- opt_loc[opt_loc$country == country, ]     if (!is.na(df[1, ""zeta""])) {         national_zeta[i, ""country""] <- country         national_zeta[i, ""zeta""] <- ((sum(df$pop * df$util_opt)/sum(df$pop *              df$util_stat)) - 1) * 100         i = i + 1     } }",evaluation,898155648028478e8,230
"source(""analysis/analysis.R"")",import,335329463239759e8,231
library(dplyr),import,335329463239759e8,231
library(knitr),import,335329463239759e8,231
library(urca),setup,406685028923675e8,232
library(vars),setup,406685028923675e8,232
"source(""data-raw/fetch-raw-data.R"")",import,406685028923675e8,232
adf <- list(),setup,406685028923675e8,232
"adf[[1]] <- ur.df(CZ2016, type = ""drift"", lags = 5)",modeling,406685028923675e8,232
"adf[[2]] <- ur.df(SX2016, type = ""drift"", lags = 5)",modeling,406685028923675e8,232
"jct <- ca.jo(cbind(CZ2016, SX2016), type = ""eigen"", K = 5)",modeling,406685028923675e8,232
"lag_selection <- VARselect(cbind(CZ2016, SX2016), lag.max = 8)",modeling,406685028923675e8,232
"var_model <- VAR(cbind(CZ2016, SX2016), p = 1, type = ""const"")",modeling,406685028923675e8,232
"save(adf, jct, lag_selection, var_model, file = ""analysis-output/results.rda"")",export,406685028923675e8,232
rm(list = ls()),setup,458558384794742e8,233
"booted_seedling_mortality <- read.table(""./analysis/seedling_mortality_analysis/bootstrapping/bootstrapping_parallel/ bootstrapped_seedling_mortality_glmer_nAGQ=1.txt"",      header = TRUE)",import,458558384794742e8,233
str(booted_seedling_mortality),exploratory,458558384794742e8,233
"load(""./analysis/seedling_mortality_analysis/models/seedling_mortality_model.R"")",import,458558384794742e8,233
"source(""./analysis/seedling_mortality_analysis/data/prediction_species_inundation_interaction.R"")",evaluation,458558384794742e8,233
"pelev_data <- read.table(""./data/pelev_data.txt"", header = TRUE)",import,458558384794742e8,233
"preds$mortality <- predict(r3, preds, type = ""response"", re.form = NA)",modeling,458558384794742e8,233
"preds$CI025 <- as.numeric(booted_seedling_mortality[1, 1:32])",data cleaning,458558384794742e8,233
"preds$CI975 <- as.numeric(booted_seedling_mortality[2, 1:32])",data cleaning,458558384794742e8,233
"preds$pe <- rep(pelev_data$pe, times = 2)",data cleaning,458558384794742e8,233
require(ggplot2),setup,458558384794742e8,233
"cols <- c(""#8CB369"", ""#F4E285"", ""#4C8577"", ""#F4A259"", ""#BC4B51"")",import,458558384794742e8,233
"colnames(preds)[5] <- ""Water inundation""",data cleaning,458558384794742e8,233
"levels(preds$`Water inundation`) <- c(""Dry"", ""Wet"")",data cleaning,458558384794742e8,233
"p1 <- ggplot(preds, aes(x = reorder(sp, pe), y = mortality, group = `Water inundation`)) +      geom_errorbar(aes(ymin = CI025, ymax = CI975), width = 0.3,          alpha = 0.2) + theme_classic() + geom_point(size = 4) +      geom_point(size = 3, aes(color = `Water inundation`)) + theme(legend.position = c(0.25,      0.8)) + xlab(""Species"") + ylab(""p(Mortality)"") + theme(axis.text.x = element_text(face = ""italic"",      angle = 45, vjust = 0.7)) + scale_color_manual(values = c(""light grey"",      cols[c(5)])) + theme(text = element_text(size = 20))",visualization,458558384794742e8,233
p1,exploratory,458558384794742e8,233
"ggsave(p1, file = ""./analysis/seedling_mortality_analysis/graph_code/graphs/species_interaction_mortality_Fig2.png"",      width = 13, height = 6)",export,458558384794742e8,233
library(glue),setup,458558384794742e8,233
library(magrittr),setup,458558384794742e8,233
library(dplyr),setup,458558384794742e8,233
library(ogbox),setup,458558384794742e8,233
library(lazyeval),setup,458558384794742e8,233
library(homologene),setup,458558384794742e8,233
library(parallel),setup,458558384794742e8,233
library(ConnectivityMap),setup,458558384794742e8,233
library(memoise),setup,458558384794742e8,233
library(VennDiagram),setup,458558384794742e8,233
library(gplots),setup,458558384794742e8,233
library(pheatmap),setup,458558384794742e8,233
library(purrr),setup,458558384794742e8,233
"data(""rankMatrix"")",import,458558384794742e8,233
"data(""instances"")",import,458558384794742e8,233
library(UpSetR),setup,458558384794742e8,233
devtools::load_all(),setup,458558384794742e8,233
FDRLimit = 0.05,import,458558384794742e8,233
"groups = c(""E12_1_week_IP_vs_naive_adult_3_IP"", ""E12_2_week_IP_vs_naive_adult_3_IP"",      ""E12_3_day_IP_vs_naive_adult_3_IP"", ""naive_1_week_IP_vs_naive_adult_3_IP"",      ""naive_2_weeks_IP_vs_naive_adult_3_IP"", ""naive_3_days_IP_vs_naive_adult_3_IP"")",import,458558384794742e8,233
"groupShorthands = c(E12_1_week_IP_vs_naive_adult_3_IP = ""regen 1 week"",      E12_2_week_IP_vs_naive_adult_3_IP = ""regen 2 week"", E12_3_day_IP_vs_naive_adult_3_IP = ""regen 3 days"",      naive_1_week_IP_vs_naive_adult_3_IP = ""naive 1 week"", naive_2_weeks_IP_vs_naive_adult_3_IP = ""naive 2 weeks"",      naive_3_days_IP_vs_naive_adult_3_IP = ""naive 3 days"")",import,458558384794742e8,233
"datasets = c(""genesVoomLimma"", ""genesVoomLimmaRUVrk1"", ""genesVoomLimmaNoOutlier"",      ""genesLimma"", ""genesEdger"", ""genesLimmaRUVrk1"", ""genesEdgerRUVrk1"",      ""genesLimmaNoOutlier"", ""genesEdgerNoOutlier"")",import,458558384794742e8,233
"datasetShorthands = c(genesVoomLimma = ""VoLimma"", genesVoomLimmaRUVrk1 = ""VoLimmaaRuv"",      genesVoomLimmaNoOutlier = ""VoLimmanoOut"", genesLimma = ""Limma"",      genesEdger = ""Edge"", genesLimmaRUVrk1 = ""LimmaRUV"", genesEdgerRUVrk1 = ""EdgeRUV"",      genesLimmaNoOutlier = ""LimmanoOut"", genesEdgerNoOutlier = ""EdgenoOut"")",import,458558384794742e8,233
"dataset = ""genesVoomLimma""",import,458558384794742e8,233
"group = ""E12_1_week_IP_vs_naive_adult_3_IP""",import,458558384794742e8,233
"dir.create(""data-raw/tags"", showWarnings = FALSE)",setup,458558384794742e8,233
"dir.create(glue(""analysis/results/enrichmentMonolith/""), recursive = TRUE,      showWarnings = FALSE)",setup,458558384794742e8,233
"dir.create(glue(""analysis/results/heatmaps/""), recursive = TRUE,      showWarnings = FALSE)",setup,458558384794742e8,233
"allResults = datasets %>% mclapply(function(dataset) {     print(dataset)     dir.create(glue(""analysis/results/enrichment/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/perturbagenHitlist/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/perturbagenSpecificHitlist/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/perturbagenHitlist01/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/perturbagenHitlistPos/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/perturbagenHitlistPos01/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/results/instanceScores/{dataset}""),          recursive = TRUE, showWarnings = FALSE)     dir.create(glue(""analysis/probes/{dataset}""), recursive = TRUE,          showWarnings = FALSE)     results = groups %>% lapply(function(group) {         print(group)         if (any(grepl(""FDR_pVal"", colnames(ogbox::teval(dataset))))) {             pVal = ""pVal_""         }         else {             pVal = """"         }         filter_criteriaUp = lazyeval::interp(~FC > 0 & Pval <              FDRLimit, FC = as.name(glue(""logFC_{group}"")), Pval = as.name(glue(""FDR_{pVal}{group}"")))         upTags = ogbox::teval(dataset) %>% dplyr::filter_(filter_criteriaUp) %>%              dplyr::arrange_(.dots = c(glue(""desc(logFC_{group})""))) %>%              dplyr::select(gene) %>% unlist %>% mouse2human %>%              {                 .$humanGene             } %>% unique %>% ogbox::gemmaProbesetMatch(""data-raw/GemmaAnnots/GPL96"")         cat(upTags$Probe, file = glue(""analysis/probes/{dataset}/{group}_upTags.grp""),              sep = ""\n"")         filter_criteriaDown = lazyeval::interp(~FC < 0 & Pval <              FDRLimit, FC = as.name(glue(""logFC_{group}"")), Pval = as.name(glue(""FDR_{pVal}{group}"")))         downTags = ogbox::teval(dataset) %>% dplyr::filter_(filter_criteriaDown) %>%              dplyr::arrange_(.dots = c(glue(""logFC_{group}""))) %>%              dplyr::select(gene) %>% unlist %>% mouse2human %>%              {                 .$humanGene             } %>% unique %>% ogbox::gemmaProbesetMatch(""data-raw/GemmaAnnots/GPL96"")         cat(downTags$Probe, file = glue(""analysis/probes/{dataset}/{group}_downTags.grp""),              sep = ""\n"")         n = rankMatrix %>% nrow         if (nrow(upTags) == 0 & nrow(downTags) == 0) {             return(NULL)         }         out = connectivityMapEnrichment(upTags$Probe, downTags$Probe,              rankMatrix, instances, d = 1e+05)         out$chemScores$specificity = 1:nrow(out$chemScores) %>%              sapply(function(i) {                 chem = rownames(out$chemScores)[i]                 enrichments = MSigDB_enrich %>% sapply(function(x) {                   x[chem, ""enrichment""]                 })                 sign = sign(out$chemScores[chem, ""enrichment""])                 if (sign == -1) {                   enrichments = enrichments[enrichments <= 0]                 }                 else if (sign == 1) {                   enrichments = enrichments[enrichments >= 0]                 }                 sum(abs(out$chemScores[chem, ""enrichment""]) <                    abs(enrichments))/length(enrichments)             })         out$chemScores$reliable = out$chemScores$nonNull > 0.5 &              out$chemScores$instanceCount > 1         out$hits = out$chemScores[out$chemScores$reliable ==              TRUE & out$chemScores$FDR < 0.05, ] %>% {             .[order(.$FDR), ]         } %>% rownames         out$hits01 = out$chemScores[out$chemScores$reliable ==              TRUE & out$chemScores$FDR < 0.1, ] %>% {             .[order(.$FDR), ]         } %>% rownames         out$hitsPos = out$chemScores[out$chemScores$reliable ==              TRUE & out$chemScores$FDR < 0.05 & out$chemScores$enrichment >              0, ] %>% {             .[order(.$FDR), ]         } %>% rownames         out$hitsPos01 = out$chemScores[out$chemScores$reliable ==              TRUE & out$chemScores$FDR < 0.1 & out$chemScores$enrichment >              0, ] %>% {             .[order(.$FDR), ]         } %>% rownames         out$specificHits = out$chemScores[out$chemScores$reliable ==              TRUE & out$chemScores$FDR < 0.05 & out$chemScores$specificity <              0.1, ] %>% rownames         write.table(out$chemScores, file = glue(""analysis/results/enrichment/{dataset}/{group}_enrichment.tsv""),              sep = ""\t"", quote = FALSE, col.names = NA)         write.table(out$instanceScores, file = glue(""analysis/results/instanceScores/{dataset}/{group}_instanceScores.tsv""),              sep = ""\t"", quote = FALSE, col.names = NA)         write.table(out$hits, file = glue(""analysis/results/perturbagenHitlist/{dataset}/{group}_hitlists.tsv""),              sep = ""\t"", quote = FALSE, col.names = FALSE, row.names = FALSE)         write.table(out$hits01, file = glue(""analysis/results/perturbagenHitlist01/{dataset}/{group}_hitlists.tsv""),              sep = ""\t"", quote = FALSE, col.names = FALSE, row.names = FALSE)         write.table(out$hitsPos, file = glue(""analysis/results/perturbagenHitlistPos/{dataset}/{group}_hitlists.tsv""),              sep = ""\t"", quote = FALSE, col.names = FALSE, row.names = FALSE)         write.table(out$hitsPos01, file = glue(""analysis/results/perturbagenHitlistPos01/{dataset}/{group}_hitlists.tsv""),              sep = ""\t"", quote = FALSE, col.names = FALSE, row.names = FALSE)         return(out)     })     names(results) = groups     results = results[(results %>% sapply(class)) != ""NULL""]     scores = results %>% purrr::map(""chemScores"") %>% purrr::map(""enrichment"") %>%          as.df %>% as.matrix %>% cor(method = ""spearman"") %>%          {             diag(.) = NA             .         }     colnames(scores) %<>% replaceElement(dictionary = groupShorthands) %$%          newVector     rn(scores) = cn(scores)     png(glue(""analysis/results/heatmaps/{dataset}.png""), width = 1200,          height = 800)     scores %>% heatmap.2(trace = ""none"", col = viridis::viridis(20),          margins = c(14, 14), main = dataset, symbreaks = FALSE)     dev.off()     results = results[(results %>% sapply(class)) != ""NULL""]     monolith = do.call(cbind, purrr::map(results, ""chemScores""))     write.table(monolith, file = glue::glue(""analysis/results/enrichmentMonolith/{dataset}_monolith.tsv""),          sep = ""\t"", quote = FALSE, col.names = NA)     return(results) }, mc.cores = 9)",setup,458558384794742e8,233
names(allResults) = datasets,setup,458558384794742e8,233
"saveRDS(allResults, ""analysis/allResults.rds"")",export,458558384794742e8,233
"files = list.files(""analysis/results/enrichment/"", recursive = TRUE,      full.names = TRUE)",setup,458558384794742e8,233
"names = list.files(""analysis/results/enrichment/"", recursive = TRUE)",setup,458558384794742e8,233
"names %<>% sapply(function(x) {     x %>% gsub(pattern = ""_enrichment.tsv"", replacement = """",          x = .) %>% strsplit(""/"") %>% {         .[[1]]     } %>% replaceElement(groupShorthands) %$% newVector %>% replaceElement(datasetShorthands) %$%          newVector %>% paste(collapse = "" "") })",data cleaning,458558384794742e8,233
"allEnrich = files %>% sapply(function(x) {     data.table::fread(x, data.table = FALSE)$enrichment })",import,458558384794742e8,233
colnames(allEnrich) = names,setup,458558384794742e8,233
"png(glue(""analysis/results/heatmaps/monolithHeatmap.png""), width = 1400,      height = 1200)",export,458558384794742e8,233
"annotCol = data.frame(Normalization = stringr::str_extract(names,      ""^.*?(?=\\s)""), group = stringr::str_extract(names, ogbox::regexMerge(groupShorthands,      exact = TRUE)), stringsAsFactors = FALSE)",data cleaning,458558384794742e8,233
rownames(annotCol) = colnames(allEnrich),setup,458558384794742e8,233
"annotColors = list(Normalization = annotCol$Normalization %>%      replaceElement(c(Edge = ""cyan"", EdgeRUV = ""blue1"", EdgenoOut = ""cadetblue4"",          Limma = ""chartreuse"", LimmaRUV = ""chartreuse4"", LimmanoOut = ""aquamarine"",          VoLimma = ""brown4"", VoLimmanoOut = ""coral"", VoLimmaaRuv = ""brown1"")) %$%      dictionary, group = annotCol$group %>% toColor %$% palette)",import,458558384794742e8,233
"allEnrich %>% cor(method = ""spearman"") %>% {     diag(.) = NA     . } %>% pheatmap(annotation_col = annotCol, fontsize = 15, border_color = NA,      annotation_colors = annotColors, color = viridis::viridis(20))",visualization,458558384794742e8,233
dev.off(),visualization,458558384794742e8,233
"filesEnrichment = list.files(""analysis/results/enrichment/"",      recursive = FALSE, full.names = TRUE)",setup,458558384794742e8,233
datasetNames = basename(filesEnrichment),import,458558384794742e8,233
"datasetEnrichments = filesEnrichment %>% sapply(function(x) {     datasetFiles = list.files(x, full.names = TRUE)     out = datasetFiles %>% lapply(function(y) {         read.design(y) %>% arrange(desc(reliable), FDR)     })     names(out) = basename(datasetFiles) %>% stringr::str_replace(""_enrichment.tsv"",          """") %>% replaceElement(groupShorthands) %$% newVector     ineligableRegenPos = out[grepl(pattern = ""naive"", names(out))] %>%          sapply(function(y) {             y %>% filter(reliable == TRUE & enrichment > 0 &                  FDR < 0.05) %$% X         })     ineligableNaivePos = out[grepl(pattern = ""regen"", names(out))] %>%          sapply(function(y) {             y %>% filter(reliable == TRUE & enrichment > 0 &                  FDR < 0.05) %$% X         })     ineligableRegenNeg = out[grepl(pattern = ""regen"", names(out))] %>%          sapply(function(y) {             y %>% filter(reliable == TRUE & enrichment < 0 &                  FDR < 0.05) %$% X         })     ineligableNaiveNeg = out[grepl(pattern = ""naive"", names(out))] %>%          sapply(function(y) {             y %>% filter(reliable == TRUE & enrichment < 0 &                  FDR < 0.05) %$% X         })     topRegenMarkersPos = out[grepl(pattern = ""regen"", names(out))] %>%          sapply(function(y) {             y %>% filter(!X %in% unlist(ineligableRegenPos) &                  reliable == TRUE & enrichment > 0 & FDR < 0.05) %$%                  X         }, simplify = FALSE)     topRegenMarkersNeg = out[grepl(pattern = ""regen"", names(out))] %>%          sapply(function(y) {             y %>% filter(!X %in% unlist(ineligableRegenNeg) &                  reliable == TRUE & enrichment < 0 & FDR < 0.05) %$%                  X         }, simplify = FALSE)     return(list(topRegenMarkersPos = topRegenMarkersPos, topRegenMarkersNeg = topRegenMarkersNeg)) }, simplify = FALSE)",data cleaning,458558384794742e8,233
names(datasetEnrichments) = basename(filesEnrichment),setup,458558384794742e8,233
"intersectList(datasetEnrichments$genesEdgerNoOutlier$topRegenMarkersPos[c(""regen 1 week"",      ""regen 2 week"")])",data cleaning,458558384794742e8,233
"intersectList(datasetEnrichments$genesLimmaNoOutlier$topRegenMarkersPos[c(""regen 1 week"",      ""regen 2 week"")])",data cleaning,458558384794742e8,233
"intersectList(datasetEnrichments$genesVoomLimmaNoOutlier$topRegenMarkersPos[c(""regen 1 week"",      ""regen 2 week"")])",data cleaning,458558384794742e8,233
"intersectList(datasetEnrichments$genesEdger$topRegenMarkersPos[c(""regen 1 week"",      ""regen 2 week"")])",data cleaning,458558384794742e8,233
"files = list.files(""analysis/results/perturbagenHitlist/"", recursive = FALSE,      full.names = TRUE)",setup,458558384794742e8,233
"datasetHitlists = files %>% sapply(function(x) {     datasetFiles = list.files(x, full.names = TRUE)     out = datasetFiles %>% sapply(function(y) {         readLines(y)     })     names(out) = basename(datasetFiles) %>% stringr::str_replace(""_hitlists.tsv"",          """") %>% replaceElement(groupShorthands) %$% newVector     return(out) })",import,458558384794742e8,233
names(datasetHitlists) = basename(files),setup,458558384794742e8,233
"dir.create(""analysis/results/upsetWithinGroups"")",setup,458558384794742e8,233
"names(datasetHitlists) %>% sapply(function(x) {     png(glue::glue(""analysis/results/upsetWithinGroups/{x}.png""),          width = 600, height = 600)     upset(UpSetR::fromList(datasetHitlists[[x]]), nsets = 6,          text.scale = 2)     dev.off() })",export,458558384794742e8,233
"files = list.files(""analysis/results/perturbagenHitlist01//"",      recursive = FALSE, full.names = TRUE)",setup,458558384794742e8,233
"datasetHitlists = files %>% sapply(function(x) {     datasetFiles = list.files(x, full.names = TRUE)     out = datasetFiles %>% sapply(function(y) {         readLines(y)     })     names(out) = basename(datasetFiles) %>% stringr::str_replace(""_hitlists.tsv"",          """") %>% replaceElement(groupShorthands) %$% newVector     return(out) })",data cleaning,458558384794742e8,233
names(datasetHitlists) = basename(files),setup,458558384794742e8,233
"dir.create(""analysis/results/upsetWithinGroups01"")",setup,458558384794742e8,233
"names(datasetHitlists) %>% sapply(function(x) {     png(glue::glue(""analysis/results/upsetWithinGroups01/{x}.png""),          width = 600, height = 600)     upset(UpSetR::fromList(datasetHitlists[[x]]), nsets = 6,          text.scale = 2)     dev.off() })",export,458558384794742e8,233
"files = list.files(""analysis/results/perturbagenHitlistPos//"",      recursive = FALSE, full.names = TRUE)",setup,458558384794742e8,233
"datasetHitlists = files %>% sapply(function(x) {     datasetFiles = list.files(x, full.names = TRUE)     out = datasetFiles %>% sapply(function(y) {         readLines(y)     })     names(out) = basename(datasetFiles) %>% stringr::str_replace(""_hitlists.tsv"",          """") %>% replaceElement(groupShorthands) %$% newVector     return(out) })",data cleaning,458558384794742e8,233
names(datasetHitlists) = basename(files),setup,458558384794742e8,233
"dir.create(""analysis/results/upsetWithinGroupsPos"")",setup,458558384794742e8,233
"names(datasetHitlists) %>% sapply(function(x) {     png(glue::glue(""analysis/results/upsetWithinGroupsPos/{x}.png""),          width = 600, height = 600)     upset(UpSetR::fromList(datasetHitlists[[x]]), nsets = 6,          text.scale = 2)     dev.off() })",export,458558384794742e8,233
"files = list.files(""analysis/results/perturbagenHitlistPos01//"",      recursive = FALSE, full.names = TRUE)",setup,458558384794742e8,233
names(datasetHitlists) = basename(files),data cleaning,458558384794742e8,233
"dir.create(""analysis/results/upsetWithinGroupsPos01"")",setup,458558384794742e8,233
"names(datasetHitlists) %>% sapply(function(x) {     png(glue::glue(""analysis/results/upsetWithinGroupsPos01/{x}.png""),          width = 600, height = 600)     upset(UpSetR::fromList(datasetHitlists[[x]]), nsets = 6,          text.scale = 2)     dev.off() })",setup,458558384794742e8,233
"names(datasetHitlists) %>% sapply(function(x) {     png(glue::glue(""analysis/results/upsetWithinGroupsPos01/{x}.png""),          width = 600, height = 600)     upset(UpSetR::fromList(datasetHitlists[[x]]), nsets = 6,          text.scale = 2)     dev.off() })",export,458558384794742e8,233
library(glue),setup,458558384794742e8,233
"source(""analysis/analysis.R"")",setup,458558384794742e8,233
library(plyr),data cleaning,576219031354412e8,234
library(dplyr),data cleaning,576219031354412e8,234
library(reshape2),data cleaning,576219031354412e8,234
"trials <- read.csv(""densities.csv"")",import,576219031354412e8,234
"colnames(trials) <- c(""analysis"", ""cell"", ""chromosomes"", ""volume"",      ""density"")",data cleaning,576219031354412e8,234
"trials$daughter = sapply(strsplit(as.character(trials$analysis),      ""offspring""), ""[["", 2)",data cleaning,576219031354412e8,234
"trials$analysis = sapply(strsplit(as.character(trials$analysis),      ""_offspring""), ""[["", 1)",data cleaning,576219031354412e8,234
"trials.counts <- dcast(trials, analysis ~ daughter, value.var = ""chromosomes"")",data cleaning,576219031354412e8,234
trials.counts$diff <- trials.counts$`1` - trials.counts$`2`,data cleaning,576219031354412e8,234
hist(trials.counts$diff),exploratory,576219031354412e8,234
rm(list = ls()),setup,537827323190868e8,235
library(ggplot2),setup,537827323190868e8,235
library(ggthemes),setup,537827323190868e8,235
library(cowplot),setup,537827323190868e8,235
"tickets <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_landings_data.RDS"")",import,537827323190868e8,235
"vessel_stats <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_stats.RDS"")",import,537827323190868e8,235
library(dplyr),setup,537827323190868e8,235
library(vegan),setup,537827323190868e8,235
"ports <- read.csv(""/Users/efuller/Desktop/CNH/processedData/spatial/ports/all_ports.csv"",      stringsAsFactors = FALSE)",import,537827323190868e8,235
"ports <- rename(ports, pcid = Pcid)",data cleaning,537827323190868e8,235
"coastwide <- ggplot(vessel_stats[which(vessel_stats$alaska ==      0 & !is.na(vessel_stats$type)), ], aes(x = type)) + geom_bar() +      ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,537827323190868e8,235
"by_zone <- ggplot(vessel_stats[which(vessel_stats$alaska == 0 &      !is.na(vessel_stats$type) & !is.na(vessel_stats$zone)), ],      aes(x = type)) + geom_bar() + facet_wrap(~zone, ncol = 1,      scales = ""free_y"") + ylab(""number of vessels"") + theme_pander() +      theme(panel.grid = element_blank())",visualization,537827323190868e8,235
"div_hist <- ggplot(subset(vessel_stats[which(!is.na(vessel_stats$zone) &      vessel_stats$alaska == 0), ], vessel_stats$eff.shannon_2010 >      1), aes(x = eff.shannon_2010)) + geom_histogram(aes(y = ..count..)) +      facet_wrap(~zone, ncol = 1, scales = ""free_y"") + xlab(""effective shannon diversity of revenue"") +      ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,537827323190868e8,235
"all_plot <- plot_grid(coastwide, by_zone, div_hist, labels = c(""A"",      ""B"", ""C""), ncol = 3, rel_widths = c(1, 1.2, 1.4))",visualization,537827323190868e8,235
"ggplot2::ggsave(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/05_figures/fig_2.pdf"",      all_plot, width = 11.4, height = 7, units = ""cm"", scale = 2.5,      dpi = 300)",export,537827323190868e8,235
"fn_dh_elfstats <- function(site = ""http://deq2.bse.vt.edu/d.dh"",      ftype = ""all"", fstatus = ""active"", analysis_timespan = ""full"",      yvar = ""all"", sampres = ""all"", stat_quantreg_qu = ""0.80"",      station_agg = ""max"", stat_quantreg_glo = ""all"", stat_quantreg_ghi = ""all"",      feature_ftype = ""all"", xvar = ""all"", dataset_tag = ""taxaLoss_PI_PressHuc8"",      featureid = ""all"") {     elf_statistics <- paste(site, ""export_elf_statistics"", ftype,          fstatus, analysis_timespan, yvar, sampres, stat_quantreg_qu,          station_agg, stat_quantreg_glo, stat_quantreg_ghi, feature_ftype,          xvar, dataset_tag, featureid, sep = ""/"")     print(paste(""Using URI: "", elf_statistics))     region <- feature_ftype     XV <- xvar     YV <- yvar     elf_statistics <- read.table(elf_statistics, header = TRUE,          sep = "","")     write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",          region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,          quote = TRUE)     return(elf_statistics) }",import,664040589472279e8,236
"packages <- c(""CIMseq"", ""sp.scRNAseqData"", ""tidyverse"", ""future"",      ""future.apply"")",setup,664040589472279e8,236
"port_df <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/port_stats.RDS"")",import,537827323190868e8,235
"source(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/02_define_participationPlot.R"")",setup,537827323190868e8,235
"port_df <- port_df[order(port_df$ic_pre, decreasing = TRUE),      ]",data cleaning,537827323190868e8,235
"port_df <- port_df[-grep(""other"", port_df$name), ]",data cleaning,537827323190868e8,235
"pdf(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/05_figures/fig_3c.pdf"",      width = 8, height = 2)",export,537827323190868e8,235
"purrr::walk(packages, library, character.only = TRUE)",setup,664040589472279e8,236
rm(packages),setup,664040589472279e8,236
currPath <- getwd(),setup,664040589472279e8,236
"if (file.exists(file.path(currPath, ""../mouseAnalysis_engeOnly/data/CIMseqData.rda""))) {     load(file.path(currPath, ""../mouseAnalysis_engeOnly/data/CIMseqData.rda"")) }",setup,664040589472279e8,236
"if (length(grep(""TGuillerme"", getwd()))) {     setwd(""~/PhD/Projects/SpatioTemporal_Disparity/Analysis"") } else {     warning(""You might have to change the directory!"") }",setup,178617905592546e8,237
"if (length(grep(""SpatioTemporal_Disparity/Analysis"", getwd())) ==      0) {     if (length(grep(""SpatioTemporal_Disparity-master/Analysis"",          getwd())) == 0) {         stop(""Wrong directory!\nThe current directory must be:\nSpatioTemporal_Disparity/Analysis/ OR SpatioTemporal_Disparity-master/Analysis/\nYou can clone the whole repository from:\nhttps://github.com/TGuillerme/SpatioTemporal_Disparity"")     } }",setup,178617905592546e8,237
"source(""functions.R"")",setup,178617905592546e8,237
"chain_name <- ""Beck2014""",import,178617905592546e8,237
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",communication,13877863669768e9,238
rm(list = ls()),setup,13877863669768e9,238
"load(""./analysis/wood_density_distribution/models/gls_models/model2.R"")",setup,13877863669768e9,238
"source(""./analysis/wood_density_distribution/organisation.R"")",setup,13877863669768e9,238
"source(""./functions/booter.R"")",setup,13877863669768e9,238
rm(list = ls()),setup,272293644025922e8,239
"setwd(""/Users/efuller/1/CNH/Analysis/VMS/results/2014-10-29/"")",setup,272293644025922e8,239
"d_seq <- with(wood_density_data_178ha, seq(min(d), max(d), length = 100))",not sure,13877863669768e9,238
preds <- data.frame(d = d_seq),modeling,13877863669768e9,238
"preds$e <- predict(model2, newdata = preds, type = ""response"")",modeling,13877863669768e9,238
"load(""../Data/R2GIS/CleanData/TimeLag12months/Sales20052010LWRmodelAirMean3-2014-03-19.RData"")",data cleaning,480272695422173e7,240
"LWRMonteCarloStats2014.03.29 <- read.csv(""~/NoiseHedonicProject/Noise-Hedonic/analysis/04MonteCarloSim/Revision/Model3/LWRMonteCarloStats2014-03-29.csv"")",data cleaning,480272695422173e7,240
"LWRMonteCarloStats2014.04.18 <- read.csv(""~/NoiseHedonicProject/Noise-Hedonic/analysis/04MonteCarloSim/Revision/Model3/LWRMonteCarloStats2014-04-18.csv"")",data cleaning,480272695422173e7,240
"MCMaster650 <- rbind(LWRMonteCarloStats2014.03.29, LWRMonteCarloStats2014.04.18)",visualization,480272695422173e7,240
library(dygraphs),setup,409523344133049e8,241
"dygraph(gpg_pauses, xlab = ""Keypress index"", ylab = ""Pause length"",      main = paste0(ID, "" "", file_index, "" "", txt_files[file_index],          "" "", n)) %>% dySeries(""V1"", label = ""Seconds"") %>% dyLegend(show = ""always"",      hideOnMouseOut = FALSE) %>% dyRangeSelector()",visualization,409523344133049e8,241
p_threshold <- 8,not sure,409523344133049e8,241
which(pause > p_threshold),data cleaning,409523344133049e8,241
library(scater),setup,409523344133049e8,241
library(tidyverse),setup,409523344133049e8,241
library(magrittr),setup,409523344133049e8,241
library(RTCGA.clinical),setup,409523344133049e8,241
"data(""COAD.clinical"")",setup,409523344133049e8,241
library(RTCGA.mutations),setup,409523344133049e8,241
"data(""COAD.mutations"")",setup,409523344133049e8,241
"coad <- read_tsv(""../data/TCGA_COAD_tpm.tsv.gz"")",import,409523344133049e8,241
sample_names <- names(coad)[-1],data cleaning,409523344133049e8,241
coad <- data.frame(coad),data cleaning,409523344133049e8,241
"names(coad)[1] <- ""feature_id""",data cleaning,409523344133049e8,241
rownames(coad) <- coad$feature_id,data cleaning,409523344133049e8,241
coad$feature_id <- NULL,data cleaning,409523344133049e8,241
names(coad) <- sample_names,data cleaning,409523344133049e8,241
"coad_counts <- read_tsv(""../data/TCGA_COAD_counts.tsv.gz"")",import,409523344133049e8,241
sample_names <- names(coad_counts)[-1],data cleaning,409523344133049e8,241
coad_counts <- data.frame(coad_counts),data cleaning,409523344133049e8,241
"names(coad_counts)[1] <- ""feature_id""",data cleaning,409523344133049e8,241
rownames(coad_counts) <- coad_counts$feature_id,data cleaning,409523344133049e8,241
coad_counts$feature_id <- NULL,data cleaning,409523344133049e8,241
names(coad_counts) <- sample_names,data cleaning,409523344133049e8,241
"stopifnot(all.equal(dim(coad), dim(coad_counts)))",data cleaning,409523344133049e8,241
"stopifnot(all.equal(rownames(coad), rownames(coad_counts)))",data cleaning,409523344133049e8,241
"stopifnot(all.equal(colnames(coad), colnames(coad_counts)))",data cleaning,409523344133049e8,241
"id_split <- strsplit(rownames(coad), ""|"", fixed = TRUE)",data cleaning,409523344133049e8,241
"feature_names <- sapply(id_split, function(x) paste0(x[1], ""_"",      x[6]))",data cleaning,409523344133049e8,241
"gene_type <- sapply(id_split, `[`, 8)",data cleaning,409523344133049e8,241
"ensembl_gene_id <- sapply(id_split, `[`, 2)",data cleaning,409523344133049e8,241
rownames(coad) <- feature_names,data cleaning,409523344133049e8,241
rownames(coad_counts) <- feature_names,data cleaning,409523344133049e8,241
"id_map <- read_csv(""../data/TCGA_ID_MAP.csv"") %>% filter(Disease ==      ""COAD"")",import,409523344133049e8,241
"to_tcga_barcode <- function(x) tolower(paste(strsplit(x, ""-"",      fixed = T)[[1]][1:3], collapse = ""-""))",data cleaning,409523344133049e8,241
"id_map %<>% mutate(patient_barcode = sapply(AliquotBarcode, to_tcga_barcode))",data cleaning,409523344133049e8,241
"sample_split <- sapply(strsplit(id_map$AliquotBarcode, ""-"", fixed = TRUE),      `[`, 4)",data cleaning,409523344133049e8,241
"sample <- as.numeric(sapply(sample_split, substr, 1, 2))",data cleaning,409523344133049e8,241
"vial <- sapply(sample_split, substr, 3, 3)",data cleaning,409523344133049e8,241
"sample_type <- sapply(sample %in% 1:10, ifelse, ""tumour"", ""normal"")",data cleaning,409523344133049e8,241
"id_map %<>% mutate(sample_type, vial)",data cleaning,409523344133049e8,241
"coad_clinical <- COAD.clinical %>% filter(patient.bcr_patient_barcode %in%      id_map$patient_barcode) %>% select(patient_barcode = patient.bcr_patient_barcode,      patient.days_to_death, patient.age_at_initial_pathologic_diagnosis,      patient.days_to_last_followup, days_to_sample_procurement = patient.biospecimen_cqcf.days_to_sample_procurement,      patient.samples.sample.days_to_collection, stage = patient.stage_event.pathologic_stage,      nuclei_percent = as.numeric(patient.biospecimen_cqcf.tumor_samples.tumor_sample.tumor_nuclei_percent),      weight = as.numeric(patient.biospecimen_cqcf.tumor_samples.tumor_sample.tumor_weight),      neoplasm_subdivision = patient.anatomic_neoplasm_subdivision,      histological_type = patient.clinical_cqcf.histological_type,      polyps_present = patient.colon_polyps_present, t_stage = patient.stage_event.tnm_categories.pathologic_categories.pathologic_t,      n_stage = patient.stage_event.tnm_categories.pathologic_categories.pathologic_n,      m_stage = patient.stage_event.tnm_categories.pathologic_categories.pathologic_m,      msi_status = patient.microsatellite_instability_test_results.microsatellite_instability_test_result.mononucleotide_and_dinucleotide_marker_panel_analysis_status) %>%      mutate(censored = is.na(patient.days_to_death))",data cleaning,409523344133049e8,241
"coad_clinical %<>% inner_join(select(id_map, patient_barcode,      CGHubAnalysisID, AliquotBarcode, sample_type, vial), by = c(""patient_barcode""))",data cleaning,409523344133049e8,241
"for (covariate_index in grep(""days"", names(coad_clinical))) coad_clinical[[covariate_index]] <- as.numeric(coad_clinical[[covariate_index]])",data cleaning,409523344133049e8,241
"plate <- factor(sapply(strsplit(coad_clinical$AliquotBarcode,      ""-""), `[`, 6))",data cleaning,409523344133049e8,241
coad_clinical$plate <- factor(plate),data cleaning,409523344133049e8,241
"common_cghub_ids <- intersect(colnames(coad), coad_clinical$CGHubAnalysisID)",data cleaning,409523344133049e8,241
"coad_clinical <- coad_clinical[match(common_cghub_ids, coad_clinical$CGHubAnalysisID),      ]",data cleaning,409523344133049e8,241
"coad <- coad[, match(common_cghub_ids, names(coad))]",data cleaning,409523344133049e8,241
"coad_counts <- coad_counts[, match(common_cghub_ids, names(coad_counts))]",data cleaning,409523344133049e8,241
"stopifnot(all.equal(colnames(coad), coad_clinical$CGHubAnalysisID))",data cleaning,409523344133049e8,241
coad_clinical_pd <- data.frame(coad_clinical),data cleaning,409523344133049e8,241
rownames(coad_clinical_pd) <- coad_clinical_pd$CGHubAnalysisID,data cleaning,409523344133049e8,241
library(data.table),setup,311625589383766e8,242
"sce <- newSCESet(tpmData = as.matrix(coad), countData = coad_counts,      phenoData = AnnotatedDataFrame(coad_clinical_pd))",not sure,409523344133049e8,241
fData(sce)$gene_type <- gene_type,data cleaning,409523344133049e8,241
fData(sce)$ensembl_gene_id <- ensembl_gene_id,data cleaning,409523344133049e8,241
sce$short_plate <- as.character(sce$plate),data cleaning,409523344133049e8,241
"gear <- ""MSC""",setup,311625589383766e8,242
to_collapse <- names(which(table(sce$plate) < 30)),data cleaning,409523344133049e8,241
"sce$short_plate[which(sce$short_plate %in% to_collapse)] <- ""other""",data cleaning,409523344133049e8,241
"to_patient_barcode <- function(bcr_barcode) {     tolower(paste0(strsplit(bcr_barcode, ""-"")[[1]][1:3], collapse = ""-"")) }",data cleaning,409523344133049e8,241
year <- 2010,setup,311625589383766e8,242
"patient_mutations <- COAD.mutations %>% filter(bcr_patient_barcode !=      ""bcr_patient_barcode"") %>% group_by(bcr_patient_barcode) %>%      summarise(n_mutations = n(), n_somatic = sum(Mutation_Status ==          ""Somatic""), n_unknown = sum(Mutation_Status == ""Unknown"")) %>%      mutate(patient_barcode = sapply(bcr_patient_barcode, to_patient_barcode))",data cleaning,409523344133049e8,241
"pdata_df <- select(pData(sce), patient_barcode)",data cleaning,409523344133049e8,241
"clusters <- fread(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/define/"",      gear, year, "".clu""))",import,311625589383766e8,242
"pdata_df <- left_join(pdata_df, patient_mutations, by = ""patient_barcode"")",data cleaning,409523344133049e8,241
"key <- read.table(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/define/"",      gear, year, ""key.txt""), sep = "","", skip = 1)",import,311625589383766e8,242
"stopifnot(all.equal(sce$patient_barcode, pdata_df$patient_barcode))",data cleaning,409523344133049e8,241
"pData(sce) <- cbind(pData(sce), select(pdata_df, n_mutations,      n_somatic, n_unknown))",data cleaning,409523344133049e8,241
"save(sce, file = ""../data/sce_coad_kallisto.Rdata"")",export,409523344133049e8,241
"key <- cbind(key, clusters)",data cleaning,311625589383766e8,242
"names(key) <- c(""ftid"", ""node"", ""cluster"")",data cleaning,311625589383766e8,242
"write.csv(key, paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/define/"",      gear, year, ""cluster_key.txt""), row.names = FALSE, quote = FALSE)",export,311625589383766e8,242
rm(list = ls()),setup,658498738892376e8,243
require(plyr),setup,658498738892376e8,243
require(dplyr),setup,658498738892376e8,243
require(data.table),import,658498738892376e8,243
require(reshape2),setup,658498738892376e8,243
require(ggplot2),setup,658498738892376e8,243
require(qgraph),setup,658498738892376e8,243
require(RColorBrewer),setup,658498738892376e8,243
require(cluster),setup,658498738892376e8,243
"CNH <- ""/Volumes/NOAA_Data/CNH/""",setup,658498738892376e8,243
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",      sep = """"), stringsAsFactors = F, skip = 2)",import,658498738892376e8,243
"FTL <- head(FTL, -2)",exploratory,658498738892376e8,243
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",      sep = """"), stringsAsFactors = F)",import,658498738892376e8,243
library(knitr),setup,190266406862065e8,244
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,190266406862065e8,244
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,190266406862065e8,244
"for (i in seq(1, (dim(mastersheet)[1]))) {     strain <- mastersheet[i, 1]     dir <- mastersheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain) }",not sure,190266406862065e8,244
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",not sure,190266406862065e8,244
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",not sure,190266406862065e8,244
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",not sure,190266406862065e8,244
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,190266406862065e8,244
"for (i in seq(1, (dim(test_master_sheet)[1]))) {     strain <- test_master_sheet[i, 1]     dir <- test_master_sheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"))     print(dir)     print(strain) }",data cleaning,190266406862065e8,244
library(knitr),setup,190266406862065e8,244
library(stringr),setup,190266406862065e8,244
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,468586856266484e8,245
library(reshape2),setup,190266406862065e8,244
"source(""powerAnalysis/lib.R"")",setup,190266406862065e8,244
"source(""analysis/utils.R"")",setup,468586856266484e8,245
"source(""analysis/analysis.R"")",setup,468586856266484e8,245
"kClustersPattern <- ""results/mcmc_clusters_%s_chrom%02d.txt""",not sure,190266406862065e8,244
kReplicates <- 1:10,setup,190266406862065e8,244
"kClustersFmt <- list(center = integer(0), cluster_length = integer(0),      occupancy = double(0), occupancy_se = double(0), localization = double(0),      localization_se = double(0), structure = double(0), structure_se = double(0),      sparsity = double(0), sparsity_se = double(0))",not sure,190266406862065e8,244
"kOutputPath <- ""powerAnalysis/output_cluster_summaries_model.RData""",not sure,190266406862065e8,244
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,850581512087956e8,246
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,850581512087956e8,246
"clusters <- ldply(kReplicates, function(rep) data.frame(rep = rep,      scan(sprintf(kClustersPattern, ""powerAnalysis"", rep), what = kClustersFmt,          skip = 1), rep = rep))",data cleaning,190266406862065e8,244
"save(clusters, file = kOutputPath)",export,190266406862065e8,244
library(metafor),setup,190266406862065e8,244
library(readxl),setup,190266406862065e8,244
"dataSetOri <- read_excel(""PhD/Systematic Reviews/History of Power Estimation Studies/PowerEstimationReviewDataCollection2018.03.05.xlsx"",      sheet = ""Data_prop_reporting_PA"")",import,190266406862065e8,244
dataSetOri <- as.data.frame(dataSetOri),import,190266406862065e8,244
dataSet <- dataSetOri,import,190266406862065e8,244
"for (i in 1:nrow(dataSet)) {     for (j in 1:ncol(dataSet)) {         if (!is.na(as.numeric(dataSet[i, j]))) {             if ((dataSet[i, j] < 0.99) && (dataSet > 0)) {                 dataSet[i, j] <- ((sum(rbinom(dataSet$NumberOfArticlesExamined[i],                    1, 0.5)))/(dataSet$NumberOfArticlesExamined[i]))             }             else if (dataSet[i, j] == 1) {                 dataSet[i, j] <- rbinom(n = 1, size = 1, prob = 0.5)             }             else {                 dataSet[i, j] <- round(rchisq(1, 40))             }         }         else {             dataSet[i, j] <- dataSet[i, j]         }     } }",data cleaning,190266406862065e8,244
"for (i in 1:length(dataSet$YearsStudied)) {     if (is.na(as.numeric(dataSet$YearsStudied[i]) && (!is.na(dataSet$YearsStudied[i])))) {         firstYear <- round(runif(1, 1962, 2017))         secondYear <- firstYear + round(rchisq(1, 2))         if ((secondYear > 2017) || (secondYear <= firstYear)) {             secondYear <- firstYear + 1         }         dataSet$YearsStudied[i] <- paste(firstYear, ""-"", secondYear,              sep = """")     }     else if (!is.na(as.numeric(dataSet$YearsStudied[i])))          dataSet$YearsStudied[i] <- round(runif(1, 1962, 2018)) }",data cleaning,190266406862065e8,244
years <- dataSet$YearsStudied,data cleaning,190266406862065e8,244
medianYear <- as.numeric(years),data cleaning,190266406862065e8,244
"for (i in 1:length(years)) {     if ((is.na(as.numeric(years)[i])) && (!is.na(as.numeric(unlist(strsplit(years[i],          ""-""))[2])))) {         minYear <- unlist(strsplit(years[i], ""-""))[1]         maxYear <- unlist(strsplit(years[i], ""-""))[2]         yearRange <- (minYear:maxYear)         medianYear[i] <- median(yearRange)     } }",data cleaning,190266406862065e8,244
dataSet$medianYear <- medianYear,data cleaning,190266406862065e8,244
"dat <- subset(dataSet, is.na(dataSet$exclude))",data cleaning,190266406862065e8,244
"dat <- dat[order(dat$medianYear), ]",data cleaning,190266406862065e8,244
dat$xi <- round(dat$ProportionReportingPA * dat$NumberOfArticlesExamined),data cleaning,190266406862065e8,244
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,850581512087956e8,246
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,850581512087956e8,246
"dat <- escalc(measure = ""PFT"", xi = xi, ni = NumberOfArticlesExamined,      data = dat)",data cleaning,190266406862065e8,244
"res <- rma(yi, vi, method = ""REML"", data = dat)",modeling,190266406862065e8,244
"pred <- predict(res, transf = transf.ipft.hm, targs = list(ni = dat$NumberOfArticlesExamined))",modeling,190266406862065e8,244
pred,not sure,190266406862065e8,244
"dat.back <- summary(dat, transf = transf.ipft, ni = dat$NumberOfArticlesExamined)",not sure,190266406862065e8,244
"forest(dat.back$yi, ci.lb = dat.back$ci.lb, ci.ub = dat.back$ci.ub,      psize = 1, xlim = c(-0.5, 1.8), alim = c(0, 1), ylim = c(-1,          23), refline = NA, digits = 3L, xlab = ""Proportion"",      slab = dat.back$PaperCitation)",visualization,190266406862065e8,244
"addpoly(pred$pred, ci.lb = pred$ci.lb, ci.ub = pred$ci.ub, row = -0.5,      digits = 3, mlab = ""REML Model"", efac = 1.3)",visualization,190266406862065e8,244
abline(h = 0.49),visualization,190266406862065e8,244
"text(-0.5, 22, ""Study"", pos = 4)",visualization,190266406862065e8,244
"text(1.8, 22, ""Proportion [95% CI]"", pos = 2)",visualization,190266406862065e8,244
"res1 <- rma(yi, vi, method = ""REML"", data = dat, mods = medianYear)",modeling,190266406862065e8,244
"pred1 <- predict(res1, transf = transf.ipft.hm, targs = list(ni = dat$NumberOfArticlesExamined))",modeling,190266406862065e8,244
pred1,not sure,190266406862065e8,244
cexs <- 1/dat$vi,not sure,190266406862065e8,244
cexs <- 1 + (cexs - min(cexs))/(max(cexs) - min(cexs)),not sure,190266406862065e8,244
"plot(NA, NA, xlab = ""Year"", ylab = ""Proportion"", xlim = c(min(dat$medianYear),      max(dat$medianYear)), ylim = c(0, 1), bty = ""l"")",visualization,190266406862065e8,244
"lines(dat$medianYear, pred1$ci.lb, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,190266406862065e8,244
"lines(dat$medianYear, pred1$ci.ub, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,190266406862065e8,244
"lines(dat$medianYear, pred1$pred, col = ""darkgray"", lwd = 2)",visualization,190266406862065e8,244
"points(dat$medianYear, transf.ipft(dat$yi, dat$NumberOfArticlesExamined),      pch = 19, cex = cexs)",visualization,190266406862065e8,244
require(plyr),setup,499663378577679e8,247
require(dplyr),setup,499663378577679e8,247
require(data.table),setup,499663378577679e8,247
require(reshape2),setup,499663378577679e8,247
require(ggplot2),setup,499663378577679e8,247
require(qgraph),setup,499663378577679e8,247
require(RColorBrewer),setup,499663378577679e8,247
require(cluster),setup,499663378577679e8,247
"CNH <- ""/Volumes/NOAA_Data/CNH/""",import,499663378577679e8,247
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",      sep = """"), stringsAsFactors = F, skip = 2)",import,499663378577679e8,247
"FTL <- head(FTL, -2)",data cleaning,499663378577679e8,247
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",      sep = """"), stringsAsFactors = F)",import,499663378577679e8,247
"mgmt_grp <- dlply(spid, .(mgmt_grp))",data cleaning,499663378577679e8,247
mgmt_grp <- mgmt_grp[2:9],data cleaning,499663378577679e8,247
"m.vec <- rep(NA, nrow(FTL))",not sure,499663378577679e8,247
for (i in 1:length(mgmt_grp)) {     m.vec[FTL$spid %in% mgmt_grp[[i]]$SPID] = names(mgmt_grp[i]) },data cleaning,499663378577679e8,247
"tickets <- select(FTL, ftid, veid, year, spid, landed_wt, ppp,      grgroup, grid, tdate, pcid, ifq_landing, processorid, pargrp)",data cleaning,499663378577679e8,247
tickets$mgmt_grp <- m.vec,data cleaning,499663378577679e8,247
rm(FTL),not sure,499663378577679e8,247
by_trip <- data.table(tickets),data cleaning,499663378577679e8,247
"setkey(by_trip, ftid)",data cleaning,499663378577679e8,247
"catch <- by_trip[, sum(landed_wt), by = c(""ftid"", ""mgmt_grp"")]",data cleaning,499663378577679e8,247
"total_catch <- dcast.data.table(catch, ftid ~ mgmt_grp, fun = sum)",data cleaning,499663378577679e8,247
prop_table <- as.data.frame(total_catch),data cleaning,499663378577679e8,247
"prop_table[, 2:ncol(prop_table)] <- prop_table[, 2:ncol(prop_table)]/rowSums(prop_table[,      2:ncol(prop_table)])",data cleaning,499663378577679e8,247
rm(list = ls(all.names = TRUE)),not sure,538696111645549e8,248
"if (!suppressMessages(require(plspm))) install.packages(""plspm"")",not sure,538696111645549e8,248
"if (!suppressMessages(require(mice))) install.packages(""mice"")",not sure,538696111645549e8,248
"if (!suppressMessages(require(ggplot2))) install.packages(""ggplot2"")",not sure,538696111645549e8,248
"if (!suppressMessages(require(RColorBrewer))) install.packages(""RColorBrewer"")",not sure,538696111645549e8,248
"if (!suppressMessages(require(reshape))) install.packages(""reshape"")",not sure,538696111645549e8,248
"if (!suppressMessages(require(pander))) install.packages(""pander"")",not sure,538696111645549e8,248
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,345822588074952e8,249
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,345822588074952e8,249
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,345822588074952e8,249
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,345822588074952e8,249
library(rstan),exploratory,345822588074952e8,249
library(dplyr),exploratory,345822588074952e8,249
library(ggplot2),visualization,345822588074952e8,249
"load(""analysis/rdata-tmp/britdat.RData"")",visualization,345822588074952e8,249
"real <- subset(britdat, NVerb != ""SEND"" & !is.na(isTo))",visualization,345822588074952e8,249
"brit.act <- subset(real, Voice == ""ACT"" & NVerb != ""NONREC"" &      !is.na(year) & !is.na(Adj) & !is.na(isDatAcc) & DO == ""Theme Noun"")",not sure,345822588074952e8,249
brit.act$isAdj <- factor(brit.act$Adj),not sure,345822588074952e8,249
"levels(brit.act$isAdj) <- c(1, 0, 1, 0)",not sure,345822588074952e8,249
brit.act$isAdj <- as.numeric(as.character(brit.act$isAdj)),not sure,345822588074952e8,249
brit.act$NAdj <- factor(brit.act$isAdj),not sure,345822588074952e8,249
"levels(brit.act$NAdj) <- c(""Not Adjacent"", ""Adjacent"")",not sure,345822588074952e8,249
"brit.act <- subset(brit.act, (year <= 1100 & isTo == 0) | year >      1100)",not sure,345822588074952e8,249
"parameters <- as.data.frame(cbind(read.csv(""analysis/parameters/parameters.csv""),      read.csv(""analysis/parameters/rise_parameters.csv"")))",not sure,345822588074952e8,249
"brit.act <- subset(brit.act, year <= parameters$end_data)",not sure,345822588074952e8,249
"fit1 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit1.RDS"")",not sure,345822588074952e8,249
"fit2 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit2.RDS"")",not sure,345822588074952e8,249
"fit3 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit3-resample.RDS"")",not sure,345822588074952e8,249
"fit4 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit4-resample.RDS"")",not sure,345822588074952e8,249
a1 <- as.data.frame(extract(fit1)),not sure,345822588074952e8,249
a2 <- as.data.frame(extract(fit2)),not sure,345822588074952e8,249
a3 <- fit3,not sure,345822588074952e8,249
a4 <- fit4,not sure,345822588074952e8,249
"load(""analysis/rdata-tmp/RoT-dat3.RData"")",not sure,345822588074952e8,249
"load(""analysis/rdata-tmp/RoT-dat4.RData"")",not sure,345822588074952e8,249
a3$s.year <- stan.dat3$t[a3$s],not sure,345822588074952e8,249
a3$re.year <- a3$s.year * sd(brit.act$year) + mean(brit.act$year),not sure,345822588074952e8,249
a4$s.year <- stan.dat4$t[a4$s],not sure,345822588074952e8,249
a4$re.year <- a4$s.year * sd(brit.act$year) + mean(brit.act$year),not sure,345822588074952e8,249
unlogit <- function(x) {     return(1/(1 + exp(-x))) },not sure,345822588074952e8,249
pred1$x <- (pred1$year - mean(brit.act$year))/sd(brit.act$year),not sure,345822588074952e8,249
Int1 <- mean(a1$Int),not sure,345822588074952e8,249
Slope1 <- mean(a1$Slope),not sure,345822588074952e8,249
pred1$z <- Int1 + Slope1 * pred1$x,not sure,345822588074952e8,249
pred1$isTo <- unlogit(pred1$z),not sure,345822588074952e8,249
"pred2 <- expand.grid(year = min(brit.act$year):max(brit.act$year),      Order = ""TR"", IO = ""Pronoun"")",not sure,345822588074952e8,249
pred2$x <- (pred2$year - mean(brit.act$year))/sd(brit.act$year),not sure,345822588074952e8,249
Int2 <- mean(a2$Int),not sure,345822588074952e8,249
Slope2 <- mean(a2$Slope),not sure,345822588074952e8,249
pred2$z <- Int2 + Slope2 * pred2$x,not sure,345822588074952e8,249
pred2$isTo <- unlogit(pred2$z),not sure,345822588074952e8,249
"pred3 <- expand.grid(year = min(brit.act$year):max(brit.act$year),      Order = ""RT"", IO = ""Noun"")",not sure,345822588074952e8,249
pred3$x <- (pred3$year - mean(brit.act$year))/sd(brit.act$year),not sure,345822588074952e8,249
Int3a <- mean(a3$Int1),not sure,345822588074952e8,249
Slope3a <- mean(a3$Slope1),not sure,345822588074952e8,249
Slope3b <- mean(a3$Slope2),not sure,345822588074952e8,249
"nhObs <- read.csv(""/wrk2/efuller/NOAA/Data_Analysis/Obs/Data/WCGOPobs/Samhouri_OBFTfinal_Allfisheries_ProcessedwFunction_2009-2012_110613.csv"")",import,937694015679881e8,250
REpoint3 <- mean(stan.dat3$t[a3$s]),not sure,345822588074952e8,249
Int3b <- (Int3a + Slope3a * REpoint3) - Slope3b * REpoint3,not sure,345822588074952e8,249
pred3$z <- NA,not sure,345822588074952e8,249
pred3$z[pred3$x <= REpoint3] <- Int3a + Slope3a * pred3$x[pred3$x <=      REpoint3],not sure,345822588074952e8,249
pred3$z[pred3$x > REpoint3] <- Int3b + Slope3b * pred3$x[pred3$x >      REpoint3],not sure,345822588074952e8,249
pred3$isTo <- unlogit(pred3$z),not sure,345822588074952e8,249
"pred4 <- expand.grid(year = min(brit.act$year):max(brit.act$year),      Order = ""RT"", IO = ""Pronoun"")",not sure,345822588074952e8,249
"Owners <- read.csv(""/wrk2/efuller/NOAA/Data_Analysis/Ownership/csvVersions/Linked_IFQ_Vessel_Accounts_01-27-14_EFmod_VesselAccounts_Exact.csv"")",import,937694015679881e8,250
pred4$x <- (pred4$year - mean(brit.act$year))/sd(brit.act$year),not sure,345822588074952e8,249
Int4a <- mean(a4$Int1),not sure,345822588074952e8,249
Slope4a <- mean(a4$Slope1),not sure,345822588074952e8,249
Slope4b <- mean(a4$Slope2),not sure,345822588074952e8,249
REpoint4 <- mean(stan.dat4$t[a4$s]),visualization,345822588074952e8,249
Int4b <- (Int4a + Slope4a * REpoint4) - Slope4b * REpoint4,visualization,345822588074952e8,249
"shrimps <- subset(nhObs, sector == ""Pink Shrimp"")",import,937694015679881e8,250
pred4$z <- NA,visualization,345822588074952e8,249
pred4$z[pred4$x <= REpoint4] <- Int4a + Slope4a * pred4$x[pred4$x <=      REpoint4],visualization,345822588074952e8,249
uniqueShrimps <- unique(shrimps$CG_NUM),exploratory,937694015679881e8,250
tracks <- unique(VMS$Doc_Number),data cleaning,937694015679881e8,250
captured <- length(uniqueShrimps[which(uniqueShrimps %in% tracks)]),data cleaning,937694015679881e8,250
library(plyr),import,215168142458424e8,251
library(stringr),import,215168142458424e8,251
library(reshape2),import,215168142458424e8,251
"source(""powerAnalysis/lib.R"")",import,215168142458424e8,251
"kClustersPattern <- ""results/mcmc_clusters_%s_chrom%02d.txt""",modeling,215168142458424e8,251
kReplicates <- 1:10,setup,215168142458424e8,251
require(rstanarm),import,731850108364597e8,252
"load(""../Data/R2GIS/CleanData/TimeLag12months/Sales20052010LWRmodelAirMean3-2014-03-19.RData"")",setup,683667317498475e7,253
library(randomForest),setup,731662313686684e8,254
library(caret),setup,731662313686684e8,254
library(doMC),setup,731662313686684e8,254
library(mmadsenr),setup,731662313686684e8,254
library(futile.logger),setup,731662313686684e8,254
library(dplyr),setup,731662313686684e8,254
library(ggthemes),setup,731662313686684e8,254
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""population-classification.log"")",import,731662313686684e8,254
"flog.appender(appender.file(log_file), name = ""cl"")",data cleaning,731662313686684e8,254
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,706880415091291e8,255
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",setup,706880415091291e8,255
"info.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/tmp/Copper.2048.both.msOnly.info""",setup,706880415091291e8,255
siteSize = 2048,setup,706880415091291e8,255
"treatment = ""Copper""",not sure,706880415091291e8,255
null = FALSE,setup,706880415091291e8,255
"source(""https://bioconductor.org/biocLite.R"")",visualization,882587436819449e8,256
biocLite(),visualization,882587436819449e8,256
"biocLite(""ChIPseeker"")",visualization,882587436819449e8,256
"biocLite(""TxDb.Hsapiens.UCSC.hg38.knownGene"")",visualization,882587436819449e8,256
"biocLite(""clusterProfiler"")",not sure,882587436819449e8,256
"biocLite(""org.Hs.eg.db"")",not sure,882587436819449e8,256
"biocLite(""ReactomePA"")",not sure,882587436819449e8,256
"runAnalysis <- function(dd, scale) {     my.inits <- function() {         list()     }     my.params <- get.params()     dd <- list(data = dd, inits = my.inits, params = get.params())     bugs <- run.model(dd, n.thin = scale, n.iter = (10000) *          scale, n.burnin = 10 * scale, n.chains = 3)     return(list(data = dd, bugs = bugs, summary = bugs$BUGSoutput$summary)) }",setup,126196742756292e8,257
library(ChIPseeker),visualization,882587436819449e8,256
library(TxDb.Hsapiens.UCSC.hg19.knownGene),visualization,882587436819449e8,256
library(httr),import,253183997003362e8,258
library(jsonlite),import,253183997003362e8,258
library(magrittr),import,253183997003362e8,258
"compareARIMA <- function(dataPoints, minRange, maxRange, iterations) {     jArima <- rArima <- c()     for (i in 1:iterations) {         tsData <- as.numeric(AirPassengers)         postJSON <- list(forecastPeriod = 10, tsdata = tsData)         JARIMAResult <- getARIMAForecast(model = ""j-arima"", payloadData = postJSON)         jArima %<>% append(JARIMAResult)         RARIMAResult <- getARIMAForecast(model = ""r-arima"", payloadData = postJSON)         rArima %<>% append(RARIMAResult)     }     results.list <- list(dataPoints = dataPoints, iterations = iterations,          jArimaResults = jArima, rARIMAResults = rArima, percentageDiff = abs(((rArima -              jArima)/rArima) * 100), variance = var(jArima, rArima),          correlation = cor(jArima, rArima))     return(results.list) }",exploratory,253183997003362e8,258
"if (!require(""pacman"")) install.packages(""pacman"")",not sure,371371071785688e8,259
"pacman::p_install_gh(""kahaaga/tstools"")",setup,371371071785688e8,259
"pacman::p_load(dplyr, data.table, pracma)",import,371371071785688e8,259
"summer.energy.data <- readRDS(""analysis/compiled_data.RData"")",import,371371071785688e8,259
"fraction.of.zeros <- readRDS(""analysis/fraction_of_zeros.RData"") %>%      as.data.frame",data cleaning,371371071785688e8,259
lags <- -12:12,data cleaning,371371071785688e8,259
E <- NULL,not sure,371371071785688e8,259
tau <- NULL,not sure,371371071785688e8,259
library.sizes <- 200,not sure,371371071785688e8,259
"lib <- c(1, dim(data)[1])",exploratory,371371071785688e8,259
pred <- lib,setup,371371071785688e8,259
samples.original <- 800,data cleaning,371371071785688e8,259
samples.surrogates <- 200,data cleaning,371371071785688e8,259
n.surrogates <- 400,data cleaning,371371071785688e8,259
"surrogate.methods <- c(""aaft"")",data cleaning,371371071785688e8,259
time.unit <- NULL,data cleaning,371371071785688e8,259
time.bin.size <- NULL,data cleaning,371371071785688e8,259
num.neighbours <- E + 1,data cleaning,371371071785688e8,259
random.libs <- TRUE,data cleaning,371371071785688e8,259
with.replacement <- TRUE,data cleaning,371371071785688e8,259
exclusion.radius <- 30,data cleaning,371371071785688e8,259
epsilon <- NULL,data cleaning,371371071785688e8,259
RNGseed <- 1111,data cleaning,371371071785688e8,259
silent <- TRUE,data cleaning,371371071785688e8,259
time.run <- F,data cleaning,371371071785688e8,259
print.to.console <- T,data cleaning,371371071785688e8,259
time.series.length.threshold <- 100,data cleaning,371371071785688e8,259
library_column <- 1,data cleaning,371371071785688e8,259
target_column <- 2,data cleaning,371371071785688e8,259
surrogate_column <- target_column,data cleaning,371371071785688e8,259
convergence.test <- TRUE,data cleaning,371371071785688e8,259
parallel <- TRUE,not sure,371371071785688e8,259
parallelize.on.each.lag <- F,data cleaning,371371071785688e8,259
num.cores <- parallel::detectCores() - 1,data cleaning,371371071785688e8,259
regression.convergence.plots <- F,data cleaning,371371071785688e8,259
always.run.surrogates <- F,data cleaning,371371071785688e8,259
n.libsizes.convergence.check <- 20,data cleaning,371371071785688e8,259
optimise.FNNdim <- T,data cleaning,371371071785688e8,259
optimise.boxcountdim <- T,data cleaning,371371071785688e8,259
min.E <- 2,data cleaning,371371071785688e8,259
max.E <- 10,data cleaning,371371071785688e8,259
min.tau <- 1,data cleaning,371371071785688e8,259
max.tau <- 1,data cleaning,371371071785688e8,259
plot.simplex.projection <- F,data cleaning,371371071785688e8,259
ccm <- list(),data cleaning,371371071785688e8,259
"thresholds <- seq(0, 500, 25)",data cleaning,371371071785688e8,259
"latitudes <- seq(-90, -90, 1)",data cleaning,371371071785688e8,259
bin.sizes <- c(1),data cleaning,371371071785688e8,259
"for (l in latitudes) {     for (b in bin.sizes) {         for (t in thresholds) {             cat(""latitude: "", l, ""\tbin.size: "", b, ""\tthreshold: "",                  t, ""\n"")             frac.zeros <- subset(x = fraction.of.zeros, subset = latitude ==                  l & threshold == t)$value[1]             if (frac.zeros > 0.02) {                 too.many.zeros <- TRUE                 cat(""Too many zeros for latitude = "", l, "" and threshold = "",                    t, "".\n\n"")             }             else {                 pracma::tic(gcFirst = T)                 df <- subset(x = summer.energy.data, subset = (threshold ==                    t & latitude == l), select = c(""SummerEnergy"",                    ""GSLSpeleoIce"")) %>% as.data.frame                 ccm.gslspel <- tstools::ccm_lagged(data = df,                    lags = lags, library.sizes = library.sizes,                    samples.original = samples.original, samples.surrogates = samples.surrogates,                    surrogate.methods = surrogate.methods, n.surrogates = n.surrogates,                    exclusion.radius = exclusion.radius, library.column = ""GSLSpeleoIce"",                    target.column = ""SummerEnergy"", surrogate.column = ""SummerEnergy"",                    optimise.FNNdim = optimise.FNNdim, optimise.boxcountdim = optimise.boxcountdim,                    parallel = parallel)                 ccm.gslspel$latitude <- rep(l)                 ccm.gslspel$bin.size <- rep(b)                 ccm.gslspel$threshold <- rep(t)                 df$threshold <- rep(t)                 filename <- paste(""SummerEnergyDrivesGSLSpeleoIce_"",                    toString(t), ""_"", toString(l), "".RData"", sep = """")                 path <- paste(""results/crossmap_summerenergy_GSL_speleoice/"",                    filename, sep = """")                 saveRDS(ccm.gslspel, path)                 print(Sys.time())                 print(head(ccm.gslspel))                 cat(""\n"")                 pracma::toc(echo = T)                 cat(""\n\n"")             }         }     } }",modeling,371371071785688e8,259
rm(list = ls()),not sure,371371071785688e8,259
"setwd(""~/Dropbox/Albert Xue/Research/Deployment/SHAPE-Seq_event_detector/"")",setup,371371071785688e8,259
"source(""support_functions/ShapeSeq_events.R"")",import,371371071785688e8,259
"source(""support_functions/find_concurrent_events.R"")",import,371371071785688e8,259
"source(""support_functions/plotting/make_visual.R"")",import,371371071785688e8,259
"source(""support_functions/load_data.R"")",import,371371071785688e8,259
"data_mat = load_data(""example_data/other_data/F_subtract.txt"")",import,371371071785688e8,259
"event_locations1 = read.csv(""analysis/F_subtract/replicates/F_subtract_1.csv"")",import,371371071785688e8,259
"event_locations2 = read.csv(""analysis/F_subtract/replicates/F_subtract_2.csv"")",import,371371071785688e8,259
"event_locations3 = read.csv(""analysis/F_subtract/replicates/F_subtract_3.csv"")",import,371371071785688e8,259
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,829776427242905e8,260
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,829776427242905e8,260
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,829776427242905e8,260
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,829776427242905e8,260
"source(""analysis/utils.R"")",visualization,829776427242905e8,260
"source(""analysis/analysis.R"")",visualization,829776427242905e8,260
"summarize_analyses <- function(analyses) {     function_type <- analyses$`function-type` %>% group_by(function_id) %>%          summarize(function_type = first(function_type))     function_distribution <- analyses$`function-name` %>% group_by(function_id) %>%          summarize(count = sum(as.numeric(count))) %>% left_join(function_type,          by = ""function_id"")     count_by_type <- function_distribution %>% group_by(function_type) %>%          summarize(call_count = sum(as.numeric(count)), function_count = n()) %>%          ungroup() %>% mutate(relative_call_count = call_count/sum(as.numeric(call_count)))     list(function_distribution = function_distribution, count_by_type = count_by_type) }",visualization,829776427242905e8,260
"visualize_analyses <- function(analyses) {     count_by_type <- analyses$count_by_type %>% mutate(function_type = ifelse(function_type ==          ""cl"", ""Closure"", ifelse(function_type == ""bu"", ""Builtin"",          ""Special"")))     total_call_count <- sum(as.numeric(analyses$count_by_type$call_count))     call_count <- count_by_type %>% ggplot(aes(function_type,          weight = relative_call_count)) + geom_bar() + scale_y_continuous(sec.axis = sec_axis(~. *          total_call_count, labels = count_labels), labels = relative_labels) +          labs(y = ""Count (%)"", x = ""Function Type"", title = ""Call Distribution"") +          scale_fill_gdocs()     function_count <- count_by_type %>% ggplot(aes(function_type,          weight = function_count)) + geom_bar() + scale_y_continuous(labels = count_labels) +          labs(y = ""Count"", x = ""Function Type"", title = ""Function distribution"") +          scale_fill_gdocs()     list(call_count = call_count, function_count = function_count) }",visualization,829776427242905e8,260
latex_analyses <- function(analyses) { },communication,829776427242905e8,260
"main <- function() {     analyzer <- create_analyzer(""Function Distribution"", combine_analyses,          summarize_analyses, visualize_analyses, latex_analyses)     drive_analysis(analyzer) }",communication,829776427242905e8,260
main(),setup,829776427242905e8,260
warnings(),evaluation,829776427242905e8,260
library(magrittr),setup,960460263537243e8,261
library(plyr),setup,960460263537243e8,261
library(dplyr),setup,960460263537243e8,261
library(ggplot2),setup,960460263537243e8,261
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,960460263537243e8,261
"record = read.csv(""Analysis/Parsed Data/pilots_production.csv"")",import,960460263537243e8,261
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",visualization,960460263537243e8,261
"ggsave(""Analysis/Plots/record_subj.png"")",export,960460263537243e8,261
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",visualization,960460263537243e8,261
"ggsave(""Analysis/Plots/record_section.png"")",export,960460263537243e8,261
"afc = read.csv(""Analysis/Parsed Data/pilots_4afc.csv"")",import,960460263537243e8,261
"afc %<>% mutate(Mapping = ifelse(Subj == ""1MK"", 1, ifelse(Subj ==      ""2DC"", 1, ifelse(Subj == ""3BR"", 1, ifelse(Subj == ""4KK"",      1, ifelse(Subj == ""5HB"", 2, ifelse(Subj == ""6MA"", 2, ifelse(Subj ==          ""7SQ"", 2, ifelse(Subj == ""8EW"", 2, NA)))))))))",data cleaning,960460263537243e8,261
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",data cleaning,960460263537243e8,261
"make.agg.df <- function(data.dir = ""analysis/data/csv-bysession"",      agg.dir = ""analysis/data/csv-aggregate"") {     source(""analysis/make.mofo.df.R"")     files <- list.files(path = data.dir, pattern = ""*.csv$"",          full.names = TRUE)     df.list <- lapply(X = files, FUN = make.mofo.df)     df.agg <- Reduce(function(x, y) merge(x, y, all = TRUE),          df.list)     write.csv(x = df.agg, file = paste(agg.dir, ""child-mofo-all.csv"",          sep = ""/""), row.names = FALSE)     return(df.agg) }",data cleaning,573538944823667e8,262
library(synapser),import,573538944823667e8,262
synLogin(),communication,573538944823667e8,262
"source(""../../bin/nf1TumorHarmonization.R"")",import,573538944823667e8,262
"prefix = paste(lubridate::today(), ""bioBank_glioma_cNF"", sep = ""-"")",evaluation,573538944823667e8,262
"biobank = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study  FROM syn13363852 WHERE ( ( \""assay\"" = 'rnaSeq' ) AND ( \""fileFormat\"" = 'sf' ) )"")$asDataFrame()",export,573538944823667e8,262
"gliomanf1 = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn11614207 WHERE ( ( \""assay\"" = 'rnaSeq' ) )"")$asDataFrame()",export,573538944823667e8,262
"cnf = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn9702734 WHERE ( ( \""parentId\"" = 'syn5493036' ) AND ( \""assay\"" = 'rnaSeq' ) AND ( \""individualID\"" IS NOT NULL ) )"")$asDataFrame()",export,573538944823667e8,262
"full.metadata <- rbind(dplyr::select(biobank, c(id, age, sex,      tumorType, isCellLine, study)), dplyr::select(gliomanf1,      c(id, age, sex, tumorType, isCellLine, study)), dplyr::select(cnf,      c(id, age, sex, tumorType, isCellLine, study))) %>% mutate(Sex = tolower(sex))",data cleaning,573538944823667e8,262
rownames(full.metadata) <- full.metadata$id,data cleaning,573538944823667e8,262
"fv.tab <- rbind(biobank, gliomanf1, cnf)",data cleaning,573538944823667e8,262
"tab.with.metadata <- plotMetadata(fv.tab, prefix)",exploratory,573538944823667e8,262
library(biomaRt),import,573538944823667e8,262
"mart = useMart(""ensembl"", dataset = ""hsapiens_gene_ensembl"")",import,573538944823667e8,262
"my_chr <- c(1:22, ""X"", ""Y"")",evaluation,573538944823667e8,262
"map <- getBM(attributes = c(""ensembl_transcript_id"", ""hgnc_symbol""),      mart = mart, filters = ""chromosome_name"", values = my_chr)",export,573538944823667e8,262
"bio.genes = do.call(""rbind"", lapply(biobank$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T, sep = ""\t"") %>% separate(Name,          into = c(""ensembl_transcript_id"", NA)) %>% inner_join(map,          by = ""ensembl_transcript_id"") %>% group_by(hgnc_symbol) %>%          summarize(totalCounts = sum(NumReads))     data.frame(dplyr::select(tab, ""totalCounts"", Symbol = ""hgnc_symbol""),          synId = rep(x, nrow(tab))) }))",data cleaning,573538944823667e8,262
"gli.genes = do.call(""rbind"", lapply(gliomanf1$id, function(x) {     f = synGet(x)$path     tab <- read.table(gzfile(f), header = F)     colnames(tab) <- c(""ensemble"", ""Symbol"", ""Counts"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,573538944823667e8,262
"cnf.genes = do.call(""rbind"", lapply(cnf$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T)     names(tab) <- c(""Counts"", ""Symbol"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,573538944823667e8,262
"full.tab <- rbind(cnf.genes, gli.genes, bio.genes)",data cleaning,573538944823667e8,262
"with.z = full.tab %>% group_by(synId) %>% mutate(zScore = (totalCounts -      mean(totalCounts + 0.001, na.rm = T))/sd(totalCounts, na.rm = T))",evaluation,573538944823667e8,262
"this.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/analysis/2019-01-31/plotThreePublicDatasets.R""",evaluation,573538944823667e8,262
"analysis.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/bin/nf1TumorHarmonization.R""",evaluation,573538944823667e8,262
"genes.with.meta = analyzeMetdataWithGenes(with.z, tab.with.metadata,      prefix)",exploratory,573538944823667e8,262
"met.file = paste(prefix, ""metadataSummary.png"", sep = ""\\"")",evaluation,573538944823667e8,262
"dataset.dir = ""syn18134640""",evaluation,573538944823667e8,262
"gz1 = gzfile(paste(prefix, ""tidiedData.csv.gz"", sep = """"))",evaluation,573538944823667e8,262
"write.csv(genes.with.meta, gz1)",export,573538944823667e8,262
"sid = synStore(File(paste(prefix, ""tidiedData.csv.gz"", sep = """"),      parent = dataset.dir), used = unique(genes.with.meta$id),      executed = c(this.script, analysis.script))",export,573538944823667e8,262
"sapply(paste(prefix, c(""genesByStudy.png"", ""genesByTumor.png"",      ""metadataSummary.png""), sep = """"), function(x) synStore(File(x,      parent = dataset.dir), used = sid$properties$id, executed = c(this.script,      analysis.script)))",export,573538944823667e8,262
"pc.files = doPcaPlots(with.z, tab.with.metadata, prefix)",visualization,573538944823667e8,262
"pca.dir = ""syn18134641""",evaluation,573538944823667e8,262
"sapply(pc.files, function(x) synStore(File(x, parent = pca.dir),      used = sid$properties$id, executed = c(this.script, analysis.script)))",export,573538944823667e8,262
library(synapser),import,573538944823667e8,262
library(gridExtra),import,573538944823667e8,262
library(brms),import,573538944823667e8,262
theme_set(theme_bw(18)),setup,573538944823667e8,262
"source(""helper_scripts/helpers.r"")",import,573538944823667e8,262
"source(""helper_scripts/createLaTeXTable.R"")",import,573538944823667e8,262
"d = read.table(file = ""../data/data_exp1.csv"", sep = ""\t"", header = T,      quote = """")",evaluation,573538944823667e8,262
nrow(d),evaluation,573538944823667e8,262
"agr = d %>% select(redundant, RedundantProperty, NumDistractors,      SceneVariation) %>% gather(Utterance, Mentioned, -RedundantProperty,      -NumDistractors, -SceneVariation) %>% group_by(Utterance,      RedundantProperty, NumDistractors, SceneVariation) %>% summarise(Probability = mean(Mentioned),      ci.low = ci.low(Mentioned), ci.high = ci.high(Mentioned)) %>%      ungroup() %>% mutate(YMin = Probability - ci.low, YMax = Probability +      ci.high, Distractors = as.factor(NumDistractors))",exploratory,573538944823667e8,262
"ggplot(agr, aes(x = SceneVariation, y = Probability, color = Distractors,      group = 1)) + geom_point() + geom_errorbar(aes(ymin = YMin,      ymax = YMax)) + xlab(""Scene variation"") + ylab(""Probability of redundancy"") +      facet_wrap(~RedundantProperty)",visualization,573538944823667e8,262
"centered = cbind(d, myCenter(d[, c(""SufficientProperty"", ""Trial"",      ""SceneVariation"")]))",exploratory,573538944823667e8,262
contrasts(centered$redUtterance),exploratory,573538944823667e8,262
contrasts(centered$SufficientProperty),exploratory,573538944823667e8,262
"pairscor.fnc(centered[, c(""redUtterance"", ""SufficientProperty"",      ""SceneVariation"")])",exploratory,573538944823667e8,262
"m = glmer(redUtterance ~ cSufficientProperty * cSceneVariation +      (1 | gameid) + (1 | clickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m),exploratory,573538944823667e8,262
"m.simple = glmer(redUtterance ~ SufficientProperty * cSceneVariation -      cSceneVariation + (1 | gameid) + (1 | clickedType), data = centered,      family = ""binomial"")",modeling,573538944823667e8,262
summary(m.simple),exploratory,573538944823667e8,262
"centered = cbind(d[d$SceneVariation > 0, ], myCenter(d[d$SceneVariation >      0, c(""SufficientProperty"", ""Trial"", ""SceneVariation"")]))",evaluation,573538944823667e8,262
contrasts(centered$redUtterance),exploratory,573538944823667e8,262
contrasts(centered$SufficientProperty),exploratory,573538944823667e8,262
"m = glmer(redUtterance ~ cSufficientProperty * cSceneVariation +      (1 + cSceneVariation | gameid) + (1 | clickedType), data = centered,      family = ""binomial"")",modeling,573538944823667e8,262
summary(m),exploratory,573538944823667e8,262
"m.b.full = brm(redUtterance ~ cSufficientProperty * cSceneVariation +      (1 + cSufficientProperty * cSceneVariation | gameid) + (1 +      cSufficientProperty * cSceneVariation | clickedType), data = centered,      family = ""bernoulli"")",modeling,573538944823667e8,262
summary(m.b.full),exploratory,573538944823667e8,262
"plot(m.b.full, pars = c(""cSufficientProperty""))",visualization,573538944823667e8,262
"plot(m.b.full, pars = c(""cSceneVariation""))",visualization,573538944823667e8,262
"plot(m.b.full, pars = c(""cSufficientProperty:cSceneVariation""))",visualization,573538944823667e8,262
"mean(posterior_samples(m.b.full, pars = ""b_cSufficientProperty"") >      0)",evaluation,573538944823667e8,262
"mean(posterior_samples(m.b.full, pars = ""b_cSceneVariation"") >      0)",evaluation,573538944823667e8,262
"mean(posterior_samples(m.b.full, pars = ""b_cSufficientProperty:cSceneVariation"") >      0)",evaluation,573538944823667e8,262
d$ratioTypicalityUnModmod = d$ColorTypicalityUnModified/d$ColorTypicalityModified,evaluation,573538944823667e8,262
d$ratioTypicalityModUnmod = d$ColorTypicalityModified/d$ColorTypicalityUnModified,evaluation,573538944823667e8,262
d$diffTypicalityModUnmod = d$ColorTypicalityModified - d$ColorTypicalityUnModified,evaluation,573538944823667e8,262
d$diffOtherTypicalityModUnmod = d$OtherColorTypicalityModified -      d$OtherColorTypicalityUnModified,evaluation,573538944823667e8,262
d$ratioTypDiffs = d$diffTypicalityModUnmod/d$diffOtherTypicalityModUnmod,evaluation,573538944823667e8,262
d$diffTypDiffs = d$diffTypicalityModUnmod - d$diffOtherTypicalityModUnmod,evaluation,573538944823667e8,262
"d$ColorclickedType = as.factor(paste(d$clickedColor, d$clickedType))",evaluation,573538944823667e8,262
"maxclickedTypes = unique(d[order(d[, c(""diffTypicalityModUnmod"")],      decreasing = T), c(""clickedType"", ""clickedColor"", ""diffTypicalityModUnmod"")])$clickedType[1:4]",evaluation,573538944823667e8,262
"maxt = droplevels(subset(d, d$clickedType %in% maxclickedTypes))",evaluation,573538944823667e8,262
nrow(maxt),evaluation,573538944823667e8,262
"agr = maxt %>% group_by(clickedColor, clickedType, ColorclickedType,      SufficientProperty, diffTypicalityModUnmod) %>% summarize(ProportionRedundant = mean(redundant),      CILow = ci.low(redundant), CIHigh = ci.high(redundant))",exploratory,573538944823667e8,262
agr = as.data.frame(agr),evaluation,573538944823667e8,262
agr$YMin = agr$ProportionRedundant - agr$CILow,evaluation,573538944823667e8,262
agr$YMax = agr$ProportionRedundant + agr$CIHigh,evaluation,573538944823667e8,262
"ggplot(agr, aes(x = diffTypicalityModUnmod, y = ProportionRedundant,      color = clickedType, group = clickedType)) + geom_point() +      geom_line(size = 2) + scale_x_continuous(name = ""Typicality gain"",      limits = c(-0.15, 0.45), breaks = seq(-0.1, 0.4, by = 0.1)) +      ylab(""Proportion of redundant utterances"") + geom_text(aes(label = clickedColor,      y = ProportionRedundant + 0.05), size = 6) + facet_wrap(~SufficientProperty)",visualization,573538944823667e8,262
"ggsave(""../writing/pics/maxtypicalitydiff.pdf"", width = 10, height = 4.5)",export,573538944823667e8,262
"centered = cbind(maxt, myCenter(maxt[, c(""SufficientProperty"",      ""NumDistractors"", ""NumSameDistractors"", ""Trial"", ""SceneVariation"",      ""ColorTypicality"", ""normTypicality"", ""TypicalityDiff"", ""ColorTypicalityModified"",      ""normTypicalityModified"", ""TypicalityDiffModified"", ""ColorTypicalityUnModified"",      ""normTypicalityUnModified"", ""TypicalityDiffUnModified"", ""ratioTypicalityUnModmod"",      ""ratioTypicalityModUnmod"", ""diffTypicalityModUnmod"", ""ratioTypDiffs"",      ""diffTypDiffs"")]))",evaluation,573538944823667e8,262
contrasts(centered$redUtterance),exploratory,573538944823667e8,262
summary(centered),exploratory,573538944823667e8,262
nrow(centered),evaluation,573538944823667e8,262
"summary(centered[, c(""SceneVariation"", ""redUtterance"", ""diffTypicalityModUnmod"",      ""SufficientProperty"")])",exploratory,573538944823667e8,262
"m.diff = glmer(redUtterance ~ cSceneVariation + cSufficientProperty +      cSceneVariation:cSufficientProperty + cdiffTypicalityModUnmod:cSufficientProperty +      (1 | gameid) + (1 | ColorclickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.diff),exploratory,573538944823667e8,262
"createLatexTable(m.diff, predictornames = c(""Intercept"", ""Scene variation"",      ""Sufficient property"", ""Scene variation : Sufficient property"",      ""Sufficient property : Typicality gain""))",export,573538944823667e8,262
"m.diff.simple = glmer(redUtterance ~ cSceneVariation + cSceneVariation:SufficientProperty +      SufficientProperty * cdiffTypicalityModUnmod - cdiffTypicalityModUnmod +      (1 | gameid) + (1 | ColorclickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.diff.simple),exploratory,573538944823667e8,262
"m = glmer(redUtterance ~ cSceneVariation + cSufficientProperty +      cSceneVariation:cSufficientProperty + cColorTypicality:cSufficientProperty +      (1 | gameid) + (1 | ColorclickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m),exploratory,573538944823667e8,262
"m.simple = glmer(redUtterance ~ cSceneVariation + cSufficientProperty +      cSceneVariation:cSufficientProperty + cColorTypicality:SufficientProperty -      cColorTypicality + (1 | gameid) + (1 | ColorclickedType),      data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.simple),exploratory,573538944823667e8,262
"centered = cbind(d, myCenter(d[, c(""SufficientProperty"", ""NumDistractors"",      ""NumSameDistractors"", ""Trial"", ""SceneVariation"", ""ColorTypicality"",      ""normTypicality"", ""TypicalityDiff"", ""ColorTypicalityModified"",      ""normTypicalityModified"", ""TypicalityDiffModified"", ""ColorTypicalityUnModified"",      ""normTypicalityUnModified"", ""TypicalityDiffUnModified"", ""ratioTypicalityUnModmod"",      ""ratioTypicalityModUnmod"", ""diffTypicalityModUnmod"", ""ratioTypDiffs"",      ""diffTypDiffs"")]))",evaluation,573538944823667e8,262
contrasts(centered$redUtterance),exploratory,573538944823667e8,262
summary(centered),exploratory,573538944823667e8,262
nrow(centered),evaluation,573538944823667e8,262
"m.diff = glmer(redUtterance ~ cSceneVariation + cSufficientProperty +      cSceneVariation:cSufficientProperty + cdiffTypicalityModUnmod:cSufficientProperty +      (1 | gameid) + (1 | clickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.diff),exploratory,573538944823667e8,262
"m.diff.simple = glmer(redUtterance ~ cSceneVariation + cSceneVariation:SufficientProperty +      SufficientProperty * cdiffTypicalityModUnmod - cdiffTypicalityModUnmod +      (1 | gameid) + (1 | clickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.diff.simple),exploratory,573538944823667e8,262
"m.diff.simple.notyp = glmer(redUtterance ~ cSceneVariation +      cSceneVariation:SufficientProperty + SufficientProperty +      (1 | gameid) + (1 | clickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m.diff.simple.notyp),exploratory,573538944823667e8,262
"anova(m.diff.simple.notyp, m.diff.simple)",evaluation,573538944823667e8,262
"m = glmer(redUtterance ~ cSceneVariation + cSufficientProperty +      cSceneVariation:cSufficientProperty + cColorTypicality:cSufficientProperty +      (1 | gameid) + (1 | ColorclickedType), data = centered, family = ""binomial"")",modeling,573538944823667e8,262
summary(m),exploratory,573538944823667e8,262
"cor(d$diffTypicalityModUnmod, d$ColorTypicality)",evaluation,573538944823667e8,262
"cor(d$ColorTypicalityModified, d$ColorTypicality)",evaluation,573538944823667e8,262
"cor(d$ColorTypicalityUnModified, d$ColorTypicality)",evaluation,573538944823667e8,262
"gathered = d %>% select(ColorTypicalityModified, ColorTypicalityUnModified) %>%      gather(TypicalityType, Value)",evaluation,573538944823667e8,262
"gathered$UtteranceType = as.factor(ifelse(gathered$TypicalityType ==      ""ColorTypicalityModified"", ""modified"", ""unmodified""))",evaluation,573538944823667e8,262
"dens = ggplot(gathered, aes(x = Value, fill = UtteranceType)) +      geom_density(alpha = 0.3) + xlab(""Typicality"") + scale_fill_discrete(name = ""Utterance type"") +      theme(legend.position = c(0.2, 0.85))",visualization,573538944823667e8,262
"diffs = ggplot(d, aes(x = diffTypicalityModUnmod)) + geom_histogram(binwidth = 0.03) +      xlab(""Typicality gain"") + geom_vline(xintercept = 0, color = ""blue"")",visualization,573538944823667e8,262
"pdf(""../writing/pics/typicality-dists.pdf"", height = 4, width = 11)",export,573538944823667e8,262
"grid.arrange(dens, diffs, nrow = 1)",setup,573538944823667e8,262
dev.off(),export,573538944823667e8,262
mean(d$ColorTypicalityModified),evaluation,573538944823667e8,262
sd(d$ColorTypicalityModified),evaluation,573538944823667e8,262
mean(d$ColorTypicalityUnModified),evaluation,573538944823667e8,262
sd(d$ColorTypicalityUnModified),evaluation,573538944823667e8,262
library(tidyverse),import,573538944823667e8,262
library(readxl),import,573538944823667e8,262
"dataSetOri <- read_excel(""PhD/Systematic Reviews/History of Power Estimation Studies/SecondaryAnalysisData2018.03.25.xlsx"",      sheet = ""Data_prop_reporting_PA"")",import,573538944823667e8,262
dataSetOri <- as.data.frame(dataSetOri),evaluation,573538944823667e8,262
dataSet <- dataSetOri,evaluation,573538944823667e8,262
"for (i in 1:nrow(dataSet)) {     for (j in 1:ncol(dataSet)) {         if (!is.na(as.numeric(dataSet[i, j]))) {             if ((dataSet[i, j] < 0.99) && (dataSet > 0)) {                 dataSet[i, j] <- ((sum(rbinom(dataSet$NumberOfArticlesExamined[i],                    1, 0.5)))/(dataSet$NumberOfArticlesExamined[i]))             }             else if (dataSet[i, j] == 1) {                 dataSet[i, j] <- rbinom(n = 1, size = 1, prob = 0.5)             }             else {                 dataSet[i, j] <- round(rchisq(1, 40))             }         }         else {             dataSet[i, j] <- dataSet[i, j]         }     } }",evaluation,573538944823667e8,262
"for (i in 1:length(dataSet$YearsStudied)) {     if (is.na(as.numeric(dataSet$YearsStudied[i]) && (!is.na(dataSet$YearsStudied[i])))) {         firstYear <- round(runif(1, 1962, 2017))         secondYear <- firstYear + round(rchisq(1, 2))         if ((secondYear > 2017) || (secondYear <= firstYear)) {             secondYear <- firstYear + 1         }         dataSet$YearsStudied[i] <- paste(firstYear, ""-"", secondYear,              sep = """")     }     else if (!is.na(as.numeric(dataSet$YearsStudied[i])))          dataSet$YearsStudied[i] <- round(runif(1, 1962, 2018)) }",evaluation,573538944823667e8,262
years <- dataSet$YearsStudied,evaluation,573538944823667e8,262
medianYear <- as.numeric(years),evaluation,573538944823667e8,262
"for (i in 1:length(years)) {     if ((is.na(as.numeric(years)[i])) && (!is.na(as.numeric(unlist(strsplit(years[i],          ""-""))[2])))) {         minYear <- unlist(strsplit(years[i], ""-""))[1]         maxYear <- unlist(strsplit(years[i], ""-""))[2]         yearRange <- (minYear:maxYear)         medianYear[i] <- median(yearRange)     } }",evaluation,573538944823667e8,262
dataSet$medianYear <- medianYear,evaluation,573538944823667e8,262
"dat <- subset(dataSet, is.na(dataSet$exclude))",evaluation,573538944823667e8,262
"dat <- dat[order(dat$medianYear), ]",evaluation,573538944823667e8,262
dat$xi <- round(dat$ProportionReportingPA * dat$NumberOfArticlesExamined),evaluation,573538944823667e8,262
"dat <- escalc(measure = ""PFT"", xi = xi, ni = NumberOfArticlesExamined,      data = dat)",evaluation,573538944823667e8,262
"res <- rma(yi, vi, method = ""REML"", data = dat)",evaluation,573538944823667e8,262
"pred <- predict(res, transf = transf.ipft.hm, targs = list(ni = dat$NumberOfArticlesExamined))",modeling,573538944823667e8,262
pred,evaluation,573538944823667e8,262
"dat.back <- summary(dat, transf = transf.ipft, ni = dat$NumberOfArticlesExamined)",exploratory,573538944823667e8,262
"forest(dat.back$yi, ci.lb = dat.back$ci.lb, ci.ub = dat.back$ci.ub,      psize = 1, xlim = c(-0.8, 1.5), alim = c(0, 1), ylim = c(-1.1,          28.7), refline = NA, digits = 3L, xlab = ""Proportion"",      slab = dat.back$PaperCitation)",modeling,573538944823667e8,262
"addpoly(pred$pred, ci.lb = pred$ci.lb, ci.ub = pred$ci.ub, row = -0.5,      digits = 3, mlab = ""REML Model"", efac = 1.3)",modeling,573538944823667e8,262
abline(h = 0.4),visualization,573538944823667e8,262
"text(-0.8, 28, ""Study"", pos = 4)",visualization,573538944823667e8,262
"text(1.5, 28, ""Proportion [95% CI]"", pos = 2)",visualization,573538944823667e8,262
"res1 <- rma(yi, vi, method = ""REML"", data = dat, mods = medianYear)",modeling,573538944823667e8,262
"pred1 <- predict(res1, transf = transf.ipft.hm, targs = list(ni = dat$NumberOfArticlesExamined))",modeling,573538944823667e8,262
pred1,evaluation,573538944823667e8,262
cexs <- 1/dat$vi,evaluation,573538944823667e8,262
cexs <- 1 + (cexs - min(cexs))/(max(cexs) - min(cexs)),evaluation,573538944823667e8,262
"plot(NA, NA, xlab = ""Year"", ylab = ""Proportion"", xlim = c(min(dat$medianYear),      max(dat$medianYear)), ylim = c(0, 1), bty = ""l"")",visualization,573538944823667e8,262
"lines(dat$medianYear, pred1$ci.lb, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,573538944823667e8,262
"lines(dat$medianYear, pred1$ci.ub, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,573538944823667e8,262
"lines(dat$medianYear, pred1$pred, col = ""darkgray"", lwd = 2)",visualization,573538944823667e8,262
"points(dat$medianYear, transf.ipft(dat$yi, dat$NumberOfArticlesExamined),      pch = 19, cex = cexs)",visualization,573538944823667e8,262
library(gplots),import,573538944823667e8,262
library(ogbox),import,573538944823667e8,262
"source(""R/puristOut.R"")",import,573538944823667e8,262
"source(""R/rnaCoexist.R"")",import,573538944823667e8,262
"rnaSeq = read.table(""data/linnarsonSingleCell/mouseRNASeq_Zeisel 2015.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = F)",import,573538944823667e8,262
"rnaMeta = rnaSeq[1:10, 3:ncol(rnaSeq)]",evaluation,573538944823667e8,262
rnaMeta = as.data.frame(t(rnaMeta)),evaluation,573538944823667e8,262
"colnames(rnaMeta) = rnaSeq[1:10, 2]",evaluation,573538944823667e8,262
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",evaluation,573538944823667e8,262
"rnaExp = apply(rnaExp, 2, as.numeric)",evaluation,573538944823667e8,262
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",evaluation,573538944823667e8,262
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",evaluation,573538944823667e8,262
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",evaluation,573538944823667e8,262
"maximExp = apply(rnaExp, 1, max)",evaluation,573538944823667e8,262
"rnaExp = rnaExp[maximExp >= 1, ]",evaluation,573538944823667e8,262
"markerGenes = puristOut(""analysis//01.Gene Selection//FinalGenes/PyramidalDeep/Cortex/"")",export,573538944823667e8,262
"tresholds = read.table(""analysis/02.Mouse Single Cell/noTresh"")",import,573538944823667e8,262
"tresholds = tresholds[maximExp >= 1, ]",evaluation,573538944823667e8,262
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,635592728620395e8,263
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,635592728620395e8,263
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,635592728620395e8,263
"rnaCoexist(rnaExp, tresholds, markerGenes, T, paste0(""analysis//02.Mouse Single Cell/Output/NoTreshold""),      paste0(""analysis//02.Mouse Single Cell/Plots/NoTreshold""),      cores = 16)",modeling,573538944823667e8,262
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,635592728620395e8,263
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,635592728620395e8,263
library(quickpsy),import,573538944823667e8,262
library(tidyverse),import,573538944823667e8,262
library(circular),import,573538944823667e8,262
library(cowplot),import,573538944823667e8,262
library(PropCIs),import,573538944823667e8,262
library(R.utils),import,573538944823667e8,262
"sourceDirectory(""R"")",import,573538944823667e8,262
"source(""graphical_parameters.R"")",import,573538944823667e8,262
"setwd(""/Users/threeprime/Dropbox/NIMBioS_END/extinctions/Analysis"")",modeling,635592728620395e8,263
"datpha <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = ""phase"",      session = as.character(1:4))",import,573538944823667e8,262
"datpha$participant <- datpha$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,573538944823667e8,262
"datpha <- datpha %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,573538944823667e8,262
"avpha <- datpha %>% group_by(participant, freq) %>% summarise(n = n(),      k = sum(response)) %>% group_by(participant, freq) %>% do({     m <- .$k/.$n     ci <- exactci(.$k, .$n, 0.05)$conf.int     data.frame(m = m, inf = ci[1], sup = ci[2]) })",evaluation,573538944823667e8,262
"data_dir <- file.path("".."", ""Data"")",setup,635592728620395e8,263
"fig_dir <- file.path("".."", ""Figures"")",setup,635592728620395e8,263
"source(""functions/coextDeg_beta.R"")",import,635592728620395e8,263
"source(""functions/coextNumber_beta.R"")",import,635592728620395e8,263
"source(""functions/netcascade.R"")",import,635592728620395e8,263
args <- commandArgs(trailingOnly = F),evaluation,774579960154369e8,262
print(length(args)),communication,774579960154369e8,262
print(args),communication,774579960154369e8,262
"beta.par <- matrix(c(0.1, 1, 0.5, 1, 1, 1, 3, 3, 4, 0.1, 0.2,      0.2), byrow = TRUE, ncol = 2)",setup,635592728620395e8,263
"readdir <- sub(""-"", """", args[length(args)])",evaluation,774579960154369e8,262
"if (length(dir) == 0 | readdir == ""-no-readline"" | readdir ==      ""/usr/lib/R/bin/exec/R"" | readdir == ""/usr/lib64/R/bin/exec/R"" |      readdir == ""/usr/global/R/3.0.1/lib64/R/bin/exec/R"" | readdir ==      ""/Library/Frameworks/R.framework/Resources/bin/exec/x86_64/R"") {     print(""No args given: using defaut directory!"")     readdir = ""Proxlike/072314/Prx24"" }",evaluation,774579960154369e8,262
print(readdir),communication,774579960154369e8,262
"rownames(beta.par) = c(""exp"", ""power"", ""unif"", ""normal"", ""left"",      ""bimod"")",setup,635592728620395e8,263
"if (substr(readdir, 1, 1) == ""/"") simdir = readdir else {     simdir = paste(""../Sims/"", readdir, sep = """") }",evaluation,774579960154369e8,262
"subdirs = c(""/DiskB-2"", ""/DiskB-3"")",evaluation,774579960154369e8,262
"source(""../Analysis/DiskUtils.R"")",import,774579960154369e8,262
"source(""../Analysis/ReadDiskFns.R"")",import,774579960154369e8,262
"survgrid = array(data = NA, dim = c(length(subdirs), 4), dimnames = list(subdirs,      c(""surv"", ""stab"", ""rEdge"", ""rAbin"")))",evaluation,774579960154369e8,262
"pdf(file = ""R_input_beta.pdf"")",export,635592728620395e8,263
l.disk = list(),evaluation,774579960154369e8,262
l.diskimg = list(),evaluation,774579960154369e8,262
l.time = list(),evaluation,774579960154369e8,262
"par(mfrow = c(3, 2))",visualization,635592728620395e8,263
l.surv.per = list(),evaluation,774579960154369e8,262
l.stab.per = list(),evaluation,774579960154369e8,262
l.edge = list(),evaluation,774579960154369e8,262
"for (i in 1:nrow(beta.par)) {     hist(rbeta(1000, beta.par[i, 1], beta.par[i, 2]), main = rownames(beta.par)[i],          xlab = ""R"") }",visualization,635592728620395e8,263
dev.off(),visualization,635592728620395e8,263
"for (dirnum in 1:length(subdirs)) {     dir = paste(readdir, subdirs[dirnum], sep = """")     aeidir = paste(simdir, subdirs[dirnum], ""/Out/AeiOutFiles/"",          sep = """")     print(aeidir)     source(""../Analysis/ReadDiskData.R"")     source(""../Analysis/ReadDiskAnalysis.R"")     l.disk[[dirnum]] = disk     l.diskimg[[dirnum]] = diskimg     l.time[[dirnum]] = time     l.surv.per[[dirnum]] = surv.per     l.stab.per[[dirnum]] = stab.per     l.edge[[dirnum]] = edge     survgrid[dirnum, 1] = l.surv.per[[dirnum]][length(l.stab.per[[dirnum]])]     survgrid[dirnum, 2] = l.stab.per[[dirnum]][length(l.stab.per[[dirnum]])]     survgrid[dirnum, 3] = r0[edge[length(edge)]]     survgrid[dirnum, 4] = rA[edge[length(edge)]] }",evaluation,774579960154369e8,262
"emp_net_path <- file.path(data_dir, ""nets_emp"")",setup,635592728620395e8,263
"sink(paste(simdir, ""/SurvGrid.txt"", sep = """"))",export,774579960154369e8,262
print(survgrid),communication,774579960154369e8,262
sink(),export,774579960154369e8,262
emp_nets <- dir(path = emp_net_path),import,635592728620395e8,263
"source(""../Analysis/ReadDiskPlot4.R"")",import,774579960154369e8,262
"if (length(args) > 2) q(""no"")",evaluation,774579960154369e8,262
list.net.deg <- list(),setup,635592728620395e8,263
list.net.numb <- list(),setup,635592728620395e8,263
mat_empirical <- list(),setup,635592728620395e8,263
library(ggplot2),import,774579960154369e8,262
library(dplyr),import,774579960154369e8,262
library(car),import,774579960154369e8,262
"for (p in 1:length(emp_nets)) {     mat_empirical[[p]] <- as.matrix(read.table(file.path(emp_net_path,          emp_nets[p]))) }",import,635592728620395e8,263
"if (!require(""gplots"")) {     install.packages(""gplots"", dependencies = TRUE)     library(gplots) }",import,723313512979075e8,262
"if (!require(""RColorBrewer"")) {     install.packages(""RColorBrewer"", dependencies = TRUE)     library(RColorBrewer) }",import,723313512979075e8,262
"if (!require(""cluster"")) {     install.packages(""cluster"", dependencies = TRUE)     library(cluster) }",import,723313512979075e8,262
"if (!require(""tidyverse"")) {     install.packages(""tidyverse"", dependencies = TRUE)     library(tidyverse) }",import,723313512979075e8,262
"sapply(lapply(mat_empirical, rowSums), min)",evaluation,635592728620395e8,263
"if (!require(""reshape2"")) {     install.packages(""reshape2"", dependencies = TRUE)     library(reshape2) }",import,723313512979075e8,262
"d897 <- read.csv(""analysis/clustering/kmeans/data/897_motor_nms.csv"",      comment.char = ""#"")",import,723313512979075e8,262
length(mat_empirical),exploratory,635592728620395e8,263
d897_nms_domains9 = d897[68:76],evaluation,723313512979075e8,262
"kmeans_nms_domains_models = vector(""list"", 11)",evaluation,723313512979075e8,262
"for (i in 1:length(kmeans_nms_domains_models)) {     kmeans_nms_domains_models[[i]] = kmeans(x = d897_nms_domains9,          centers = i + 1, iter.max = 30, nstart = 20) }",evaluation,723313512979075e8,262
"filtered_d897_nms_domains = d897[c(68:76, 3:7, 82, 33, 81)]",evaluation,723313512979075e8,262
"filtered_d897_nms_domains_withClusters = vector(""list"", 11)",evaluation,723313512979075e8,262
"for (p in 1:length(mat_empirical)) {     mat <- mat_empirical[[p]]     if (min(c(rowSums(mat), colSums(mat))) == 0) {         stop(""Hey, you have a species in your network that does not interact with any other species. The following functions will get stuck."")     }     m <- nrow(mat)     n <- ncol(mat)     list.deg <- list()     list.numb <- list()     for (k in 1:nrow(beta.par)) {         list.deg[[k]] <- coextDeg_beta(imatrix = mat, nsims = 1000,              beta_par1_T1 = beta.par[k, 1], beta_par2_T1 = beta.par[k,                  2], beta_par1_T2 = beta.par[k, 1], beta_par2_T2 = beta.par[k,                  2])         list.numb[[k]] <- coextNumber_beta(imatrix = mat, nsims = 1000,              beta_par1_T1 = beta.par[k, 1], beta_par2_T1 = beta.par[k,                  2], beta_par1_T2 = beta.par[k, 1], beta_par2_T2 = beta.par[k,                  2])     }     list.net.deg[[p]] <- list.deg     list.net.numb[[p]] <- list.numb }",evaluation,635592728620395e8,263
for (i in 1:length(filtered_d897_nms_domains_withClusters)) {     filtered_d897_nms_domains_withClusters[[i]] = kmeans_nms_domains_models[[i]]$cluster },evaluation,723313512979075e8,262
"nms_heatmaps = vector(""list"", 11)",evaluation,723313512979075e8,262
q = 8,setup,635592728620395e8,263
"for (i in 1:length(kmeans_nms_domains_models)) {     only_nms_domains_centers_data = kmeans_nms_domains_models[[i]]$centers     ordered_heat_map_data = only_nms_domains_centers_data[do.call(order,          lapply(1:NCOL(only_nms_domains_centers_data), function(i) only_nms_domains_centers_data[,              i])), ]     rownames(ordered_heat_map_data) = 1:nrow(ordered_heat_map_data)     melted_heat_map_data = melt(ordered_heat_map_data)     names(melted_heat_map_data) = c(Var1 = ""Clusters"", Var2 = ""NMS_domains"",          value = ""value"")     nms_heatmaps[[i]] = ggplot(data = melted_heat_map_data, aes(x = Clusters,          y = NMS_domains, fill = value)) + geom_tile(aes(fill = value)) +          geom_text(aes(label = round(value, 1))) + scale_fill_gradient(low = ""white"",          high = ""red"") }",visualization,723313512979075e8,262
Temp.deg <- list.net.deg[[q]],setup,635592728620395e8,263
library(knitr),import,723313512979075e8,262
Temp.numb <- list.net.numb[[q]],setup,635592728620395e8,263
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,723313512979075e8,262
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,723313512979075e8,262
"Temp.numb <- lapply(Temp.numb, log)",evaluation,635592728620395e8,263
"par(mfrow = c(2, 1), mar = c(3, 4, 2, 2))",visualization,635592728620395e8,263
"boxplot(Temp.deg[[1]], Temp.deg[[2]], Temp.deg[[3]], Temp.deg[[4]],      Temp.deg[[5]], main = ""Degree"", col = ""darkgray"")",visualization,635592728620395e8,263
"for (i in seq(1, (dim(mastersheet)[1]))) {     strain <- mastersheet[i, 1]     dir <- mastersheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain) }",export,723313512979075e8,262
"boxplot(Temp.numb[[1]], Temp.numb[[2]], Temp.numb[[3]], Temp.numb[[4]],      Temp.numb[[5]], main = ""Number"", col = ""darkgray"")",visualization,635592728620395e8,263
"axis(1, at = 1:5, label = rownames(beta.par))",visualization,635592728620395e8,263
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",setup,723313512979075e8,262
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",setup,723313512979075e8,262
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",setup,723313512979075e8,262
m <- 10,setup,635592728620395e8,263
n <- 5,setup,635592728620395e8,263
"test_master_sheet <- (rbind(test1, test2, test3))",setup,723313512979075e8,262
"mat <- matrix(rbinom(100, 10, 0.1), m, n)",setup,635592728620395e8,263
"for (i in seq(1, (dim(test_master_sheet)[1]))) {     strain <- test_master_sheet[i, 1]     dir <- test_master_sheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"))     print(dir)     print(strain) }",export,723313512979075e8,262
rm(list = ls()),setup,723313512979075e8,262
"if (min(c(rowSums(mat), colSums(mat))) == 0) stop(""Hey, you have a species in your network that does not interact with any other species. The following functions will get stuck."")",evaluation,635592728620395e8,263
library(ggplot2),import,723313512979075e8,262
library(mixRSVP),import,723313512979075e8,262
"par(mfrow = c(2, 3))",visualization,635592728620395e8,263
library(dplyr),import,723313512979075e8,262
library(magrittr),import,723313512979075e8,262
library(BayesFactor),import,723313512979075e8,262
"hist(list.deg[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
"setwd(""~/gitCode/nStream/"")",setup,723313512979075e8,262
"source(""ggplotElements.R"")",import,723313512979075e8,262
"hist(list.deg[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
"hist(list.deg[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
theme_set(theme_apa(base_size = 20)),setup,723313512979075e8,262
"hist(list.deg[[4]], xlab = ""number"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
"hist(list.deg[[5]], xlab = ""number"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
"par(mfrow = c(2, 3))",visualization,635592728620395e8,263
"inclusionBF <- function(priorProbs, variable) {     if (typeof(priorProbs) == ""S4"")          priorProbs <- as.vector(priorProbs)     theseNames <- names(priorProbs)     nProbs <- 1:length(priorProbs)     variableMatches <- grep(variable, theseNames)     if (grepl("":"", variable)) {         subordinateVariables <- variable %>% strsplit("":"") %>%              unlist()         thisRegex <- paste0(subordinateVariables, collapse = "".*\\+.*"")         subordinateEffects <- grep(thisRegex, theseNames, perl = T)         subordinateEffects <- subordinateEffects[!subordinateEffects %in%              variableMatches]         sum(priorProbs[variableMatches])/sum(priorProbs[subordinateEffects])     }     else {         interactionMatches <- grep(paste0(variable, ""(?=:)|(?<=:)"",              variable), theseNames, perl = T)         variableMainEffects <- variableMatches[!variableMatches %in%              interactionMatches]         otherMainEffects <- nProbs[!nProbs %in% c(variableMainEffects,              interactionMatches)]         sum(priorProbs[variableMainEffects])/sum(priorProbs[otherMainEffects])     } }",evaluation,723313512979075e8,262
"hist(list.numb[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",exploratory,635592728620395e8,263
testPositions = T,evaluation,723313512979075e8,262
plots <- F,evaluation,723313512979075e8,262
"hist(list.numb[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",exploratory,635592728620395e8,263
if (plots) {     savePlots <- F },setup,723313512979075e8,262
saveIndividualTSV <- F,setup,723313512979075e8,262
saveAllErrorsTSV <- F,setup,723313512979075e8,262
participantPlots <- T,setup,723313512979075e8,262
"hist(list.numb[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",visualization,635592728620395e8,263
bootstrapPredictions <- F,setup,723313512979075e8,262
nRepetitions <- 1000,setup,723313512979075e8,262
"dataPath <- ""rawData/18Streams""",setup,723313512979075e8,262
pracTrials <- 1:20,setup,723313512979075e8,262
maxTrials <- 270,setup,723313512979075e8,262
"group = ""SONA/18Streams""",setup,723313512979075e8,262
"if (plots) {     if (savePlots) {         if (!""plots"" %in% list.dirs(full.names = F)) {             dir.create(""plots"")         }         if (!group %in% list.dirs(path = ""plots"", full.names = F)) {             dir.create(paste0(""plots/"", group))         }     } }",setup,723313512979075e8,262
"files <- list.files(pattern = ""^18[A-Z][A-Z].*\\.txt$"", path = dataPath,      full.names = T)",setup,723313512979075e8,262
print(files),communication,723313512979075e8,262
widthPix = 1024,setup,723313512979075e8,262
heightPix = 768,setup,723313512979075e8,262
monitorwidth = 40.5,setup,723313512979075e8,262
viewingDist = 42,setup,723313512979075e8,262
pixelsPerDegree = widthPix/(atan(monitorwidth/viewingDist)/pi *      180),setup,723313512979075e8,262
rate = 1000/12,setup,723313512979075e8,262
"eyetrackerFiles <- list.files(path = ""rawData/18Streams/Eyetracker"",      full.names = T)",setup,723313512979075e8,262
criterion = 1,setup,723313512979075e8,262
"skew <- function(x) {     denom <- (sd(x, na.rm = T)^3) * (length(which(!is.na(x))) -          1) * (length(which(!is.na(x))) - 2)     deviation <- x[!is.na(x)] - mean(x, na.rm = T)     numer <- sum(deviation^3) * length(which(!is.na(x)))     numer/denom }",evaluation,723313512979075e8,262
totalRows <- length(files) * 250,setup,723313512979075e8,262
"allErrors <- data.frame(exp = character(totalRows), condition = character(totalRows),      SPE = numeric(totalRows), targetSP = numeric(totalRows),      ID = character(totalRows), fixationReject = logical(totalRows),      button = numeric(totalRows), ring = numeric(totalRows), stringsAsFactors = F)",evaluation,723313512979075e8,262
startRow <- 1,setup,723313512979075e8,262
"for (dataset in files) {     temp <- read.table(dataset, sep = ""\t"", header = T, stringsAsFactors = F)     if (testPositions) {         print(xtabs(~ring + nStreams, data = temp))         print(xtabs(~whichStreamCuedAngle0 + ring, data = temp))     }     temp <- temp[-pracTrials, ]     participant <- temp$subject[1]     temp %<>% mutate(responsePos = cuePos0 + responsePosRelative0)     thisEyetrackerFile <- eyetrackerFiles[grepl(paste0("".*"",          participant, "".*""), eyetrackerFiles)]     temp %<>% mutate(fixationReject = FALSE)     if (length(thisEyetrackerFile) > 0) {         theseFixations <- read.table(thisEyetrackerFile, sep = ""\t"",              stringsAsFactors = F, header = T)         theseFixations %<>% mutate(CURRENT_FIX_X_DEG = CURRENT_FIX_X/pixelsPerDegree)         theseFixations %<>% mutate(CURRENT_FIX_Y_DEG = CURRENT_FIX_Y/pixelsPerDegree)         theseFixations %<>% filter(!TRIAL_INDEX %in% pracTrials)         theseFixations %<>% mutate(fixationDistance = 0)         for (index in unique(theseFixations$TRIAL_INDEX)) {             theseFixationsThisTrial = which(theseFixations$TRIAL_INDEX ==                  index)             nFixationsThisTrial <- length(theseFixationsThisTrial)             if (nFixationsThisTrial > 1) {                 initialFixationX = theseFixations$CURRENT_FIX_X_DEG[theseFixationsThisTrial[1]]                 initialFixationY = theseFixations$CURRENT_FIX_Y_DEG[theseFixationsThisTrial[1]]                 for (thisFixationRow in theseFixationsThisTrial) {                   if (thisFixationRow == theseFixationsThisTrial[1]) {                   }                   else {                     xVector <- theseFixations$CURRENT_FIX_X_DEG[thisFixationRow] -                        initialFixationX                     yVector <- theseFixations$CURRENT_FIX_Y_DEG[thisFixationRow] -                        initialFixationY                     fixationDistance <- sqrt(xVector^2 + yVector^2)                     theseFixations$fixationDistance[thisFixationRow] <- fixationDistance                     if (fixationDistance >= criterion) {                       if (!theseFixations$CURRENT_FIX_BLINK_AROUND[thisFixationRow] %in%                          c(""BEFORE"", ""AFTER"")) {                         temp %<>% mutate(fixationReject = replace(fixationReject,                            trialnum == index - 1, TRUE))                       }                     }                   }                 }             }         }         if (mean(temp$fixationReject) > 0.4) {             next         }     }     streamColumns <- grep(""streamLtrSequence"", colnames(temp))     endRow = startRow + nrow(temp) - 1     allErrors[startRow:endRow, ] <- temp[, c(1, 4, 16, 8, 3,          37, 7, 5)]     startRow <- endRow + 1     if (saveIndividualTSV) {         write.table(twoStreams[!twoStreams$fixationReject, ],              paste0(""wrangledData/"", group, ""/twoStreams/"", participant,                  "".txt""), sep = ""\t"", col.names = T, row.names = F)         write.table(eighteenStreams[!eighteenStreams$fixationReject,              ], paste0(""wrangledData/"", group, ""/eighteenStreams/"",              participant, "".txt""), sep = ""\t"", col.names = T,              row.names = F)     }     print(mean(temp$fixationReject)) }",data cleaning,723313512979075e8,262
nStreams <- allErrors %>% pull(condition) %>% unique,evaluation,723313512979075e8,262
participants <- allErrors %>% pull(ID) %>% unique,evaluation,723313512979075e8,262
nReps <- 100,setup,723313512979075e8,262
bounds <- parameterBounds(),setup,723313512979075e8,262
bounds$upper[3] <- 3,setup,723313512979075e8,262
runAnyway <- TRUE,setup,723313512979075e8,262
plots <- FALSE,setup,723313512979075e8,262
"nParamFiles <- length(list.files(path = ""modelOutput"", pattern = ""parameterEstimates.*\\.csv"",      full.names = T))",setup,723313512979075e8,262
"source(""https://bioconductor.org/biocLite.R"")",setup,254228336270899e8,264
"if (nParamFiles > 0) {     print(""we out here"")     paramFiles <- list.files(path = ""modelOutput"", pattern = ""parameterEstimates.*\\.csv"",          full.names = T)     splits <- strsplit(paramFiles, ""Estimates|(?<=[0-9][0-9])_|\\.csv"",          perl = T)     theseDates <- lapply(splits, FUN = function(x) paste(x[2],          x[3])) %>% unlist %>% as.POSIXct(., format = ""%d-%m-%Y %H-%M-%S"")     whichMaxDate <- which(theseDates == max(theseDates))     params <- read.csv(paramFiles[whichMaxDate])     notModelled <- allErrors %>% filter(., !ID %in% params$ID) %>%          pull(ID) %>% unique     unModelledRows <- expand.grid(ID = factor(notModelled), condition = factor(unique(allErrors$condition)),          efficacy = 999, latency = 999, precision = 999, val = 999,          valGuessing = 999, pLRtest = 999, stringsAsFactors = F)     params <- rbind(params, unModelledRows) } else {     notModelled <- allErrors %>% pull(ID) %>% unique     params <- expand.grid(ID = factor(notModelled), condition = factor(unique(allErrors$condition)),          efficacy = 999, latency = 999, precision = 999, val = 999,          valGuessing = 999, pLRtest = 999, stringsAsFactors = F) }",data cleaning,723313512979075e8,262
"biocLite(""GenomicFeatures"")",exploratory,254228336270899e8,264
"biocLite(""GenomicRanges"")",not sure,254228336270899e8,264
"if (length(notModelled) > 0) {     for (thisParticipant in notModelled) {         for (thisCondition in unique(allErrors$condition)) {             print(paste0(""Participant: "", thisParticipant, "". Condition: "",                  thisCondition))             theseParams <- allErrors %>% filter(., condition ==                  thisCondition, ID == thisParticipant) %>% analyzeOneCondition(.,                  24, bounds, nReps)             if (theseParams$pLRtest < 0.05) {                 params %<>% mutate(efficacy = replace(efficacy,                    ID == thisParticipant & condition == thisCondition,                    theseParams$efficacy)) %>% as.data.frame()                 params %<>% mutate(latency = replace(latency,                    ID == thisParticipant & condition == thisCondition,                    theseParams$latency)) %>% as.data.frame()                 params %<>% mutate(precision = replace(precision,                    ID == thisParticipant & condition == thisCondition,                    theseParams$precision)) %>% as.data.frame()             }             else {                 params %<>% mutate(efficacy = replace(efficacy,                    ID == thisParticipant & condition == thisCondition,                    0)) %>% as.data.frame()                 params %<>% mutate(latency = replace(latency,                    ID == thisParticipant & condition == thisCondition,                    NaN)) %>% as.data.frame()                 params %<>% mutate(precision = replace(precision,                    ID == thisParticipant & condition == thisCondition,                    NaN)) %>% as.data.frame()             }             params %<>% mutate(val = replace(val, ID == thisParticipant &                  condition == thisCondition, theseParams$val)) %>%                  as.data.frame()             params %<>% mutate(valGuessing = replace(valGuessing,                  ID == thisParticipant & condition == thisCondition,                  theseParams$valGuessing)) %>% as.data.frame()             params %<>% mutate(pLRtest = replace(pLRtest, ID ==                  thisParticipant & condition == thisCondition,                  theseParams$pLRtest)) %>% as.data.frame()         }     }     write.csv(params, paste0(""modelOutput/parameterEstimates"",          format(Sys.time(), ""%d-%m-%Y_%H-%M-%S""), "".csv""), row.names = F) }",export,723313512979075e8,262
"biocLite(""SummarizedExperiment"")",not sure,254228336270899e8,264
"biocLite(""VariantAnnotation"")",not sure,254228336270899e8,264
nParticipants <- params %>% pull(ID) %>% unique %>% length,evaluation,723313512979075e8,262
"biocLite(""RMySQL"")",not sure,254228336270899e8,264
params %<>% mutate(stringID = ID),evaluation,723313512979075e8,262
"biocLite(""systemPipeR"")",not sure,254228336270899e8,264
"biocLite(""codetools"")",not sure,254228336270899e8,264
"biocLite(""DiffBind"")",not sure,254228336270899e8,264
"params %<>% mutate(ID = as.factor(rep(1:nParticipants, times = 3)))",evaluation,723313512979075e8,262
params %<>% mutate(condition = ordered(condition)),evaluation,723313512979075e8,262
"paramsForAnalysis <- params %>% filter(efficacy > 0.1 & efficacy <      bounds[1, 2] & efficacy > bounds[1, 1] & latency < bounds[2,      2] & latency > bounds[2, 1] & precision < bounds[3, 2] &      precision > bounds[3, 1])",evaluation,723313512979075e8,262
library(GenomicFeatures),setup,254228336270899e8,264
paramsForAnalysis %<>% mutate(latency = latency * rate),evaluation,723313512979075e8,262
paramsForAnalysis %<>% mutate(precision = precision * rate),evaluation,723313512979075e8,262
library(GenomicRanges),setup,254228336270899e8,264
library(SummarizedExperiment),setup,254228336270899e8,264
library(VariantAnnotation),setup,254228336270899e8,264
"efficacyBF <- anovaBF(efficacy ~ condition + ID, data = paramsForAnalysis,      whichRandom = ""ID"")",evaluation,723313512979075e8,262
"ggplot(paramsForAnalysis, aes(x = condition, y = efficacy)) +      geom_jitter(position = position_dodge(0.9)) + stat_summary(geom = ""point"",      fun.y = mean, position = position_dodge(0.9)) + stat_summary(geom = ""errorbar"",      fun.data = mean_se, position = position_dodge(0.9)) + lims(y = c(0,      1))",visualization,723313512979075e8,262
"latencyBF <- anovaBF(latency ~ condition + ID, data = paramsForAnalysis,      whichRandom = ""ID"")",evaluation,723313512979075e8,262
"ggplot(paramsForAnalysis, aes(x = condition, y = latency)) +      geom_point(position = position_dodge(0.9)) + stat_summary(geom = ""point"",      fun.y = mean, position = position_dodge(0.9)) + stat_summary(geom = ""errorbar"",      fun.data = mean_se, position = position_dodge(0.9))",visualization,723313512979075e8,262
"precisionBF <- anovaBF(precision ~ condition + ring + ID, data = paramsForAnalysis,      whichRandom = ""ID"")",visualization,723313512979075e8,262
"ggplot(paramsForAnalysis, aes(x = condition, y = precision)) +      geom_violin(position = position_dodge(0.9)) + geom_jitter(position = position_dodge(0.9)) +      stat_summary(geom = ""point"", fun.y = mean, position = position_dodge(0.9)) +      stat_summary(geom = ""errorbar"", fun.data = mean_se, position = position_dodge(0.9))",visualization,723313512979075e8,262
paramsForAnalysis %<>% mutate(ID = stringID) %>% as.data.frame(),evaluation,723313512979075e8,262
"if (participantPlots) {     for (thisParticipant in unique(paramsForAnalysis$ID)) {         for (thisCondition in unique(paramsForAnalysis$condition)) {             thisEfficacy <- paramsForAnalysis %>% filter(ID ==                  thisParticipant & condition == thisCondition) %>%                  pull(efficacy)             thisLatency <- paramsForAnalysis %>% filter(ID ==                  thisParticipant & condition == thisCondition) %>%                  pull(latency) %>% `/`(1000/12)             thisPrecision <- paramsForAnalysis %>% filter(ID ==                  thisParticipant & condition == thisCondition) %>%                  pull(precision) %>% `/`(1000/12)             theseErrors <- allErrors %>% filter(ID == thisParticipant &                  condition == thisCondition)             print(paste0(""Participant: "", thisParticipant, "". Condition: "",                  thisCondition, "". N = "", nrow(theseErrors)))             minError <- theseErrors %>% pull(SPE) %>% min             maxError <- theseErrors %>% pull(SPE) %>% max             thisRange <- seq(minError, maxError, 0.1)             theseDensities <- data.frame(SPE = thisRange, density = dnorm(thisRange,                  thisLatency, thisPrecision))             if (any(is.nan(theseDensities$density))) {                 print(theseDensities)             }             thisPlot <- ggplot(theseErrors, aes(x = SPE)) + geom_histogram(binwidth = 1) +                  geom_line(data = theseDensities, aes(x = SPE,                    y = density * nrow(theseErrors))) + scale_y_continuous(sec.axis = sec_axis(~./nrow(theseErrors),                  name = ""Density"")) + labs(y = ""Frequency"")             thisFileName <- paste0(""modelOutput/Plots/"", thisCondition,                  ""/"", thisParticipant, ""-"", format(Sys.time(),                    ""%d-%m-%Y_%H-%M-%S""), "".png"")             ggsave(filename = thisFileName, thisPlot, width = 16,                  height = 9)         }     } }",visualization,723313512979075e8,262
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/cleaning"")",setup,723313512979075e8,262
"source(""standardize_feature.R"")",import,723313512979075e8,262
"source(""subsets_list.R"")",import,723313512979075e8,262
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/ch1 discrimination/plots"")",setup,723313512979075e8,262
"source(""correlation.R"")",import,723313512979075e8,262
subsets_novictims <- subsets_list[5:length(subsets_list)],evaluation,723313512979075e8,262
subset_names <- names(subsets_list)[5:length(subsets_list)],evaluation,723313512979075e8,262
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,      2)))",evaluation,723313512979075e8,262
"ivs <- c(""black_not_white"", ""agency_offenders_count"", ""mean_inc"")",setup,723313512979075e8,262
"continuous_ivs <- c(""agency_offenders_count"", ""mean_inc"")",setup,723313512979075e8,262
"ivs_string <- paste0(ivs, "" + "", collapse = """")",setup,723313512979075e8,262
"iv_names <- c(""Constant"", ""Offender Black (ref = White)"", ""Offenders Reported to Agency"",      ""County Mean Income"")",setup,723313512979075e8,262
numSites = 500,setup,723313512979075e8,262
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/""",setup,723313512979075e8,262
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/""",setup,723313512979075e8,262
"case.name = c(""4fullread.10ind.over"")",setup,723313512979075e8,262
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.alt, case.name[cc], "".output/pval."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[4])) {                   pval_list[IX] = as.numeric(dat[4])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     save(""pval_list"", ""done_res"", file = paste0(path.alt, ""sum/pval."",          case.name[cc], "".Robj"")) }",export,723313512979075e8,262
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.null, case.name[cc], "".output/pval."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[4])) {                   pval_list[IX] = as.numeric(dat[4])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     save(""pval_list"", ""done_res"", file = paste0(path.null, ""sum/pval."",          case.name[cc], "".Robj"")) }",export,723313512979075e8,262
args = (commandArgs(TRUE)),setup,723313512979075e8,262
eval(parse(text = args[[1]])),evaluation,723313512979075e8,262
"setwd(""~/WaveQTL/R"")",setup,723313512979075e8,262
"Wmat_1024 = read.table(""../data/DWT/Wmat_1024"", as.is = TRUE)",import,723313512979075e8,262
W2mat_1024 = Wmat_1024 * Wmat_1024,setup,723313512979075e8,262
"WaveQTL.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/WaveQTL/""",setup,723313512979075e8,262
"wd.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/prepareData/""",setup,723313512979075e8,262
setwd(wd.path),setup,723313512979075e8,262
"path.fig = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/fig/ES/""",setup,723313512979075e8,262
"path.output = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/data/""",setup,723313512979075e8,262
"path.data = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/""",setup,723313512979075e8,262
"phenoD = as.matrix(read.table(paste0(path.data, ""pheno.dat."",      ss), as.is = TRUE))",evaluation,723313512979075e8,262
"genoD = scan(paste0(path.data, ""orig.geno.dat."", ss), what = double())",import,723313512979075e8,262
genoR = as.numeric(round(genoD)),data cleaning,723313512979075e8,262
wh0 = which(genoR == 0),data cleaning,723313512979075e8,262
wh1 = which(genoR == 1),data cleaning,723313512979075e8,262
wh2 = which(genoR == 2),data cleaning,723313512979075e8,262
"if ((length(wh0) > 2) & (length(wh1) > 2)) {     sig0 = apply(phenoD[wh0, ], 2, mean)     sig1 = apply(phenoD[wh1, ], 2, mean)     library(wavethresh)     sig.all = c(sig0, sig1)     sig.all.smooth = BAYES.THR(sig.all)     sig0.smooth = sig.all.smooth[1:1024]     sig1.smooth = sig.all.smooth[1025:2048]     val = 6     cut.thresh = val/70     delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh)     sig1.smooth[delix] = sig0.smooth[delix]     wh.zero = which(sig0.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig0.smooth[wh.zero] = 1/70     }     wh.zero = which(sig1.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig1.smooth[wh.zero] = 1/70     }     beta_mean_path = paste0(WaveQTL.path, ""output/res."", ss,          "".fph.mean.txt"")     beta_var_path = paste0(WaveQTL.path, ""output/res."", ss, "".fph.var.txt"")     sel_geno_IX = 1     beta_mean = as.numeric(read.table(beta_mean_path)[sel_geno_IX,          2:1025])     beta_dataS = as.vector(-matrix(data = beta_mean, nr = 1,          nc = 1024) %*% as.matrix(Wmat_1024))     beta_var = as.numeric(read.table(beta_var_path)[sel_geno_IX,          2:1025])     beta_var_dataS = as.vector(matrix(data = beta_var, nr = 1,          nc = 1024) %*% as.matrix(W2mat_1024))     beta_sd_dataS = sqrt(beta_var_dataS)     WaveQTL.mean = beta_dataS     WaveQTL.sd = beta_sd_dataS     wh = which(abs(WaveQTL.mean) < 2 * WaveQTL.sd)     WaveQTL.mean.sig2 = WaveQTL.mean     WaveQTL.mean.sig2[wh] = 0     wh = which(abs(WaveQTL.mean) < 3 * WaveQTL.sd)     WaveQTL.mean.sig3 = WaveQTL.mean     WaveQTL.mean.sig3[wh] = 0     raw.data = phenoD     raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))     wh = which(raw.data.T == 0)     this.path = paste0(path.output, ""smooth.ratio.2."", ss)     res = 1 + 70 * WaveQTL.mean.sig2/raw.data.T     res[wh] = 1     write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,          quote = FALSE)     this.path = paste0(path.output, ""smooth.ratio.3."", ss)     res = 1 + 70 * WaveQTL.mean.sig3/raw.data.T     res[wh] = 1     write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,          quote = FALSE)     png(paste0(path.fig, ""ESWaveQTL"", ss, "".png""), height = 4,          width = 7, units = ""in"", res = 300)     numBPs = 1024     xmin = 1     xmax = numBPs     xval = xmin:xmax     nf <- layout(matrix(1:3, 3, 1, byrow = TRUE))     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Major Homozygotes, dark green from multiseq"")     lines(xval, sig0, type = ""l"", col = ""orange"")     lines(xval, sig0.smooth, type = ""l"", col = ""red"")     axis(2, font = 2)     box()     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Heterozygotes"")     lines(xval, sig1, type = ""l"", col = ""skyblue"")     lines(xval, sig1.smooth, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,          WaveQTL.mean)     ymin = min(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,          WaveQTL.mean)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Major Homozygotes - Heterozygotes, effect size from WaveQTL (0, 2, 3 sd)"")     lines(xval, sig1.smooth - sig0.smooth, type = ""l"", col = ""green"")     lines(xval, WaveQTL.mean, type = ""l"", col = ""orange"")     lines(xval, WaveQTL.mean.sig2, type = ""l"", col = ""red"")     lines(xval, WaveQTL.mean.sig3, type = ""l"", col = ""blue"")     abline(h = 0)     axis(2, font = 2)     box()     dev.off()     png(paste0(path.fig, ""ESsimuWaveQTL"", ss, "".png""), height = 4,          width = 7, units = ""in"", res = 300)     nf <- layout(matrix(1:4, 4, 1, byrow = TRUE))     raw.data = phenoD     raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))     mu0.sig = rep(1/70, 1024)     sig0.WaveQTL = mu0.sig * raw.data.T     sig1.WaveQTL = sig0.WaveQTL - WaveQTL.mean.sig3     wh = which(sig1.WaveQTL < 0)     sig1.WaveQTL[wh] = 0     sig0 = sig0.WaveQTL     sig1 = sig1.WaveQTL     ymax = max(raw.data.T)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Raw data"")     lines(xval, raw.data.T, type = ""l"", col = ""black"")     axis(2, font = 2)     box()     ymax = max(sig0, sig1)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Expected mean g0: red g1: blue [WaveQTL]"")     lines(xval, sig0, type = ""l"", col = ""red"")     lines(xval, sig1, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig1 - sig0)     ymin = min(sig1 - sig0)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected difference (g1 - g0) [WaveQTL]"")     lines(xval, sig1 - sig0, type = ""l"", col = ""green"")     abline(h = 0)     axis(2, font = 2)     box()     wh1 = which(sig1 == 0)     wh0 = which(sig0 == 0)     min.val = min(sig1[-wh1], sig0[-wh0])     sig1[wh1] = min.val     sig0[wh0] = min.val     ymax = max(log(sig1) - log(sig0))     ymin = min(log(sig1) - log(sig0))     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected log ratio (log(g1) - log(g0)) [WaveQTL]"")     lines(xval, log(sig1) - log(sig0), type = ""l"", col = ""green"")     abline(h = 0)     axis(2, font = 2)     box()     dev.off() } else {     cat("""", file = paste0(path.fig, ""NG."", ss)) }",export,723313512979075e8,262
"sensAnalysisMultPoints <- function(sRandTs, png = FALSE, pngDir = ""M:/thesis_MSc/visualizations/sensAnalysis/"") {     sensRandTS <- NULL     ewsRandTSwins50bw4 <- NULL     ewsRandTSwins50bw7 <- NULL     ewsRandTSwins70bw4 <- NULL     ewsRandTSwins70bw7 <- NULL     for (randPoint in 1:nrow(sRandTs)) {         ts <- sRandTs[randPoint, 2:ncol(sRandTs)]         ts <- removeoutliers(ts, mildness = 1.5)         timeSteps <- (1:length(ts))         tsNames <- t(rbind(timeSteps, ts))         colnames(tsNames) <- c(""ndvi"", ""day16x"")         rownames(tsNames) <- (1:length(ts))         sensRandTS[[randPoint]] <- sensitivity_ews(tsNames, indicator = ""acf1"",              interpolate = T, detrending = ""gaussian"", bandwidthrange = c(2,                  10), incrbandwidth = 1, winsizerange = c(10,                  75), incrwinsize = 5)         if (png == TRUE) {             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, "".png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, "".png""), width = 600, height = 600)             ewsRandTSwins50bw4[[randPoint]] <- generic_ews(tsNames,                  winsize = 50, detrending = ""gaussian"", bandwidth = 4,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins50bw4.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins50bw4.png""), width = 600, height = 600)             ewsRandTSwins50bw7[[randPoint]] <- generic_ews(tsNames,                  winsize = 50, detrending = ""gaussian"", bandwidth = 7,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins50bw7.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins50bw7.png""), width = 600, height = 600)             ewsRandTSwins70bw4[[randPoint]] <- generic_ews(tsNames,                  winsize = 70, detrending = ""gaussian"", bandwidth = 4,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins70bw4.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins70bw4.png""), width = 600, height = 600)             ewsRandTSwins70bw7[[randPoint]] <- generic_ews(tsNames,                  winsize = 70, detrending = ""gaussian"", bandwidth = 7,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins70bw7.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins70bw7.png""), width = 600, height = 600)             graphics.off()         }     }     return(list(sensRandTS, ewsRandTSwins50bw4, ewsRandTSwins50bw7,          ewsRandTSwins70bw4, ewsRandTSwins70bw7)) }",export,723313512979075e8,262
library(dplyr),import,723313512979075e8,262
library(rstan),import,723313512979075e8,262
library(matrixStats),import,723313512979075e8,262
"fits <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit4.RDS"")",import,723313512979075e8,262
"mats <- data.frame(Int1 = NULL, Slope1 = NULL, Slope2 = NULL,      Int2 = NULL, lp__ = NULL, s = NULL)",setup,723313512979075e8,262
"for (i in 1:length(fits)) {     if (!(is.null(fits[[i]]))) {         tmpdat <- as.data.frame(extract(fits[[i]]))         tmpdat$s <- i         mats <- as.data.frame(rbind(mats, tmpdat))     } }",setup,723313512979075e8,262
"qs <- group_by(mats, s) %>% summarise(q = logSumExp(lp__) - log(n()))",evaluation,723313512979075e8,262
qs$p <- qs$q - logSumExp(qs$q),evaluation,723313512979075e8,262
"mats <- merge(mats, qs)",evaluation,723313512979075e8,262
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,723313512979075e8,262
set.seed(parameters$seed),setup,723313512979075e8,262
"newmcmc <- sample_n(mats, 8000, replace = T, weight = exp(mats$p))",evaluation,723313512979075e8,262
"saveRDS(newmcmc, ""analysis/mcmc-runs/ToRaising-Stan-Fit4-resample.RDS"")",export,723313512979075e8,262
siteSize = 2048,setup,723313512979075e8,262
"treatment = ""Copper""",setup,723313512979075e8,262
"strand = ""both""",setup,723313512979075e8,262
window.size = 100,setup,723313512979075e8,262
numSam = 6,setup,723313512979075e8,262
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,723313512979075e8,262
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete."",      600, "".Robj"")",setup,723313512979075e8,262
load(out.path),import,723313512979075e8,262
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,723313512979075e8,262
"pdf(""hist.statistic.pval.DESeq2.600.0.discrete.pdf"")",export,723313512979075e8,262
filter.cut = 0,setup,723313512979075e8,262
pval = pval.deseq.600.0,setup,723313512979075e8,262
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.600.min.pval."",      filter.cut, "".txt""))[, 1])",import,723313512979075e8,262
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.600.min.pval."",      filter.cut, "".txt""))[, 1])",import,723313512979075e8,262
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,723313512979075e8,262
xmax = 1,setup,723313512979075e8,262
xmin = 0,setup,723313512979075e8,262
"par(mfrow = c(3, 1))",setup,723313512979075e8,262
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,723313512979075e8,262
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,723313512979075e8,262
"hist(pval[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : pvalue [600]"", length(pval) - length(del.ix.deseq)),      xlim = c(xmin, xmax), xlab = ""p=value"")",visualization,723313512979075e8,262
dev.off(),visualization,723313512979075e8,262
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,723313512979075e8,262
"pdf(""hist.statistic.pval.DESeq2.600.0.discrete.pooling.pdf"")",export,723313512979075e8,262
filter.cut = 0,setup,723313512979075e8,262
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.600.all.pval."",      filter.cut, "".txt""))))",import,723313512979075e8,262
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.600.all.pval."",      filter.cut, "".txt""))))",import,723313512979075e8,262
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,723313512979075e8,262
xmax = 1,setup,723313512979075e8,262
xmin = 0,setup,723313512979075e8,262
"par(mfrow = c(2, 1))",setup,723313512979075e8,262
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,723313512979075e8,262
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,723313512979075e8,262
siteSize = 2048,visualization,728440370876342e7,265
dev.off(),visualization,723313512979075e8,262
"setwd(""C:/Users/morle001/Dropbox/Micro_IPOP"")",setup,723313512979075e8,262
library(foreign),import,723313512979075e8,262
library(dplyr),import,723313512979075e8,262
"plot.IO <- read.csv(""./Analysis/Cleaned_data/plot_IO_Y2.csv"")",import,723313512979075e8,262
"AQSEC2A <- read.dta(""./Data/Tanzania/2010_11/Stata/TZNPS2AGRDTA/AG_SEC2A.dta"",      convert.factors = TRUE)",import,723313512979075e8,262
"treatment = ""Copper""",not sure,728440370876342e7,265
"output <- filter(plot.IO, zaocode == ""Maize"") %>% select(y2_hhid,      plotnum, output.kg)",evaluation,723313512979075e8,262
output$y2_hhid <- as.character(output$y2_hhid),data cleaning,723313512979075e8,262
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,728440370876342e7,265
"area <- select(AQSEC2A, y2_hhid, plotnum, area = ag2a_09)",evaluation,723313512979075e8,262
"maize <- left_join(output, area)",data cleaning,723313512979075e8,262
"maize <- transform(maize, area = area * 0.40468564224)",data cleaning,723313512979075e8,262
"maize <- filter(maize, !(area == 0), !(output.kg == 0))",data cleaning,723313512979075e8,262
maize$yield <- maize$output.kg/maize$area,data cleaning,723313512979075e8,262
summary(maize),evaluation,723313512979075e8,262
"hist(maize$yield, breaks = 50, col = 50, main = ""maize yield"",      xlab = ""yield"")",visualization,723313512979075e8,262
"lon.lat <- read.csv(""./Analysis/Cleaned_data/lon_lat.csv"")",import,723313512979075e8,262
numSites.list = scan(path),exploratory,728440370876342e7,265
lon.lat$y2_hhid <- as.character(lon.lat$y2_hhid),data cleaning,723313512979075e8,262
"chr.list = sites.list = vector(""list"", 22)",exploratory,728440370876342e7,265
"x <- left_join(maize, select(lon.lat, y2_hhid, lon, lat))",data cleaning,723313512979075e8,262
"com <- ddply(x, .(lon, lat), summarize, avg = mean(yield, na.rm = TRUE))",exploratory,723313512979075e8,262
"TZA_map <- getData(""GADM"", country = ""TZA"", level = 1)",import,723313512979075e8,262
tf = fortify(TZA_map),setup,723313512979075e8,262
"ggplot(tf) + geom_polygon(aes(long, lat, fill = id), colour = ""black"") +      coord_map(""mercator"") + geom_point(data = com, aes(x = lon,      y = lat, colour = avg, size = 5))",visualization,723313512979075e8,262
"lon.lat <- read.csv(""./Analysis/Cleaned_data/lon_lat.csv"")",import,723313512979075e8,262
lon.lat$y2_hhid <- as.character(lon.lat$y2_hhid),data cleaning,723313512979075e8,262
"maize <- left_join(maize, select(lon.lat, y2_hhid, lon, lat))",data cleaning,723313512979075e8,262
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,728440370876342e7,265
"maize <- left_join(maize, select(plot.geo, y2_hhid, ea_id))",data cleaning,723313512979075e8,262
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,728440370876342e7,265
"maize.com <- ddply(maize, .(ea_id), )",exploratory,723313512979075e8,262
library(ggplot2),import,723313512979075e8,262
library(devtools),import,723313512979075e8,262
library(data.table),import,723313512979075e8,262
library(reshape2),import,723313512979075e8,262
library(survival),import,723313512979075e8,262
library(Hmisc),import,723313512979075e8,262
"save(""chr.list"", ""sites.list"", file = out.path)",export,728440370876342e7,265
library(Cairo),import,723313512979075e8,262
version_dcmMisc <- 0.1,setup,723313512979075e8,262
"if (""dcmMisc"" %in% rownames(installed.packages()) == FALSE) {     install_github(""dcmMisc"", username = ""dcmuller"", ref = paste0(""v"",          version_dcmMisc)) }",import,723313512979075e8,262
"if (installed.packages()[""dcmMisc"", ""Version""] != version_dcmMisc) {     warning(paste(""replacing dcmMisc with version"", version_randsurv))     install_github(""dcmMisc"", username = ""dcmuller"", ref = paste0(""v"",          version_dcmMisc)) }",import,723313512979075e8,262
library(dcmMisc),import,723313512979075e8,262
"params <- read.csv(""./analysis/output/o03_params.csv"", stringsAsFactors = FALSE)",import,723313512979075e8,262
siteSize = 1024,evaluation,728440370876342e7,265
params <- data.table(params),evaluation,723313512979075e8,262
"treatment = ""Copper""",evaluation,728440370876342e7,265
"samples <- read.csv(""./analysis/output/o03_all_samples.csv"",      stringsAsFactors = FALSE)",import,723313512979075e8,262
"seedling_mortality_data <- read.table(""./analysis/seedling_mortality_analysis/data/seedling_mortality_data.txt"",      header = T)",import,458421879447997e8,266
"samples <- rename(samples, c(""X"", ""param""), c(""sim_id"", ""param_type""))",data cleaning,723313512979075e8,262
samples$sim_id <- floor((samples$sim_id + 1)/2),data cleaning,723313512979075e8,262
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",setup,728440370876342e7,265
"samples <- data.table(samples, key = c(""settings"", ""model"", ""param_type""))",evaluation,723313512979075e8,262
"samples_long <- melt(samples, id.vars = c(""settings"", ""model"",      ""param_type"", ""sim_id""), measure.vars = c(""intercept"", ""exposure"",      ""matchvar_centred"", ""log_scale""), value.name = ""estimate"",      variable.name = ""param"")",data cleaning,723313512979075e8,262
numSites.list = scan(path),setup,728440370876342e7,265
samples_long <- data.table(samples_long),evaluation,723313512979075e8,262
samples_long$param <- as.character(samples_long$param),data cleaning,723313512979075e8,262
"seedling_mortality_data <- seedling_mortality_data[seedling_mortality_data$f.time !=      0, ]",data cleaning,458421879447997e8,266
"setkey(samples_long, settings, model, param_type, param)",setup,723313512979075e8,262
"summary_samples <- samples_long[, list(mean = mean(estimate),      sd = sd(estimate), min = min(estimate), max = max(estimate)),      by = c(""settings"", ""model"", ""param"", ""param_type"")]",exploratory,723313512979075e8,262
"setkey(summary_samples, model, param, param_type)",setup,723313512979075e8,262
summary_samples,evaluation,723313512979075e8,262
"tabcox <- summary_samples[(model == ""coxfull"" | model == ""conditional"" |      model == ""coxweighted"") & param == ""exposure"", list(settings,      model, param_type, mean, sd)]",exploratory,723313512979075e8,262
tabcox_1 <- tabcox[settings == 1],setup,723313512979075e8,262
"chr.list = sites.list = vector(""list"", 22)",evaluation,728440370876342e7,265
"tabcox_1[, `:=`(settings, NULL)]",setup,723313512979075e8,262
"tabcox_1 <- reshape(tabcox_1, v.names = c(""mean"", ""sd""), idvar = ""model"",      direction = ""wide"", timevar = ""param_type"")",data cleaning,723313512979075e8,262
"seedling_mortality_data$idia <- rep(seedling_mortality_data$dia[1:2048],      times = 4)",not sure,458421879447997e8,266
tabcox_1 <- data.frame(tabcox_1),evaluation,723313512979075e8,262
tabcox_2 <- tabcox[settings == 2],setup,723313512979075e8,262
"tabcox_2[, `:=`(settings, NULL)]",setup,723313512979075e8,262
"tabcox_2 <- reshape(tabcox_2, v.names = c(""mean"", ""sd""), idvar = ""model"",      direction = ""wide"", timevar = ""param_type"")",data cleaning,723313512979075e8,262
tabcox_2 <- data.frame(tabcox_2),evaluation,723313512979075e8,262
seedling_mortality_data$f.time <- factor(seedling_mortality_data$f.time),data cleaning,458421879447997e8,266
"tabcox <- rbind.data.frame(tabcox_2, tabcox_1)",data cleaning,723313512979075e8,262
"rownames(tabcox) <- c(""common disease"", """", "" "", ""rare disease"",      ""  "", ""   "")",data cleaning,723313512979075e8,262
"for (i in 1:ncol(tabcox)) {     if (is.numeric(tabcox[, i])) {         tabcox[, i] <- round(tabcox[, i], 3)     } }",data cleaning,723313512979075e8,262
"tabcox[[""model""]] <- ifelse(tabcox[[""model""]] == ""coxfull"", ""Full cohort"",      ifelse(tabcox[[""model""]] == ""coxweighted"", ""Weighted NCC"",          ""Conditional""))",data cleaning,723313512979075e8,262
"colnames(tabcox) <- c(""analysis"", ""mean(log HR)"", ""sd(log HR)"",      ""mean(se(log HR))"", ""sd(se(log HR))"")",data cleaning,723313512979075e8,262
"textab <- latex(tabcox, file = ""./analysis/output/t04_cox_full_vs_ncc_match.tex"",      booktabs = TRUE, rowlabel = """")",export,723313512979075e8,262
"samples_weighted <- samples[model == ""weighted"" & param_type ==      ""coef"", ]",evaluation,723313512979075e8,262
samples_weighted$sim <- c(1:nrow(samples_weighted)),evaluation,723313512979075e8,262
"x <- matrix(c(1, -1, 1, 0, 1, 1), nrow = 2)",setup,723313512979075e8,262
"xb <- as.matrix(samples_weighted[, list(intercept, exposure)]) %*%      x",evaluation,723313512979075e8,262
"samples_weighted <- data.frame(samples_weighted, xb)",evaluation,723313512979075e8,262
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",evaluation,728440370876342e7,265
"samples_weighted <- melt(samples_weighted, id.vars = c(""settings"",      ""model"", ""param_type"", ""sim_id"", ""sim"", ""intercept"", ""matchvar_centred"",      ""exposure"", ""log_scale""), value.name = ""xb"", variable.name = ""x"")",data cleaning,723313512979075e8,262
"t <- seq(30, 80, by = 0.5)",evaluation,723313512979075e8,262
"time_mat <- matrix(rep(t, each = nrow(samples_weighted)), nrow = nrow(samples_weighted))",evaluation,723313512979075e8,262
"pred <- cbind(samples_weighted, time_mat)",evaluation,723313512979075e8,262
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,728440370876342e7,265
"pred_long <- melt(pred, id.vars = c(""settings"", ""model"", ""param_type"",      ""sim_id"", ""sim"", ""intercept"", ""exposure"", ""matchvar_centred"",      ""log_scale"", ""x"", ""xb""), value.name = ""time"")",data cleaning,723313512979075e8,262
"save(""chr.list"", ""sites.list"", file = out.path)",export,728440370876342e7,265
pred_long <- data.table(pred_long),evaluation,723313512979075e8,262
pred_long$p <- 1/exp(pred_long$log_scale),evaluation,723313512979075e8,262
pred_long$lambda <- exp(-pred_long$p * pred_long$xb),evaluation,723313512979075e8,262
pred_long$surv <- exp(-pred_long$lambda * (pred_long$time - 30)^pred_long$p),evaluation,723313512979075e8,262
pred_long$pr <- 1 - pred_long$surv,evaluation,723313512979075e8,262
"pred_long$plotgroup <- paste0(pred_long$x, pred_long$sim)",evaluation,723313512979075e8,262
"surv_plot <- ggplot(data = pred_long[settings == 1], aes(x = time,      y = pr, group = plotgroup, colour = x))",visualization,723313512979075e8,262
surv_plot <- surv_plot + theme_bw(),visualization,723313512979075e8,262
siteSize = 2048,not sure,728440370876342e7,265
surv_plot <- surv_plot + geom_line(alpha = I(1/sqrt(max(pred_long$sim) *      8))),visualization,723313512979075e8,262
"surv_plot <- surv_plot + scale_x_continuous(name = ""Age (years)"")",visualization,723313512979075e8,262
"surv_plot <- surv_plot + scale_y_continuous(name = ""Cumulative probability"")",visualization,723313512979075e8,262
"hr <- exp(params[1, lhr1])",evaluation,723313512979075e8,262
"origin <- params[1, origin]",evaluation,723313512979075e8,262
"treatment = ""Selenium""",not sure,728440370876342e7,265
"weib_param <- params[1, weib_param1]",evaluation,723313512979075e8,262
"lambda0 <- c(1/hr, 1, hr) * params[1, baseline_rate1]",evaluation,723313512979075e8,262
"lambda0 <- rep(lambda0, each = length(t))",evaluation,723313512979075e8,262
surv_true <- exp(-lambda0 * (t - origin)^weib_param),evaluation,723313512979075e8,262
"true <- data.frame(time = t, surv = surv_true, lambda = lambda0,      pr = 1 - surv_true, plotgroup = rep(0, length(surv_true)),      x = rep(c(""X1"", ""X2"", ""X3""), each = length(t)))",evaluation,723313512979075e8,262
"surv_plot <- surv_plot + geom_line(data = true, aes(x = time,      y = pr, group = x))",visualization,723313512979075e8,262
"CairoPDF(file = ""./analysis/output/g04_cumul_risk_rare_match.pdf"",      width = 6, height = 5)",export,723313512979075e8,262
surv_plot,evaluation,723313512979075e8,262
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,629798089154065e8,267
dev.off(),export,723313512979075e8,262
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,629798089154065e8,267
"pred_long$plotgroup <- paste0(pred_long$x, pred_long$sim)",evaluation,723313512979075e8,262
"surv_plot <- ggplot(data = pred_long[settings == 2], aes(x = time,      y = pr, group = plotgroup, colour = x))",visualization,723313512979075e8,262
surv_plot <- surv_plot + theme_bw(),visualization,723313512979075e8,262
surv_plot <- surv_plot + geom_line(alpha = I(1/sqrt(max(pred_long$sim) *      8))),visualization,723313512979075e8,262
"surv_plot <- surv_plot + scale_x_continuous(name = ""Age (years)"")",visualization,723313512979075e8,262
"surv_plot <- surv_plot + scale_y_continuous(name = ""Cumulative probability"")",visualization,723313512979075e8,262
library(ggplot2),setup,629798089154065e8,267
"hr <- exp(params[2, lhr1])",evaluation,723313512979075e8,262
library(dplyr),setup,629798089154065e8,267
"origin <- params[2, origin]",evaluation,723313512979075e8,262
"weib_param <- params[2, weib_param1]",evaluation,723313512979075e8,262
"lambda0 <- c(1/hr, 1, hr) * params[2, baseline_rate1]",evaluation,723313512979075e8,262
"lambda0 <- rep(lambda0, each = length(t))",evaluation,723313512979075e8,262
library(magrittr),setup,629798089154065e8,267
surv_true <- exp(-lambda0 * (t - origin)^weib_param),evaluation,723313512979075e8,262
library(markerGeneProfile),setup,629798089154065e8,267
"true <- data.frame(time = t, surv = surv_true, lambda = lambda0,      pr = 1 - surv_true, plotgroup = rep(0, length(surv_true)),      x = rep(c(""X1"", ""X2"", ""X3""), each = length(t)))",evaluation,723313512979075e8,262
"filepath2 <- ""/Data/OilGasRigsSplit.csv""",setup,690942289773375e8,268
"surv_plot <- surv_plot + geom_line(data = true, aes(x = time,      y = pr, group = x))",visualization,723313512979075e8,262
"path <- c(getwd(), filepath2)",modeling,690942289773375e8,268
"CairoPDF(file = ""./analysis/output/g04_cumul_risk_common_match.pdf"",      width = 6, height = 5)",export,723313512979075e8,262
devtools::load_all(),setup,629798089154065e8,267
surv_plot,evaluation,723313512979075e8,262
dev.off(),export,723313512979075e8,262
set.seed(1),setup,629798089154065e8,267
"StanleyC = data.frame(Gene.Symbol = rn(StanleyCExp), Probe = paste(""p"",      1:nrow(StanleyCExp)), StanleyCExp)",data cleaning,629798089154065e8,267
"path <- paste(path, collapse = """")",not sure,690942289773375e8,268
"StanleyC = data.frame(Gene.Symbol = rn(StanleyCExp), StanleyCExp)",data cleaning,629798089154065e8,267
"OilGasRigsSplit <- read.csv(path, header = TRUE, sep = "","", stringsAsFactors = FALSE)",import,690942289773375e8,268
"OilGasRigsSplit <- OilGasRigsSplit[, -1]",data cleaning,690942289773375e8,268
"colnames(OilGasRigsSplit) <- c(""Date"", ""OilRigCount"", ""GasRigCount"",      ""MiscRigCount"", ""TotalRigCount"", ""PercOilRig"", ""PercGasRig"")",data cleaning,690942289773375e8,268
oldwd <- getwd(),setup,690942289773375e8,268
"filepath2 <- ""/Data/""",setup,690942289773375e8,268
"path <- c(getwd(), filepath2)",setup,690942289773375e8,268
"path <- paste(path, collapse = """")",setup,690942289773375e8,268
setwd(path),setup,690942289773375e8,268
"write.csv(OilGasRigsSplit, file = ""CleanOilGasRigsSplit.csv"")",export,690942289773375e8,268
setwd(oldwd),setup,690942289773375e8,268
library(car),setup,690942289773375e8,268
library(lattice),setup,690942289773375e8,268
library(ppcor),setup,690942289773375e8,268
library(ggplot2),setup,690942289773375e8,268
rm(list = ls()),setup,690942289773375e8,268
"data <- read.table(file = ""order2size"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2tran"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2erep"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2domain"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2dist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2expr"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2breadth"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""order2solo"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprtran"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprsize"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprerep"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprbreadth"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprdomain"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""exprdist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadthsize"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadthtran"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadtherep"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadthdomain"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadthexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""breadthdist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizetran"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizeorder_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizerep"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizedom_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizedist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""sizeexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""tranorder_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""tranerep"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""trandom"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""trandist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""tranexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""ordererep_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""orderdom_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""orderdist_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""orderexon_BIEN"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""erepdom"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""erepdist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""erepexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""domdist"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""domexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data <- read.table(file = ""distexon"", header = TRUE, sep = ""\t"")",import,690942289773375e8,268
"data_subset <- subset(data, breadth == ""low"")",import,690942289773375e8,268
"mod2 = lm(data_subset[[""Ka_pos""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,690942289773375e8,268
"setwd(""~/GitHub/SMU/Doing_Data_Science_1/CaseStudy/Beer analysis project"")",setup,723313512979075e8,262
"mod2 = lm(data_subset[[""Ka_neg""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,690942289773375e8,268
"beers_df = read.csv(""analysis/Data/Beers.csv"")",import,723313512979075e8,262
"breweries_df = read.csv(""analysis/Data/Breweries.csv"")",import,723313512979075e8,262
summary(mod2),exploratory,690942289773375e8,268
"Anova(mod2, type = ""2"")",exploratory,690942289773375e8,268
"colnames(breweries_df)[which(names(breweries_df) == ""Brew_ID"")] <- ""Brewery_ID""",data cleaning,723313512979075e8,262
"colnames(breweries_df)[which(names(breweries_df) == ""Name"")] <- ""Brewery_Name""",data cleaning,723313512979075e8,262
"colnames(beers_df)[which(names(beers_df) == ""Brewery_id"")] <- ""Brewery_ID""",data cleaning,723313512979075e8,262
"colnames(beers_df)[which(names(beers_df) == ""Name"")] <- ""Beer_Name""",data cleaning,723313512979075e8,262
"data[[""mutation""]] = factor(data[[""mutation""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
"data[[""recombination""]] = factor(data[[""recombination""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
"beer_brew_merge = merge(beers_df, breweries_df, by = c(""Brewery_ID""))",data cleaning,723313512979075e8,262
"data[[""order""]] = factor(data[[""order2""]], levels = c(""low"",      ""high""))",data cleaning,690942289773375e8,268
"data[[""size""]] = factor(data[[""size""]], levels = c(""low"", ""medium"",      ""high""))",data cleaning,690942289773375e8,268
"data[[""transcripts""]] = factor(data[[""transcripts""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
"data[[""distance""]] = factor(data[[""distance""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
"data[[""exons""]] = factor(data[[""exons""]], levels = c(""low"", ""medium"",      ""high""))",data cleaning,690942289773375e8,268
"data[[""expression""]] = factor(data[[""expression""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
"data[[""breadth""]] = factor(data[[""breadth""]], levels = c(""low"",      ""medium"", ""high""))",data cleaning,690942289773375e8,268
tail(beer_brew_merge),communication,723313512979075e8,262
"data[[""erep""]] = factor(data[[""erep""]], levels = c(""low"", ""high""))",data cleaning,690942289773375e8,268
"data[[""domain""]] = factor(data[[""domain""]], levels = c(""active"",      ""both"", ""inactive""))",data cleaning,690942289773375e8,268
"data[[""order""]] = factor(data[[""order""]], levels = c(""low"", ""medium"",      ""high"", ""sup""))",data cleaning,690942289773375e8,268
head(beer_brew_merge),exploratory,723313512979075e8,262
tail(beer_brew_merge),exploratory,723313512979075e8,262
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,690942289773375e8,268
summary(mod2),exploratory,690942289773375e8,268
"Anova(mod2, type = ""2"")",exploratory,690942289773375e8,268
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",data cleaning,690942289773375e8,268
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690942289773375e8,268
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,690942289773375e8,268
summary(mod2),exploratory,690942289773375e8,268
"Anova(mod2, type = ""2"")",exploratory,690942289773375e8,268
"source(""./R/VAR_functions.R"")",setup,691115134395659e6,269
"country_name <- ""Peru""",setup,691115134395659e6,269
forecast_exercise_year <- 2018,setup,691115134395659e6,269
forecast_exercise_number <- 2,setup,691115134395659e6,269
"s2_12345 <- readRDS(file = ""analysis/VAR_output/Peru_s2_12345_t2.rds"")",import,691115134395659e6,269
"s3_ic <- readRDS(file = ""analysis/VAR_output/Peru_s3_aic_fpe_hq_sc_t2.rds"")",import,691115134395659e6,269
"s3_12345 <- readRDS(file = ""analysis/VAR_output/Peru_s3_12345_t2.rds"")",import,691115134395659e6,269
"s4_ic <- readRDS(file = ""analysis/VAR_output/Peru_s4_aic_fpe_hq_sc_t2.rds"")",import,691115134395659e6,269
"s4_12345 <- readRDS(file = ""analysis/VAR_output/Peru_s4_12345_t2.rds"")",import,691115134395659e6,269
"s4_6 <- readRDS(file = ""analysis/VAR_output/Peru_s4_6_t2.rds"")",import,691115134395659e6,269
"all_models <- as_tibble(rbind(s2_12345, s3_12345, s3_ic, s4_12345,      s4_6, s4_ic)) %>% dplyr::select(vars_select(names(.), -starts_with(""wn""))) %>%      dplyr::select(vars_select(names(.), -starts_with(""rank""))) %>%      mutate(lags = unlist(lags))",modeling,691115134395659e6,269
"all_models <- all_models %>% mutate(short_name = map2(variables,      lags, ~make_model_name(variables = .x, lags = .y)), short_name = unlist(short_name),      var_size = map_dbl(variables, length))",modeling,691115134395659e6,269
"all_models <- all_models %>% dplyr::distinct(short_name, .keep_all = TRUE)",modeling,691115134395659e6,269
"format(object.size(all_models), units = ""auto"")",exploratory,691115134395659e6,269
all_models_ranked <- add_rmse_rankings(all_models),modeling,691115134395659e6,269
"all_models_ranked <- all_models_ranked %>% dplyr::select(short_name,      var_size, lags, everything()) %>% dplyr::select(everything(),      -one_of(c(""variables"", ""full_sample_varest"")), one_of(c(""variables"",          ""full_sample_varest"")))",modeling,691115134395659e6,269
"format(object.size(all_models_ranked), units = ""auto"")",exploratory,691115134395659e6,269
"all_models_ranked_long <- all_models_ranked %>% dplyr::select(-full_sample_varest) %>%      gather(key = ""rmse_h"", value = ""rmse"", c(""rmse_1"", ""rmse_2"",          ""rmse_3"", ""rmse_4"", ""rmse_5"", ""rmse_6"", ""rmse_7"")) %>%      dplyr::select(vars_select(names(.), -starts_with(""rank""))) %>%      group_by(rmse_h) %>% arrange(rmse_h, rmse) %>% mutate(rank_h = rank(rmse)) %>%      ungroup()",modeling,691115134395659e6,269
"format(object.size(all_models_ranked_long), units = ""auto"")",modeling,691115134395659e6,269
"foo <- variable_freq_by_n(all_models_ranked_long, h_max = 7,      max_rank = 20, n_freq = 4)",modeling,691115134395659e6,269
foo,modeling,691115134395659e6,269
library(pacman),setup,24292606418021e9,270
"p_load(char = c(""dplyr"", ""haven"", ""tidyr"", ""rprojroot"", ""ggplot2"",      ""stargazer"", ""stringr""), install = TRUE)",setup,24292606418021e9,270
root <- find_root(is_rstudio_project),setup,24292606418021e9,270
"db1 <- read.csv(file.path(root, ""Cache/db1.csv""))",import,24292606418021e9,270
"gha_data <- mutate(db1, N_users = ifelse(yesN == 0, NA, N), maize_area = ifelse(crop_count >      1, NA, area)) %>% ungroup()",data cleaning,24292606418021e9,270
"desc_stats <- dplyr::select(gha_data, `Yield (kg/ha)` = yld,      `Nitrogen Users (kg/ha)` = N_users, `Nitrogen All (kg/ha)` = N,      `Labor (hours/ha)` = lab, `Assets (GHC/ha)` = asset, `Plot Area (ha)` = area,      `Maize Area (ha)` = maize_area, Manure = manure, Elevation = elevation,      `Ph dummy` = phdum2, SOC2, `Single Crop == 1` = crop_count2,      `Maize price (GHC/kg)` = Pm, `Nitrogen price (GHC/kg)` = Pn,      `Sub nitrogen price (GHC/kg)` = Pns) %>% as.data.frame",data cleaning,24292606418021e9,270
"tmp <- select(gha_data, yld, N_users, lab, asset, Pm, Pns, area) %>%      gather(variable, value)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""yld"", ""Yield"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""N_users"", ""Nitrogen"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""lab"", ""Labor"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""asset"", ""Asset"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""Pm"", ""Maize Price"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""Pns"", ""Nitrogen Price"", tmp$variable)",data cleaning,24292606418021e9,270
"tmp$variable <- gsub(""area"", ""Plot Area"", tmp$variable)",data cleaning,24292606418021e9,270
"ggvars <- ggplot(data = tmp, aes(x = value, fill = variable)) +      geom_histogram(colour = ""black"", alpha = 0.5) + facet_wrap(~variable,      scale = ""free"") + theme_bw() + guides(fill = FALSE)",visualization,24292606418021e9,270
"gha_data$plot_type <- ifelse(gha_data$crop_count2 %in% 1, ""PURE"",      ""MIXED"")",data cleaning,24292606418021e9,270
"yield_tab <- group_by(gha_data, plot_type) %>% summarise(count = n(),      `Yield\n(kg/ha)` = round(mean(yld, na.rm = TRUE), 3), `area\n(ha)` = round(mean(area,          na.rm = TRUE), 3), `fertilizer\n(%)` = round(sum(N >          0)/count * 100, 1), `Nitrogen\n(kg/ha)` = round(mean(N,          na.rm = TRUE), 2))",data cleaning,24292606418021e9,270
"names(yield_tab)[1] <- ""Plot Type""",data cleaning,24292606418021e9,270
"sf_results <- readRDS(file.path(root, ""Cache/CD_sf_res.rds""))",import,24292606418021e9,270
"sf_results <- rbind(sf_results, c(1226, ""-"", ""-"", ""-""))",data cleaning,24292606418021e9,270
"row.names(sf_results) <- c(""Intercept"", ""ln(nitrogen)"", ""ln(labour)"",      ""ln(asset)"", ""ln(area)"", ""herbicide == 1"", ""mechanisation == 1"",      ""elevation"", ""manure == 1"", ""Soil organic content"", ""Ph dummy"",      ""crop_count == 1"", ""nitrogen use == 1"", ""sigmaSq"", ""gamma"",      ""observations"")",data cleaning,24292606418021e9,270
"yield_gaps_gha <- readRDS(file.path(root, ""Cache/db3.rds""))",import,24292606418021e9,270
"econ_analysis <- group_by(yield_gaps_gha, REGNAME) %>% summarise(`Nit Users` = sum(yesN ==      1, na.rm = TRUE), `Nit price (GHC/kg)` = round(mean(Pns,      na.rm = TRUE), 2), `Maize price (GHC/kg)` = round(mean(Pm,      na.rm = TRUE), 2), `Rel price` = round(mean(relprice, na.rm = TRUE),      2), MPP = round(mean(mpp, na.rm = TRUE), 2), VCR = round(mean(mpp/relprice,      na.rm = TRUE), 2)) %>% rename(Region = REGNAME) %>% mutate(Region = tolower(Region))",data cleaning,24292606418021e9,270
"econ_analysis$Region <- gsub("" region"", """", econ_analysis$Region)",data cleaning,24292606418021e9,270
econ_analysis$Region <- str_to_title(econ_analysis$Region),data cleaning,24292606418021e9,270
"opt_nitrogen <- group_by(yield_gaps_gha, REGNAME) %>% summarise(Count = n(),      Nit = sum(yesN == 1), `Nit all (kg/ha)` = round(mean(N),          2), `Nit users (kg/ha)` = round(mean(N[yesN == 1]), 2),      `Opt. Nit (kg/ha)` = round(mean(Npm, na.rm = TRUE), 2)) %>%      rename(Region = REGNAME) %>% mutate(Region = tolower(Region))",data cleaning,24292606418021e9,270
"opt_nitrogen$Region <- gsub("" region"", """", opt_nitrogen$Region)",data cleaning,24292606418021e9,270
opt_nitrogen$Region <- str_to_title(opt_nitrogen$Region),data cleaning,24292606418021e9,270
"fn_dh_elfstats <- function(site = ""http://deq2.bse.vt.edu/d.dh"",      ftype = ""all"", fstatus = ""active"", analysis_timespan = ""full"",      yvar = ""all"", sampres = ""all"", stat_quantreg_qu = ""0.80"",      station_agg = ""max"", stat_quantreg_glo = ""all"", stat_quantreg_ghi = ""all"",      feature_ftype = ""all"", xvar = ""all"", dataset_tag = ""taxaLoss_PI_PressHuc8"",      featureid = ""all"") {     elf_statistics <- paste(site, ""export_elf_statistics"", ftype,          fstatus, analysis_timespan, yvar, sampres, stat_quantreg_qu,          station_agg, stat_quantreg_glo, stat_quantreg_ghi, feature_ftype,          xvar, dataset_tag, featureid, sep = ""/"")     print(paste(""Using URI: "", elf_statistics))     region <- feature_ftype     XV <- xvar     YV <- yvar     elf_statistics <- read.table(elf_statistics, header = TRUE,          sep = "","")     write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",          region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,          quote = TRUE)     return(elf_statistics) }",data cleaning,24292606418021e9,270
numSites = 578,setup,24292606418021e9,270
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/""",setup,24292606418021e9,270
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/""",setup,24292606418021e9,270
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",setup,24292606418021e9,270
"done_list_alt = vector(""list"", length(case.name))",setup,24292606418021e9,270
"done_list_null = vector(""list"", length(case.name))",setup,24292606418021e9,270
rm(list = ls()),setup,921007604338229e7,271
"prototypes <- read.table(""../prototypes_0.txt"")",import,921007604338229e7,271
"uber.proto <- prototypes[1, 2:length(prototypes[1, ])]",not sure,921007604338229e7,271
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.alt, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.pval.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[4, ])) {                   pval_list[IX] = dat[4, ]                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_alt[[cc]] = done_res     save(""pval_list"", ""done_res"", file = paste0(path.alt, ""sum/pval."",          case.name[cc], "".Robj"")) }",data cleaning,24292606418021e9,270
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,571410476230085e8,272
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.null, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.pval.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[4, ])) {                   pval_list[IX] = dat[4, ]                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""pval_list"", ""done_res"", file = paste0(path.null, ""sum/pval."",          case.name[cc], "".Robj"")) }",data cleaning,24292606418021e9,270
no.features <- length(uber.proto),modeling,921007604338229e7,271
"no.agents <- length(prototypes[, 1]) - 1",modeling,921007604338229e7,271
"harmonic = ""1F1""",setup,571410476230085e8,272
"d.0 <- read.table(""../history_0.txt"", skip = 2)",import,921007604338229e7,271
p_thresh = 5e-04,modeling,571410476230085e8,272
plot_titles = TRUE,visualization,571410476230085e8,272
"condition = ""Direction""",modeling,571410476230085e8,272
"study = ""MOFO""",import,571410476230085e8,272
"group = ""child""",data cleaning,571410476230085e8,272
dpi = 300,data cleaning,571410476230085e8,272
n_top = 9,data cleaning,571410476230085e8,272
"analysis_path <- ""child-tuning/analysis/""",data cleaning,571410476230085e8,272
"data_path <- paste(analysis_path, ""data/"", sep = """")",data cleaning,571410476230085e8,272
"figs_path <- ""child-tuning/figs/""",data cleaning,571410476230085e8,272
"data_fn <- ""child-mofo-all.csv""",not sure,571410476230085e8,272
"egi_fn <- ""egi.csv""",not sure,571410476230085e8,272
"topo_fn <- ""topoplog.png""",not sure,571410476230085e8,272
"fn_path <- paste(data_path, data_fn, sep = """")",not sure,571410476230085e8,272
"egi_path <- paste(data_path, egi_fn, sep = """")",not sure,571410476230085e8,272
"outputs <- d.0[(no.agents + 1):length(d.0[, 1]), (4 + no.features +      1):(4 + no.features + 1 + no.features - 1)]",modeling,921007604338229e7,271
"topo_path <- paste(figs_path, ""topoplot.png"", sep = """")",not sure,571410476230085e8,272
library(ggplot2),not sure,571410476230085e8,272
library(dplyr),not sure,571410476230085e8,272
library(png),not sure,571410476230085e8,272
library(gridExtra),not sure,571410476230085e8,272
library(tidyr),not sure,571410476230085e8,272
library(knitr),not sure,571410476230085e8,272
library(DescTools),not sure,571410476230085e8,272
library(heplots),not sure,571410476230085e8,272
library(Cairo),not sure,571410476230085e8,272
"direction_conds <- c(1, 2, 3, 6, 7, 8)",not sure,571410476230085e8,272
"coherence.conds <- c(4, 9)",not sure,571410476230085e8,272
"fig.only.conds <- c(5, 10)",not sure,571410476230085e8,272
csim <- function(x1) {     x <- as.numeric(x1)     y <- as.numeric(uber.proto)     c <- x %*% y/sqrt(x %*% x * y %*% y)     return(c) },not sure,921007604338229e7,271
"d.sim <- apply(outputs, 1, csim)",evaluation,921007604338229e7,271
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"")",visualization,921007604338229e7,271
rm(list = ls()),setup,921007604338229e7,271
"respostasTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50Respostas.csv"",      header = TRUE, sep = "";"")",import,921007604338229e7,271
"perguntasTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50Perguntas.csv"",      header = TRUE, sep = "";"")",import,921007604338229e7,271
"wc <- wilcox.test(respostasTop50$media, perguntasTop50$media)",exploratory,921007604338229e7,271
"effectSize <- vargha.delaney(respostasTop50$media, perguntasTop50$media)",evaluation,921007604338229e7,271
print(wc),communication,921007604338229e7,271
options(scipen = 999),setup,921007604338229e7,271
"print(paste(""Tamanho de efeito "", effectSize))",communication,921007604338229e7,271
"print(paste(""p-value "", wc$p.value))",communication,921007604338229e7,271
print(wc$p.value < 0.05),communication,921007604338229e7,271
"print(""********************************"")",communication,921007604338229e7,271
"wc <- wilcox.test(perguntasTop50$media, respostasTop50$media)",modeling,921007604338229e7,271
"effectSize <- vargha.delaney(perguntasTop50$media, respostasTop50$media)",communication,921007604338229e7,271
print(wc),communication,921007604338229e7,271
options(scipen = 999),setup,921007604338229e7,271
"print(paste(""Tamanho de efeito "", effectSize))",communication,921007604338229e7,271
"print(paste(""p-value "", wc$p.value))",communication,921007604338229e7,271
print(wc$p.value < 0.05),communication,921007604338229e7,271
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,921007604338229e7,271
files <- list.files(path = diffdir),exploratory,921007604338229e7,271
files[1] <- NA,data cleaning,921007604338229e7,271
files[8] <- NA,data cleaning,921007604338229e7,271
files[29] <- NA,data cleaning,921007604338229e7,271
files[30] <- NA,data cleaning,921007604338229e7,271
files[31] <- NA,data cleaning,921007604338229e7,271
files <- files[!is.na(files)],data cleaning,921007604338229e7,271
names <- files,exploratory,921007604338229e7,271
"split <- data.frame(strsplit(names, ""_""))",import,921007604338229e7,271
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,921007604338229e7,271
"mat <- matrix(nrow = dim(split)[2], ncol = 4)",modeling,921007604338229e7,271
data = data.frame(mat),modeling,921007604338229e7,271
"colnames(data) <- c(""strain"", ""timepoint"", ""filename"", ""dir"")",not sure,921007604338229e7,271
"for (i in seq(1, (dim(split)[2]))) {     data$strain[i] <- as.character(split[1, i])     data$timepoint[i] <- as.character(split[4, i])     filename <- paste(split[, i], collapse = ""_"")     data$filename[i] <- filename     data$dir[i] <- paste(diffdir, filename, sep = ""/"") }",data cleaning,921007604338229e7,271
"write.table(data, ""autoanalysisInfo.csv"", sep = "","")",communication,921007604338229e7,271
"dat <- read.csv(""autoanalysisInfo.csv"", header = TRUE, stringsAsFactors = FALSE)",import,921007604338229e7,271
i <- as.numeric(as.character(commandArgs(TRUE)[1])),not sure,921007604338229e7,271
filename <- dat$filename[i],not sure,921007604338229e7,271
print(filename),communication,921007604338229e7,271
print(dat$strain[i]),communication,921007604338229e7,271
dir.create(filename),export,921007604338229e7,271
setwd(filename),setup,921007604338229e7,271
"knit2html(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/StrainTemplate.Rmd"",      output = paste(filename, "".md"", sep = """"), quiet = TRUE)",communication,921007604338229e7,271
library(knitr),setup,921007604338229e7,271
"analysisdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/""",not sure,921007604338229e7,271
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",export,921007604338229e7,271
setwd(diffdir),setup,921007604338229e7,271
search(),import,261222483357415e8,273
library(igraph),import,261222483357415e8,273
library(rgexf),import,261222483357415e8,273
"writing.dir <- c(""/home/morr9/analysis"")",setup,261222483357415e8,273
"wd <- c(""/home/morr9/sdal/projects/mann/git/book_2/multidisciplinary-diffusion-model-experiments/results/simulations"")",setup,261222483357415e8,273
setwd(wd),setup,261222483357415e8,273
"batch.dir.list <- c(""02-lens_batch_2016-02-16_00-30-30"", ""02-lens_batch_2016-02-16_08-22-22"",      ""02-lens_batch_2016-02-17_21-20-02"", ""02-lens_batch_2016-02-18_21-01-43"",      ""02-lens_batch_2016-02-19_11-51-15"", ""02-lens_batch_2016-02-19_19-37-18"",      ""02-lens_batch_2016-02-22_00-21-05"", ""02-lens_batch_2016-02-22_08-01-36"",      ""02-lens_batch_2016-02-23_09-16-38"", ""02-lens_batch_2016-02-23_19-25-08"",      ""02-lens_batch_2016-02-24_09-36-21"", ""02-lens_batch_2016-02-24_20-44-42"",      ""02-lens_batch_2016-02-25_14-44-10"", ""02-lens_batch_2016-02-26_14-16-36"",      ""02-lens_batch_2016-02-28_12-46-18"", ""02-lens_batch_2016-02-28_23-26-30"",      ""02-lens_batch_2016-02-29_12-18-15"", ""02-lens_batch_2016-03-01_06-48-37"",      ""02-lens_batch_2016-03-01_06-48-44"", ""02-lens_batch_2016-03-02_11-35-21"",      ""02-lens_batch_2016-03-02_11-36-09"", ""02-lens_batch_2016-03-03_11-05-15"")",import,261222483357415e8,273
"btwn.list <- c(21:29, 3, 31:39, 4, 41:45)",not sure,261222483357415e8,273
"wn.list <- c(5, 51:59, 6, 61:69, 7, 71:79, 8)",not sure,261222483357415e8,273
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,575507807778195e8,274
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,575507807778195e8,274
library(glue),visualization,804275582311675e8,275
library(magrittr),visualization,804275582311675e8,275
library(dplyr),visualization,804275582311675e8,275
library(ogbox),visualization,804275582311675e8,275
library(lazyeval),visualization,804275582311675e8,275
library(homologene),visualization,804275582311675e8,275
library(parallel),visualization,804275582311675e8,275
library(ConnectivityMap),visualization,804275582311675e8,275
library(memoise),visualization,804275582311675e8,275
library(VennDiagram),visualization,804275582311675e8,275
library(gplots),visualization,804275582311675e8,275
library(pheatmap),visualization,804275582311675e8,275
library(purrr),modeling,804275582311675e8,275
"data(""rankMatrix"")",import,804275582311675e8,275
"data(""instances"")",import,804275582311675e8,275
library(UpSetR),import,804275582311675e8,275
devtools::load_all(),import,804275582311675e8,275
FDRLimit = 0.05,import,804275582311675e8,275
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,505870047025383e8,276
"library(""multiseq"")",import,505870047025383e8,276
"library(""ashr"")",import,505870047025383e8,276
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",exploratory,505870047025383e8,276
"source(paste0(multiscale.analysis.repodir, ""/src/R/utils.R""))",not sure,505870047025383e8,276
"source(paste0(multiscale.analysis.repodir, ""/src/R/my.utils.R""))",not sure,505870047025383e8,276
"setwd(""~/Analysis/lambda/AliAnalysisLambda/Fitting/FemtoFitting/FitResults/RAnalysis/Analysis"")",setup,224489181768149e8,277
"dataSepFree <- read.csv(""../Cleaning/SepNoImF0FixFits.csv"", row.names = 1)",data cleaning,224489181768149e8,277
"dataSepFixed <- read.csv(""../Cleaning/SepImF0FixedFits.csv"",      row.names = 1)",import,224489181768149e8,277
"dataGlobalFree <- read.csv(""../Cleaning/GlobalNoImF0FixFits.csv"",      row.names = 1)",import,224489181768149e8,277
"dataGlobalFixed <- read.csv(""../Cleaning/GlobalImF0FixedFits.csv"",      row.names = 1)",import,224489181768149e8,277
"Analyze(dataSepFree, ""SepFitFree"")",import,224489181768149e8,277
"Analyze(dataSepFixed, ""SepFitFixed"")",modeling,224489181768149e8,277
"Analyze(dataGlobalFree, ""GlobalFitFree"")",modeling,224489181768149e8,277
"Analyze(dataGlobalFixed, ""GlobalFitFixed"")",modeling,224489181768149e8,277
"Analyze(dataGlobalFixed, ""GlobalFitFixed"")",modeling,224489181768149e8,277
"age_dat <- filter(data_abt, !Umb.Scar %in% c(""y"", ""p"")) %>% select(STL,      Month, Sex, AgeAgree, Reader1, Reader2) %>% na.omit() %>%      mutate(partial_age = AgeAgree - Reader2) %>% mutate(adjustment = ifelse(partial_age <      0, -1, partial_age)) %>% mutate(adjustment = ifelse(partial_age >      1, 1, adjustment)) %>% mutate(partial_age = ifelse(partial_age <      0, partial_age + 1, partial_age)) %>% mutate(Reader1 = Reader1 +      adjustment) %>% mutate(Reader2 = Reader2 + adjustment) %>%      mutate(Reader1 = pmax(0, Reader1), Reader2 = pmax(0, Reader2))",data cleaning,785162621177733e8,278
library(limma),setup,84892385546118e9,279
library(gplots),setup,84892385546118e9,279
"humanExp = fread(""data/UCLregions/GSE60862_expression"")",setup,84892385546118e9,279
"humanExp = humanExp[!is.na(humanExp$Gene.Symbol), ]",setup,84892385546118e9,279
"humanExp = humanExp[humanExp$Gene.Symbol != """", ]",setup,84892385546118e9,279
"list[genes, expr] = sepExpr(humanExp)",setup,84892385546118e9,279
"colnames(expr) = gsub(""\\.cel\\.gz"", """", colnames(expr))",setup,84892385546118e9,279
"softFile = read.design(""data/UCLregions/GSE60862_meta"")",setup,84892385546118e9,279
groups = unique(softFile$brainRegion),setup,84892385546118e9,279
"pairwise = combn(groups, 2)",setup,84892385546118e9,279
rm(list = ls()),setup,295344239100814e8,280
"source(""latex/plotDefaults.R"")",import,295344239100814e8,280
"source(""analysis/prepare_individual_series.R"")",import,295344239100814e8,280
"source(""analysis/make_series_stationary.R"")",import,295344239100814e8,280
"source(""analysis/model_identification.R"")",import,295344239100814e8,280
"source(""analysis/missing_values.R"")",import,295344239100814e8,280
rm(list = ls()),setup,295344239100814e8,280
library(sp),import,295344239100814e8,280
library(jsonlite),import,295344239100814e8,280
library(doBy),import,295344239100814e8,280
library(raster),import,295344239100814e8,280
library(plyr),import,295344239100814e8,280
"source(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis/Code/geoSIMEX.R"")",import,295344239100814e8,280
"setwd(""/home/aiddata/Desktop/Github/geoSIMEX_NDVI/Analysis"")",setup,295344239100814e8,280
"data.subset.categories <- list(c(""Burundi"", ""Democratic Republic of the Congo"",      ""Kenya"", ""Malawi"", ""Mozambique"", ""Rwanda"", ""Tanzania"", ""Uganda"",      ""Zambia"", ""Cambodia"", ""Laos"", ""Myanmar"", ""Thailand"", ""Vietnam"",      ""Bolivia"", ""Colombia"", ""Ecuador"", ""Peru"", ""Venezuela""), c(""Burundi"",      ""Democratic Republic of the Congo"", ""Kenya"", ""Malawi"", ""Mozambique"",      ""Rwanda"", ""Tanzania"", ""Uganda"", ""Zambia""), c(""Cambodia"",      ""Laos"", ""Myanmar"", ""Thailand"", ""Vietnam""), c(""Bolivia"", ""Colombia"",      ""Ecuador"", ""Peru"", ""Venezuela""), ""Burundi"", ""Democratic Republic of the Congo"",      ""Kenya"", ""Malawi"", ""Mozambique"", ""Rwanda"", ""Tanzania"", ""Uganda"",      ""Zambia"", ""Cambodia"", ""Laos"", ""Myanmar"", ""Thailand"", ""Vietnam"",      ""Bolivia"", ""Colombia"", ""Ecuador"", ""Peru"", ""Venezuela"")",data cleaning,295344239100814e8,280
data.subset.categories.i <- 3,data cleaning,295344239100814e8,280
analysis.year.begin <- 2001,data cleaning,295344239100814e8,280
analysis.year.end <- 2013,data cleaning,295344239100814e8,280
aid.year.begin <- 2005,data cleaning,295344239100814e8,280
aid.year.end <- 2010,data cleaning,295344239100814e8,280
pre.end <- aid.year.begin - 1,data cleaning,295344239100814e8,280
post.begin <- aid.year.end + 1,data cleaning,295344239100814e8,280
"macArth.level_1a <- read.csv(paste(getwd(), ""/Data/MacArthur_Geocoded_data/level_1a.csv"",      sep = """"))",import,295344239100814e8,280
"macArth.inf <- macArth.level_1a[macArth.level_1a$ad_sector_codes %in%      c(""210"", ""220"", ""230"", ""320""), ]",data cleaning,295344239100814e8,280
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,930329127935693e8,281
library(dplyr),setup,930329127935693e8,281
library(tidyr),setup,930329127935693e8,281
library(ggplot2),setup,930329127935693e8,281
library(scatterplot3d),setup,930329127935693e8,281
library(lme4),setup,930329127935693e8,281
library(psych),setup,930329127935693e8,281
library(scales),setup,930329127935693e8,281
library(smacof),setup,930329127935693e8,281
library(eba),setup,930329127935693e8,281
rm(list = ls()),setup,930329127935693e8,281
dev.off(),export,930329127935693e8,281
"dd_adults = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-08-17_data_anonymized.csv"")[-1]",import,930329127935693e8,281
"dd_adults <- dd_adults %>% mutate(ageGroup = ""adults"")",data cleaning,930329127935693e8,281
glimpse(dd_adults),exploratory,930329127935693e8,281
"route <- ""./analysis/seedling_mortality_analysis/""",setup,112166434293613e8,282
options(stringsAsFactors = FALSE),import,112166434293613e8,282
"setwd(""analysis"")",modeling,413592573953792e8,283
library(randomForest),modeling,413592573953792e8,283
"source(""./R/FunctionsForRWLAnalysis.R"")",setup,112166434293613e8,282
library(ica),exploratory,413592573953792e8,283
"analysis_opts <- yaml.load_file(""./analysis_options.yaml"")",modeling,112166434293613e8,282
library(e1071),modeling,413592573953792e8,283
bin_width <- analysis_opts$bin_width,visualization,112166434293613e8,282
good_phon <- analysis_opts$targets_s1$phono,export,112166434293613e8,282
good_semy <- analysis_opts$targets_s1$semantic,export,112166434293613e8,282
require(Hmisc),not sure,413592573953792e8,283
"s1_looks <- read_csv(""./data/study1/02_looking_data.csv"")",import,112166434293613e8,282
library(osfr),not sure,413592573953792e8,283
"s1_infos <- read_csv(""./data/study1/01_test_scores.csv"") %>%      rename(Subj = ParticipantID) %>% select(-Income, -medu)",import,112166434293613e8,282
s1_looks %>% select(Target) %>% distinct %>% unlist(use.names = FALSE) %>%      sort,data cleaning,112166434293613e8,282
s1_looks %>% select(Target) %>% distinct %>% nrow,data cleaning,112166434293613e8,282
library(tidyverse),visualization,413592573953792e8,283
length(good_phon),exploratory,112166434293613e8,282
length(good_semy),exploratory,112166434293613e8,282
library(stringr),data cleaning,413592573953792e8,283
library(gridExtra),visualization,413592573953792e8,283
library(RGraphics),visualization,413592573953792e8,283
"s1_infos %>% mutate(EVTThirds = cut_by_thirds(EVT_GSV)) %>% select(-contains(""PPVT"",      -EVT_raw)) %>% gather(Variable, value, -Subj, -AAE, -female,      -EVTThirds) %>% group_by(EVTThirds, Variable) %>% summarise(n = n(),      mean = mean(value), min = min(value), max = max(value))",data cleaning,112166434293613e8,282
"AggregateLooks(s1_looks, 1 ~ GazeByImageAOI)",data cleaning,112166434293613e8,282
"source(""Rcode/functions.r"")",import,413592573953792e8,283
"n_trials <- s1_looks %>% select(Subj, Block, TrialNo) %>% distinct %>%      nrow",data cleaning,112166434293613e8,282
"versions = try(system(""git tag"", intern = TRUE))",not sure,413592573953792e8,283
"bad_trials <- find_mistracked_trials(s1_looks, analysis_opts$excessive_na)",data cleaning,112166434293613e8,282
nrow(bad_trials)/n_trials,data cleaning,112166434293613e8,282
"if (class(versions) == ""try-error"") {     versions = list.files(""../.git/refs/tags"") }",not sure,413592573953792e8,283
n_blank <- bad_trials %>% filter(PropNA == 1) %>% nrow,data cleaning,112166434293613e8,282
version = versions[length(versions)],not sure,413592573953792e8,283
n_blank/n_trials,data cleaning,112166434293613e8,282
"missing_by_kid <- AggregateLooks(s1_looks, Subj ~ GazeByImageAOI)",data cleaning,112166434293613e8,282
"PMeta = ""../data/Projects_metadata.csv""",import,413592573953792e8,283
"PMeta = paste0(""http://www.osf.io/download/"", ""myxcv"")",import,413592573953792e8,283
"d_missing <- inner_join(missing_by_kid, s1_infos)",data cleaning,112166434293613e8,282
"summary(lm(PropNA ~ Age, d_missing))",modeling,112166434293613e8,282
"summary(lm(PropNA ~ EVT_GSV, d_missing))",modeling,112166434293613e8,282
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,815568058518693e8,284
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,815568058518693e8,284
library(foreign),import,815568058518693e8,284
"nm_dat <- read.dta(""~/Dropbox/professional/Research/Active/causalityinnetworks-agenda/interference_in_field_experiments/Analysis/nm_legislators/qjps_11019_supp/nm.replication.dta"")",import,815568058518693e8,284
"write.csv(nm_dat, ""~/Dropbox/professional/Research/Active/causalityinnetworks-agenda/interference_in_field_experiments/Analysis/nm_legislators/NM_new_data/nm.replication.csv"",      row.names = F)",import,815568058518693e8,284
library(dplyr),import,815568058518693e8,284
library(stringr),import,815568058518693e8,284
"if (!require(""pacman"")) install.packages(""pacman"")",setup,342423115856945e8,285
"pacman::p_load(stringr, reshape, ggplot2, optparse)",setup,342423115856945e8,285
"source(""multiplot.R"")",setup,342423115856945e8,285
"readHitTable <- function(file) {     df = read.csv(file, header = TRUE, stringsAsFactors = FALSE)     colnames(df)[1] <- ""gene_Id""     return(df) }",setup,342423115856945e8,285
numSites = 500,setup,299892011797056e8,286
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/""",setup,299892011797056e8,286
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,770469327457249e8,287
"runAnalysis <- function(dd, scale) {     my.inits <- function() {         list()     }     my.params <- get.params()     dd <- list(data = dd, inits = my.inits, params = get.params())     bugs <- run.model(dd, n.thin = scale, n.iter = (10000) *          scale, n.burnin = 10 * scale, n.chains = 3)     return(list(data = dd, bugs = bugs, summary = bugs$BUGSoutput$summary)) }",not sure,770469327457249e8,287
"try(setwd(""U:/Pragmatics/New/Analysis/""))",setup,770469327457249e8,287
"try(setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis""))",setup,770469327457249e8,287
"source(""RestrictionsApplied.R"")",import,770469327457249e8,287
"source(""grammars.R"")",import,770469327457249e8,287
"source(""makeDataVariables.R"")",import,770469327457249e8,287
"l.details.out = l.details[l.details$glotto %in% names2glotto[colnames(d.wh.m)],      ]",import,770469327457249e8,287
"l.details.out = l.details.out[!duplicated(l.details.out$glotto),      ]",import,770469327457249e8,287
"l.details.out$Interrogative.Position.Source = """"",setup,770469327457249e8,287
"l.details.out[!is.na(l.details.out$WALS.qpos), ]$Interrogative.Position.Source = ""WALS""",not sure,770469327457249e8,287
"l.details.out[!is.na(l.details.out$S.qpos) & is.na(l.details.out$WALS.qpos),      ]$Interrogative.Position.Source = ""S&R""",not sure,770469327457249e8,287
"l.details.out[l.details.out$glotto == ""basq1248"", ]$Interrogative.Position.Source = ""WALS""",not sure,770469327457249e8,287
"l.details.out$ref = """"",not sure,770469327457249e8,287
numIND = 4,setup,949877692852169e8,288
"title.name = c(""full"", ""2full"", ""4full"")",import,949877692852169e8,288
"case.name = c(paste0(""fullread."", numIND, ""ind.over""), paste0(""2fullread."",      numIND, ""ind.over""), paste0(""4fullread."", numIND, ""ind.over""))",data cleaning,949877692852169e8,288
"ROC.file.name = paste0(""logLR_ROC_RD"", numIND, "".pdf"")",export,949877692852169e8,288
"hist.file.name = paste0(""logLR_hist_RD"", numIND, "".pdf"")",export,949877692852169e8,288
"ms.null = vector(""list"", length(case.name))",setup,949877692852169e8,288
"ms.alt = vector(""list"", length(case.name))",setup,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,949877692852169e8,288
logLR.alt = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.alt = done_res,not sure,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,949877692852169e8,288
logLR.null = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.null = done_res,not sure,949877692852169e8,288
sum(done.alt),exploratory,949877692852169e8,288
sum(done.null),exploratory,949877692852169e8,288
min(logLR.alt),exploratory,949877692852169e8,288
max(logLR.alt),exploratory,949877692852169e8,288
min(logLR.null),exploratory,949877692852169e8,288
max(logLR.null),exploratory,949877692852169e8,288
ms.null[[1]] = logLR.null,setup,949877692852169e8,288
ms.alt[[1]] = logLR.alt,setup,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,949877692852169e8,288
logLR.alt = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.alt = done_res,not sure,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,949877692852169e8,288
logLR.null = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.null = done_res,not sure,949877692852169e8,288
sum(done.alt),exploratory,949877692852169e8,288
sum(done.null),exploratory,949877692852169e8,288
min(logLR.alt),exploratory,949877692852169e8,288
max(logLR.alt),exploratory,949877692852169e8,288
min(logLR.null),exploratory,949877692852169e8,288
max(logLR.null),exploratory,949877692852169e8,288
ms.null[[2]] = logLR.null,not sure,949877692852169e8,288
ms.alt[[2]] = logLR.alt,not sure,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,949877692852169e8,288
logLR.alt = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.alt = done_res,not sure,949877692852169e8,288
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,949877692852169e8,288
logLR.null = as.numeric(logLR_list),data cleaning,949877692852169e8,288
done.null = done_res,not sure,949877692852169e8,288
sum(done.alt),exploratory,949877692852169e8,288
sum(done.null),exploratory,949877692852169e8,288
min(logLR.alt),exploratory,949877692852169e8,288
max(logLR.alt),exploratory,949877692852169e8,288
min(logLR.null),exploratory,949877692852169e8,288
max(logLR.null),exploratory,949877692852169e8,288
ms.null[[3]] = logLR.null,not sure,949877692852169e8,288
ms.alt[[3]] = logLR.alt,not sure,949877692852169e8,288
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,534769620280713e8,289
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,534769620280713e8,289
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,534769620280713e8,289
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,534769620280713e8,289
numSites = 578,setup,534769620280713e8,289
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/""",setup,534769620280713e8,289
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/""",setup,534769620280713e8,289
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",not sure,534769620280713e8,289
"harmonic = ""1F1""",not sure,569999100640416e8,290
p_thresh = 5e-04,modeling,569999100640416e8,290
plot_titles = TRUE,visualization,569999100640416e8,290
"condition = ""Direction""",data cleaning,569999100640416e8,290
"study = ""MOFO""",evaluation,569999100640416e8,290
"group = ""child""",visualization,569999100640416e8,290
dpi = 300,visualization,569999100640416e8,290
n_top = 9,exploratory,569999100640416e8,290
"analysis_path <- ""child-tuning/analysis/""",import,569999100640416e8,290
"data_path <- paste(analysis_path, ""data/"", sep = """")",setup,569999100640416e8,290
"figs_path <- ""child-tuning/figs/""",import,569999100640416e8,290
"data_fn <- ""child-mofo-all.csv""",import,569999100640416e8,290
"egi_fn <- ""egi.csv""",import,569999100640416e8,290
"topo_fn <- ""topoplog.png""",import,569999100640416e8,290
"fn_path <- paste(data_path, data_fn, sep = """")",import,569999100640416e8,290
"egi_path <- paste(data_path, egi_fn, sep = """")",import,569999100640416e8,290
"topo_path <- paste(figs_path, ""topoplot.png"", sep = """")",visualization,569999100640416e8,290
library(ggplot2),visualization,569999100640416e8,290
library(dplyr),modeling,569999100640416e8,290
library(png),visualization,569999100640416e8,290
library(gridExtra),visualization,569999100640416e8,290
library(tidyr),data cleaning,569999100640416e8,290
library(knitr),communication,569999100640416e8,290
library(DescTools),exploratory,569999100640416e8,290
library(heplots),visualization,569999100640416e8,290
library(Cairo),visualization,569999100640416e8,290
"direction_conds <- c(1, 2, 3, 6, 7, 8)",modeling,569999100640416e8,290
"coherence.conds <- c(4, 9)",modeling,569999100640416e8,290
"fig.only.conds <- c(5, 10)",modeling,569999100640416e8,290
library(ggplot2),setup,673548730555922e8,291
library(ggthemes),setup,673548730555922e8,291
library(magrittr),setup,673548730555922e8,291
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_hosts.rda""))",import,673548730555922e8,291
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_applicants.rda""))",import,673548730555922e8,291
computer_subjects <- c(),data cleaning,673548730555922e8,291
"for (subject in ucas_applicants$`Subject Group (Detailed Level)` %>%      unique()) {     lowerSubject <- subject %>% tolower()     if ((grepl(""compu"", lowerSubject) || grepl(""cyber"", lowerSubject) ||          grepl(""engineer"", lowerSubject) || grepl(""software"",          lowerSubject)) && (!grepl(""comb"", lowerSubject) & !grepl(""other"",          lowerSubject) & !grepl(""any"", lowerSubject) & !grepl(""general"",          lowerSubject) & !grepl(""audio"", lowerSubject) & !grepl(""aerospace"",          lowerSubject) & !grepl(""civil"", lowerSubject) & !grepl(""mechanical"",          lowerSubject) & !grepl(""manufact"", lowerSubject) & !grepl(""chemical"",          lowerSubject))) {         computer_subjects %<>% append(subject)     } }",data cleaning,673548730555922e8,291
"filters <- list(subjects = computer_subjects, applicationRoute = ""'Insurance choice'"",      domicile = ""'Northern Ireland'"")",data cleaning,673548730555922e8,291
ucas_data <- ucas_applicants %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Applicant Domicile (High Level)` == filters$domicile),exploratory,673548730555922e8,291
hostEntrants <- ucas_hosts %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Provider Country` == filters$domicile),exploratory,673548730555922e8,291
allYears <- ucas_data$`Cycle Year` %>% unique(),exploratory,673548730555922e8,291
totalYears <- totalHostYears <- c(),exploratory,673548730555922e8,291
"for (year in allYears) {     sub <- subset(ucas_data, `Cycle Year` == year)     totalYears %<>% append(sum(sub$`Number of Acceptances`))     subHosts <- subset(hostEntrants, `Cycle Year` == year)     totalHostYears %<>% append(sum(subHosts$`Number of Acceptances`)) }",exploratory,673548730555922e8,291
"df <- data.frame(years = allYears, totalApplicationYears = totalYears,      totalHostYears = totalHostYears, stringsAsFactors = FALSE)",data cleaning,673548730555922e8,291
"ggplot(data = df) + geom_line(aes(x = years, y = totalApplicationYears,      colour = ""Applications"")) + geom_point(aes(x = years, y = totalApplicationYears,      colour = ""Applications"")) + geom_line(aes(x = years, y = totalHostYears,      colour = ""Acceptances"")) + geom_point(aes(x = years, y = totalHostYears,      colour = ""Acceptances"")) + scale_colour_discrete(name = """",      labels = c(""UCAS Acceptances"", ""UCAS Applications"")) + ylab(""Number"") +      xlab(""Years"") + labs(title = ""Number of UCAS applications from NI students to UK firms &\n number of UCAS acceptancs by NI universities in EEECS subjects"") +      theme_minimal()",visualization,673548730555922e8,291
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-applications-insurance.png""),      device = ""png"")",visualization,673548730555922e8,291
ucas_data$demandSupplyDiff <- ucas_data$`Number of Acceptances` -      hostEntrants$`Number of Acceptances`,evaluation,673548730555922e8,291
"ucas_data$vacanciesRecorded <- c(540, 505, 530, 560, 610, 635,      700, 775, 760, 715, 785, 745)",data cleaning,673548730555922e8,291
"ucas_application_chart <- ggplot(data = ucas_data, aes(x = `Cycle Year`,      y = `Number of Acceptances`, fill = `Subject Group (Detailed Level)`)) +      geom_area(colour = ""black"", size = 0.2, alpha = 0.4) + labs(title = paste0(""UK university applications by all "",      filters$applicationRoute, "" NI applicants (2007-2018)"")) +      ylab(""Number of acceptances"") + xlab(""Year"") + scale_fill_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,673548730555922e8,291
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-applications-insurance.png""),      plot = ucas_application_chart, device = ""png"")",visualization,673548730555922e8,291
"ucas_acceptance_chart <- ggplot(data = hostEntrants, aes(x = `Cycle Year`,      y = `Number of Acceptances`, fill = `Subject Group (Detailed Level)`)) +      geom_area(colour = ""black"", size = 0.2, alpha = 0.4) + labs(title = paste0(""All NI University acceptances by all "",      filters$applicationRoute, "" applicants (2007--2018)"")) +      ylab(""Number of acceptances"") + xlab(""Year"") + scale_fill_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,673548730555922e8,291
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-acceptance.png""),      plot = ucas_acceptance_chart, device = ""png"")",export,673548730555922e8,291
"ucas_gap_chart <- ggplot(data = ucas_data, aes(x = `Cycle Year`)) +      geom_point(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      geom_line(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      labs(title = paste0(""Difference between number of University applications and number of acceptances (2007--2018)"")) +      ylab(""Demand / supply difference"") + xlab(""Year"") + scale_colour_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,673548730555922e8,291
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-demand-suplus.png""),      plot = ucas_gap_chart, device = ""png"")",export,673548730555922e8,291
library(knitr),setup,30178872612305e9,292
"pandoc(""analysis_results.md"", format = ""html"")",communication,30178872612305e9,292
library(magrittr),setup,30178872612305e9,292
library(plyr),setup,30178872612305e9,292
library(dplyr),setup,30178872612305e9,292
library(ggplot2),setup,30178872612305e9,292
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,30178872612305e9,292
"record = read.csv(""Analysis/Parsed Data/exp1_production.csv"")",import,30178872612305e9,292
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/record_subj.png"")",export,30178872612305e9,292
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/record_section.png"")",export,30178872612305e9,292
"afc = read.csv(""Analysis/Parsed Data/exp1_4afc.csv"")",import,30178872612305e9,292
library(magrittr),setup,677540961187333e8,293
library(plyr),setup,677540961187333e8,293
"afc$Mapping <- ifelse(afc$Subj == ""9EH"" | afc$Subj == ""10DC"" |      afc$Subj == ""11DA"" | afc$Subj == ""12KM"" | afc$Subj == ""13CS"" |      afc$Subj == ""18TW"" | afc$Subj == ""19JL"" | afc$Subj == ""20ST"" |      afc$Subj == ""21MY"" | afc$Subj == ""26SK"" | afc$Subj == ""27RB"" |      afc$Subj == ""28JJ"" | afc$Subj == ""29PP"", ""A"", ifelse(afc$Subj ==      ""14CL"" | afc$Subj == ""15SJ"" | afc$Subj == ""16YK"" | afc$Subj ==      ""17JI"" | afc$Subj == ""22DT"" | afc$Subj == ""23KV"" | afc$Subj ==      ""24JF"" | afc$Subj == ""25AL"" | afc$Subj == ""30HO"" | afc$Subj ==      31 | afc$Subj == 32 | afc$Subj == 33, ""B"", NA))",data cleaning,30178872612305e9,292
library(dplyr),setup,677540961187333e8,293
library(ggplot2),setup,677540961187333e8,293
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,677540961187333e8,293
afc$Mapping <- as.factor(afc$Mapping),data cleaning,30178872612305e9,292
"record = read.csv(""Analysis/Parsed Data/pilots_production.csv"")",import,677540961187333e8,293
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",exploratory,30178872612305e9,292
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",visualization,677540961187333e8,293
"limits <- aes(ymax = mean + se, ymin = mean - se)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/record_subj.png"")",export,677540961187333e8,293
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",visualization,677540961187333e8,293
"ggsave(""Analysis/Plots/record_section.png"")",export,677540961187333e8,293
"afc = read.csv(""Analysis/Parsed Data/pilots_4afc.csv"")",import,677540961187333e8,293
"afc1 <- ddply(afc_nonce, c(""Section""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",evaluation,30178872612305e9,292
"afc %<>% mutate(Mapping = ifelse(Subj == ""1MK"", 1, ifelse(Subj ==      ""2DC"", 1, ifelse(Subj == ""3BR"", 1, ifelse(Subj == ""4KK"",      1, ifelse(Subj == ""5HB"", 2, ifelse(Subj == ""6MA"", 2, ifelse(Subj ==          ""7SQ"", 2, ifelse(Subj == ""8EW"", 2, NA)))))))))",data cleaning,677540961187333e8,293
"afc_all <- ggplot(afc1, aes(x = Section, y = mean, fill = Section)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits)",visualization,30178872612305e9,292
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",data cleaning,677540961187333e8,293
"ggsave(""Analysis/Plots/afc_all.png"")",export,30178872612305e9,292
library(httr),import,984756462508812e8,294
"limits <- aes(ymax = mean + se, ymin = mean - se)",visualization,677540961187333e8,293
library(jsonlite),import,984756462508812e8,294
"afc2 <- ddply(afc_nonce, c(""Section"", ""Subj""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",modeling,30178872612305e9,292
"afc_subj <- ggplot(afc2, aes(x = Section, y = mean, fill = Section)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits) +      facet_wrap(~Subj)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/afc_subj.png"")",export,30178872612305e9,292
"afc3 <- ddply(afc_nonce, c(""Section"", ""Target""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",modeling,30178872612305e9,292
"afc_item <- ggplot(afc3, aes(x = Section, y = mean, fill = Section)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits) +      facet_wrap(~Target)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/afc_item.png"")",export,30178872612305e9,292
"afc4 <- ddply(afc_nonce, c(""Section"", ""Mapping""), summarise,      N = sum(!is.na(Correct)), mean = mean(Correct, na.rm = TRUE),      sd = sd(Correct, na.rm = TRUE), se = sd/sqrt(N))",modeling,30178872612305e9,292
"afc_mapping <- ggplot(afc4, aes(x = Section, y = mean, fill = Section)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits) +      facet_wrap(~Mapping)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/afc_mapping.png"")",export,30178872612305e9,292
"afc_rt = mutate(afc, RT = ClickTime - StartTime) %>% filter(Section !=      ""Practice"") %>% mutate(Type = ifelse(Target == ""bliffenLion"",      ""Nonce"", ifelse(Target == ""doklaDeer"", ""Nonce"", ifelse(Target ==          ""kooftaRhino"", ""Nonce"", ifelse(Target == ""lanfuTurtle"",          ""Nonce"", ifelse(Target == ""melnawgYak"", ""Nonce"", ifelse(Target ==              ""zamperCamel"", ""Nonce"", ifelse(Target == ""forpihWasp"",              ""Nonce"", ifelse(Target == ""geedCricket"", ""Nonce"",                  ifelse(Target == ""morshipFly"", ""Nonce"", ifelse(Target ==                    ""norgBug"", ""Nonce"", ifelse(Target == ""pezaAnt"",                    ""Nonce"", ifelse(Target == ""skroopMoth"", ""Nonce"",                      ifelse(Target == ""kooftaDeer"", ""Nonce"", ifelse(Target ==                        ""lanfuCamel"", ""Nonce"", ifelse(Target ==                        ""bliffenTurtle"", ""Nonce"", ifelse(Target ==                        ""zamperLion"", ""Nonce"", ifelse(Target ==                        ""melnawgRhino"", ""Nonce"", ifelse(Target ==                        ""doklaYak"", ""Nonce"", ifelse(Target == ""pezaCricket"",                        ""Nonce"", ifelse(Target == ""forpihBug"",                          ""Nonce"", ifelse(Target == ""geedMoth"",                            ""Nonce"", ifelse(Target == ""skroopWasp"",                              ""Nonce"", ifelse(Target == ""norgFly"",                                ""Nonce"", ifelse(Target == ""morshipAnt"",                                  ""Nonce"", ""Real"")))))))))))))))))))))))))",data cleaning,30178872612305e9,292
"afc5 <- ddply(afc_rt, c(""Type"", ""Target"", ""Section""), summarise,      N = sum(!is.na(RT)), mean = mean(RT, na.rm = TRUE), sd = sd(RT,          na.rm = TRUE), se = sd/sqrt(N))",modeling,30178872612305e9,292
"afc_rt_all = ggplot(afc5, aes(x = Target, y = mean, fill = Type)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits) +      facet_wrap(~Type)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/rt_item.png"")",export,30178872612305e9,292
"afc6 <- ddply(afc_rt, c(""Type"", ""Section""), summarise, N = sum(!is.na(RT)),      mean = mean(RT, na.rm = TRUE), sd = sd(RT, na.rm = TRUE),      se = sd/sqrt(N))",modeling,30178872612305e9,292
"afc_rt_mean = ggplot(afc6, aes(x = Type, y = mean, fill = Type)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits)",visualization,30178872612305e9,292
"ggsave(""Analysis/Plots/rt_type.png"")",export,30178872612305e9,292
"root = ""~/ANALYSIS""",setup,657413579057902e8,295
"Plot_title = ""Perseids (EDMOND dataset: 2001 to 2015)""",modeling,657413579057902e8,295
Binsize = 0.002,not sure,657413579057902e8,295
"D_Type = ""DD""",visualization,657413579057902e8,295
"J_catalog = paste(root, ""/CONFIG/j8.csv"", sep = """")",not sure,657413579057902e8,295
"source(paste(root, ""/CONFIG/Lib_Config.r"", sep = """"))",export,657413579057902e8,295
"source(paste(FuncDir, ""/common_functions.r"", sep = """"))",evaluation,657413579057902e8,295
library(ShortRead),import,48487759870477e9,296
"samples <- c(""TORN_Pool_4_S4"", ""TORN_Pool_5_S5"", ""TORN_Pool_6_S6"",      ""TORN_Pool_7_S7"", ""TORN_Pool_8_S8"", ""TORN_Pool_9_S9"", ""TORN_Pool_10_S10"")",setup,48487759870477e9,296
"source(paste(FuncDir, ""/D_Criteria.r"", sep = """"))",import,657413579057902e8,295
"lanes <- c(""L006"", ""L008"")",setup,48487759870477e9,296
library(caret),setup,427386616589501e8,297
"directions <- c(""R1"", ""R2"")",setup,48487759870477e9,296
"streamlist = read.csv(J_catalog, header = TRUE)",modeling,657413579057902e8,295
"streamlist <- streamlist[!is.na(streamlist$X_name) & !(streamlist$X_name ==      ""SPO""), ]",import,657413579057902e8,295
library(doMC),setup,427386616589501e8,297
"source(""~/selection/code/lib/readlib.R"")",setup,711840801173821e8,298
"setwd(""/Users/calderatta/Desktop/FISH546_Bioinformatics/project/data"")",setup,48487759870477e9,296
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/FTL_cp.R"")",data cleaning,812593935988843e8,299
data <- c(),setup,48487759870477e9,296
version = NA,setup,711840801173821e8,298
setwd(WorkingDir),data cleaning,657413579057902e8,295
mt <- read_ufo(),setup,657413579057902e8,295
if (length(commandArgs(TRUE))) {     version = commandArgs(TRUE)[1] },setup,711840801173821e8,298
"for (sample in samples) {     for (lane in lanes) {         for (direction in directions) {             file <- paste(sample, ""_"", lane, ""_"", direction,                  ""_001.fastq"", sep = """")             data <- c(data, file)         }     } }",setup,48487759870477e9,296
library(mmadsenr),setup,427386616589501e8,297
"root <- paste0(""~/selection/counts/"", version, ""/all"")",setup,711840801173821e8,298
data,not sure,48487759870477e9,296
"FTL <- read.csv(""/Volumes/NOAA_Data/CNH/Data/Catch/FTL_2009-2013_2014-03-21.csv"",      as.is = TRUE)",setup,812593935988843e8,299
library(futile.logger),setup,427386616589501e8,297
rows_read <- nrow(mt),import,657413579057902e8,295
"file <- ""TORN_Pool_4_S4_L006_R1_001.fastq""",setup,48487759870477e9,296
"spid_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/remove_spid.csv"",      as.is = TRUE)",import,812593935988843e8,299
"read.totals <- paste0(""~/selection/analysis/"", version, ""/effsize/effsize_reads.txt.gz"")",setup,711840801173821e8,298
library(dplyr),setup,427386616589501e8,297
"if (rows_read == 0) {     stop(""No data in input file"") } else {     cat(paste(""*** Rows read from input file"", as.character(rows_read),          ""\n""))     mu <- filter_stream(mt, mtype = ""UNIFIED"")     if (nrow(mu) == 0) {         stop(""No data in UNIFIED dataframe"")     }     else {         if (Apply_QA) {             mu <- filter_apply_qa(mu)         }         rows_to_process <- nrow(mu)         if (rows_to_process == 0) {             stop(""No data to process - check QA filter settings"")         }         else {             mu$D_Value <- 9999             mu$D_Stream <- ""SPO""             for (ix in 1:nrow(streamlist)) {                 stream_name = as.factor(streamlist$X_name[ix])                 e = as.numeric(streamlist$X_e[ix])                 q = as.numeric(streamlist$X_q[ix])                 i = as.numeric(streamlist$X_incl[ix])                 n = as.numeric(streamlist$X_node[ix])                 p = as.numeric(streamlist$X_peri[ix])                 zlist <- DCalc(mu, e, q, i, n, p, D_Type = D_Type)                 idx <- (zlist$D_Value <= mu$D_Value) & (zlist$D_Value <=                    d_threshold)                 mu$D_Stream[idx] <- as.character(stream_name)                 mu$D_Value[idx] <- zlist$D_Value[idx]             }             mu_tab = table(mu$D_Stream, mu$X_stream)             result_tab <- NA             for (i in 1:nrow(mu_tab)) {                 for (j in 1:ncol(mu_tab)) {                   if (mu_tab[i, j] > 0) {                     result_tab <- rbind(result_tab, data.frame(rownames(mu_tab)[i],                        colnames(mu_tab)[j], mu_tab[i, j]))                   }                 }             }             colnames(result_tab) <- c(""D_ANALYSIS"", ""UFO"", ""Count"")             result_tab <- result_tab[with(result_tab, order(Count)),                  ]         }     } }",exploratory,657413579057902e8,295
reads <- readFastq(file),import,48487759870477e9,296
library(ggthemes),setup,427386616589501e8,297
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""population-classification.log"")",setup,427386616589501e8,297
"cmplx_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/cmplx.csv"",      as.is = TRUE)",import,812593935988843e8,299
rd <- read.counts.and.data(root),setup,711840801173821e8,298
sread(reads)[1:10],exploratory,48487759870477e9,296
counts <- rd$counts,setup,711840801173821e8,298
length(reads),exploratory,48487759870477e9,296
totals <- rd$totals,setup,711840801173821e8,298
"mgmt_remove <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/mgmt_grp.csv"",      as.is = TRUE)",import,812593935988843e8,299
data <- rd$data,setup,711840801173821e8,298
"flog.appender(appender.file(log_file), name = ""cl"")",import,427386616589501e8,297
"species_data <- read.csv(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-28/new_plan/input_data/spid.csv"",      as.is = TRUE)",import,812593935988843e8,299
table(width(reads)),exploratory,48487759870477e9,296
mean(width(reads)),exploratory,48487759870477e9,296
sd(width(reads)),exploratory,48487759870477e9,296
"if (rows_read == 0) {     stop(""No data in input file"") } else {     cat(paste(""*** Rows read from input file"", as.character(rows_read),          ""\n""))     mu <- filter_stream(mt, mtype = ""UNIFIED"")     if (nrow(mu) == 0) {         stop(""No data in UNIFIED dataframe"")     }     else {         if (Apply_QA) {             mu <- filter_apply_qa(mu)         }         rows_to_process <- nrow(mu)         if (rows_to_process == 0) {             stop(""No data to process - check QA filter settings"")         }         else {             mu$D_Value <- 9999             mu$D_Stream <- ""SPO""             for (ix in 1:nrow(streamlist)) {                 stream_name = as.factor(streamlist$X_name[ix])                 e = as.numeric(streamlist$X_e[ix])                 q = as.numeric(streamlist$X_q[ix])                 i = as.numeric(streamlist$X_incl[ix])                 n = as.numeric(streamlist$X_node[ix])                 p = as.numeric(streamlist$X_peri[ix])                 zlist <- DCalc(mu, e, q, i, n, p, D_Type = D_Type)                 idx <- (zlist$D_Value <= mu$D_Value) & (zlist$D_Value <=                    d_threshold)                 mu$D_Stream[idx] <- as.character(stream_name)                 mu$D_Value[idx] <- zlist$D_Value[idx]             }             mu_tab = table(mu$D_Stream, mu$X_stream)             result_tab <- NA             for (i in 1:nrow(mu_tab)) {                 for (j in 1:ncol(mu_tab)) {                   if (mu_tab[i, j] > 0) {                     result_tab <- rbind(result_tab, data.frame(rownames(mu_tab)[i],                        colnames(mu_tab)[j], mu_tab[i, j]))                   }                 }             }             colnames(result_tab) <- c(""D_ANALYSIS"", ""UFO"", ""Count"")             result_tab <- result_tab[with(result_tab, order(Count)),                  ]         }     } }",communication,657413579057902e8,295
"prop_tripTable <- FTL_cp(FTL, type = ""proportion"", times = 300,      spid_remove, cmplx_remove, mgmt_remove)",import,812593935988843e8,299
lengths <- c(),setup,48487759870477e9,296
means <- c(),setup,48487759870477e9,296
sds <- c(),setup,48487759870477e9,296
"for (file in data) {     print(file)     reads <- readFastq(file)     lengths <- c(lengths, length(reads))     means <- c(means, mean(width(reads)))     sds <- c(sds, sd(width(reads))) }",setup,48487759870477e9,296
"(report <- data.frame(data, lengths, means, sds))",setup,48487759870477e9,296
"root = ""~/ANALYSIS""",communication,657413579057902e8,295
"setwd(""/Users/calderatta/Desktop/FISH546_Bioinformatics/project/analysis/merge"")",setup,48487759870477e9,296
data <- c(),setup,48487759870477e9,296
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",      Sys.Date(), "".Rdata"", sep = """"))",evaluation,812593935988843e8,299
"for (sample in samples) {     for (direction in directions) {         file <- paste(sample, ""_"", direction, "".fastq"", sep = """")         data <- c(data, file)     } }",import,48487759870477e9,296
data,setup,48487759870477e9,296
lengths <- c(),setup,48487759870477e9,296
means <- c(),setup,48487759870477e9,296
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",      Sys.Date(), "".Rdata"", sep = """"))",export,812593935988843e8,299
sds <- c(),setup,48487759870477e9,296
"for (file in data) {     print(file)     reads <- readFastq(file)     lengths <- c(lengths, length(reads))     means <- c(means, mean(width(reads)))     sds <- c(sds, sd(width(reads))) }",import,48487759870477e9,296
"(report <- data.frame(data, lengths, means, sds))",import,48487759870477e9,296
library(knitr),setup,393323906464502e8,300
"setwd(""/Users/calderatta/Desktop/FISH546_Bioinformatics/project/analysis/trimgalore"")",setup,48487759870477e9,296
data <- c(),setup,48487759870477e9,296
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,393323906464502e8,300
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,393323906464502e8,300
"for (i in seq(1, (dim(mastersheet)[1]))) {     strain <- mastersheet[i, 1]     dir <- mastersheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain) }",not sure,393323906464502e8,300
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",import,393323906464502e8,300
rm(list = ls(all = TRUE)),data cleaning,812593935988843e8,299
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",import,393323906464502e8,300
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",import,393323906464502e8,300
"pathLinks <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/Links2011V28.csv""",setup,812593935988843e8,299
"pathHeight <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/Standardized.csv""",setup,812593935988843e8,299
"pathOutput <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-12-14/DoubleEntered.csv""",setup,812593935988843e8,299
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,393323906464502e8,300
dsLinks <- read.csv(pathLinks),import,812593935988843e8,299
"for (i in seq(1, (dim(test_master_sheet)[1]))) {     strain <- test_master_sheet[i, 1]     dir <- test_master_sheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"))     print(dir)     print(strain) }",not sure,393323906464502e8,300
"dsLinksLeftHand <- subset(dsLinks, select = c(""Subject1Tag"",      ""Subject2Tag"", ""R""))",data cleaning,812593935988843e8,299
"dsLinksRightHand <- subset(dsLinks, select = c(""Subject2Tag"",      ""Subject1Tag"", ""R""))",data cleaning,812593935988843e8,299
"colnames(dsLinksRightHand) <- c(""Subject1Tag"", ""Subject2Tag"",      ""R"")",setup,812593935988843e8,299
rm(dsLinks),data cleaning,812593935988843e8,299
dsHeight <- read.csv(pathHeight),import,812593935988843e8,299
"dsHeight1 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst19to25"", ""age_ht""))",data cleaning,812593935988843e8,299
"dsHeight2 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst19to25"", ""age_ht""))",data cleaning,812593935988843e8,299
"colnames(dsHeight1) <- c(""CID"", ""CRace1"", ""CGender1"", ""HtSt1"",      ""AgeHt1"")",setup,812593935988843e8,299
"Make.trim.mofo <- function(fn) {     stopifnot(file.exists(fn))     df <- read.csv(fn)     df$db.session <- substr(fn, 1:5)     df$db.participant.id <- substr(fn, 7:10)     drops <- c(""iSess"", """")     df <- df[, 2] }",data cleaning,393323906464502e8,300
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,163532093865797e8,301
"colnames(dsHeight2) <- c(""CID"", ""CRace2"", ""CGender2"", ""HtSt2"",      ""AgeHt2"")",setup,812593935988843e8,299
rm(dsHeight),data cleaning,812593935988843e8,299
library(dplyr),communication,163532093865797e8,301
library(ggplot2),communication,163532093865797e8,301
library(scales),visualization,163532093865797e8,301
"fl <- list.files(""analysis/data/csv-bysession"", pattern = ""\\.csv$"",      full.names = TRUE)",import,393323906464502e8,300
library(stringr),data cleaning,163532093865797e8,301
library(tidyr),setup,163532093865797e8,301
"dsLeftHand <- merge(x = dsLinksLeftHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",data cleaning,812593935988843e8,299
"if (is.null(fl)) {     stop(""No files in file list."") }",import,393323906464502e8,300
"dsLeftHand <- merge(x = dsLeftHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",data cleaning,812593935988843e8,299
"dsRightHand <- merge(x = dsLinksRightHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",data cleaning,812593935988843e8,299
"dfl <- lapply(fl, Make.trim.mofo)",data cleaning,393323906464502e8,300
"dsRightHand <- merge(x = dsRightHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",data cleaning,812593935988843e8,299
library(igraph),import,905876096338034e8,302
"rm(dsLinksLeftHand, dsLinksRightHand, dsHeight1, dsHeight2)",data cleaning,812593935988843e8,299
trip_mat <- m1.trips.ignore,import,905876096338034e8,302
"ds <- rbind(dsLeftHand, dsRightHand)",setup,812593935988843e8,299
require(tidyverse),setup,497270786669105e8,303
trip_mat[is.na(trip_mat)] <- 0,data cleaning,905876096338034e8,302
library(ggplot2),setup,497270786669105e8,303
library(plotly),setup,497270786669105e8,303
"rm(dsLeftHand, dsRightHand)",data cleaning,812593935988843e8,299
"setwd(""~/proyectos/exploratory-data-analysis/turistificacion/"")",setup,497270786669105e8,303
"write.csv(ds, pathOutput)",export,812593935988843e8,299
"f1 <- ""~/proyectos/exploratory-data-analysis/turistificacion/data/raw/actividades-comerciales/20150201.csv""",import,497270786669105e8,303
ageFloor <- 19,setup,812593935988843e8,299
trip_mat <- abs(trip_mat),data cleaning,905876096338034e8,302
"f2 <- ""~/proyectos/exploratory-data-analysis/turistificacion/data/raw/actividades-comerciales/20180301.csv""",import,497270786669105e8,303
"ds <- subset(ds, AgeHt1 >= ageFloor & AgeHt2 >= ageFloor)",data cleaning,812593935988843e8,299
"paint <- matrix(""indianred"", nrow = nrow(trip_mat), ncol = ncol(trip_mat))",visualization,905876096338034e8,302
"merged <- Reduce(f = function(x, y) merge(x, y, all = TRUE),      dfl)",data cleaning,393323906464502e8,300
"ds[is.na(ds$R), ""R""] <- 0.375",setup,812593935988843e8,299
siteSize = 2048,setup,170372030697763e7,1
"paint[m1.trips.ignore < 0] <- ""grey""",visualization,905876096338034e8,302
"distritos <- c(""ARGANZUELA"", ""USERA"", ""CENTRO"")",data cleaning,497270786669105e8,303
library(e1071),setup,812593935988843e8,299
paint[is.na(m1.trips.ignore)] <- NA,visualization,905876096338034e8,302
"treatment = ""Copper""",data cleaning,170372030697763e7,1
"write.csv(merged, file = ""analysis/data/csv-aggregate/child-mofo-all.csv"",      row.names = FALSE)",export,393323906464502e8,300
paint_vec <- as.vector(paint),visualization,905876096338034e8,302
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,735702050849795e8,304
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,735702050849795e8,304
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,735702050849795e8,304
paint_vec <- paint_vec[-which(is.na(paint_vec))],visualization,905876096338034e8,302
"brief <- summary(lm(HtSt1 ~ 1 + HtSt2 + R + HtSt2 * R, data = ds))",modeling,812593935988843e8,299
numSites.list = scan(path),import,170372030697763e7,1
"Make.trim.mofo <- function(fn) {     stopifnot(file.exists(fn))     df <- read.csv(fn)     df$db.session <- substr(fn, 1:5)     df$db.participant.id <- substr(fn, 7:10)     drops <- c(""iSess"", """")     df <- df[, 2] }",data cleaning,393323906464502e8,300
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,735702050849795e8,304
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
coeficients <- coef(brief),exploratory,812593935988843e8,299
"source(""analysis/analysis.R"")",setup,393323906464502e8,300
count <- length(brief$residuals),exploratory,812593935988843e8,299
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
siteSize = 1024,setup,170372030697763e7,1
"g <- graph_from_adjacency_matrix(trip_mat, mode = ""undirected"",      weighted = TRUE, add.rownames = TRUE)",modeling,905876096338034e8,302
"treatment = ""Copper""",data cleaning,170372030697763e7,1
"df1 <- read_delim(f1, "";"") %>% select(desc_situacion_local, id_local,      desc_distrito_local, desc_barrio_local, clase_vial_acceso,      desc_vial_acceso, rotulo, desc_seccion, desc_division, desc_epigrafe) %>%      filter(!is.na(desc_seccion) & desc_situacion_local == ""Abierto"") %>%      mutate(desc_distrito_local = trim(desc_distrito_local)) %>%      filter(desc_distrito_local %in% distritos)",data cleaning,497270786669105e8,303
"hSquared <- coeficients[""HtSt2:R"", ""Estimate""]",evaluation,812593935988843e8,299
E(g)$paint <- paint_vec,visualization,905876096338034e8,302
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
numSites.list = scan(path),import,170372030697763e7,1
"summarize_analyses <- function(analyses) {     evaluated_promise_count <- analyses$`evaluated-promise-type` %>%          group_by(promise_type) %>% summarize(count = sum(as.numeric(count))) %>%          ungroup() %>% mutate(promise_mode = ""Evaluated"")     unevaluated_promise_count <- analyses$`unevaluated-promise-type` %>%          group_by(promise_type) %>% summarize(count = sum(as.numeric(count))) %>%          ungroup() %>% mutate(promise_mode = ""Unevaluated"")     promise_distribution = rbind(evaluated_promise_count, unevaluated_promise_count)     total_promise_count <- sum(as.numeric(promise_distribution$count))     promise_distribution <- promise_distribution %>% mutate(relative_count = count/total_promise_count,          promise_type = ifelse(promise_type == ""ca"", ""Custom argument"",              ifelse(promise_type == ""da"", ""Default argument"",                  ""Non argument"")))     list(promise_distribution = promise_distribution) }",modeling,393323906464502e8,300
"df2 <- read_delim(f2, "";"") %>% select(desc_situacion_local, id_local,      desc_distrito_local, desc_barrio_local, clase_vial_acceso,      desc_vial_acceso, rotulo, desc_seccion, desc_division, desc_epigrafe) %>%      filter(!is.na(desc_seccion) & desc_situacion_local == ""Abierto"") %>%      mutate(desc_distrito_local = trim(desc_distrito_local)) %>%      filter(desc_distrito_local %in% distritos)",data cleaning,497270786669105e8,303
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
"visualize_analyses <- function(analyses) {     total_object_count <- analyses$aggregate$total_object_count     promise_distribution <- analyses$promise_distribution %>%          rename(`Promise mode` = promise_mode) %>% ggplot(aes(promise_type,          weight = relative_count, fill = `Promise mode`)) + geom_bar() +          scale_y_continuous(labels = relative_labels) + labs(y = ""Count (%)"") +          labs(x = ""Promise type"") + guides(title = ""Promise distribution"") +          scale_fill_gdocs() + theme(legend.position = ""bottom"")     list(promise_distribution = promise_distribution) }",visualization,393323906464502e8,300
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
"pdf(file = ""Analysis/ses_network/figures/correlation_trips_coastwide.pdf"",      width = 8, height = 8)",export,905876096338034e8,302
"df1_aggr <- df1 %>% group_by(desc_distrito_local, desc_epigrafe) %>%      summarize(count_2015 = n())",exploratory,497270786669105e8,303
"cSquared <- coeficients[""HtSt2"", ""Estimate""]",evaluation,812593935988843e8,299
"par(bg = ""transparent"", oma = rep(0, 4), mai = rep(0, 4))",visualization,905876096338034e8,302
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"df2_aggr <- df2 %>% group_by(desc_distrito_local, desc_epigrafe) %>%      summarize(count_2018 = n())",exploratory,497270786669105e8,303
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
"plot(g, edge.width = E(g)$weight * 10, edge.color = E(g)$paint,      vertex.frame.color = ""grey"", vertex.color = ""white"", vertex.label.family = ""sans"",      vertex.label = tolower(V(g)$name), vertex.label.color = ""black"",      vertex.label.cex = 1, edge.curved = TRUE, layout = layout.grid)",visualization,905876096338034e8,302
eSquared <- 1 - hSquared - cSquared,evaluation,812593935988843e8,299
siteSize = 2048,setup,170372030697763e7,1
dev.off(),visualization,905876096338034e8,302
mean(ds$HtSt1),evaluation,812593935988843e8,299
"treatment = ""Selenium""",data cleaning,170372030697763e7,1
sd(ds$HtSt1),evaluation,812593935988843e8,299
skewness(ds$HtSt1),evaluation,812593935988843e8,299
"colors_common <- function(g) {     descrp <- read.csv(""processedData/catch/3_exploreBuildwebs/ref_tables/metier_descrp.csv"",          stringsAsFactors = FALSE)     descrp$paint <- NA     library(RColorBrewer)     descrp$Metier <- tolower(descrp$Metier)     n.gear = length(grep(""pot"", tolower(descrp$Metier)))     paint = rev(colorRampPalette(brewer.pal(9, ""Reds""))(n.gear))     descrp$paint[grep(""pot"", tolower(descrp$Metier))] <- paint     n.gear = length(grep(""tws"", descrp$Metier))     paint = colorRampPalette(c(""#FA9FB5"", ""#E7298A""))(n.gear)     descrp$paint[grep(""tws"", descrp$Metier)] <- paint     n.gear = length(grep(""tls"", descrp$Metier))     paint = colorRampPalette(c(""#FFEDA0"", ""#FED976""))(n.gear)     descrp$paint[grep(""tls"", descrp$Metier)] <- paint     n.gear = length(grep(""msc"", descrp$Metier))     paint = colorRampPalette(brewer.pal(9, ""Purples""))(n.gear)     descrp$paint[grep(""msc"", descrp$Metier)] <- paint     n.gear = length(grep(""hkl"", descrp$Metier))     paint = rev(colorRampPalette(brewer.pal(9, ""Greens""))(n.gear))     descrp$paint[grep(""hkl"", descrp$Metier)] <- paint     n.gear = length(grep(""twl"", descrp$Metier))     paint = colorRampPalette(brewer.pal(9, ""Oranges""))(n.gear)     descrp$paint[grep(""twl"", descrp$Metier)] <- paint     n.gear = length(grep(""net"", descrp$Metier))     paint = colorRampPalette(brewer.pal(9, ""Blues""))(n.gear)     descrp$paint[grep(""net"", descrp$Metier)] <- paint     contain_metier <- which(descrp$Metier %in% tolower(V(g)$name))     cn <- data.frame(cn = paste(descrp$Major_species[contain_metier],          descrp$Major_gear[contain_metier], sep = ""\n""), metier = descrp$Metier[contain_metier],          paint = descrp$paint[contain_metier], stringsAsFactors = FALSE)     cn <- cn[match(tolower(V(g)$name), cn$metier), ]     V(g)$name <- cn$cn     V(g)$color <- cn$paint     return(g) }",visualization,905876096338034e8,302
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
numSites.list = scan(path),import,170372030697763e7,1
latex_analyses <- function(analyses) {     list() },not sure,393323906464502e8,300
"df_diff <- df1_aggr %>% inner_join(df2_aggr, by = c(desc_distrito_local = ""desc_distrito_local"",      desc_epigrafe = ""desc_epigrafe"")) %>% mutate(diff_perc = ((count_2018 -      count_2015)/count_2015) * 100) %>% mutate(diff = (count_2018 -      count_2015))",exploratory,497270786669105e8,303
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
"write_csv(df_diff, ""diff.csv"")",export,497270786669105e8,303
"dsResult <- data.frame(N = count, H2 = hSquared, C2 = cSquared,      E2 = eSquared, Mean = mean(ds$HtSt1), SD = sd(ds$HtSt1),      Skew = skewness(ds$HtSt1))",communication,812593935988843e8,299
library(scater),setup,43149194563739e9,305
"participation_plots <- function(type = ""jaccard"", port_choose,      years, cool_plot = FALSE, save = FALSE, tickets) {     library(dplyr)     library(tidyr)     if (type == ""jaccard"") {         if (port_choose == ""coastwide"") {             ports <- unique(tickets$pcid)         }         else {             ports <- port_choose         }         trips <- tickets %>% dplyr::filter(pcid %in% ports, year %in%              years) %>% dplyr::select(drvid, metier.2010) %>%              distinct()         library(reshape2)         cast_trips <- dcast(trips, metier.2010 ~ drvid, fun.aggregate = length)         rownames(cast_trips) <- cast_trips$metier.2010         cast_trips$metier.2010 <- NULL         library(vegan)         dist_mat <- vegdist(cast_trips, method = ""jaccard"")         sim_mat <- as.matrix(1 - dist_mat)         library(igraph)         g <- graph_from_adjacency_matrix(sim_mat, mode = ""undirected"",              weighted = TRUE, diag = NULL)         fleet_size <- rowSums(cast_trips)         V(g)$size <- fleet_size         g = delete.vertices(g, which(V(g)$size < 3))         g <- colors_common(g)         if (cool_plot) {             network <- make_plotly(g, save, port_id = port_choose,                  n.fisheries = length(E(g)))         }         else {             plot(g, edge.width = E(g)$weight * 10, layout = layout_nicely,                  vertex.size = sqrt(V(g)$size))         }     }     return(g) }",visualization,905876096338034e8,302
"main <- function() {     analyzer <- create_analyzer(""Promise Analysis"", combine_analyses,          summarize_analyses, visualize_analyses, latex_analyses)     drive_analysis(analyzer) }",communication,393323906464502e8,300
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
df <- data.frame(),setup,497270786669105e8,303
library(tidyverse),import,43149194563739e9,305
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
siteSize = 1024,setup,170372030697763e7,1
rm(list = ls(all = TRUE)),data cleaning,812593935988843e8,299
library(magrittr),import,43149194563739e9,305
"treatment = ""Selenium""",exploratory,170372030697763e7,1
library(RTCGA.clinical),import,43149194563739e9,305
main(),not sure,393323906464502e8,300
require(tidyverse),setup,630892023444176e8,306
"for (x in files) {     print(x)     y <- strsplit(x, ""/"")     file_name <- y[[1]][[length(y[[1]])]]     date <- as.Date(file_name, ""%Y%m%d"")     df_sum <- read_delim(x, "","") %>% group_by(desc_distrito_local,          desc_barrio_local, categoria) %>% summarize(count = n()) %>%          mutate(date = date)     if (nrow(df) == 0) {         df <- df_sum     }     else {         df <- rbind(df, df_sum)     } }",import,497270786669105e8,303
version = NA,setup,812593935988843e8,299
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
numSites.list = scan(path),import,170372030697763e7,1
"tt <- subset(tickets, metier.2010 %in% V(g)$name)",exploratory,905876096338034e8,302
"data(""OV.clinical"")",import,43149194563739e9,305
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
warnings(),evaluation,393323906464502e8,300
if (length(commandArgs(TRUE))) {     version = commandArgs(TRUE)[1] },evaluation,812593935988843e8,299
library(cmdsddfeitc),setup,630892023444176e8,306
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
"ov <- read_tsv(""../data/TCGA_OV_tpm.tsv.gz"")",import,43149194563739e9,305
View(df),exploratory,497270786669105e8,303
tickets <- tt,exploratory,905876096338034e8,302
"root <- paste0(""~/selection/counts/"", version, ""/all"")",setup,812593935988843e8,299
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
args <- commandArgs(TRUE),setup,630892023444176e8,306
library(e1071),import,771891796495765e8,307
siteSize = 2048,setup,170372030697763e7,1
"try(setwd(""U:/Pragmatics/New/Analysis/""))",setup,393323906464502e8,300
"treatment = ""Retinoic""",data cleaning,170372030697763e7,1
"try(setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis""))",setup,393323906464502e8,300
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
sample_names <- names(ov)[-1],data cleaning,43149194563739e9,305
notebook_ix <- as.integer(args[1]),setup,630892023444176e8,306
numSites.list = scan(path),import,170372030697763e7,1
"read.totals <- paste0(""~/selection/analysis/"", version, ""/effsize/effsize_reads.txt.gz"")",setup,812593935988843e8,299
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
ov <- data.frame(ov),data cleaning,43149194563739e9,305
"g2 <- participation_plots(port_choose = ""coastwide"", years = 2009:2013,      tickets = tt)",visualization,905876096338034e8,302
rd <- read.counts.and.data(root),import,812593935988843e8,299
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
library(SimSurvey),setup,36537865572609e9,308
"getRes = function(filename) {     histCol = ""gray""     widthx = 7     heightx = 5     d = read.csv(filename, stringsAsFactors = F)     langNames = d[, 1]     data = d[, 2:ncol(d)]     graphName = paste(""Graphs/WithinLanguage/"", tail(strsplit(filename,          ""/"")[[1]], 1), ""_Diff.pdf"", sep = """")     xlimx = max(abs(range(rowMeans(data))))     xlimx = c(-xlimx, xlimx)     pdf(file = graphName, width = widthx, height = heightx)     hist(rowMeans(data), xlab = ""Mean Difference in Entropies"",          border = histCol, col = histCol, breaks = 20, main = """",          xlim = xlimx, ylab = ""Number of Languages"")     abline(v = 0)     dev.off()     res = apply(data, 1, function(X) {         sum(X < 0, na.rm = T)/sum(!is.na(X))     })     gx = tail(strsplit(filename, ""/"")[[1]], 1)     graphName = paste(""Graphs/WithinLanguage/"", gx, ""_Prop.pdf"",          sep = """")     pdf(file = graphName, width = widthx, height = heightx)     hist(res, xlab = ""Proportion of random samples\nwith a higher entropy"",          border = histCol, col = histCol, breaks = 20, main = """",          ylab = ""Number of Languages"")     dev.off()     return(c(gx, sum(res > 0.95), sum(rowMeans(data) > 0), length(res))) }",visualization,393323906464502e8,300
siteSize = 1024,setup,170372030697763e7,1
counts <- rd$counts,setup,812593935988843e8,299
library(data.table),setup,36537865572609e9,308
"treatment = ""Retinoic""",data cleaning,170372030697763e7,1
"notebook_file <- switch(notebook_ix, `1` = ""01_preprocessing.Rmd"",      `2` = ""02_exploratory_data_analysis.Rmd"", `3` = ""03_computational_modeling_analysis.Rmd"")",import,630892023444176e8,306
totals <- rd$totals,setup,812593935988843e8,299
"pdf(file = ""Analysis/ses_network/figures/jacquard_coastwide.pdf"",      width = 8, height = 8)",export,905876096338034e8,302
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,170372030697763e7,1
set.seed(438),setup,36537865572609e9,308
data <- rd$data,setup,812593935988843e8,299
numSites.list = scan(path),import,170372030697763e7,1
"names(ov)[1] <- ""feature_id""",data cleaning,43149194563739e9,305
"chr.list = sites.list = vector(""list"", 22)",data cleaning,170372030697763e7,1
"for (chr in 1:22) {     chr.list[[chr]] = rep(chr, numSites.list[chr])     sites.list[[chr]] = 1:numSites.list[chr] }",data cleaning,170372030697763e7,1
"read.totals <- read.table(read.totals, as.is = TRUE, header = TRUE)",import,812593935988843e8,299
rownames(ov) <- ov$feature_id,data cleaning,43149194563739e9,305
"agreement <- function(gear, year) {     df10 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/classify/2010p"",          gear, year, "".RDS""))     df12 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/classify/2012p"",          gear, year, "".RDS""))     df10$predicted_metier <- paste0(df10$predicted_metier, ""_10"")     df12$predicted_metier <- paste0(df12$predicted_metier, ""_12"")     predicted_df <- merge(df10, df12, by = ""trip_id"")     table(predicted_df$predicted_metier.x, predicted_df$predicted_metier.y) }",evaluation,771891796495765e8,307
"par(bg = ""transparent"", oma = rep(0, 4), mai = rep(0, 4))",visualization,905876096338034e8,302
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,170372030697763e7,1
"save(""chr.list"", ""sites.list"", file = out.path)",export,170372030697763e7,1
ov$feature_id <- NULL,data cleaning,43149194563739e9,305
"plot(g2, edge.width = E(g)$weight * 10, vertex.label.family = ""sans"",      vertex.label = tolower(V(g)$name), vertex.label.color = ""black"",      vertex.label.cex = 1, edge.curved = TRUE, layout = layout.grid,      vertex.size = 20)",visualization,905876096338034e8,302
names(ov) <- sample_names,data cleaning,43149194563739e9,305
dev.off(),visualization,905876096338034e8,302
"id_split <- strsplit(rownames(ov), ""|"", fixed = TRUE)",data cleaning,43149194563739e9,305
"ret = data.frame(name = NA, prop95 = NA, diffGT0 = NA, N = NA)",setup,393323906464502e8,300
"results <- data.frame(pops = colnames(totals), size = apply(totals,      2, max), effective.size = colMeans(totals))",communication,812593935988843e8,299
"classAgreement(agreement(""HKL"", 2013))$crand",not sure,771891796495765e8,307
"classAgreement(agreement(""TWS"", 2013))$crand",not sure,771891796495765e8,307
"write.table(results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,812593935988843e8,299
"feature_names <- sapply(id_split, function(x) paste0(x[1], ""_"",      x[6]))",data cleaning,43149194563739e9,305
"source(""./R/VAR_functions.R"")",setup,842345289653167e8,309
"ret = rbind(ret, getRes(""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_FirstSegments.csv""))",data cleaning,393323906464502e8,300
"grgroups <- c(""TLS"", ""TWS"", ""TWL"", ""NET"", ""HKL"", ""MSC"")",data cleaning,771891796495765e8,307
"ret = rbind(ret, getRes(""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_unanalyzable_FirstSegments.csv""))",data cleaning,393323906464502e8,300
"gene_type <- sapply(id_split, `[`, 8)",data cleaning,43149194563739e9,305
rownames(ov) <- feature_names,data cleaning,43149194563739e9,305
"pop <- sim_abundance(ages = 1:20, years = 1:20, R = sim_R(mean = 3e+07,      log_sd = 0.5, random_walk = TRUE), Z = sim_Z(mean = 0.5,      log_sd = 0.2, phi_age = 0.9, phi_year = 0.5), growth = sim_vonB(Linf = 120,      L0 = 5, K = 0.1, log_sd = 0.1, length_group = 3, digits = 0)) %>%      sim_distribution(grid = make_grid(x_range = c(-140, 140),          y_range = c(-140, 140), res = c(3.5, 3.5), shelf_depth = 200,          shelf_width = 100, depth_range = c(0, 1000), n_div = 1,          strat_breaks = seq(0, 1000, by = 40), strat_splits = 2),          ays_covar = sim_ays_covar(sd = 2.8, range = 300, phi_age = 0.5,              phi_year = 0.9, group_ages = 5:20), depth_par = sim_parabola(mu = 200,              sigma = 70))",exploratory,36537865572609e9,308
"ret = ret[!is.na(ret$name), ]",data cleaning,393323906464502e8,300
"years <- c(2009, 2011, 2013)",exploratory,771891796495765e8,307
ret$prop95 = as.numeric(ret$prop95),data cleaning,393323906464502e8,300
"id_map <- read_csv(""../data/TCGA_ID_MAP.csv"") %>% filter(Disease ==      ""OV"")",import,43149194563739e9,305
ret$diffGT0 = as.numeric((ret$diffGT0)),data cleaning,393323906464502e8,300
"ARI <- matrix(NA, ncol = length(years), nrow = length(grgroups))",exploratory,771891796495765e8,307
ret$N = as.numeric(ret$N),data cleaning,393323906464502e8,300
ret$prop95.prop = ret$prop95/ret$N,data cleaning,393323906464502e8,300
"country_name <- ""Peru""",data cleaning,842345289653167e8,309
ret$diffGT0.prop = ret$diffGT0/ret$N,data cleaning,393323906464502e8,300
rownames(ARI) <- grgroups,data cleaning,771891796495765e8,307
"write.csv(ret, file = ""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/Summary.csv"")",export,393323906464502e8,300
colnames(ARI) <- years,data cleaning,771891796495765e8,307
forecast_exercise_year <- 2018,data cleaning,842345289653167e8,309
"read.results <- data.frame(pops = colnames(read.totals), effective.size = colMeans(read.totals))",setup,812593935988843e8,299
forecast_exercise_number <- 2,data cleaning,842345289653167e8,309
library(randomForest),setup,393323906464502e8,300
library(caret),setup,393323906464502e8,300
library(doMC),setup,393323906464502e8,300
library(mmadsenr),setup,393323906464502e8,300
"write.table(read.results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size_reads.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,812593935988843e8,299
library(futile.logger),setup,393323906464502e8,300
library(dplyr),setup,393323906464502e8,300
"excel_data_path <- paste0(""./data/edd_exercises/"", forecast_exercise_year,      ""_exercise_"", forecast_exercise_number, ""/"")",import,842345289653167e8,309
library(ggthemes),setup,393323906464502e8,300
"plot_india = d_analysis %>% filter(country == ""india"") %>% ggplot(aes(x = animal_selfrank,      y = mean, label = n)) + facet_wrap(~condition) + geom_bar(stat = ""identity"",      position = ""identity"", width = 0.5) + geom_errorbar(aes(ymin = mean -      2 * sd/sqrt(n), ymax = mean + 2 * sd/sqrt(n), width = 0.1)) +      theme_bw() + coord_cartesian(ylim = c(-3, 3)) + theme(text = element_text(size = 20),      legend.position = ""none"", axis.text.x = element_text(angle = 60,          hjust = 1)) + labs(title = ""Mean scaled responses, by condition: Indian adults\n"",      x = ""Pictures (sorted by mean Indian adult response to ANIMAL)"") +      stat_smooth(aes(group = 1))",exploratory,563459365395829e8,310
"country_data_level_ts <- get_raw_data_ts(country_name, excel_data_path)",import,842345289653167e8,309
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",      filename = ""per-locus-only-classification.log"")",import,393323906464502e8,300
plot_india,exploratory,563459365395829e8,310
"base_case <- sim_survey_parallel(pop, n_sims = 5, n_loops = 5,      cores = 6, set_den = 0.002, lengths_cap = 500, ages_cap = 10,      q = sim_logistic(k = 2, x0 = 3), quiet = FALSE)",modeling,36537865572609e9,308
"reco_all_variables <- find_statio_diffs(country_data_level_ts,      country_name)",data cleaning,842345289653167e8,309
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,393323906464502e8,300
"plot_us = d_analysis %>% filter(country == ""us"") %>% ggplot(aes(x = animal_selfrank,      y = mean, label = n)) + facet_wrap(~condition) + geom_bar(stat = ""identity"",      position = ""identity"", width = 0.5) + geom_errorbar(aes(ymin = mean -      2 * sd/sqrt(n), ymax = mean + 2 * sd/sqrt(n), width = 0.1)) +      theme_bw() + coord_cartesian(ylim = c(-3, 3)) + theme(text = element_text(size = 20),      legend.position = ""none"", axis.text.x = element_text(angle = 60,          hjust = 1)) + labs(title = ""Mean scaled responses, by condition: US adults\n"",      x = ""Pictures (sorted by mean US adult response to ANIMAL)"") +      stat_smooth(aes(group = 1))",visualization,563459365395829e8,310
"country_transformed_data <- follow_rec(country_data_level_ts,      reco_all_variables)",data cleaning,842345289653167e8,309
clargs <- commandArgs(trailingOnly = TRUE),setup,393323906464502e8,300
plot_us,visualization,563459365395829e8,310
VAR_data_for_estimation <- country_transformed_data,data cleaning,842345289653167e8,309
variable_names <- colnames(VAR_data_for_estimation),data cleaning,842345289653167e8,309
"plot_india = d_analysis %>% filter(country == ""india"") %>% filter(condition ==      ""animal"") %>% ggplot(aes(x = reorder(swatch, animal_selfrank),      y = mean, label = n)) + geom_bar(stat = ""identity"", position = ""identity"",      width = 0.5) + geom_errorbar(aes(ymin = mean - 2 * sd/sqrt(n),      ymax = mean + 2 * sd/sqrt(n), width = 0.1)) + theme_bw() +      coord_cartesian(ylim = c(-3, 3)) + theme(text = element_text(size = 20),      legend.position = ""none"", axis.text.x = element_text(angle = 60,          hjust = 1)) + labs(title = ""Mean scaled responses, by condition: Indian adults\n"",      x = ""Pictures (sorted by mean Indian adult response to ANIMAL)"") +      stat_smooth(aes(group = 1))",not sure,563459365395829e8,310
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,436525623546913e8,311
plot_india,not sure,563459365395829e8,310
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-population-data.rda"")     sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-sampled-data.rda"")     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-ta-sampled-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-population-data.rda"", args = clargs)     sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-sampled-data.rda"", args = clargs)     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""equifinality-3-ta-sampled-data.rda"", args = clargs) }",import,393323906464502e8,300
load(pop_data_file),import,393323906464502e8,300
library(synapser),setup,436525623546913e8,311
load(sampled_data_file),import,393323906464502e8,300
ncolumns <- ncol(VAR_data_for_estimation),not sure,842345289653167e8,309
synLogin(),setup,436525623546913e8,311
load(ta_sampled_data_file),import,393323906464502e8,300
"setdet <- base_case$setdet[, list(year, x, y, depth, strat, n,      sim, set)]",data cleaning,36537865572609e9,308
library(knitr),setup,224903381662443e8,312
"clean_rgdp <- na.omit(VAR_data_for_estimation[, ""rgdp""])",data cleaning,842345289653167e8,309
"source(""../../bin/nf1TumorHarmonization.R"")",not sure,436525623546913e8,311
"samp <- base_case$samp[base_case$samp$measured, ]",data cleaning,36537865572609e9,308
start_rgdp <- start(clean_rgdp),not sure,842345289653167e8,309
"trackdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/tracks/""",import,224903381662443e8,312
end_rgdp <- end(clean_rgdp),not sure,842345289653167e8,309
nobs_rgdp <- length(clean_rgdp),not sure,842345289653167e8,309
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,224903381662443e8,312
"prefix = paste(lubridate::today(), ""bioBank_glioma_cNF_pnf"",      sep = ""-"")",setup,436525623546913e8,311
samp$age[!samp$aged] <- NA,data cleaning,36537865572609e9,308
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",import,393323906464502e8,300
files <- list.files(path = diffdir),import,224903381662443e8,312
"flog.info(""Loaded data file: %s"", sampled_data_file, name = ""cl"")",import,393323906464502e8,300
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",import,393323906464502e8,300
samp$measured <- samp$aged <- NULL,data cleaning,36537865572609e9,308
"VAR_data_rgdp_period <- window(VAR_data_for_estimation, start = start_rgdp,      end = end_rgdp)",exploratory,842345289653167e8,309
names <- files,import,224903381662443e8,312
"flog.info(""Beginning classification analysis of equifinality-3 data sets for per-locus only predictors"",      name = ""cl"")",import,393323906464502e8,300
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,393323906464502e8,300
first_half_row <- floor(nrow(VAR_data_rgdp_period)/2),not sure,842345289653167e8,309
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",setup,393323906464502e8,300
second_half <- nrow(VAR_data_rgdp_period) - first_half_row,not sure,842345289653167e8,309
"split <- data.frame(strsplit(names, ""_""))",data cleaning,224903381662443e8,312
registerDoMC(cores = num_cores),setup,393323906464502e8,300
"saveRDS(VAR_data_for_estimation, paste0(""./analysis/VAR_output/VAR_data_"",      country_name, "".rds""))",export,842345289653167e8,309
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,224903381662443e8,312
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (1:10) *      25, .shrinkage = 0.05)",data cleaning,393323906464502e8,300
"rgdp_rec <- reco_all_variables[reco_all_variables$variable ==      ""rgdp"", ][[""kpss_05_level""]]",data cleaning,842345289653167e8,309
"adult_directories <- split[, which(split[4, ] == ""Adult"")]",data cleaning,224903381662443e8,312
"samp <- merge(setdet[, list(year, sim, set)], samp, by = ""set"")",data cleaning,36537865572609e9,308
"fn_dh_elfstats <- function(site = ""http://deq2.bse.vt.edu/d.dh"",      ftype = ""all"", fstatus = ""active"", analysis_timespan = ""full"",      yvar = ""all"", sampres = ""all"", stat_quantreg_qu = ""0.80"",      station_agg = ""max"", stat_quantreg_glo = ""all"", stat_quantreg_ghi = ""all"",      feature_ftype = ""all"", xvar = ""all"", dataset_tag = ""taxaLoss_PI_PressHuc8"",      featureid = ""all"") {     elf_statistics <- paste(site, ""export_elf_statistics"", ftype,          fstatus, analysis_timespan, yvar, sampres, stat_quantreg_qu,          station_agg, stat_quantreg_glo, stat_quantreg_ghi, feature_ftype,          xvar, dataset_tag, featureid, sep = ""/"")     print(paste(""Using URI: "", elf_statistics))     region <- feature_ftype     XV <- xvar     YV <- yvar     elf_statistics <- read.table(elf_statistics, header = TRUE,          sep = "","")     write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",          region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,          quote = TRUE)     return(elf_statistics) }",import,75470082461834e8,313
setwd(trackdir),setup,224903381662443e8,312
print(rgdp_rec),communication,842345289653167e8,309
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,393323906464502e8,300
seed_value <- 58132133,setup,393323906464502e8,300
set.seed(seed_value),setup,393323906464502e8,300
n_best <- 50,not sure,842345289653167e8,309
"bias_case <- sim_survey_parallel(pop, n_sims = 1, n_loops = 25,      cores = 6, set_den = 0.01, lengths_cap = 10, ages_cap = 10,      q = sim_logistic(k = 2, x0 = 3), quiet = FALSE)",modeling,36537865572609e9,308
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",setup,393323906464502e8,300
number_of_cv <- 8,not sure,842345289653167e8,309
fc_horizon <- 7,not sure,842345289653167e8,309
train_span <- 24,not sure,842345289653167e8,309
"setdet <- bias_case$setdet[, list(year, x, y, depth, strat, n,      sim, set)]",data cleaning,36537865572609e9,308
"for (i in seq(1, (dim(adult_directories)[2]))) {     setwd(trackdir)     strain <- as.character(adult_directories[1, i])     timepoint <- ""Adult""     filename <- paste(adult_directories[, i], collapse = ""_"")     dir <- paste(diffdir, filename, sep = ""/"")     dir.create(filename)     print(filename)     print(dir)     print(strain)     setwd(filename)     knit2html(""../Track_vis.Rmd"", output = paste(filename, "".md"",          sep = """"), quiet = TRUE)     print(dir)     print(strain) }",export,224903381662443e8,312
training_set_fraction <- 0.8,setup,393323906464502e8,300
"samp <- bias_case$samp[bias_case$samp$measured, ]",data cleaning,36537865572609e9,308
test_set_fraction <- 1 - training_set_fraction,setup,393323906464502e8,300
"source(""analysis/utils.R"")",setup,75470082461834e8,313
library(knitr),setup,224903381662443e8,312
obs_used_in_cv <- train_span + number_of_cv + fc_horizon,not sure,842345289653167e8,309
"experiment_names <- c(""Per-Locus Population Census"", ""Per-Locus Sampled 10%"",      ""Per-Locus Sampled 20%"")",setup,393323906464502e8,300
samp$age[!samp$aged] <- NA,data cleaning,36537865572609e9,308
obs_to_spare <- nobs_rgdp - obs_used_in_cv,not sure,842345289653167e8,309
"source(""analysis/analysis.R"")",setup,75470082461834e8,313
numSites = 500,setup,278662267839536e8,314
suppressPackageStartupMessages(library(dplyr)),setup,75470082461834e8,313
"trackdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/tracks/""",setup,224903381662443e8,312
perlocus_results <- data.frame(),setup,393323906464502e8,300
samp$measured <- samp$aged <- NULL,data cleaning,36537865572609e9,308
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,224903381662443e8,312
"print(paste(""Obs. used in cv:"", obs_used_in_cv))",not sure,842345289653167e8,309
perlocus_results_roc <- NULL,setup,393323906464502e8,300
perlocus_results_model <- NULL,setup,393323906464502e8,300
"print(paste(""(transformed) rgdp series has"", nobs_rgdp, ""observations""))",not sure,842345289653167e8,309
perlocus_results_cm <- NULL,setup,393323906464502e8,300
"samp <- merge(setdet[, list(year, sim, set)], samp, by = ""set"")",data cleaning,36537865572609e9,308
"print(paste(""Extra rgdp observations available:"", obs_to_spare))",not sure,842345289653167e8,309
"setwd(""C:/Users/morle001/Dropbox/Micro_IPOP"")",setup,575243528233841e8,315
"flog.info(""Starting analysis of population data without per-locus values only"",      name = ""cl"")",setup,393323906464502e8,300
i <- 1,setup,393323906464502e8,300
"print(paste(""Or, equiv., using any variable together with rgdp that forces us to loose more than"",      obs_to_spare, ""observations, will result in an error when using fixed-length training window""))",not sure,842345289653167e8,309
library(Hmisc),setup,575243528233841e8,315
exp_name <- experiment_names[i],setup,393323906464502e8,300
setwd(diffdir),setup,224903381662443e8,312
library(raster),setup,575243528233841e8,315
"eq3_pop_df$two_class_label <- factor(ifelse(eq3_pop_df$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",data cleaning,393323906464502e8,300
files <- list.files(),import,224903381662443e8,312
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/""",setup,278662267839536e8,314
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"", ""configuration_slatkin"", ""num_trait_configurations"")",data cleaning,393323906464502e8,300
library(dplyr),setup,575243528233841e8,315
"library(""dplyr"")",setup,93823644076474e9,316
names <- files,import,224903381662443e8,312
"library(""readr"")",setup,93823644076474e9,316
"plot.IO <- read.csv(""./Analysis/Cleaned_data/plot_IO_Y2.csv"")",setup,575243528233841e8,315
"model <- train_gbm_classifier(eq3_pop_df, training_set_fraction,      ""two_class_label"", gbm_grid, training_control, exclude_columns,      verbose = FALSE)",modeling,393323906464502e8,300
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/""",setup,278662267839536e8,314
"split <- data.frame(strsplit(names, ""_""))",data cleaning,224903381662443e8,312
"perlocus_results_model[[""perlocus_pop""]] <- model$tunedmodel",modeling,393323906464502e8,300
"library(""devtools"")",setup,93823644076474e9,316
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,224903381662443e8,312
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,393323906464502e8,300
"maize <- filter(plot.IO, zaocode == ""Maize"")",import,575243528233841e8,315
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",modeling,393323906464502e8,300
"embryonic_directories <- split[, which(split[4, ] == ""Embryonic"")]",data cleaning,224903381662443e8,312
results <- get_parsed_binary_confusion_matrix_stats(cm),modeling,393323906464502e8,300
results$experiments <- exp_name,modeling,393323906464502e8,300
setwd(trackdir),setup,224903381662443e8,312
results$elapsed <- model$elapsed,modeling,393323906464502e8,300
"case.name = c(""fullread.6ind.over"", ""2fullread.6ind.over"", ""4fullread.6ind.over"")",setup,278662267839536e8,314
"perlocus_results_cm[[""perlocus_pop""]] <- cm",modeling,393323906464502e8,300
"library(""SummarizedExperiment"")",setup,93823644076474e9,316
"for (i in seq(1, (dim(embryonic_directories)[2]))) {     setwd(trackdir)     strain <- as.character(embryonic_directories[1, i])     timepoint <- ""Embryonic""     filename <- paste(embryonic_directories[, i], collapse = ""_"")     dir <- paste(diffdir, filename, sep = ""/"")     dir.create(filename)     print(filename)     print(dir)     print(strain)     setwd(filename)     knit2html(""../Track_vis.Rmd"", output = paste(filename, "".md"",          sep = """"), quiet = TRUE)     print(dir)     print(strain) }",not sure,224903381662443e8,312
maize$y2_hhid <- as.character(maize$y2_hhid),data cleaning,575243528233841e8,315
results$sample_size <- 0,modeling,393323906464502e8,300
results$ta_duration <- 0,modeling,393323906464502e8,300
"perlocus_pop_roc <- calculate_roc_binary_classifier(model$tunedmodel,      model$test_data, ""two_class_label"", exp_name)",modeling,393323906464502e8,300
"hhid.reg.zone <- read.csv(""./Analysis/Cleaned_data/hhid_reg_zone_y2.csv"")",data cleaning,575243528233841e8,315
results$auc <- unlist(perlocus_pop_roc$auc@y.values),modeling,393323906464502e8,300
"load_all(""../seqUtils/"")",import,93823644076474e9,316
"perlocus_results_roc[[""perlocus_pop""]] <- perlocus_pop_roc",modeling,393323906464502e8,300
"perlocus_results <- rbind(perlocus_results, results)",modeling,393323906464502e8,300
"load_all(""analysis/housekeeping/"")",import,93823644076474e9,316
hhid.reg.zone$y2_hhid <- as.character(hhid.reg.zone$y2_hhid),import,575243528233841e8,315
"flog.info(""Starting analysis of sampled data without per-locus values only"",      name = ""cl"")",setup,393323906464502e8,300
"sample_names = read.table(""analysis/data/sample_lists/SL1344_names_all.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = FALSE)[,      1]",import,93823644076474e9,316
"design_matrix = constructDesignMatrix_SL1344(sample_names) %>%      dplyr::filter(!(donor == ""fpdj"")) %>% tbl_df() %>% dplyr::filter(!(donor ==      ""fpdl"" & replicate == 2)) %>% dplyr::filter(!(donor == ""ougl"" &      replicate == 2)) %>% dplyr::filter(!(donor == ""mijn"")) %>%      dplyr::filter(!(donor == ""qaqx"")) %>% dplyr::mutate(replicate = ifelse(donor ==      ""babk"", 2, replicate)) %>% dplyr::arrange(donor, condition) %>%      as.data.frame()",import,93823644076474e9,316
i <- 2,setup,393323906464502e8,300
exp_name <- experiment_names[i],setup,393323906464502e8,300
"coords <- read.csv(""./Analysis/Cleaned_data/lon_lat.csv"")",data cleaning,575243528233841e8,315
"eq3_sampled_10 <- dplyr::filter(eq3_sampled_df, sample_size ==      10)",data cleaning,393323906464502e8,300
coords$y2_hhid <- as.character(coords$y2_hhid),import,575243528233841e8,315
"eq3_sampled_10$two_class_label <- factor(ifelse(eq3_sampled_10$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",data cleaning,393323906464502e8,300
"with(coords, plot(lon, lat))",data cleaning,575243528233841e8,315
"count_matrix = loadCounts(""processed/salmonella/featureCounts/"",      design_matrix$sample_id, sub_dir = FALSE, counts_suffix = "".featureCounts.txt"")",exploratory,93823644076474e9,316
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"", ""configuration_slatkin"", ""num_trait_configurations"",      ""sample_size"")",data cleaning,393323906464502e8,300
log <- plot.IO$y2_hhid %in% hhid.reg.zone$y2_hhid,visualization,575243528233841e8,315
"model <- train_gbm_classifier(eq3_sampled_10, training_set_fraction,      ""two_class_label"", gbm_grid, training_control, exclude_columns,      verbose = FALSE)",modeling,393323906464502e8,300
"perlocus_results_model[[""perlocus_sampled_10""]] <- model$tunedmodel",modeling,393323906464502e8,300
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,393323906464502e8,300
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",modeling,393323906464502e8,300
results <- get_parsed_binary_confusion_matrix_stats(cm),modeling,393323906464502e8,300
"transcript_data = tbl_df(readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.transcript_data.rds"")) %>%      dplyr::rename(gene_id = ensembl_gene_id, transcript_id = ensembl_transcript_id,          gene_name = external_gene_name, chr = chromosome_name)",data cleaning,93823644076474e9,316
results$experiments <- exp_name,modeling,393323906464502e8,300
table(log),data cleaning,575243528233841e8,315
results$elapsed <- model$elapsed,modeling,393323906464502e8,300
"perlocus_results_cm[[""perlocus_sampled_10""]] <- cm",modeling,393323906464502e8,300
results$sample_size <- 10,modeling,393323906464502e8,300
library(caret),import,750256308587268e8,317
rm(list = ls()),setup,776496840175241e8,318
log2 <- plot.IO$y2_hhid %in% coords$y2_hhid,exploratory,575243528233841e8,315
results$ta_duration <- 0,modeling,393323906464502e8,300
"perlocus_sampled_10_roc <- calculate_roc_binary_classifier(model$tunedmodel,      model$test_data, ""two_class_label"", exp_name)",modeling,393323906464502e8,300
results$auc <- unlist(perlocus_sampled_10_roc$auc@y.values),modeling,393323906464502e8,300
library(doMC),import,750256308587268e8,317
library(data.table),setup,776496840175241e8,318
"perlocus_results_roc[[""perlocus_sampled_10""]] <- perlocus_sampled_10_roc",modeling,393323906464502e8,300
table(log2),visualization,575243528233841e8,315
"perlocus_results <- rbind(perlocus_results, results)",modeling,393323906464502e8,300
"""\nFor each set there are three lines:\n  the set number, position (x,y,depth), number in the set and number measured\nthe age composition with spatially varying age-length key\nage composition with spatially uniform key\n\nyear 4 sim 1\n645 [103.25 103.25 226.  ] 516 500\n[  1 199 314   1   0   0   0   0   0   0   0   0]\n[  8 233 274   2   0   0   0   0   0   0   0   0]\n\n683 [-117.25 -138.25  147.  ] 550 500\n[  0   0   0 101 210 120  64  33  12   5   3   0]\n[  1   0   0  30 134 123 107  88  38  17  10   0]\n\n666 [-138.25 -127.75   15.  ] 562 500\n[  0   0   0   0 291 144  71  36  10   7   3   0]\n[  1   0   0   4 192 141 103  69  25  15   8   2]\n\nyear 4 sim 3\n8270 [-131.25 -113.75   68.  ] 636 500\n[  0   0   0   0 309 143  82  50  35  10   6   0]\n[  2   0   0   4 187 143 124  67  74  19  11   1]\n\n8190 [ 85.75  96.25 141.  ] 831 500\n[  8 246 565  11   0   0   0   0   0   0   0   0]\n[ 30 318 469  14   0   0   0   0   0   0   0   0]\n\n8186 [ 89.25  96.25 148.  ] 1040 500\n[ 17 253 743  28   0   0   0   0   0   0   0   0]\n[ 36 390 597  17   0   0   0   0   0   0   0   0]\n\nyear 7 sim 1\n1214 [103.25  33.25 226.  ] 479 479\n[  0  14 464   0   0   0   0   0   0   0   0   0]\n[  0  36 442   0   0   0   0   0   0   0   0   0]\n\n1276 [-106.75 -106.75  184.  ] 802 500\n[  0   1   0  36 323 255  95  38  20  20   7   2]\n[  2   4   0  18 226 215 120  91  44  50  12  12]\n\n1260 [-113.75 -138.25  161.  ] 1014 500\n[  0   2   0 209 266 244 141 104  20  17   8   1]\n[  1   6   0  87 221 218 154 172  55  56  26  10]\n\nyear 7 sim 3\n8819 [110.25  64.75 303.  ] 731 500\n[  0  46 685   0   0   0   0   0   0   0   0   0]\n[  0  38 692   0   0   0   0   0   0   0   0   0]\n\n8817 [106.75  64.75 261.  ] 837 500\n[  0   4 832   0   0   0   0   0   0   0   0   0]\n[  0  44 793   0   0   0   0   0   0   0   0   0]\n\n8818 [110.25  68.25 303.  ] 1056 500\n[  0  66 990   0   0   0   0   0   0   0   0   0]\n[   0   56 1000    0    0    0    0    0    0    0    0    0]\n""",communication,36537865572609e9,308
library(maps),setup,776496840175241e8,318
"valid_chromosomes = c(""1"", ""10"", ""11"", ""12"", ""13"", ""14"", ""15"",      ""16"", ""17"", ""18"", ""19"", ""2"", ""20"", ""21"", ""22"", ""3"", ""4"",      ""5"", ""6"", ""7"", ""8"", ""9"", ""MT"", ""X"", ""Y"")",data cleaning,93823644076474e9,316
"flog.info(""Starting analysis of sampled data without per-locus values only"",      name = ""cl"")",setup,393323906464502e8,300
library(stringr),setup,776496840175241e8,318
length(unique(plot.IO$y2_hhid)),exploratory,575243528233841e8,315
i <- 3,setup,393323906464502e8,300
exp_name <- experiment_names[i],setup,393323906464502e8,300
"valid_gene_biotypes = c(""lincRNA"", ""protein_coding"", ""IG_C_gene"",      ""IG_D_gene"", ""IG_J_gene"", ""IG_V_gene"", ""TR_C_gene"", ""TR_D_gene"",      ""TR_J_gene"", ""TR_V_gene"", ""3prime_overlapping_ncrna"", ""known_ncrna"",      ""processed_transcript"", ""antisense"", ""sense_intronic"", ""sense_overlapping"")",data cleaning,93823644076474e9,316
library(mmadsenr),not sure,750256308587268e8,317
"maize2 <- left_join(maize[, c(""y2_hhid"", ""plotnum"", ""output.kg"")],      hhid.reg.zone)",exploratory,575243528233841e8,315
"eq3_sampled_20 <- dplyr::filter(eq3_sampled_df, sample_size ==      10)",data cleaning,393323906464502e8,300
library(survey),setup,776496840175241e8,318
library(futile.logger),not sure,750256308587268e8,317
"filtered_tx_data = dplyr::filter(transcript_data, gene_biotype %in%      valid_gene_biotypes, chr %in% valid_chromosomes)",data cleaning,93823644076474e9,316
"eq3_sampled_20$two_class_label <- factor(ifelse(eq3_sampled_20$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",data cleaning,393323906464502e8,300
library(ggplot2),setup,776496840175241e8,318
"countryFedStatsUrl <- ""https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv""",data cleaning,29281301307492e9,319
library(plyr),setup,776496840175241e8,318
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"", ""configuration_slatkin"", ""num_trait_configurations"",      ""sample_size"")",data cleaning,393323906464502e8,300
library(twang),setup,776496840175241e8,318
"maize3 <- left_join(maize2, select(coords, y2_hhid, lon, lat))",data cleaning,575243528233841e8,315
"length_df = dplyr::select(count_matrix, gene_id, length)",data cleaning,93823644076474e9,316
"model <- train_gbm_classifier(eq3_sampled_20, training_set_fraction,      ""two_class_label"", gbm_grid, training_control, exclude_columns,      verbose = FALSE)",modeling,393323906464502e8,300
"source(""ppta.r"")",setup,776496840175241e8,318
"perlocus_results_model[[""perlocus_sampled_20""]] <- model$tunedmodel",modeling,393323906464502e8,300
"download.file(countryFedStatsUrl, destfile = ""./countryFedStats.csv"")",data cleaning,29281301307492e9,319
"source(""crump.r"")",setup,776496840175241e8,318
"maize3$cats <- cut2(maize3$output.kg, g = 4)",data cleaning,575243528233841e8,315
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,393323906464502e8,300
"source(""ato.r"")",setup,776496840175241e8,318
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",modeling,393323906464502e8,300
library(dplyr),exploratory,750256308587268e8,317
results <- get_parsed_binary_confusion_matrix_stats(cm),modeling,393323906464502e8,300
results$experiments <- exp_name,modeling,393323906464502e8,300
results$elapsed <- model$elapsed,modeling,393323906464502e8,300
"perlocus_results_cm[[""perlocus_sampled_20""]] <- cm",modeling,393323906464502e8,300
library(ggthemes),visualization,750256308587268e8,317
"maize3.split <- split(maize3, maize3$cats)",not sure,575243528233841e8,315
"dat = fread(""AllEGUs.csv"")",import,776496840175241e8,318
results$sample_size <- 20,modeling,393323906464502e8,300
results$ta_duration <- 0,modeling,393323906464502e8,300
"perlocus_sampled_20_roc <- calculate_roc_binary_classifier(model$tunedmodel,      model$test_data, ""two_class_label"", exp_name)",modeling,393323906464502e8,300
small <- maize3.split[[1]],not sure,575243528233841e8,315
results$auc <- unlist(perlocus_sampled_20_roc$auc@y.values),modeling,393323906464502e8,300
"countryFedStatsraw <- read.csv(""countryFedStats.csv"", stringsAsFactors = FALSE,      header = TRUE)",import,29281301307492e9,319
big <- maize3.split[[4]],not sure,575243528233841e8,315
"perlocus_results_roc[[""perlocus_sampled_20""]] <- perlocus_sampled_10_roc",modeling,393323906464502e8,300
"perlocus_results <- rbind(perlocus_results, results)",modeling,393323906464502e8,300
"with(small, plot(lon, lat))",not sure,575243528233841e8,315
dim(countryFedStatsraw),exploratory,29281301307492e9,319
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""per-locus-only-classification.log"")",setup,750256308587268e8,317
"comp_fun <- function(x_y_year = c(103.25, 103.25, 4), mod_N = NULL,      sp_N = NULL) {     I <- sp_N[x == x_y_year[1] & y == x_y_year[2] & year == x_y_year[3],          list(age, I)]     I$prop <- I$I/sum(I$I)     true <- I$prop[I$age %in% 1:12] * 100     true_mat <- t(replicate(2, true))     est <- fread(mod_N)     est <- unname(as.matrix(est))     est_prop <- prop.table(est, margin = 1) * 100     dif <- true_mat - est_prop     blank <- rep(NA, ncol(est))     comp_tab <- rbind(est, blank, est_prop, blank, true, blank,          dif)     rownames(comp_tab) <- c(""Est"", """", """", ""Est prop"", """", """",          ""True prop"", """", ""Diff"", """")     colnames(comp_tab) <- 1:12     options(knitr.kable.NA = """")     cat(""x = "", x_y_year[1], "" | y = "", x_y_year[2], "" | year = "",          x_y_year[3])     knitr::kable(comp_tab, digits = 0) }",evaluation,36537865572609e9,308
"if (length(clargs) == 0) {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""per-locus-analysis-gbm.RData"")     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""per-locus-analysis-gbm-dfonly.RData"") } else {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""per-locus-analysis-gbm.RData"", args = clargs)     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-3"",          filename = ""per-locus-analysis-gbm-dfonly.RData"", args = clargs) }",evaluation,393323906464502e8,300
str(countryFedStatsraw),exploratory,29281301307492e9,319
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,750256308587268e8,317
"flog.info(""Saving combined_results of analysis to R environment snapshot: %s"",      image_file, name = ""cl"")",setup,393323906464502e8,300
clargs <- commandArgs(trailingOnly = TRUE),setup,750256308587268e8,317
"save(perlocus_results, perlocus_results_model, perlocus_results_cm,      perlocus_results_roc, file = image_file)",visualization,393323906464502e8,300
"sp_N <- merge(base_case$grid_xy, base_case$sp_N, by = ""cell"")",data cleaning,36537865572609e9,308
"flog.info(""Saving just data frame of results of analysis to R environment snapshot: %s"",      image_file_results, name = ""cl"")",visualization,393323906464502e8,300
"save(perlocus_results, file = image_file_results)",visualization,393323906464502e8,300
minyear = min(dat$Year),exploratory,776496840175241e8,318
"q_fun <- sim_logistic(k = 2, x0 = 3)",modeling,36537865572609e9,308
"flog.info(""Analysis complete"", name = ""cl"")",setup,393323906464502e8,300
plot,visualization,393323906464502e8,300
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,204531198134646e8,320
minmonth = min(dat$Month[dat$Year == minyear]),exploratory,776496840175241e8,318
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-population-data.rda"")     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-population-data.rda"", args = clargs)     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"", args = clargs) }",not sure,750256308587268e8,317
maxyear = max(dat$Year),exploratory,776496840175241e8,318
"message(""Observations while reading the Federal Stats raw data file: \na. GDP data file contains Federal Stats on Income and some census survey data with 234 observations.\nb. The file has appropriate headers and kept it while reading\nc. Only Contry Code and Income Group has relavent and useful data for analysis\nd. The file contains various other data, incomplete, which is not be required for final analysis"")",communication,29281301307492e9,319
maxmonth = max(dat$Month[dat$Year == maxyear]),exploratory,776496840175241e8,318
load(pop_data_file),import,750256308587268e8,317
nmonths = length(unique(dat$year_month)),exploratory,776496840175241e8,318
load(ta_sampled_data_file),import,750256308587268e8,317
"dir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs/WT_Adult_Male_v_Female_balanced/""",setup,393323906464502e8,300
"GTF <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/annotation/mm10_gencode_vM2_with_lncRNAs_and_LacZ.gtf""",setup,393323906464502e8,300
"dat[, `:=`(Tx, S_n_CR > 0)]",exploratory,776496840175241e8,318
"genome <- ""mm10""",setup,393323906464502e8,300
library(cummeRbund),setup,393323906464502e8,300
sp_N$I <- sp_N$N * q_fun(sp_N$age),evaluation,36537865572609e9,308
"cuff <- readCufflinks(dir = dir, gtfFile = ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/annotation/mm10_gencode_vM2_with_lncRNAs_and_LacZ.gtf"",      genome = genome)",import,393323906464502e8,300
"source(""../../bin/dermalNFData.R"")",import,29281301307492e9,319
"dat[, `:=`(Outcome, NOx..tons.)]",exploratory,776496840175241e8,318
years = 2002:2014,exploratory,776496840175241e8,318
"sig <- getSig(cuff, alpha = 0.05)",setup,393323906464502e8,300
"comp_fun(x_y_year = c(103.25, 103.25, 4), sp_N = sp_N, mod_N = ""1 199 314   1   0   0   0   0   0   0   0   0\n                  8 233 274   2   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
require(dplyr),import,29281301307492e9,319
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",not sure,750256308587268e8,317
"sigGenes <- getGenes(cuff, sig)",setup,393323906464502e8,300
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",not sure,750256308587268e8,317
require(ggplot2),import,29281301307492e9,319
"flog.info(""Beginning classification analysis of equifinality-4 data sets for per-locus only predictors"",      name = ""cl"")",not sure,750256308587268e8,317
"results = array(NA, c(5, 3, length(years)))",evaluation,776496840175241e8,318
annot <- annotation(sigGenes),setup,393323906464502e8,300
"all.mutations <- read.table(synGet(""syn5713423"")@filePath, header = T,      sep = ""\t"")",import,29281301307492e9,319
"comp_fun(x_y_year = c(-117.25, -138.25, 4), sp_N = sp_N, mod_N = ""0   0   0 101 210 120  64  33  12   5   3   0\n                  1   0   0  30 134 123 107  88  38  17  10   0"")",evaluation,36537865572609e9,308
names <- annot$gene_short_name,setup,393323906464502e8,300
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,750256308587268e8,317
"forgmt <- c(""Sexdiffs"", ""NA"", unlist(names))",setup,393323906464502e8,300
"cancer.gene.muts = read.table(synGet(""syn5611520"")@filePath,      header = T, sep = ""\t"")",import,29281301307492e9,319
"dimnames(results) = list(c(""IPTW"", ""IPTWt50"", ""Crump"", ""OverlapWeight"",      ""PPTA""), c(""Est"", ""2.5%"", ""97.5%""), years)",data cleaning,776496840175241e8,318
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",not sure,750256308587268e8,317
gmt <- data.frame(forgmt),import,393323906464502e8,300
"cat(forgmt, file = ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"",      sep = ""\t"")",import,393323906464502e8,300
"sample_sizes = matrix(NA, length(years), 3)",exploratory,776496840175241e8,318
"non.silent = subset(all.mutations, Mutation_Type != ""Silent"")",data cleaning,29281301307492e9,319
registerDoMC(cores = num_cores),not sure,750256308587268e8,317
library(GSA),setup,393323906464502e8,300
"test <- GSA.read.gmt(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs_upper.gmt"")",import,393323906464502e8,300
"comp_fun(x_y_year = c(-138.25, -127.75, 4), sp_N = sp_N, mod_N = ""0   0   0   0 291 144  71  36  10   7   3   0\n                  1   0   0   4 192 141 103  69  25  15   8   2"")",evaluation,36537865572609e9,308
"som.counts = subset(non.silent, Mutation_Status == ""Somatic"") %>%      group_by(Sample_ID) %>% summarize(MutatedGenes = n_distinct(Hugo_Symbol),      DistinctMutations = n_distinct(Protein_Change))",data cleaning,29281301307492e9,319
"comp_fun(x_y_year = c(-138.25, -113.75, 4), sp_N = sp_N, mod_N = ""0   0   0   0 309 143  82  50  35  10   6   0\n                  2   0   0   4 187 143 124  67  74  19  11   1"")",evaluation,36537865572609e9,308
"comp_fun(x_y_year = c(85.75, 96.25, 4), sp_N = sp_N, mod_N = "" 8 246 565  11   0   0   0   0   0   0   0   0\n                  30 318 469  14   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/cluster_sol_objectives_asw.Rdata"")",import,393323906464502e8,300
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/propTable_tickets.Rdata"")",import,393323906464502e8,300
"comp_fun(x_y_year = c(89.25, 96.25, 4), sp_N = sp_N, mod_N = ""17 253 743  28   0   0   0   0   0   0   0   0\n                  36 390 597  17   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
"dimnames(sample_sizes) = list(years, c(""Untreated"", ""Treated"",      ""Total""))",data cleaning,776496840175241e8,318
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (2:10) *      50, .shrinkage = 0.05)",exploratory,750256308587268e8,317
"df = tidyr::gather(som.counts, ""SomaticEvent"", ""Count"", 2:3)",data cleaning,29281301307492e9,319
"comp_fun(x_y_year = c(103.25, 33.25, 7), sp_N = sp_N, mod_N = ""0  14 464   0   0   0   0   0   0   0   0   0\n                  0  36 442   0   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
"prop_table$cluster <- cluster_ind[, ""cluster""]",data cleaning,393323906464502e8,300
"gf_prop <- subset(prop_table, cluster == 3)",data cleaning,393323906464502e8,300
"comp_fun(x_y_year = c(-106.75, -106.75, 7), sp_N = sp_N, mod_N = ""0   1   0  36 323 255  95  38  20  20   7   2\n                  2   4   0  18 226 215 120  91  44  50  12  12"")",evaluation,36537865572609e9,308
"gf_tickets <- subset(tickets, ftid %in% gf_prop$ftid)",data cleaning,393323906464502e8,300
"p <- ggplot(df) + geom_bar(aes(x = Sample_ID, y = Count, fill = SomaticEvent),      stat = ""identity"", position = ""dodge"") + theme(axis.text.x = element_text(angle = 90,      hjust = 1))",visualization,29281301307492e9,319
"comp_fun(x_y_year = c(-113.75, -138.25, 7), sp_N = sp_N, mod_N = ""0   2   0 209 266 244 141 104  20  17   8   1\n                  1   6   0  87 221 218 154 172  55  56  26  10"")",evaluation,36537865572609e9,308
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,750256308587268e8,317
"comp_fun(x_y_year = c(110.25, 64.75, 7), sp_N = sp_N, mod_N = ""0  46 685   0   0   0   0   0   0   0   0   0\n                  0  38 692   0   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
"som.cancer = subset(subset(non.silent, Hugo_Symbol %in% cancer.gene.muts$Hugo_Symbol),      Mutation_Status == ""Somatic"") %>% group_by(Sample_ID) %>%      summarize(MutatedCancerGenes = n_distinct(Hugo_Symbol), DistinctCancerMutations = n_distinct(Protein_Change))",data cleaning,29281301307492e9,319
"comp_fun(x_y_year = c(106.75, 64.75, 7), sp_N = sp_N, mod_N = ""0   4 832   0   0   0   0   0   0   0   0   0\n                  0  44 793   0   0   0   0   0   0   0   0   0"")",evaluation,36537865572609e9,308
seed_value <- 58132133,setup,750256308587268e8,317
"comp_fun(x_y_year = c(110.25, 68.25, 7), sp_N = sp_N, mod_N = ""0   66  990    0    0    0    0    0    0    0    0    0\n                  0   56 1000    0    0    0    0    0    0    0    0    0"")",evaluation,36537865572609e9,308
by_trip <- data.table(gf_tickets),data cleaning,393323906464502e8,300
set.seed(seed_value),setup,750256308587268e8,317
"df2 = tidyr::gather(som.cancer, ""SomaticEvent"", ""Count"", 2:3)",data cleaning,29281301307492e9,319
"setkey(by_trip, ftid)",data cleaning,393323906464502e8,300
library(Rstrap),setup,36537865572609e9,308
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",not sure,750256308587268e8,317
"p <- ggplot(rbind(df, df2)) + geom_bar(aes(x = Sample_ID, y = Count,      fill = SomaticEvent), stat = ""identity"", position = ""dodge"") +      theme(axis.text.x = element_text(angle = 90, hjust = 1))",visualization,29281301307492e9,319
"catch <- by_trip[, sum(landed_wt), by = c(""ftid"", ""spid"")]",data cleaning,393323906464502e8,300
"load(""analysis/rv_data/converted_set_details_2018-02-26.Rdata"")",import,36537865572609e9,308
p <- p + scale_y_log10(),visualization,29281301307492e9,319
"load(""analysis/rv_data/converted_length-frequency_data_2018-02-26.Rdata"")",import,36537865572609e9,308
"total_catch <- dcast.data.table(catch, ftid ~ spid, fun = sum)",modeling,393323906464502e8,300
"library(""reshape2"")",data cleaning,831366214435548e8,321
training_set_fraction <- 0.8,setup,750256308587268e8,317
"png(""somaticMutationLoadAcrossSamples.png"")",export,29281301307492e9,319
test_set_fraction <- 1 - training_set_fraction,setup,750256308587268e8,317
prop_table <- as.data.frame(total_catch),setup,393323906464502e8,300
"library(""reshape"")",data cleaning,831366214435548e8,321
"prop_table[, 2:ncol(prop_table)] <- prop_table[, 2:ncol(prop_table)]/rowSums(prop_table[,      2:ncol(prop_table)])",not sure,393323906464502e8,300
"library(""tidyr"")",data cleaning,831366214435548e8,321
"experiment_names <- c(""Per-Locus Population Census"")",setup,750256308587268e8,317
"load(""analysis/rv_data/age-growth_data_2018-02-26.Rdata"")",import,36537865572609e9,308
"for (i in 1:length(years)) {     dat_annual = dat[Year == years[i], list(Outcome = sum(Outcome,          na.rm = TRUE), months_with_outcome = sum(!is.na(Outcome)),          Txmonths = sum(Tx == TRUE), isCoal = Fuel.Type..Primary..x[1] ==              ""Coal"", initialYear = Initial.Year.of.Operation[1],          S_n_CR = (sum(S_n_CR) >= 6), avgNOxControls = mean(NumNOxControls -              (Tx == 1), na.rm = TRUE), scrubber = (sum(AnySO2control) >=              6), totOpTime = sum(Operating.Time), NOxemissions = sum(NOx..tons.),          SO2emissions = sum(SO2..tons.), CO2emissions = sum(CO2..short.tons.),          GrossLoad = sum(Gross.Load..MW.h.), HeatInput = sum(Heat.Input..MMBtu.),          pctCapacity = mean(Heat.Input..MMBtu./Capacity), Phase2 = Is.Phase2[1],          EPA.Region = EPA.Region[1], Latitude = Facility.Latitude.x[1],          Longitude = Facility.Longitude.x[1]), by = c(""uID"")]     dim(dat_annual)     dat_annual = dat_annual[Outcome != 0, ]     with(dat_annual, table(months_with_outcome))     dat_annual = dat_annual[months_with_outcome == 12, ]     dim(dat_annual)     with(dat_annual, table(Txmonths))     dat_annual = dat_annual[Txmonths %in% c(0, 12)]     dim(dat_annual)     colMeans(is.na(dat_annual))     dat_annual = dat_annual[!is.na(HeatInput) & !is.na(pctCapacity),          ]     dat_annual[, `:=`(Tx, (Txmonths == 12))]     with(dat_annual, table(Tx))     dim(dat_annual)     dat_annual[, `:=`(Outcome, log(Outcome))]     n_grp = with(dat_annual, table(Tx))     sample_sizes[i, c(""Untreated"", ""Treated"")] = n_grp     sample_sizes[i, ""Total""] = dim(dat_annual)[[1]]     with(dat_annual, t.test(Outcome ~ Tx))     dat_annual[, `:=`(coal_no_scrubber, (isCoal == TRUE & scrubber ==          FALSE))]     dat_annual[, `:=`(coal_with_scrubber, (isCoal == TRUE & scrubber ==          TRUE))]     psmod = glm(Tx ~ totOpTime + HeatInput + pctCapacity + Phase2 +          avgNOxControls + coal_no_scrubber + coal_with_scrubber +          as.factor(EPA.Region), family = binomial, data = dat_annual)     summary(psmod)     dat_annual[, `:=`(ps, psmod$fitted)]     colors = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5))     par(mfrow = c(1, 1))     with(subset(dat_annual, Tx == FALSE), hist(ps, breaks = 100,          col = colors[1], main = """", xlab = ""Estimated Propensity Scores"",          xlim = c(0, 1)))     with(subset(dat_annual, Tx == TRUE), hist(ps, breaks = 100,          col = colors[2], add = TRUE))     legend(""top"", c(""Untreated"", ""Treated""), fill = colors, bty = ""n"")     par(mfrow = c(2, 1))     with(subset(dat_annual, Tx == FALSE), hist(ps, xlim = c(0,          1), breaks = 50, main = paste(n_grp[1], ""Untreated"")))     with(subset(dat_annual, Tx == TRUE), hist(ps, xlim = c(0,          1), breaks = 50, main = paste(n_grp[2], ""Treated"")))     dev.off()     dat_annual[, `:=`(W, Tx/ps + (1 - Tx)/(1 - ps))]     with(dat_annual, hist(W, breaks = 50))     summary(dat_annual$W)     msm = svyglm(Outcome ~ Tx, family = ""gaussian"", design = svydesign(~1,          weights = ~W, data = dat_annual))     IPW = c(coef(msm)[2], confint(msm)[2, ])     IPW     bal.ipw = bal.table(dx.wts(dat_annual$ps, dat_annual, treat.var = ""Tx"",          vars = c(""totOpTime"", ""HeatInput"", ""pctCapacity"", ""Phase2"",              ""avgNOxControls"", ""coal_no_scrubber"", ""coal_with_scrubber""),          estimand = ""ATE"", x.as.weights = F))     if (i == 1) {         balance = numeric(length(years) * 6 * 9)         dim(balance) = c(length(years), 9, 6)         dimnames(balance)[[2]] <- rownames(bal.ipw[[1]])         dimnames(balance)[[3]] <- c(""Unweighted"", ""IPTW"", ""IPTWt50"",              ""PPTA"", ""OverlapWeight"", ""Crump"")     }     balance[i, , ""Unweighted""] = bal.ipw[[1]][, ""std.eff.sz""]     balance[i, , ""IPTW""] = bal.ipw[[2]][, ""std.eff.sz""]     dat_annual[, `:=`(Wt50, ifelse(W > 50, 50, W))]     with(dat_annual, table(Wt50 == 50))     msmt50 = svyglm(Outcome ~ Tx, family = ""gaussian"", design = svydesign(~1,          weights = ~Wt50, data = dat_annual))     IPWt50 = c(coef(msmt50)[2], confint(msmt50)[2, ])     IPWt50     balance[i, , ""IPTWt50""] = bal.table(dx.wts(dat_annual$Wt50,          dat_annual, treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"",              ""pctCapacity"", ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"",              ""coal_with_scrubber""), estimand = ""ATE"", x.as.weights = T))[[2]][,          ""std.eff.sz""]     crum = crump(Y = dat_annual$Outcome, A = dat_annual$Tx, PS = dat_annual$ps)     crum[c(""est"", ""CI"")]     balance[i, , ""Crump""] = bal.table(dx.wts(crum$w, dat_annual,          treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"",              ""pctCapacity"", ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"",              ""coal_with_scrubber""), estimand = ""ATE"", x.as.weights = T))[[2]][,          ""std.eff.sz""]     overlap_wt = ato(Y = dat_annual$Outcome, A = dat_annual$Tx,          PS = dat_annual$ps)     overlap_wt[c(""ato"", ""CI"")]     balance[i, , ""OverlapWeight""] = bal.table(dx.wts(overlap_wt$w,          dat_annual, treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"",              ""pctCapacity"", ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"",              ""coal_with_scrubber""), estimand = ""ATE"", x.as.weights = T))[[2]][,          ""std.eff.sz""]     X = model.matrix(psmod)[, -1]     out.design = PPTA.design(A = dat_annual$Tx, X = X, M = 1000)     out.analysis = PPTA.analysis(Y = dat_annual$Outcome, out = out.design,          Qburn = 100, Q = 1000, outcome.dist = ""gaussian"")     cond.means = apply(out.analysis$mcmc[, 2, ], 2, mean)     out.ppta = c(mean(cond.means), quantile(out.analysis$mcmc[,          2, ], c(0.025, 0.975)))     if (T) {         S = out.design$S         S[is.na(S)] = 0         temp2 = apply(S, 2, function(x) bal.table(dx.wts(1 *              x, dat_annual, treat.var = ""Tx"", vars = c(""totOpTime"",              ""HeatInput"", ""pctCapacity"", ""Phase2"", ""avgNOxControls"",              ""coal_no_scrubber"", ""coal_with_scrubber""), estimand = ""ATE"",              x.as.weights = T))[[2]][, ""std.eff.sz""])         balance[i, , ""PPTA""] = rowMeans(temp2, na.rm = T)     }     results[""IPTW"", , i] = IPW     results[""IPTWt50"", , i] = IPWt50     results[""Crump"", , i] = c(crum$est, crum$CI)     results[""OverlapWeight"", , i] = c(overlap_wt$ato, overlap_wt$CI)     results[""PPTA"", , i] = out.ppta     print(paste(""Year"", years[i], ""completed."")) }",not sure,776496840175241e8,318
print(p),visualization,29281301307492e9,319
"library(""gdata"")",not sure,831366214435548e8,321
"pca_prop <- prcomp(prop_table[, 2:ncol(prop_table)], scale = T)",exploratory,393323906464502e8,300
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,251347755547613e8,322
"npc <- length(which(summary(pca_prop)[[6]][3, ] < 0.79))",exploratory,393323906464502e8,300
getwd(),setup,831366214435548e8,321
"balance[, , ""Unweighted""]",exploratory,776496840175241e8,318
"while (summary(pca_prop)[[6]][3, ][npc] < 0.8) npc = npc + 1",exploratory,393323906464502e8,300
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,251347755547613e8,322
dev.off(),export,29281301307492e9,319
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,251347755547613e8,322
"con.setdet <- con.setdet[(con.setdet$rec == 5 | (con.setdet$rec ==      6 & con.setdet$spec == 438)) & con.setdet$NAFOdiv == ""3P"",      ]",data cleaning,36537865572609e9,308
"dat_setup <- pca_prop$x[, 1:npc]",data cleaning,393323906464502e8,300
"data_test <- read.csv(""Analysis/data/ImportedAsIsDataChulwalar.csv"",      sep = "";"")",import,831366214435548e8,321
bal = data.frame(),not sure,776496840175241e8,318
row <- seq(1:nrow(dat_setup)),data cleaning,393323906464502e8,300
"con.lf <- con.lf[con.lf$spec == 438 & con.lf$NAFOdiv == ""3P"",      ]",data cleaning,36537865572609e9,308
"dat_setup <- cbind(dat_setup, row)",data cleaning,393323906464502e8,300
"dat_setup <- dat_setup[sample(nrow(dat_setup)), ]",data cleaning,393323906464502e8,300
"ag <- ag[ag$spec == 438 & ag$NAFOdiv == ""3P"", ]",data cleaning,36537865572609e9,308
"data_test <- data_test[c(-13, -14, -27, -28, -41, -42, -55, -56,      -69, -70, -83, -84, -97), ]",import,831366214435548e8,321
"dat_prop <- dat_setup[, 1:(ncol(dat_setup) - 1)]",data cleaning,393323906464502e8,300
require(cluster),setup,393323906464502e8,300
"rv_data <- list(setdet = con.setdet, lf = con.lf, ag = ag)",data cleaning,36537865572609e9,308
max.clusts = 12,setup,393323906464502e8,300
samples = 50,setup,393323906464502e8,300
sampsize = 500,setup,393323906464502e8,300
"harmonic = ""1F1""",setup,251347755547613e8,322
"path2read = ""~/Desktop/gitHub/protracted_sp/analysis/R/""",data cleaning,411880841711536e8,323
"clust.dat.prop <- vector(""list"", length = max.clusts)",setup,393323906464502e8,300
set.seed(2),setup,393323906464502e8,300
"synStore(File(""somaticMutationLoadAcrossSamples.png"", parentId = ""syn5605256""),      used = list(list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/analysis/2016-03-08/somaticMutsRnaProcessing.R"",          wasExecuted = TRUE)))",not sure,29281301307492e9,319
"x <- c(""total_as_is"", ""efak_as_is"", ""wuge_as_is"", ""total_etel_as_is"",      ""blue_etel_as_is"", ""red_etel_as_is"", ""total_yearly_exports_as_is"")",import,831366214435548e8,321
p_thresh = 5e-04,setup,251347755547613e8,322
"for (i in 1:max.clusts) {     clust.dat.prop[[i]] <- clara(dat_prop, i, stand = TRUE, samples = samples,          sampsize = sampsize, keep.data = FALSE, pamLike = TRUE,          rngR = TRUE)     cat(i, ""..."") }",modeling,393323906464502e8,300
plot_titles = TRUE,setup,251347755547613e8,322
"ga.files <- synapseQuery(""select * from entity where parentId=='syn5605256'"")",import,29281301307492e9,319
"index.strata <- c(293:300, 306:326, 705:708, 711:716, 779:783)",evaluation,36537865572609e9,308
"condition = ""Direction""",setup,251347755547613e8,322
"y <- rep(x, each = 12)",evaluation,831366214435548e8,321
"path2data = ""~/Desktop/gitHub/protracted_sp/analysis/data/""",export,411880841711536e8,323
objectives <- vector(length = max.clusts),setup,393323906464502e8,300
"study = ""MOFO""",setup,251347755547613e8,322
"group = ""child""",setup,251347755547613e8,322
"data_test[""new_col""] <- y",data cleaning,831366214435548e8,321
"path2plot = ""~/Desktop/gitHub/protracted_sp/analysis/output/""",visualization,411880841711536e8,323
for (i in 1:max.clusts) {     objectives[i] <- clust.dat.prop[[i]]$objective },not sure,393323906464502e8,300
"source(paste0(path2read, ""plot_functions.R""))",visualization,411880841711536e8,323
"out <- strat.fun(setdet = rv_data$setdet, lf = rv_data$lf, ag = rv_data$ag,      data.series = ""Campelen"", program = ""strat2 & strat1"", species = 438,      survey.year = 1995:2017, season = ""spring"", NAFOdiv = ""3P"",      strat = c(293:300, 306:326, 705:708, 711:716, 779:783), sex = c(""male"",          ""female"", ""unsexed""), length.group = 3, group.by = ""length & age"",      export = NULL, plot.results = FALSE)",export,36537865572609e9,308
dpi = 300,visualization,251347755547613e8,322
n_top = 9,visualization,251347755547613e8,322
"fwrite(out$raw.data$set.details, file = ""analysis/cod_sim_exports/2018-09-12_for_Geoff/cod_3Ps_setdet.csv"")",export,36537865572609e9,308
asw <- vector(length = max.clusts),setup,393323906464502e8,300
"data_new <- reshape2::melt(data_test, c(""Total.As.Is"", ""new_col""))",data cleaning,831366214435548e8,321
"par = get_param(output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",modeling,411880841711536e8,323
"fwrite(out$raw.data$age.growth, file = ""analysis/cod_sim_exports/2018-09-12_for_Geoff/cod_3Ps_samp.csv"")",export,36537865572609e9,308
"names(data_new) <- c(""month"", ""variable"", ""year"", ""total_amount"")",data cleaning,831366214435548e8,321
for (i in 2:max.clusts) {     asw[i] <- clust.dat.prop[[i]]$silinfo$avg.width },not sure,393323906464502e8,300
"analysis_path <- ""child-tuning/analysis/""",import,251347755547613e8,322
head(par),exploratory,411880841711536e8,323
"species_total <- colSums(prop_table[, 2:ncol(prop_table)])",data cleaning,393323906464502e8,300
"tsvs = ga.files$entity.id[grep(""mutations.tsv"", ga.files$entity.name)]",exploratory,29281301307492e9,319
"data_path <- paste(analysis_path, ""data/"", sep = """")",import,251347755547613e8,322
"species_total <- sort(species_total, decreasing = T)",data cleaning,393323906464502e8,300
"data_new$month[data_new$month == ""Dez""] <- ""Dec""",data cleaning,831366214435548e8,321
barplot(species_total),visualization,393323906464502e8,300
"pdfs = ga.files$entity.id[grep(""PerPatient"", ga.files$entity.name)]",exploratory,29281301307492e9,319
"data_new$month[data_new$month == ""Mai""] <- ""May""",data cleaning,831366214435548e8,321
str(par),exploratory,411880841711536e8,323
"figs_path <- ""child-tuning/figs/""",export,251347755547613e8,322
"data_fn <- ""child-mofo-all.csv""",import,251347755547613e8,322
"data_new_new <- spread(data_new, key = variable, value = total_amount)",data cleaning,831366214435548e8,321
"res = read.BPBD(chains = 2, output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",modeling,411880841711536e8,323
"egi_fn <- ""egi.csv""",export,251347755547613e8,322
"data_new_new$year <- substr(data_new_new$year, 2, 5)",data cleaning,831366214435548e8,321
"topo_fn <- ""topoplog.png""",visualization,251347755547613e8,322
"save(res, file = paste0(path2data, ""simulation_study_results.RData""))",export,411880841711536e8,323
data_new_new$year <- as.numeric(data_new_new$year),data cleaning,831366214435548e8,321
"accp = check_MCMC(res$samples, ""acc"")",modeling,411880841711536e8,323
library(quickpsy),setup,393323906464502e8,300
library(circular),setup,393323906464502e8,300
"fn_path <- paste(data_path, data_fn, sep = """")",export,251347755547613e8,322
library(cowplot),setup,393323906464502e8,300
logNorm <- rna_count_matrix(doLogNorm = TRUE),modeling,29281301307492e9,319
library(Hmisc),setup,393323906464502e8,300
"data_new_new[""month_number""] <- match(data_new_new$month, month.abb)",data cleaning,831366214435548e8,321
"gg0 = ggplot(melt(accp), aes(value)) + geom_histogram() + facet_grid(. ~      variable) + geom_vline(aes(xintercept = 0.3), colour = ""red"")",visualization,411880841711536e8,323
oneColumnWidth <- 3.42,setup,393323906464502e8,300
onehalfColumnWidth <- 4.5,setup,393323906464502e8,300
twoColumnWidth <- 7,setup,393323906464502e8,300
sizeLine1 <- 0.25,setup,393323906464502e8,300
sizeText <- 2.5,setup,393323906464502e8,300
"ggsave(filename = paste0(path2plot, ""Simulation_study_accpRatio.pdf""),      plot = gg0)",communication,411880841711536e8,323
theme_track <- theme_set(theme_bw(10)),setup,393323906464502e8,300
"data_new_new <- data_new_new[, c(""month"", ""month_number"", ""year"",      ""blue_etel_as_is"", ""red_etel_as_is"", ""total_etel_as_is"",      ""efak_as_is"", ""wuge_as_is"", ""total_as_is"", ""total_yearly_exports_as_is"")]",data cleaning,831366214435548e8,321
voomNorm <- rna_count_matrix(doVoomNorm = TRUE),exploratory,29281301307492e9,319
"egi_path <- paste(data_path, egi_fn, sep = """")",not sure,251347755547613e8,322
"theme_track <- theme_update(panel.border = element_blank(), panel.grid = element_blank(),      strip.background = element_blank(), axis.ticks = element_line(size = sizeLine1),      axis.line.x = element_line(colour = ""black"", size = sizeLine1,          linetype = ""solid""), axis.line.y = element_line(colour = ""black"",          size = sizeLine1, linetype = ""solid""), axis.ticks = element_line(size = sizeLine1),      strip.background = element_blank())",visualization,393323906464502e8,300
"data_new_new <- data_new_new[order(data_new_new$year, data_new_new$month_number),      ]",data cleaning,831366214435548e8,321
"(ZERO = check_MCMC(res$samples, ""all""))",modeling,411880841711536e8,323
"write.table(logNorm, ""featureCountsByGeneLogNormalized.txt"")",export,29281301307492e9,319
"topo_path <- paste(figs_path, ""topoplot.png"", sep = """")",export,251347755547613e8,322
"write.table(voomNorm, ""featureCountsByGeneVOOMnormalized.txt"")",export,29281301307492e9,319
totalerrorToDegSemi <- function(x) (x + 90)%%180 - 90,setup,393323906464502e8,300
library(ggplot2),import,251347755547613e8,322
plot(res$mcmc[[1]]),visualization,411880841711536e8,323
degSemiToDegFull <- function(x) 2 * x,setup,393323906464502e8,300
library(dplyr),import,251347755547613e8,322
degFullToDegSemi <- function(x) x/2,setup,393323906464502e8,300
library(png),import,251347755547613e8,322
"degFullToRadFull <- function(x) circular(x/180 * pi, units = ""radians"")",setup,393323906464502e8,300
library(gridExtra),import,251347755547613e8,322
"radFullToDegFull <- function(x) circular(x/pi * 180, units = ""deg"")",setup,393323906464502e8,300
library(coda),import,411880841711536e8,323
library(tidyr),import,251347755547613e8,322
library(knitr),import,251347755547613e8,322
library(DescTools),import,251347755547613e8,322
"datpha <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk""), task = ""phase"", session = as.character(1:4))",import,393323906464502e8,300
"synStore(File(""featureCountsByGeneLogNormalized.txt"", parentId = ""syn4984701""),      used = list(list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/analysis/2016-03-08/somaticMutsRnaProcessing.R"",          wasExecuted = TRUE)))",import,29281301307492e9,319
"gelman = lapply(res$mcmc, gelman.diag)",modeling,411880841711536e8,323
library(heplots),import,251347755547613e8,322
as_is_data <- data_new_new,data cleaning,831366214435548e8,321
"synStore(File(""featureCountsByGeneVOOMnormalized.txt"", parentId = ""syn4984701""),      used = list(list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/analysis/2016-03-08/somaticMutsRnaProcessing.R"",          wasExecuted = TRUE)))",import,29281301307492e9,319
"datpha$participant <- datpha$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"")",data cleaning,393323906464502e8,300
library(Cairo),import,251347755547613e8,322
"datpha <- datpha %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,393323906464502e8,300
"plan_base <- read.csv(""Analysis/data/ImportedPlanDataChulwalar.csv"",      sep = "";"")",import,831366214435548e8,321
"avpha <- datpha %>% group_by(participant, freq) %>% do({     m <- smean.cl.boot(.$response)     data.frame(m = m[[1]], inf = m[[2]], sup = m[[3]]) })",data cleaning,393323906464502e8,300
"ggplot(avpha, aes(x = freq, y = m, ymin = inf, ymax = sup, color = participant)) +      geom_line() + geom_pointrange()",visualization,393323906464502e8,300
"dattrack <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk""), task = c(""tracking""),      session = as.character(1:4))",import,393323906464502e8,300
"plan_base <- plan_base[c(-13, -14, -27, -28, -41, -42, -55, -56,      -69, -70, -83, -84), ]",data cleaning,831366214435548e8,321
"dattrack$participant <- dattrack$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"")",data cleaning,393323906464502e8,300
"conver = do.call(rbind, lapply(gelman, function(x) setNames(c(x[[2]],      x[[1]][, 1]), c(""mult"", ""b"", ""mu1"", ""la1"", ""mu2""))))",modeling,411880841711536e8,323
"direction_conds <- c(1, 2, 3, 6, 7, 8)",data cleaning,251347755547613e8,322
"dattrack <- dattrack %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,393323906464502e8,300
library(synapser),import,29281301307492e9,319
"plan_names <- c(""total_plan"", ""efak_plan"", ""wuge_plan"", ""total_etel_plan"",      ""blue_etel_plan"", ""red_etel_plan"", ""total_yearly_exports_plan"")",data cleaning,831366214435548e8,321
"psychom <- function(x, p) (1 - p[3]) - (0.5 - p[3]) * cum_normal_fun(x,      c(p[1], p[2]))",data cleaning,393323906464502e8,300
"gg = ggplot(melt(conver), aes(value)) + geom_histogram() + facet_grid(. ~      Var2) + geom_vline(aes(xintercept = 1.1), colour = ""red"")",visualization,411880841711536e8,323
synLogin(),setup,29281301307492e9,319
"pini <- list(c(0.5, 4), c(0.05, 5), c(0, 0.5))",setup,393323906464502e8,300
"plan_names_blowout <- rep(plan_names, each = 12)",data cleaning,831366214435548e8,321
"coherence.conds <- c(4, 9)",modeling,251347755547613e8,322
"source(""../../bin/nf1TumorHarmonization.R"")",import,29281301307492e9,319
"fig.only.conds <- c(5, 10)",modeling,251347755547613e8,322
"plan_base[""new_col""] <- plan_names_blowout",data cleaning,831366214435548e8,321
"fit70 <- quickpsy(dattrack, freq, response, grouping = .(participant),      fun = psychom, parini = pini, prob = 0.7, bootstrap = ""none"")",modeling,393323906464502e8,300
"fit90 <- quickpsy(dattrack, freq, response, grouping = .(participant),      fun = psychom, parini = pini, prob = 0.9, bootstrap = ""none"")",modeling,393323906464502e8,300
library(magrittr),setup,402218802366406e8,187
library(plyr),setup,402218802366406e8,187
"fit80 <- quickpsy(dattrack, freq, response, grouping = .(participant),      fun = psychom, parini = pini, prob = 0.8, B = 1000)",modeling,393323906464502e8,300
library(dplyr),setup,402218802366406e8,187
"ggsave(filename = paste0(path2plot, ""Simulation_study_convergence.pdf""),      plot = gg)",export,411880841711536e8,323
library(ggplot2),setup,402218802366406e8,187
fitthre70 <- fit70$thresholds %>% rename(thre70 = thre) %>% select(-prob),modeling,393323906464502e8,300
fitthre90 <- fit90$thresholds %>% rename(thre90 = thre) %>% select(-prob),modeling,393323906464502e8,300
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,402218802366406e8,187
fitthre <- fitthre70 %>% merge(fitthre90),modeling,393323906464502e8,300
"plan_base_new <- reshape2::melt(plan_base, c(""Total.Plan"", ""new_col""))",exploratory,831366214435548e8,321
"ml = mclapply(X = branches, FUN = function(b) pbd_ML(brts = b,      initparsopt = c(1, 0.5, 3, 2), exteq = 0, verbose = FALSE),      mc.cores = 3)",modeling,411880841711536e8,323
"record = read.csv(""Analysis/Parsed Data/pilots_production.csv"")",import,402218802366406e8,187
"ptrack <- ggplot() + facet_wrap(~participant) + geom_ribbon(data = fit70$curves %>%      merge(fitthre) %>% filter(x > thre90 & x < thre70), aes(x = x,      ymin = 0.4, ymax = y), alpha = 0.1) + geom_point(data = fit70$averages,      size = 0.8, aes(x = freq, y = prob, color = ""Tracking"")) +      geom_line(data = fit70$curves, size = sizeLine1, aes(x = x,          y = y, color = ""Tracking"")) + geom_point(data = avpha,      size = 0.8, aes(x = freq, y = m, ymin = inf, ymax = sup,          color = ""Alignment"")) + geom_line(data = avpha, size = sizeLine1,      aes(x = freq, y = m, ymin = inf, ymax = sup, color = ""Alignment"")) +      scale_color_brewer(palette = ""Set1"") + scale_x_continuous(limits = c(0,      3.5), breaks = seq(0, 3.5, 1)) + scale_y_continuous(breaks = seq(0.5,      1, 0.25)) + labs(x = ""Frequency (rps)"", y = ""Probability of correct responses"") +      theme(legend.key = element_blank(), legend.title = element_blank(),          legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,393323906464502e8,300
"names(plan_base_new) <- c(""month"", ""variable"", ""year"", ""total_amount"")",data cleaning,831366214435548e8,321
ptrack,visualization,393323906464502e8,300
"save_plot(""analysis/figures/trackalig.pdf"", ptrack, base_width = twoColumnWidth)",export,393323906464502e8,300
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",exploratory,402218802366406e8,187
"ggsave(""Analysis/Plots/record_subj.png"")",export,402218802366406e8,187
"dat <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk""), task = c(""press""), session = as.character(1:4))",import,393323906464502e8,300
"plan_base_new_wide <- spread(plan_base_new, key = variable, value = total_amount)",exploratory,831366214435548e8,321
"dat$participant <- dat$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"")",data cleaning,393323906464502e8,300
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",visualization,402218802366406e8,187
"dat <- dat %>% select(participant, direction, angleLandmark,      freq, response) %>% filter(response != 9999)",data cleaning,393323906464502e8,300
"plan_base_new_wide$year <- substr(plan_base_new_wide$year, 2,      5)",data cleaning,831366214435548e8,321
"dat <- dat %>% mutate(totalerror = direction * (response - angleLandmark),      degSemi = totalerror %>% totalerrorToDegSemi(), degFull = degSemi %>%          degSemiToDegFull(), radFull = degFull %>% degFullToRadFull())",data cleaning,393323906464502e8,300
"ggsave(""Analysis/Plots/record_section.png"")",export,402218802366406e8,187
"uniformity <- dat %>% group_by(participant, freq) %>% summarise(rayp = rayleigh.test(radFull)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",data cleaning,393323906464502e8,300
plan_base_new_wide$year <- as.numeric(plan_base_new_wide$year),data cleaning,831366214435548e8,321
"afc = read.csv(""Analysis/Parsed Data/pilots_4afc.csv"")",import,402218802366406e8,187
datuniformity <- dat %>% merge(uniformity),data cleaning,393323906464502e8,300
"circmeans <- datuniformity %>% group_by(participant, freq, uniform) %>%      summarise(mrad = mean.circular(radFull), mdegSemi = mrad %>%          radFullToDegFull() %>% degFullToDegSemi()) %>% filter(!uniform)",data cleaning,393323906464502e8,300
"plan_base_new_wide[""month_number""] <- match(plan_base_new_wide$month,      month.abb)",data cleaning,831366214435548e8,321
"afc %<>% mutate(Mapping = ifelse(Subj == ""1MK"", 1, ifelse(Subj ==      ""2DC"", 1, ifelse(Subj == ""3BR"", 1, ifelse(Subj == ""4KK"",      1, ifelse(Subj == ""5HB"", 2, ifelse(Subj == ""6MA"", 2, ifelse(Subj ==          ""7SQ"", 2, ifelse(Subj == ""8EW"", 2, NA)))))))))",data cleaning,402218802366406e8,187
"anglestoplot <- tibble(n = 1:4, x = rep(3.6, 4), y = c(0, 45,      90, -45), angle = c(""0"", ""45"", "" 90\n-90"", ""-45""), participant = ""Participant 5"")",data cleaning,393323906464502e8,300
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",data cleaning,402218802366406e8,187
"zeroline <- tibble(participant = datuniformity$participant %>%      unique(), x = 0, xend = c(3.8, 3.8, 3.8, 3.2, 3.2, 3.2, 3.2),      y = 0, yend = 0)",data cleaning,393323906464502e8,300
"plan_base_new_wide <- plan_base_new_wide[, c(""month"", ""month_number"",      ""year"", ""blue_etel_plan"", ""red_etel_plan"", ""total_etel_plan"",      ""efak_plan"", ""wuge_plan"", ""total_plan"", ""total_yearly_exports_plan"")]",data cleaning,831366214435548e8,321
"limits <- aes(ymax = mean + se, ymin = mean - se)",visualization,402218802366406e8,187
"praw <- ggplot() + facet_wrap(~participant, ncol = 3) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.2, aes(xmin = thre70, xmax = thre90,          ymin = -90, ymax = 90)) + geom_point(data = datuniformity,      aes(x = freq, y = degSemi, color = uniform), size = 0.35,      alpha = 0.5, shape = 16) + geom_text(data = anglestoplot,      aes(x = x, y = y, label = angle, group = n), size = sizeText) +      geom_segment(data = zeroline, aes(y = y, yend = yend, x = x,          xend = xend), size = sizeLine1) + scale_color_discrete(guide = guide_legend(title = NULL,      override.aes = list(size = 1)), breaks = c(T, F), labels = c(""Uniform"",      ""Non-uniform"")) + scale_x_continuous(breaks = seq(0, 3, 1),      labels = as.character(0:3)) + scale_y_continuous(breaks = seq(-45,      90, 45), limits = c(-90, 90), labels = c(""-45"", ""0"", ""45"",      ""90"")) + xlab(""Frequency (rps)"") + ylab(""Error (deg)"") +      coord_polar(theta = ""y"", start = pi/2, direction = -1) +      theme(axis.text.x = element_blank(), axis.title.x = element_blank(),          axis.line.y = element_line(size = sizeLine1), panel.margin = unit(-0.32,              ""lines""), legend.key = element_blank(), legend.position = c(0.7,              0.16))",visualization,393323906464502e8,300
praw,visualization,393323906464502e8,300
"prefix = paste(lubridate::today(), ""bioBank_glioma_cNF"", sep = ""-"")",data cleaning,29281301307492e9,319
"save_plot(""analysis/figures/raw.pdf"", praw, base_width = oneColumnWidth)",export,393323906464502e8,300
"biobank = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study  FROM syn13363852 WHERE ( ( \""assay\"" = 'rnaSeq' ) AND ( \""fileFormat\"" = 'sf' ) )"")$asDataFrame()",import,29281301307492e9,319
"gliomanf1 = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn11614207 WHERE ( ( \""assay\"" = 'rnaSeq' ) )"")$asDataFrame()",import,29281301307492e9,319
"datboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     dat %>% group_by(participant, freq) %>% sample_frac(1, replace = T) })",data cleaning,393323906464502e8,300
"cnf = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn9702734 WHERE ( ( \""parentId\"" = 'syn5493036' ) AND ( \""assay\"" = 'rnaSeq' ) AND ( \""individualID\"" IS NOT NULL ) )"")$asDataFrame()",import,29281301307492e9,319
"full.metadata <- rbind(dplyr::select(biobank, c(id, age, sex,      tumorType, isCellLine, study)), dplyr::select(gliomanf1,      c(id, age, sex, tumorType, isCellLine, study)), dplyr::select(cnf,      c(id, age, sex, tumorType, isCellLine, study))) %>% mutate(Sex = tolower(sex))",data cleaning,29281301307492e9,319
"datsim <- data_frame(freqsim = unique(dat$freq)) %>% merge(dat) %>%      filter(freqsim >= freq) %>% mutate(degFullSim = freqsim/freq *      degFull, radFullSim = degFullSim %>% degFullToRadFull())",data cleaning,393323906464502e8,300
"afc1 <- ddply(afc_nonce, c(""Section""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",modeling,402218802366406e8,187
"datsimboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     datsim %>% group_by(participant, freq, freqsim) %>% sample_frac(1,          replace = T) })",data cleaning,393323906464502e8,300
"afc_all <- ggplot(afc1, aes(x = Section, y = mean, fill = Section)) +      geom_bar(stat = ""identity"", position = ""dodge"") + geom_errorbar(limits)",visualization,402218802366406e8,187
"dispersion <- dat %>% group_by(participant, freq) %>% summarise(rho = rho.circular(radFull))",data cleaning,393323906464502e8,300
"ggsave(""Analysis/Plots/afc_all.png"")",export,402218802366406e8,187
dispersionuniformity <- dispersion %>% merge(uniformity),data cleaning,393323906464502e8,300
rownames(full.metadata) <- full.metadata$id,data cleaning,29281301307492e9,319
"dispersionboot <- datboot %>% group_by(participant, freq, n) %>%      summarise(rho = rho.circular(radFull))",data cleaning,393323906464502e8,300
"fv.tab <- rbind(biobank, gliomanf1, cnf)",data cleaning,29281301307492e9,319
"dispersionbootci <- dispersionboot %>% group_by(participant,      freq) %>% summarise(inf = quantile(rho, 0.025), sup = quantile(rho,      0.975))",data cleaning,393323906464502e8,300
"tab.with.metadata <- plotMetadata(fv.tab, prefix)",visualization,29281301307492e9,319
dispersionbootciuniformity <- dispersionbootci %>% merge(uniformity),data cleaning,393323906464502e8,300
"dispersionsim <- datsim %>% group_by(participant, freq, freqsim) %>%      summarise(rho = rho.circular(radFullSim))",data cleaning,393323906464502e8,300
library(biomaRt),import,29281301307492e9,319
"dispersionsimboot <- datsimboot %>% group_by(participant, freq,      freqsim, n) %>% summarise(rho = rho.circular(radFullSim))",data cleaning,393323906464502e8,300
"dispersionsimbootci <- dispersionsimboot %>% group_by(participant,      freq, freqsim) %>% summarise(inf = quantile(rho, 0.025),      sup = quantile(rho, 0.975))",data cleaning,393323906464502e8,300
"mart = useMart(""ensembl"", dataset = ""hsapiens_gene_ensembl"")",import,29281301307492e9,319
"dispersionsimbootciplot <- dispersionsimbootci %>% mutate(freqsim2 = freq,      freq2 = freqsim)",data cleaning,393323906464502e8,300
"prho <- ggplot() + facet_grid(freqsim2 ~ participant) + geom_line(data = dispersionsimbootciplot,      size = sizeLine1, aes(x = freq2, y = inf), color = ""grey"") +      geom_line(data = dispersionsimbootciplot, size = sizeLine1,          aes(x = freq2, y = sup), color = ""grey"") + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_line(data = dispersionuniformity,      size = sizeLine1, aes(x = freq, y = rho, color = uniform)) +      geom_point(data = dispersionuniformity, size = 0.8, aes(x = freq,          y = rho, color = uniform)) + geom_ribbon(data = dispersionbootciuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          1)) + theme(legend.key = element_blank(), legend.position = c(0.7,      0.16), axis.title.x = element_text(hjust = 0.01))",visualization,393323906464502e8,300
prho,visualization,393323906464502e8,300
"save_plot(""analysis/figures/rho2.pdf"", prho, base_width = twoColumnWidth,      base_height = twoColumnWidth)",export,393323906464502e8,300
"my_chr <- c(1:22, ""X"", ""Y"")",not sure,29281301307492e9,319
"dispersionsimbootciunifotest <- datsimboot %>% group_by(participant,      freq, freqsim, n) %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE)) %>% group_by(participant,      freq, freqsim) %>% summarise(m = mean(uniform))",data cleaning,393323906464502e8,300
script.dir <- function() {     dirname(sys.frame(1)$ofile) },setup,804646127391607e8,324
"map <- getBM(attributes = c(""ensembl_transcript_id"", ""hgnc_symbol""),      mart = mart, filters = ""chromosome_name"", values = my_chr)",import,29281301307492e9,319
dispersionuniformityplot <- dispersionuniformity %>% rename(freqsim = freq),data cleaning,393323906464502e8,300
"prhouni <- ggplot() + facet_grid(freq ~ participant) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_line(data = dispersionsimbootciunifotest %>%      filter(freq < 2.5), aes(x = freqsim, y = m)) + geom_line(data = dispersionuniformityplot,      size = sizeLine1, aes(x = freqsim, y = rho, color = uniform)) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          0.5)) + theme(legend.key = element_blank(), axis.title.x = element_text(hjust = 0.01))",visualization,393323906464502e8,300
prhouni,visualization,393323906464502e8,300
"save_plot(""analysis/figures/rhounif.pdf"", prhouni, base_width = oneColumnWidth)",export,393323906464502e8,300
"bio.genes = do.call(""rbind"", lapply(biobank$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T, sep = ""\t"") %>% separate(Name,          into = c(""ensembl_transcript_id"", NA)) %>% inner_join(map,          by = ""ensembl_transcript_id"") %>% group_by(hgnc_symbol) %>%          summarize(totalCounts = sum(NumReads))     data.frame(dplyr::select(tab, ""totalCounts"", Symbol = ""hgnc_symbol""),          synId = rep(x, nrow(tab))) }))",data cleaning,29281301307492e9,319
"funWrap <- function(d) {     sta <- mle.wrappednormal(d$radFull)$sd     stams <- sta/(4 * pi * first(d$freq)) * 1000     data.frame(sta, stams) }",setup,393323906464502e8,300
"gli.genes = do.call(""rbind"", lapply(gliomanf1$id, function(x) {     f = synGet(x)$path     tab <- read.table(gzfile(f), header = F)     colnames(tab) <- c(""ensemble"", ""Symbol"", ""Counts"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",import,29281301307492e9,319
"dispersionwrap <- dat %>% group_by(participant, freq) %>% do(funWrap(.))",data cleaning,393323906464502e8,300
dispersiowrapnuniformity <- dispersionwrap %>% merge(uniformity),data cleaning,393323906464502e8,300
"dispersionwrapboot <- datboot %>% group_by(participant, freq,      n) %>% do(funWrap(.))",data cleaning,393323906464502e8,300
"cnf.genes = do.call(""rbind"", lapply(cnf$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T)     names(tab) <- c(""Counts"", ""Symbol"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,29281301307492e9,319
"dispersionwrapbootci <- dispersionwrapboot %>% group_by(participant,      freq) %>% summarise(inf = quantile(stams, 0.025), sup = quantile(stams,      0.975))",data cleaning,393323906464502e8,300
dispersionwrapbootciuniformity <- dispersionwrapbootci %>% merge(uniformity),data cleaning,393323906464502e8,300
"full.tab <- rbind(cnf.genes, gli.genes, bio.genes)",data cleaning,29281301307492e9,319
"dispersionwrapsim <- datsim %>% group_by(participant, freq, freqsim) %>%      do(funWrap(.))",data cleaning,393323906464502e8,300
library(lme4),setup,410727980080992e8,325
"dispersionwrapsimboot <- datsimboot %>% filter(freq == 0.75) %>%      group_by(participant, freq, freqsim, n) %>% do(funWrap(.))",data cleaning,393323906464502e8,300
"with.z = full.tab %>% group_by(synId) %>% mutate(zScore = (totalCounts -      mean(totalCounts + 0.001, na.rm = T))/sd(totalCounts, na.rm = T))",data cleaning,29281301307492e9,319
"dispersionwrapsimbootci <- dispersionwrapsimboot %>% group_by(participant,      freq, freqsim) %>% summarise(inf = quantile(stams, 0.025),      sup = quantile(stams, 0.975))",data cleaning,393323906464502e8,300
"pwra <- ggplot() + facet_wrap(~participant, scales = ""free_x"") +      geom_rect(data = fitthre, fill = ""black"", alpha = 0.1, aes(xmin = thre70,          xmax = thre90, ymin = 0, ymax = 160)) + geom_line(data = dispersionwrapsimbootci,      size = sizeLine1, aes(x = freqsim, y = inf), color = ""grey"") +      geom_line(data = dispersionwrapsimbootci, size = sizeLine1,          aes(x = freqsim, y = sup), color = ""grey"") + geom_line(data = dispersiowrapnuniformity,      size = sizeLine1, aes(x = freq, y = stams, color = uniform)) +      geom_point(data = dispersiowrapnuniformity, size = 0.8, aes(x = freq,          y = stams, color = uniform)) + geom_ribbon(data = dispersionwrapbootciuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Standard deviation (ms)"") + scale_x_continuous(limits = c(0,      3.5), breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,393323906464502e8,300
"this.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/analysis/2019-01-31/plotThreePublicDatasets.R""",import,29281301307492e9,319
pwra,visualization,393323906464502e8,300
"analysis.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/bin/nf1TumorHarmonization.R""",import,29281301307492e9,319
"save_plot(""analysis/figures/wrap.pdf"", pwra, base_width = oneColumnWidth)",export,393323906464502e8,300
"source(""R/GoogleSpreadsheets.R"")",setup,410727980080992e8,325
"source(""R/DataFormat.R"")",setup,410727980080992e8,325
"genes.with.meta = analyzeMetdataWithGenes(with.z, tab.with.metadata,      prefix)",import,29281301307492e9,319
"dif <- dispersionsim %>% filter(freq == 0.75) %>% ungroup() %>%      select(-freq) %>% rename(freq = freqsim, rhosim = rho) %>%      merge(dispersion) %>% group_by(participant, freq) %>% summarise(dif = rhosim -      rho)",data cleaning,393323906464502e8,300
"ggplot() + facet_wrap(~participant) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_line(data = dif, aes(x = freq,      y = dif))",visualization,393323906464502e8,300
"source(""R/SensitivityAnalysis.R"")",setup,410727980080992e8,325
"geom_line(data = dispersionsim %>% filter(freq == 0.75), aes(x = freqsim,      rho)) + geom_line(data = dispersion, aes(x = freq, rho))",visualization,393323906464502e8,300
"met.file = paste(prefix, ""metadataSummary.png"", sep = ""\\"")",import,29281301307492e9,319
"for (i in 1:dim(balance)[1]) {     for (j in 1:dim(balance)[2]) {         for (k in 1:dim(balance)[3]) {             bal = rbind(bal, data.frame(Year = years[i], Balance = balance[i,                  j, k], Estimator = dimnames(balance)[[3]][k],                  Covariate = dimnames(balance)[[2]][j]))         }     } }",data cleaning,776496840175241e8,318
"if (!dir.exists(""Figures"")) {     dir.create(""Figures"") }",setup,410727980080992e8,325
"figure_out <- ""Figures""",setup,410727980080992e8,325
setDT(bal),not sure,776496840175241e8,318
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"load(""Models/FinalDensityModel.rda"")",setup,410727980080992e8,325
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"load(""Models/FinalRichnessModel.rda"")",setup,410727980080992e8,325
"dataset.dir = ""syn18134640""",setup,29281301307492e9,319
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,393323906464502e8,300
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"library(""countrycode"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,393323906464502e8,300
"garden <- read.csv(""data/Wildlife Garden - data collection - Sheet1.csv"")",import,410727980080992e8,325
"capitals <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/country-capitals.csv"")",import,393323906464502e8,300
"ggplot(bal[, list(Balance = mean(abs(Balance))), by = .(Estimator,      Year)]) + geom_line(aes(y = Balance, x = Year, color = Estimator,      group = interaction(Estimator)))",visualization,776496840175241e8,318
"capitals <- capitals[capitals$ContinentName == ""Africa"", ]",import,393323906464502e8,300
"gz1 = gzfile(paste(prefix, ""tidiedData.csv.gz"", sep = """"))",export,29281301307492e9,319
"write.csv(genes.with.meta, gz1)",export,29281301307492e9,319
"ggplot(bal[, list(Balance = max(abs(Balance))), by = .(Estimator,      Year)]) + geom_line(aes(y = Balance, x = Year, color = Estimator,      group = interaction(Estimator)))",visualization,776496840175241e8,318
capitals$x <- as.numeric(paste(capitals$CapitalLongitude)),data cleaning,393323906464502e8,300
capitals$y <- as.numeric(paste(capitals$CapitalLatitude)),data cleaning,393323906464502e8,300
garden <- prepareGS(garden),data cleaning,410727980080992e8,325
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,393323906464502e8,300
"opt_loc$wbcode <- countrycode(opt_loc$country, origin = ""country.name"",      destination = ""wb"")",data cleaning,393323906464502e8,300
sample_sizes,communication,776496840175241e8,318
"survival_data <- read.table(""./analysis/nursery_experiment_inundation/data/nursery_experiment_data.txt"",      header = TRUE)",import,869149817619473e8,326
"df <- opt_loc[!is.na(opt_loc$wbcode), ]",data cleaning,393323906464502e8,300
"sid = synStore(File(paste(prefix, ""tidiedData.csv.gz"", sep = """"),      parent = dataset.dir), used = unique(genes.with.meta$id),      executed = c(this.script, analysis.script))",import,29281301307492e9,319
df$capital <- NA,data cleaning,393323906464502e8,300
"range(sample_sizes[, ""Total""])",communication,776496840175241e8,318
str(survival_data),exploratory,869149817619473e8,326
"for (i in 1:nrow(capitals)) {     country <- countrycode(capitals$CountryCode[i], origin = ""iso2c"",          destination = ""wb"")     if (!is.na(country)) {         subset <- df[df$wbcode == country, ]         nearest_ID <- NA         min_dist <- 1e+09         if (nrow(subset) > 0) {             for (j in 1:nrow(subset)) {                 if (!is.na(subset[j, c(""x"")]) & !is.na(subset[j,                    c(""y"")])) {                   dist <- gdist(capitals[i, c(""x"")], capitals[i,                      c(""y"")], subset[j, c(""x"")], subset[j, c(""y"")])                   if (dist < min_dist) {                     min_dist <- dist                     nearest_ID <- subset[j, ""ID""]                   }                 }             }             df[df$ID == nearest_ID, ""capital""] <- 1         }     } }",data cleaning,393323906464502e8,300
"df[is.na(df$capital), ""capital""] <- 0",data cleaning,393323906464502e8,300
"wooddensity_data <- read.table(""./analysis/inundation_wooddensity_relationship/data/data_sap_adult_rr_density.txt"")",import,869149817619473e8,326
"df <- merge(opt_loc, df, by = ""ID"", all.x = T)",data cleaning,393323906464502e8,300
"df[is.na(df$capital), ""capital""] <- 0",data cleaning,393323906464502e8,300
"tx_prev = sample_sizes[, ""Treated""]/sample_sizes[, ""Total""]",modeling,776496840175241e8,318
"SA_scaled <- Sensitivity_Analysis(density3, reps = 1000, scale.area = TRUE,      pointsize = 11)",visualization,410727980080992e8,325
"write.csv(df[, c(""ID"", ""capital"")], file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/ID_capitals.csv"",      row.names = FALSE)",export,393323906464502e8,300
tx_prev,communication,776496840175241e8,318
range(tx_prev),communication,776496840175241e8,318
"pdf(file.path(figure_out, ""SensitivityAnalysis_scaled.pdf""))",export,410727980080992e8,325
"sapply(paste(prefix, c(""genesByStudy.png"", ""genesByTumor.png"",      ""metadataSummary.png""), sep = """"), function(x) synStore(File(x,      parent = dataset.dir), used = sid$properties$id, executed = c(this.script,      analysis.script)))",import,29281301307492e9,319
"dden_mat <- with(survival_data, tapply(dden, list(sp, treat),      mean, na.rm = T))[-5, ]",exploratory,869149817619473e8,326
"hist(SA_scaled, xlab = ""% Change"", main = """", cex.lab = 1.2)",visualization,410727980080992e8,325
"pc.files = doPcaPlots(with.z, tab.with.metadata, prefix)",visualization,29281301307492e9,319
abline(v = 0),visualization,410727980080992e8,325
dev.off(),visualization,410727980080992e8,325
"pca.dir = ""syn18134641""",setup,29281301307492e9,319
"sapply(pc.files, function(x) synStore(File(x, parent = pca.dir),      used = sid$properties$id, executed = c(this.script, analysis.script)))",import,29281301307492e9,319
sum(SA_scaled < 0)/1000 * 100,data cleaning,410727980080992e8,325
"wooddensity_data <- wooddensity_data[which(tolower(wooddensity_data$sp) %in%      levels(survival_data$sp)), ]",data cleaning,869149817619473e8,326
"SA_notscaled <- Sensitivity_Analysis(density3, reps = 1000, scale.area = FALSE)",not sure,410727980080992e8,325
sum(SA_notscaled < 0)/1000 * 100,data cleaning,410727980080992e8,325
rsquared <- numeric(8),not sure,869149817619473e8,326
"SA_richness <- Sensitivity_Analysis(richness2, reps = 1000, scale.area = FALSE)",data cleaning,410727980080992e8,325
sum(SA_richness < 0)/1000 * 100,data cleaning,410727980080992e8,325
"for (i in 1:8) {     m <- lm(wooddensity_data$adult_dden ~ dden_mat[, i])     rsquared[i] <- summary(m)$r.squared }",modeling,869149817619473e8,326
"library(""tidyr"")",data cleaning,999636801658198e8,327
"pdf(file.path(figure_out, ""SensitivityAnalysis_notscaled.pdf""),      width = 8)",export,410727980080992e8,325
"par(mfrow = c(1, 2))",visualization,410727980080992e8,325
"par(mar = c(4, 4, 2, 0))",visualization,410727980080992e8,325
"data <- data.frame(r = rsquared, treat = seq(0, 21, by = 3))",evaluation,869149817619473e8,326
"hist(SA_notscaled, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200), breaks = 20)",visualization,410727980080992e8,325
"mtext(""(a)"", side = 3, line = 0, at = 0)",visualization,410727980080992e8,325
"hist(SA_richness, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200))",visualization,410727980080992e8,325
"mtext(""(b)"", side = 3, line = 0, at = 0)",visualization,410727980080992e8,325
"data_movies <- read_csv(""data/tmdb_5000_movies.csv"")",import,29281301307492e9,319
"mtext(""Frequency"", side = 2, outer = TRUE, line = -1.5, las = 0,      at = 0.55)",visualization,410727980080992e8,325
"data_credits <- read_csv(""data/tmdb_5000_credits.csv"")",import,29281301307492e9,319
"mtext(""% Change"", side = 1, outer = TRUE, line = -1.5, las = 0)",visualization,410727980080992e8,325
"summary(lm(r ~ treat + I(treat^2), data))",modeling,869149817619473e8,326
dev.off(),visualization,410727980080992e8,325
"p1 <- ggplot(data, aes(x = treat, y = r)) + geom_point() + stat_smooth(method = lm,      formula = y ~ x + I(x^2), color = ""black"", size = 0.2) +      theme_bw() + ylab(""r-squared(adult ~ exp)"") + xlab(expression(Inundation ~      frequency ~ days ~ cycle^-1)) + theme(text = element_text(size = 20))",visualization,869149817619473e8,326
"Marriages <- read.csv(file = ""Analysis/data/RawData/160-03-4_marriage_2011.csv"",      sep = "";"", na.strings = c(""-"", "".""), nrows = 3150, skip = 9,      header = FALSE, col.names = c(""district"", ""DistrictName"",          ""PersonalStatus"", ""Total"", ""TotalMale"", ""TotalFemale"",          ""TotalGerman"", ""TotalForeigner""))",import,999636801658198e8,327
"both <- list(data_movies = data_movies, data_credits = data_credits)",setup,29281301307492e9,319
"ggsave(p1, file = ""./analysis/nursery_experiment_inundation/graph_code/graphs/rsquared_wooddensity.png"",      width = 6, height = 6)",export,869149817619473e8,326
both %>% map(names),exploratory,29281301307492e9,319
data_movies,exploratory,29281301307492e9,319
glimpse(data_movies),exploratory,29281301307492e9,319
both %>% map(glimpse),exploratory,29281301307492e9,319
setEPS(),setup,869149817619473e8,326
"Marriages$DistrictName <- iconv(Marriages$DistrictName, from = ""latin1"",      to = ""UTF-8"")",data cleaning,999636801658198e8,327
"data_movies %>% select(original_title, budget, revenue, vote_average,      popularity) %>% arrange(desc(budget))",exploratory,29281301307492e9,319
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/partFunctions.eps"",      width = 5, height = 2.1)",export,869149817619473e8,326
"data_movies %>% select(original_title, budget, revenue, vote_average,      popularity) %>% arrange(desc(budget))",exploratory,29281301307492e9,319
"data_movies <- data_movies %>% mutate(Production = case_when(str_detect(production_companies,      ""Disney"") ~ ""Disney"", str_detect(production_companies, ""Marvel"") ~      ""Marvel"", str_detect(production_companies, ""DC"") ~ ""DC"",      TRUE ~ ""Other""))",data cleaning,29281301307492e9,319
"par(mar = c(1, 4, 1, 1), cex = 0.97)",evaluation,869149817619473e8,326
"data_movies %>% count(Production, sort = TRUE)",exploratory,29281301307492e9,319
"Marriages <- Marriages[-c(1:6), ]",exploratory,999636801658198e8,327
"data_movies %>% ggplot(aes(x = Production, fill = Production)) +      geom_bar()",visualization,29281301307492e9,319
"Marriages <- Marriages[, -c(2, 5:8)]",data cleaning,999636801658198e8,327
"M_partFunctions = matrix(c(31054, 7116, 5788, 1084, 1825, 124,      6826, 77), ncol = 1, byrow = T)",import,869149817619473e8,326
"data_movies2 <- data_movies %>% filter(Production != ""Other"")",data cleaning,29281301307492e9,319
"data_movies2 %>% ggplot(aes(x = Production, fill = Production)) +      geom_bar()",visualization,29281301307492e9,319
"Marriages[, 1] <- as.numeric(as.character(Marriages[, 1]))",data cleaning,999636801658198e8,327
"data_movies2 %>% ggplot(aes(x = budget, y = vote_average, col = Production,      label = original_title)) + geom_smooth() + facet_wrap(~Production) +      geom_text(check_overlap = TRUE)",visualization,29281301307492e9,319
"rownames(M_partFunctions) = c(""re.compile 31,054 (57.6%)"", ""re.search 7,116 (13.2%)"",      ""re.match 5,788 (10.7%)"", ""re.split 1,084 (2%)"", ""re.findall 1,825 (3.4%)"",      ""re.finditer 124 (0.2%)"", ""re.sub 6,826 (12.7%)"", ""re.subn 77 (0.1%)"")",import,869149817619473e8,326
"Marriages[, 3] <- as.numeric(as.character(Marriages[, 3]))",data cleaning,999636801658198e8,327
"barplot(M_partFunctions, legend = rownames(M_partFunctions),      col = c(""gray50"", ""gray30"", ""gray75"", ""gray12"", ""gray87"",          ""gray20"", ""gray67"", ""gray8""), xlim = c(0, 9), width = 0.6,      ylim = range(pretty(c(0, 53894))), las = 1)",visualization,869149817619473e8,326
"data_movies %>% group_by(Production) %>% top_n(5, revenue) %>%      select(original_title, budget, revenue, vote_average)",data cleaning,29281301307492e9,319
dev.off(),export,869149817619473e8,326
setEPS(),setup,869149817619473e8,326
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/partFlags.eps"",      width = 5, height = 2.1)",export,869149817619473e8,326
"Marriages <- spread(Marriages, ""PersonalStatus"", ""Total"")",data cleaning,999636801658198e8,327
"spread_data <- data_movies2 %>% spread(key = Production, value = vote_average)",data cleaning,29281301307492e9,319
"spread_data %>% gather(key = ""Prod"", value = ""vote"", -title,      -budget) %>% filter(!is.na(vote))",data cleaning,29281301307492e9,319
"Marriages <- Marriages[, c(1, 6)]",data cleaning,999636801658198e8,327
"par(mar = c(1, 4, 1, 1), cex = 0.97)",import,869149817619473e8,326
"M_partFlags = matrix(c(2996, 24, 1764, 711, 397, 943, 0), ncol = 1,      byrow = T)",import,869149817619473e8,326
"rownames(M_partFlags) = c(""IGNORECASE 2,996 (43.8%)"", ""LOCALE 24 (0.4%)"",      ""MULTILINE 1,764 (25.8%)"", ""DOTALL 711 (10.4%)"", ""UNICODE 397 (5.8%)"",      ""VERBOSE 943 (13.8%)"", ""multiple flags 0 (0%)"")",import,869149817619473e8,326
"barplot(M_partFlags, legend = rownames(M_partFlags), col = c(""gray80"",      ""gray32"", ""gray67"", ""gray8"", ""gray50"", ""gray92"", ""grey20""),      xlim = c(0, 9), width = 0.6, ylim = range(pretty(c(0, 6835))),      las = 1)",visualization,869149817619473e8,326
dev.off(),export,869149817619473e8,326
"MarriageBerHam <- subset(Marriages, Marriages$district == 2 |      Marriages$district == 11, all(TRUE))",data cleaning,999636801658198e8,327
setEPS(),setup,869149817619473e8,326
"Marriages <- Marriages[Marriages$district > 1000, ]",data cleaning,999636801658198e8,327
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/patternFiltering.eps"",      width = 3.5, height = 2)",export,869149817619473e8,326
"Marriages <- rbind(Marriages, MarriageBerHam)",data cleaning,999636801658198e8,327
"par(mar = c(1, 4, 1, 1), cex = 0.97)",import,869149817619473e8,326
"M_patternFiltering = matrix(c(25, 97, 13597), ncol = 1, byrow = T)",import,869149817619473e8,326
"rownames(M_patternFiltering) = c(""alien feature 25 (0.2%)"", ""pcre error 97 (0.7%)"",      ""included patterns 13,597 (99.1%)"")",import,869149817619473e8,326
rm(MarriageBerHam),data cleaning,999636801658198e8,327
"barplot(M_patternFiltering, legend = rownames(M_patternFiltering),      col = c(""mediumblue"", ""lightskyblue1"", ""seagreen2""), xlim = c(0,          9), width = 0.6, ylim = range(pretty(c(0, 13719))), las = 1)",visualization,869149817619473e8,326
dev.off(),export,869149817619473e8,326
"names(Marriages)[names(Marriages) == ""verheiratet / eingetragene Lebenspartnerschaft""] <- ""marriageTotal""",data cleaning,999636801658198e8,327
library(randomForest),setup,869149817619473e8,326
"write.csv(Marriages, file = ""Analysis/data/Marriages2.csv"")",export,999636801658198e8,327
library(caret),setup,869149817619473e8,326
library(doMC),setup,869149817619473e8,326
library(mmadsenr),setup,869149817619473e8,326
library(futile.logger),setup,869149817619473e8,326
library(dplyr),setup,869149817619473e8,326
library(survminer),setup,119833128992468e8,328
library(ggthemes),setup,869149817619473e8,326
library(survival),setup,119833128992468e8,328
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",import,869149817619473e8,326
"fn_dh_elfstats <- function(site = ""http://deq2.bse.vt.edu/d.dh"",      ftype = ""all"", fstatus = ""active"", analysis_timespan = ""full"",      yvar = ""all"", sampres = ""all"", stat_quantreg_qu = ""0.80"",      station_agg = ""max"", stat_quantreg_glo = ""all"", stat_quantreg_ghi = ""all"",      feature_ftype = ""all"", xvar = ""all"", dataset_tag = ""taxaLoss_PI_PressHuc8"",      featureid = ""all"") {     elf_statistics <- paste(site, ""export_elf_statistics"", ftype,          fstatus, analysis_timespan, yvar, sampres, stat_quantreg_qu,          station_agg, stat_quantreg_glo, stat_quantreg_ghi, feature_ftype,          xvar, dataset_tag, featureid, sep = ""/"")     print(paste(""Using URI: "", elf_statistics))     region <- feature_ftype     XV <- xvar     YV <- yvar     elf_statistics <- read.table(elf_statistics, header = TRUE,          sep = "","")     write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",          region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,          quote = TRUE)     return(elf_statistics) }",not sure,631672533694655e8,1
library(stringr),setup,119833128992468e8,328
"harmonic = ""1F1""",not sure,999636801658198e8,327
library(tibble),setup,119833128992468e8,328
library(multcomp),setup,119833128992468e8,328
p_thresh = 5e-04,evaluation,999636801658198e8,327
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""biasedmodels-classification.log"")",setup,869149817619473e8,326
plot_titles = TRUE,visualization,999636801658198e8,327
"flog.appender(appender.file(log_file), name = ""cl"")",setup,869149817619473e8,326
library(rstan),setup,631672533694655e8,1
rstan_options(auto_write = TRUE),setup,631672533694655e8,1
options(mc.cores = parallel::detectCores()),setup,631672533694655e8,1
clargs <- commandArgs(trailingOnly = TRUE),setup,869149817619473e8,326
"load(""analysis/rdata-tmp/RoT-dat2.RData"")",import,631672533694655e8,1
"condition = ""Direction""",not sure,999636801658198e8,327
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-population-data.rda"")     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-population-data.rda"", args = clargs)     ta_sampled_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-3-4-tasampled-data.rda"", args = clargs) }",setup,869149817619473e8,326
"study = ""MOFO""",not sure,999636801658198e8,327
"group = ""child""",not sure,999636801658198e8,327
dpi = 300,not sure,999636801658198e8,327
n_top = 9,not sure,999636801658198e8,327
"MainData <- read.table(""Analysis/Data/MainData"", sep = "","", stringsAsFactors = FALSE)",import,887816657777876e7,329
load(pop_data_file),import,869149817619473e8,326
load(ta_sampled_data_file),import,869149817619473e8,326
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",communication,869149817619473e8,326
"flog.info(""Loaded data file: %s"", ta_sampled_data_file, name = ""cl"")",communication,869149817619473e8,326
"APIData <- read.table(""Analysis/Data/APIData"", sep = "","", stringsAsFactors = FALSE)",import,887816657777876e7,329
"analysis_path <- ""child-tuning/analysis/""",not sure,999636801658198e8,327
"AddressData <- read.table(""Analysis/Data/AddressData"", sep = "","",      stringsAsFactors = FALSE)",import,887816657777876e7,329
"data_path <- paste(analysis_path, ""data/"", sep = """")",import,999636801658198e8,327
"figs_path <- ""child-tuning/figs/""",import,999636801658198e8,327
"ZillowDataSet6 <- read.table(""Analysis/Data/ZillowDataSet6"",      sep = "","", stringsAsFactors = FALSE)",import,887816657777876e7,329
"data_fn <- ""child-mofo-all.csv""",import,999636801658198e8,327
"egi_fn <- ""egi.csv""",import,999636801658198e8,327
"topo_fn <- ""topoplog.png""",import,999636801658198e8,327
"fn_path <- paste(data_path, data_fn, sep = """")",import,999636801658198e8,327
"test_pop_indices <- createDataPartition(eq4_pop_df$model_class_label,      p = 0.1, list = FALSE)",import,869149817619473e8,326
"egi_path <- paste(data_path, egi_fn, sep = """")",import,999636801658198e8,327
"test_tasampled_indices <- createDataPartition(eq4_ta_sampled_df$model_class_label,      p = 0.03, list = FALSE)",import,869149817619473e8,326
"topo_path <- paste(figs_path, ""topoplot.png"", sep = """")",import,999636801658198e8,327
library(ggplot2),visualization,999636801658198e8,327
"MainData2 <- data.frame(MainData, APIData)",data cleaning,887816657777876e7,329
library(dplyr),data cleaning,999636801658198e8,327
"eq4_pop_df <- eq4_pop_df[test_pop_indices, ]",import,869149817619473e8,326
library(png),visualization,999636801658198e8,327
"eq4_ta_sampled_df <- eq4_ta_sampled_df[test_tasampled_indices,      ]",import,869149817619473e8,326
library(gridExtra),visualization,999636801658198e8,327
"MainData2 <- MainData2[!duplicated(MainData[, 1]), ]",data cleaning,887816657777876e7,329
"MainData3 <- data.frame(MainData2, AddressData)",data cleaning,887816657777876e7,329
library(tidyr),data cleaning,999636801658198e8,327
"MainData4 <- data.frame(MainData3, ZillowDataSet6)",data cleaning,887816657777876e7,329
"flog.info(""Beginning classification analysis of neutral versus balanced bias models from equifinality-4 data sets"",      name = ""cl"")",communication,869149817619473e8,326
"write.table(MainData4, file = ""Analysis/Data/EnrichedData"", sep = "","")",export,887816657777876e7,329
library(knitr),not sure,999636801658198e8,327
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,869149817619473e8,326
library(DescTools),exploratory,999636801658198e8,327
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",communication,869149817619473e8,326
library(heplots),not sure,999636801658198e8,327
registerDoMC(cores = num_cores),setup,869149817619473e8,326
library(Cairo),not sure,999636801658198e8,327
seed_value <- 58132133,setup,869149817619473e8,326
set.seed(seed_value),setup,869149817619473e8,326
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",communication,869149817619473e8,326
"direction_conds <- c(1, 2, 3, 6, 7, 8)",exploratory,999636801658198e8,327
"coherence.conds <- c(4, 9)",exploratory,999636801658198e8,327
training_set_fraction <- 0.8,setup,869149817619473e8,326
"fig.only.conds <- c(5, 10)",exploratory,999636801658198e8,327
test_set_fraction <- 1 - training_set_fraction,setup,869149817619473e8,326
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (2:10) *      50, .shrinkage = 0.05)",modeling,869149817619473e8,326
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,869149817619473e8,326
devtools::load_all(),import,999636801658198e8,327
library(ggplot2),visualization,999636801658198e8,327
"experiment_names <- c(""Neutral vs Balanced Biased - Population Census"")",setup,869149817619473e8,326
library(magrittr),not sure,999636801658198e8,327
bias_results <- data.frame(),setup,869149817619473e8,326
library(dplyr),data cleaning,999636801658198e8,327
bias_results_roc <- NULL,setup,869149817619473e8,326
bias_results_model <- NULL,setup,869149817619473e8,326
bias_results_cm <- NULL,setup,869149817619473e8,326
"flog.info(""Starting analysis of neutral vs. mixconfequal with pop census data"",      name = ""cl"")",communication,869149817619473e8,326
i <- 1,setup,869149817619473e8,326
exp_name <- experiment_names[i],setup,869149817619473e8,326
"eq4_pop_subset <- subset(eq4_pop_df, eq4_pop_df$model_class_label %in%      c(""mixconfequal"", ""allneutral""))",data cleaning,869149817619473e8,326
"eq4_pop_subset$model_class_label = factor(eq4_pop_subset$model_class_label,      levels = c(""mixconfequal"", ""allneutral""))",data cleaning,869149817619473e8,326
"exclude_columns <- c(""simulation_run_id"", ""innovation_rate"")",data cleaning,869149817619473e8,326
"balanced_bias_neutral_model <- train_gbm_classifier(eq4_pop_subset,      training_set_fraction, ""model_class_label"", gbm_grid, training_control,      exclude_columns, verbose = FALSE)",modeling,869149817619473e8,326
"bias_results_model[[""balanced_bias_neutral_model""]] <- balanced_bias_neutral_model$tunedmodel",evaluation,869149817619473e8,326
"predictions <- predict(balanced_bias_neutral_model$tunedmodel,      newdata = balanced_bias_neutral_model$test_data)",evaluation,869149817619473e8,326
"cm <- confusionMatrix(predictions, balanced_bias_neutral_model$test_data$model_class_label,      positive = ""allneutral"")",evaluation,869149817619473e8,326
results <- get_parsed_binary_confusion_matrix_stats(cm),evaluation,869149817619473e8,326
results$experiments[i] <- exp_name,evaluation,869149817619473e8,326
results$elapsed <- balanced_bias_neutral_model$elapsed,evaluation,869149817619473e8,326
"bias_results_cm[[""balanced_bias_neutral_model""]] <- cm",evaluation,869149817619473e8,326
"bias_dominance_roc <- calculate_roc_binary_classifier(balanced_bias_neutral_model$tunedmodel,      balanced_bias_neutral_model$test_data, ""model_class_label"",      exp_name)",evaluation,869149817619473e8,326
results$auc[i] <- unlist(bias_dominance_roc$auc@y.values),evaluation,869149817619473e8,326
"bias_results_roc[[""balanced_bias_neutral_model""]] <- bias_dominance_roc",evaluation,869149817619473e8,326
"list[geneDat, exp] = n_expressoExpr %>% filter(!grepl(pattern = ""\\|"",      Gene.Symbol)) %>% sepExpr",data cleaning,999636801658198e8,327
"bias_results <- rbind(bias_results, results)",evaluation,869149817619473e8,326
bias_results$sample_size <- 0,evaluation,869149817619473e8,326
bias_results$ta_duration <- 0,evaluation,869149817619473e8,326
rownames(exp) = geneDat$Gene.Symbol,data cleaning,999636801658198e8,327
design = n_expressoSamples,not sure,999636801658198e8,327
"design %<>% filter(PyramidalDeep %in% c(""ForebrainCholin"", ""ThalamusCholin"")) %>%      mutate(PyramidalDeep = PyramidalDeep %>% factor(levels = c(""ForebrainCholin"",          ""ThalamusCholin""))) %>% arrange(PyramidalDeep)",data cleaning,999636801658198e8,327
"cholinergic = exp[geneDat$Gene.Symbol %in% c(""Gad1"", ""Gad2"",      ""Slc32a1"", ""Slc17a6"", ""Slc18a3""), design$sampleName] %>%      as.matrix %>% melt %>% mutate(Var2 = design$ShinyNames[match(Var2,      design$sampleName)], Var1 = factor(Var1, levels = c(""Slc18a3"",      ""Gad1"", ""Gad2"", ""Slc32a1"", ""Slc17a6"")))",data cleaning,999636801658198e8,327
"(cholinergic %>% ggplot(aes(x = Var1, y = value, group = Var2,      color = Var2)) + geom_point(position = position_dodge(width = 0.4),      size = 4, fill = ""black"") + scale_x_discrete(name = """") +      theme_cowplot(21) + theme(legend.position = ""bottom"", legend.direction = ""vertical"") +      geom_vline(xintercept = c(1.5, 2.5, 3.5, 4.5), linetype = ""dotted"") +      scale_y_continuous(name = bquote(log[2] ~ "" expression"")) +      scale_color_manual(name = ""Cell Type"", values = c(""darkorange"",          ""darkorange4""))) %>% ggsave(plot = ., filename = ""analysis/07.GeneExpressionPlots/cholinergic.png"",      width = 8, height = 4)",visualization,999636801658198e8,327
design = n_expressoSamples,not sure,999636801658198e8,327
"design %<>% filter(ShinyNames %in% c(""FS Basket (G42)"", ""Martinotti (GIN)"",      ""VIPReln (G30)"")) %>% mutate(ShinyNames = ShinyNames %>%      factor(levels = c(""FS Basket (G42)"", ""Martinotti (GIN)"",          ""VIPReln (G30)""))) %>% arrange(ShinyNames)",data cleaning,999636801658198e8,327
"gabaergic = exp[geneDat$Gene.Symbol %in% c(""Sst""), design$sampleName] %>%      as.matrix %>% melt %>% mutate(Var2 = design$ShinyNames[match(Var2,      design$sampleName)])",data cleaning,999636801658198e8,327
"(gabaergic %>% ggplot(aes(x = Var2, y = value, color = Var2)) +      geom_point(size = 4) + theme_cowplot(17) + theme(legend.position = ""none"",      axis.text.x = element_text(angle = 90, hjust = 1)) + scale_color_manual(name = ""Cell Type"",      values = c(""firebrick2"", ""firebrick3"", ""firebrick4"")) + xlab("""") +      ylab(bquote(""Sst "" ~ log[2] ~ "" expression""))) %>% ggsave(plot = .,      filename = ""analysis/07.GeneExpressionPlots/gabaergic.png"",      width = 3, height = 5)",visualization,999636801658198e8,327
design = n_expressoSamples,not sure,999636801658198e8,327
"design %<>% filter(Reference %in% c(""Chung et al., 2005"", ""Phani et al. 2015"")) %>%      mutate(PyramidalDeep = PyramidalDeep %>% factor(levels = c(""Phani et al. 2015"",          ""Chung et al., 2005""))) %>% arrange(Reference)",data cleaning,999636801658198e8,327
require(plyr),setup,470287234755233e8,330
require(dplyr),setup,470287234755233e8,330
require(data.table),setup,470287234755233e8,330
require(reshape2),setup,470287234755233e8,330
require(ggplot2),setup,470287234755233e8,330
require(qgraph),setup,470287234755233e8,330
require(RColorBrewer),setup,470287234755233e8,330
require(cluster),setup,470287234755233e8,330
"CNH <- ""/Volumes/NOAA_Data/CNH/""",setup,470287234755233e8,330
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",      sep = """"), stringsAsFactors = F, skip = 2)",import,470287234755233e8,330
"dopaminergic = exp[geneDat$Gene.Symbol %in% c(""Map2"", ""Plcb4"",      ""Card10"", ""Kifc2""), design$sampleName] %>% as.matrix %>%      melt %>% mutate(Var2 = design$Reference[match(Var2, design$sampleName)],      Var1 = factor(Var1, levels = c(""Map2"", ""Plcb4"", ""Card10"",          ""Kifc2"")))",data cleaning,999636801658198e8,327
"(dopaminergic %>% ggplot(aes(x = Var1, y = value, group = Var2,      color = Var2)) + geom_point(position = position_dodge(width = 0.4),      size = 4, fill = ""black"") + scale_x_discrete(name = """") +      theme_cowplot(21) + theme(legend.position = ""bottom"", legend.direction = ""vertical"") +      geom_vline(xintercept = c(1.5, 2.5, 3.5, 4.5), linetype = ""dotted"") +      scale_y_continuous(name = bquote(log[2] ~ "" expression"")) +      scale_color_manual(name = ""Cell Type"", values = c(""black"",          ""gray""), guide = guide_legend(title = """"))) %>% ggsave(plot = .,      filename = ""analysis/07.GeneExpressionPlots/dopaminergic.png"",      width = 5, height = 4)",visualization,999636801658198e8,327
design = n_expressoSamples,not sure,999636801658198e8,327
"FTL <- head(FTL, -2)",data cleaning,470287234755233e8,330
"regionSamples = memoReg(design = design, regionNames = ""Region"",      groupNames = ""CellTypes"", regionHierarchy = regionHierarchy)",not sure,999636801658198e8,327
"design %<>% filter(!is.na(regionSamples$Cortex_CellTypes)) %>%      arrange(MajorType, Neurotransmitter, CellTypes)",data cleaning,999636801658198e8,327
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",      sep = """"), stringsAsFactors = F)",import,470287234755233e8,330
"cortical = exp[geneDat$Gene.Symbol %in% c(""Fam114a1""), design$sampleName] %>%      as.matrix %>% melt %>% mutate(Var2 = design$CellTypes[match(Var2,      design$sampleName)] %>% translatePublishable)",data cleaning,999636801658198e8,327
"cortical$source = ""Microarray""",data cleaning,999636801658198e8,327
"setwd(""C:/Users/Chris/Desktop/GIT home/MSDS 6306 - Case Study 2/Analysis"")",setup,750258568907157e8,331
design = meltedSingleCells,data cleaning,999636801658198e8,327
"data(""Orange"")",import,750258568907157e8,331
"temp <- read.csv(file = ""data/TEMP.csv"", header = TRUE)",import,750258568907157e8,331
"CityTemp <- read.csv(file = ""data/CityTemp.csv"", header = TRUE)",import,750258568907157e8,331
"mgmt_grp <- dlply(spid, .(mgmt_grp))",data cleaning,470287234755233e8,330
library(tidyverse),import,750258568907157e8,331
mgmt_grp <- mgmt_grp[2:9],data cleaning,470287234755233e8,330
"cortical2 = TasicPrimaryMeanLog[c(""Fam114a1""), design$sampleName] %>%      as.matrix %>% melt %>% mutate(Var2 = design$CellTypes[match(Var2,      design$sampleName)])",data cleaning,999636801658198e8,327
"cortical2$source = ""RNAseq""",data cleaning,999636801658198e8,327
"m.vec <- rep(NA, nrow(FTL))",not sure,470287234755233e8,330
cortical2$Var2 %<>% translatePublishable,data cleaning,999636801658198e8,327
"cortical2$Var2 %<>% replaceElement(c(`Oligodendrocyte precursors` = ""Oligodendrocyte prec."")) %$%      newVector",data cleaning,999636801658198e8,327
"order = cellOrder %>% translatePublishable %>% replaceElement(c(`Oligodendrocyte precursors` = ""Oligodendrocyte prec."")) %$%      newVector",data cleaning,999636801658198e8,327
"cortical = rbind(cortical, cortical2)",data cleaning,999636801658198e8,327
"cortical %<>% mutate(Var2 = Var2 %>% factor(levels = cortical$Var2 %>%      unique %>% {     .[match(order, .)] } %>% trimNAs))",data cleaning,999636801658198e8,327
"(cortical %>% ggplot(aes(x = Var2, y = value, color = Var2)) +      geom_point(size = 1) + theme_cowplot(8) + xlab("""") + ylab(bquote(""Fam114a1 "" ~      log[2] ~ "" expression"")) + theme(axis.text.x = element_text(angle = 45,      hjust = 1), panel.background = element_rect(fill = NA, color = ""black"",      size = 0.3, linetype = ""solid"")) + facet_wrap(~source, scales = ""free"",      nrow = 2) + scale_color_manual(values = cellColors(), guide = FALSE)) %>%      ggsave(plot = ., filename = ""analysis/07.GeneExpressionPlots/olig1_Fam114a1.png"",          width = 4.1, height = 9.5, units = ""cm"")",visualization,999636801658198e8,327
design = n_expressoSamples,data cleaning,999636801658198e8,327
"regionSamples = memoReg(design = design, regionNames = ""Region"",      groupNames = ""ShinyNames"", regionHierarchy = regionHierarchy)",data cleaning,999636801658198e8,327
"design %<>% filter((!is.na(regionSamples$Cortex_ShinyNames)) |      design$ShinyNames %in% ""Dopaminergic"") %>% arrange(MajorType,      Neurotransmitter, PyramidalDeep)",data cleaning,999636801658198e8,327
"cortical = exp[geneDat$Gene.Symbol %in% c(""Ddc""), design$sampleName] %>%      as.matrix %>% melt %>% mutate(Source = design$Reference[match(Var2,      design$sampleName)], Var2 = design$ShinyNames[match(Var2,      design$sampleName)] %>% factor(levels = design$ShinyNames %>%      unique))",data cleaning,999636801658198e8,327
"cortical$Groups = cortical %>% apply(1, function(x) {     if (x[""Var2""] == ""Oligodendrocyte"") {         return(x[""Source""])     }     else if (x[""Var2""] == ""Dopaminergic"") {         return(""dopaminergic"")     }     else {         return(""others"")     } })",data cleaning,999636801658198e8,327
"cortical$Source = ""Microarray""",data cleaning,999636801658198e8,327
design = meltedSingleCells,data cleaning,999636801658198e8,327
"regionSamples = memoReg(design = design, regionNames = ""Region"",      groupNames = ""ShinyNames"", regionHierarchy = regionHierarchy)",data cleaning,999636801658198e8,327
"design %<>% filter((!is.na(regionSamples$Cortex_ShinyNames)) |      design$ShinyNames %in% ""Dopaminergic"") %>% arrange(MajorType,      Neurotransmitter, PyramidalDeep)",data cleaning,999636801658198e8,327
"cortical2 = TasicPrimaryMeanLog[""Ddc"", design$sampleName] %>%      as.matrix %>% melt %>% mutate(Source = design$Reference[match(Var2,      design$sampleName)], Var2 = design$ShinyNames[match(Var2,      design$sampleName)] %>% factor(levels = design$ShinyNames %>%      unique))",data cleaning,999636801658198e8,327
"cortical2$Groups = cortical2 %>% apply(1, function(x) {     if (x[""Var2""] == ""Oligodendrocyte"" | x[""Var2""] == ""Oligodendrocyte precursors"") {         return(x[""Var2""])     }     else {         return(""others"")     } })",data cleaning,999636801658198e8,327
"cortical2$Source = ""RNAseq""",data cleaning,999636801658198e8,327
"cortical = rbind(cortical, cortical2)",data cleaning,999636801658198e8,327
"cortical$Groups %<>% replaceElement(c(`Oligodendrocyte precursors` = ""Oligodendrocyte prec"")) %$%      newVector",data cleaning,999636801658198e8,327
"cortical$Groups %<>% factor(levels = c(""Cahoy et al., 2008"",      ""Doyle et al., 2008"", ""Fomchenko et al 2011"", ""dopaminergic"",      ""Oligodendrocyte"", ""Oligodendrocyte prec"", ""others""))",data cleaning,999636801658198e8,327
"(cortical %>% ggplot(aes(x = Groups, y = value, color = Groups)) +      facet_wrap(~Source, scales = ""free"") + geom_point(size = 4) +      theme_cowplot(21) + xlab("""") + ylab(bquote(""Ddc "" ~ log[2] ~      "" expression"")) + theme(axis.text.x = element_text(angle = 60,      hjust = 1)) + scale_color_viridis(discrete = TRUE, guide = FALSE)) %>%      ggsave(plot = ., filename = ""analysis/07.GeneExpressionPlots/Ddc.png"",          width = 4.5, height = 6)",visualization,999636801658198e8,327
"tiff(filename = ""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Presentation\\Article\\figure\\Figure1.tif"",      width = 6.83, height = 9.19, units = ""in"", res = 300)",export,718617484671995e8,332
"windows(width = 8, height = 12)",setup,718617484671995e8,332
"par(mfrow = c(2, 1))",setup,718617484671995e8,332
"plot(nspm.2mo.tow.count.la, select = 1, shade = T, all.terms = T,      scale = 0, xlab = ""Dissolved Oxygen (mg l ^-1)"", ylab = ""Effect of Dissolved Oxygen"")",visualization,718617484671995e8,332
abline(h = 0),visualization,718617484671995e8,332
"text(3, -2, ""A"", cex = 1.5, font = 2)",visualization,718617484671995e8,332
"plot(nspm.2mo.tow.count.tx, select = 1, shade = T, all.terms = T,      scale = 0, xlab = ""Dissolved Oxygen (mg l^-1"", ylab = """")",visualization,718617484671995e8,332
abline(h = 0),visualization,718617484671995e8,332
"text(3, -2, ""B"", cex = 1.5, font = 2)",visualization,718617484671995e8,332
library(shiny),import,718617484671995e8,332
"request_types = c(""Bulky Items"", ""Dead Animal Removal"", ""Graffiti Removal"",      ""Electronic Waste"", ""Illegal Dumping Pickup"", ""Other"", ""Metal/Household Appliances"",      ""Homeless Encampment"", ""Single Streetlight Issue"", ""Multiple Streetlight Issue"",      ""Feedback"", ""Report Water Waste"")",exploratory,718617484671995e8,332
"CD_lists = c(as.character(1:15), ""city of LA"")",not sure,718617484671995e8,332
"social_types = c(""Median_Age"", ""Median_Household_Income"")",data cleaning,718617484671995e8,332
"favorite_weird <- read.csv(""/Users/andesgomez/Documents/Stanford/Autumn2013-Masters/PayedWork/andres_data/scaleweird_6stimuli_no_fam_favorite_19_february_WERF.csv"",      header = TRUE, sep = ""\t"", row.names = NULL, stringsAsFactors = FALSE)",import,331625089747831e8,333
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, navbarMenu(""Time-based Analysis"",      tabPanel(""Time-based Requests Type Analysis"", sidebarPanel(actionButton(inputId = ""duration"",          label = ""Avg. Processing Time"", width = 200), br(), actionButton(inputId = ""bymonth"",          label = ""Requests by Month"", width = 200), br(), actionButton(inputId = ""byweek"",          label = ""Requests by Weekday"", width = 200), br(), actionButton(inputId = ""weekday_hour"",          label = ""Weekday and Hour"", width = 200), br(), actionButton(inputId = ""type_month"",          label = ""Request Type by Month"", width = 200), br(),          actionButton(inputId = ""type_weekday"", label = ""Request Type by Weekday"",              width = 200)), mainPanel(plotOutput(""plot""))), tabPanel(""Time-based Requests Source Analysis"",          sidebarPanel(actionButton(inputId = ""source_count"", label = ""Requests by Source"",              width = 200), br(), actionButton(inputId = ""source_type_count"",              label = ""Requests by Source and Type"", width = 200),              br(), actionButton(inputId = ""source_eff"", label = ""Efficiency by Source"",                  width = 200), br(), actionButton(inputId = ""source_month"",                  label = ""Request Source by Month"", width = 200),              br(), actionButton(inputId = ""source_weekday"", label = ""Request Source by Weekday"",                  width = 200), br(), actionButton(inputId = ""calls_month"",                  label = ""Calls by Month"", width = 200), br(),              actionButton(inputId = ""calls_hour"", label = ""Calls by Hour"",                  width = 200)), mainPanel(plotOutput(""plot2"")))),      navbarMenu(""Efficiency Analysis"", tabPanel(""Requests Type Efficiency Analysis"",          fluidRow(column(6, tableOutput(outputId = ""type_summary"")),              column(4, plotOutput(outputId = ""wc"")))), tabPanel(""Department Efficiency Analysis"",          column(3, actionButton(inputId = ""dep_source"", label = ""Department and request source"")),          column(3, actionButton(inputId = ""dep_type"", label = ""Department and request type"")),          column(3, actionButton(inputId = ""dep_cd"", label = ""Department and Council Districts"")),          plotOutput(""dep_plot""))), navbarMenu(""Social Analysis"",          tabPanel(""Regional Requests Social Analysis"", sidebarLayout(sidebarPanel(selectInput(inputId = ""CD"",              label = ""Council Districts: "", choices = CD_lists,              multiple = TRUE, selectize = TRUE, selected = ""city of LA""),              actionButton(inputId = ""button_cd"", label = ""Submit"",                  style = ""padding:3px""), width = 3), mainPanel(fluidRow(tableOutput(""cd_summary"")))),              hr(), fluidRow(column(6, plotlyOutput(outputId = ""plot_income"")),                  column(6, plotlyOutput(outputId = ""plot_unemployment"")))),          tabPanel(""Requests Type Social Analysis"", sidebarPanel(selectInput(inputId = ""request_type"",              label = ""Request Type: "", choices = request_types,              multiple = FALSE, selectize = TRUE, selected = ""Metal/Household Appliances""),              selectInput(inputId = ""social_type"", label = ""Social Characteristics: "",                  choices = social_types, multiple = FALSE, selectize = TRUE,                  selected = ""Median_Household_Income""), actionButton(inputId = ""button_req"",                  label = ""Submit""), width = 4), mainPanel(fluidRow(plotOutput(outputId = ""req_summary""))))))",communication,718617484671995e8,332
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, navbarMenu(""Time-based Analysis"",      tabPanel(""Time-based Requests Type Analysis"", sidebarPanel(actionButton(inputId = ""duration"",          label = ""Avg. Processing Time"", width = 200), br(), actionButton(inputId = ""bymonth"",          label = ""Requests by Month"", width = 200), br(), actionButton(inputId = ""byweek"",          label = ""Requests by Weekday"", width = 200), br(), actionButton(inputId = ""weekday_hour"",          label = ""Weekday and Hour"", width = 200), br(), actionButton(inputId = ""type_month"",          label = ""Request Type by Month"", width = 200), br(),          actionButton(inputId = ""type_weekday"", label = ""Request Type by Weekday"",              width = 200)), mainPanel(plotOutput(""plot""))), tabPanel(""Time-based Requests Source Analysis"",          sidebarPanel(actionButton(inputId = ""source_count"", label = ""Requests by Source"",              width = 200), br(), actionButton(inputId = ""source_type_count"",              label = ""Requests by Source and Type"", width = 200),              br(), actionButton(inputId = ""source_eff"", label = ""Efficiency by Source"",                  width = 200), br(), actionButton(inputId = ""source_month"",                  label = ""Request Source by Month"", width = 200),              br(), actionButton(inputId = ""source_weekday"", label = ""Request Source by Weekday"",                  width = 200), br(), actionButton(inputId = ""calls_month"",                  label = ""Calls by Month"", width = 200), br(),              actionButton(inputId = ""calls_hour"", label = ""Calls by Hour"",                  width = 200)), mainPanel(plotOutput(""plot2"")))),      navbarMenu(""Efficiency Analysis"", tabPanel(""Requests Type Efficiency Analysis"",          fluidRow(column(6, tableOutput(outputId = ""type_summary"")),              column(4, plotOutput(outputId = ""wc"")))), tabPanel(""Department Efficiency Analysis"",          column(3, actionButton(inputId = ""dep_source"", label = ""Department and request source"")),          column(3, actionButton(inputId = ""dep_type"", label = ""Department and request type"")),          column(3, actionButton(inputId = ""dep_cd"", label = ""Department and Council Districts"")),          plotOutput(""dep_plot""))), navbarMenu(""Social Analysis"",          tabPanel(""Regional Requests Social Analysis"", sidebarLayout(sidebarPanel(selectInput(inputId = ""CD"",              label = ""Council Districts: "", choices = CD_lists,              multiple = TRUE, selectize = TRUE, selected = ""city of LA""),              actionButton(inputId = ""button_cd"", label = ""Submit"",                  style = ""padding:3px""), width = 3), mainPanel(fluidRow(tableOutput(""cd_summary"")))),              hr(), fluidRow(column(6, plotlyOutput(outputId = ""plot_income"")),                  column(6, plotlyOutput(outputId = ""plot_unemployment"")))),          tabPanel(""Requests Type Social Analysis"", sidebarPanel(selectInput(inputId = ""request_type"",              label = ""Request Type: "", choices = request_types,              multiple = FALSE, selectize = TRUE, selected = ""Metal/Household Appliances""),              selectInput(inputId = ""social_type"", label = ""Social Characteristics: "",                  choices = social_types, multiple = FALSE, selectize = TRUE,                  selected = ""Median_Household_Income""), actionButton(inputId = ""button_req"",                  label = ""Submit""), width = 4), mainPanel(fluidRow(plotOutput(outputId = ""req_summary""))))))",communication,718617484671995e8,332
library(shiny),import,718617484671995e8,332
"request_types = c(""Bulky Items"", ""Dead Animal Removal"", ""Graffiti Removal"",      ""Electronic Waste"", ""Illegal Dumping Pickup"", ""Other"", ""Metal/Household Appliances"",      ""Homeless Encampment"", ""Single Streetlight Issue"", ""Multiple Streetlight Issue"",      ""Feedback"", ""Report Water Waste"")",data cleaning,718617484671995e8,332
"CD_lists = c(as.character(1:15), ""city of LA"")",not sure,718617484671995e8,332
"social_types = c(""Median_Age"", ""Median_Household_Income"")",not sure,718617484671995e8,332
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, navbarMenu(""Time-based Analysis"",      tabPanel(""Time-based Requests Type Analysis"", sidebarPanel(actionButton(inputId = ""duration"",          label = ""Avg. Processing Time"", width = 200), br(), actionButton(inputId = ""bymonth"",          label = ""Requests by Month"", width = 200), br(), actionButton(inputId = ""byweek"",          label = ""Requests by Weekday"", width = 200), br(), actionButton(inputId = ""weekday_hour"",          label = ""Weekday and Hour"", width = 200), br(), actionButton(inputId = ""type_month"",          label = ""Request Type by Month"", width = 200), br(),          actionButton(inputId = ""type_weekday"", label = ""Request Type by Weekday"",              width = 200)), mainPanel(plotOutput(""plot""))), tabPanel(""Time-based Requests Source Analysis"",          sidebarPanel(actionButton(inputId = ""source_count"", label = ""Requests by Source"",              width = 200), br(), actionButton(inputId = ""source_type_count"",              label = ""Requests by Source and Type"", width = 200),              br(), actionButton(inputId = ""source_eff"", label = ""Efficiency by Source"",                  width = 200), br(), actionButton(inputId = ""source_month"",                  label = ""Request Source by Month"", width = 200),              br(), actionButton(inputId = ""source_weekday"", label = ""Request Source by Weekday"",                  width = 200), br(), actionButton(inputId = ""calls_month"",                  label = ""Calls by Month"", width = 200), br(),              actionButton(inputId = ""calls_hour"", label = ""Calls by Hour"",                  width = 200)), mainPanel(plotOutput(""plot2"")))),      navbarMenu(""Efficiency Analysis"", tabPanel(""Requests Type Efficiency Analysis"",          fluidRow(column(6, tableOutput(outputId = ""type_summary"")),              column(4, plotOutput(outputId = ""wc"")))), tabPanel(""Department Efficiency Analysis"",          column(3, actionButton(inputId = ""dep_source"", label = ""Department and request source"")),          column(3, actionButton(inputId = ""dep_type"", label = ""Department and request type"")),          column(3, actionButton(inputId = ""dep_cd"", label = ""Department and Council Districts"")),          plotOutput(""dep_plot""))), navbarMenu(""Social Analysis"",          tabPanel(""Regional Requests Social Analysis"", sidebarLayout(sidebarPanel(selectInput(inputId = ""CD"",              label = ""Council Districts: "", choices = CD_lists,              multiple = TRUE, selectize = TRUE, selected = ""city of LA""),              actionButton(inputId = ""button_cd"", label = ""Submit"",                  style = ""padding:3px""), width = 3), mainPanel(fluidRow(tableOutput(""cd_summary"")))),              hr(), fluidRow(column(6, plotlyOutput(outputId = ""plot_income"")),                  column(6, plotlyOutput(outputId = ""plot_unemployment"")))),          tabPanel(""Requests Type Social Analysis"", sidebarPanel(selectInput(inputId = ""request_type"",              label = ""Request Type: "", choices = request_types,              multiple = FALSE, selectize = TRUE, selected = ""Metal/Household Appliances""),              selectInput(inputId = ""social_type"", label = ""Social Characteristics: "",                  choices = social_types, multiple = FALSE, selectize = TRUE,                  selected = ""Median_Household_Income""), actionButton(inputId = ""button_req"",                  label = ""Submit""), width = 4), mainPanel(fluidRow(plotOutput(outputId = ""req_summary""))))))",communication,718617484671995e8,332
library(parallel),import,651064552133903e8,334
library(randomForest),setup,475761936511844e8,335
library(PBD),import,651064552133903e8,334
library(caret),setup,475761936511844e8,335
library(doMC),setup,475761936511844e8,335
library(mmadsenr),setup,475761936511844e8,335
"setwd(""~/Desktop/gitHub/protracted_sp/"")",setup,651064552133903e8,334
library(futile.logger),setup,475761936511844e8,335
library(dplyr),data cleaning,475761936511844e8,335
library(ggthemes),visualization,475761936511844e8,335
"input_data = ""analysis/data/""",setup,651064552133903e8,334
"input_code = ""analysis/R/""",setup,651064552133903e8,334
"ouput_data = ""analysis/data/""",setup,651064552133903e8,334
"load(file = paste0(input_data, ""Jetz_Botero14_30min_0.3mixed_0multilat_branches.RData""))",import,651064552133903e8,334
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",data cleaning,475761936511844e8,335
library(dplyr),setup,363556126365438e8,336
"propMixedHarsh = read.csv(file = paste0(input_data, ""Jetz_Botero14_propMixedHarsh.csv""))",import,651064552133903e8,334
library(ggplot2),setup,363556126365438e8,336
library(tidyr),setup,363556126365438e8,336
"tickets <- readRDS(""processedData/catch/1_cleaningData/tickets.RDS"")",import,363556126365438e8,336
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,917228200240061e8,337
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,917228200240061e8,337
"dscrp <- read.csv(""processedData/catch/3_exploreBuildwebs/ref_tables/metier_descrp.csv"",      stringsAsFactors = FALSE)",import,363556126365438e8,336
"dscrp$name <- paste(dscrp$Major_species, dscrp$Major_gear)",data cleaning,363556126365438e8,336
"dscrp <- rename(dscrp, metier.2010 = Metier)",data cleaning,363556126365438e8,336
"tickets <- left_join(tickets, dscrp[, c(""metier.2010"", ""name"")])",data cleaning,363556126365438e8,336
"tickets$tdate <- as.Date(tickets$tdate, format = ""%d-%b-%y"")",data cleaning,363556126365438e8,336
"tickets$doy <- as.numeric(format(tickets$tdate, ""%j""))",data cleaning,363556126365438e8,336
"fig3a <- tickets %>% filter(metier.2010 %in% c(""POT_1"", ""HKL_2"",      ""TWL_1"", ""NET_2"", ""TLS_1"", ""TLS_2"", ""HKL_12"", ""TWS_1"")) %>%      group_by(name, metier.2010, tdate) %>% summarize(n_trips = length(unique(trip_id))) %>%      ggplot(aes(x = tdate, y = n_trips)) + geom_bar(stat = ""identity"") +      facet_wrap(~name, scale = ""free"", ncol = 1) + theme_classic() +      theme(axis.line.x = element_line(size = 0.5, color = ""black""),          axis.line.y = element_line(size = 0.5, color = ""black""),          strip.background = element_rect(size = 0)) + xlab(""date landed"") +      ylab(""number of trips"")",visualization,363556126365438e8,336
"ggsave(fig3a, filename = ""Analysis/new_analysis/metiers/tables_figures/fig3a.png"",      height = 10, width = 5, dpi = 300)",communication,363556126365438e8,336
"all_ports <- read.csv(""processedData/spatial/ports/all_ports.csv"",      stringsAsFactors = FALSE) %>% rename(pcid = Pcid)",import,363556126365438e8,336
"tickets <- tickets %>% left_join(all_ports[, c(""pcid"", ""lat"")],      by = ""pcid"")",data cleaning,363556126365438e8,336
"tickets$bin_lat <- cut(tickets$lat, breaks = seq(32, 49, 0.2))",data cleaning,363556126365438e8,336
"fig3b <- tickets %>% filter(metier.2010 %in% c(""POT_1"", ""POT_2""),      !is.na(lat)) %>% group_by(trip_id, bin_lat, name) %>% summarize(rev = sum(adj_revenue)) %>%      ggplot(aes(x = bin_lat, y = rev, fill = name)) + geom_bar(stat = ""identity"") +      scale_fill_manual(values = c(""grey20"", ""grey80"")) + theme_classic() +      coord_flip() + xlab(""latitude"") + ylab(""revenue ($)"") + scale_y_reverse() +      theme(axis.line.x = element_line(color = ""black"", size = 0.5),          axis.line.y = element_line(color = ""black"", size = 0.5),          axis.text.y = element_blank(), axis.ticks.y = element_blank(),          axis.title.y = element_blank())",visualization,363556126365438e8,336
"ggsave(fig3b, filename = ""Analysis/new_analysis/metiers/tables_figures/fig3b.png"",      height = 10, width = 5, dpi = 300)",communication,363556126365438e8,336
"req <- c(""mvtnorm"", ""ggplot2"", ""reshape2"", ""foreign"", ""Hmisc"",      ""scales"", ""splines"", ""Cairo"", ""lubridate"", ""gridExtra"", ""gtable"",      ""plyr"", ""lmtest"", ""survival"", ""data.table"")",setup,20849522924982e9,338
"load(""processedData/spatial/2_coastline.Rdata"")",import,363556126365438e8,336
"png(filename = ""Analysis/new_analysis/metiers/tables_figures/fig3b_map.png"",      height = 960, width = 400)",communication,363556126365438e8,336
"lapply(req, library, character.only = TRUE)",setup,20849522924982e9,338
set.seed(753892375),setup,20849522924982e9,338
"par(mai = rep(0, 4), bg = ""transparent"")",export,363556126365438e8,336
"plot(WC, col = ""black"")",export,363556126365438e8,336
dev.off(),export,363556126365438e8,336
nsamples <- 1000,modeling,20849522924982e9,338
"analysis <- read.dta(""data/d01_cacoh_stset_barlow.dta"", convert.underscore = TRUE)",import,20849522924982e9,338
analysis_stata <- analysis,not sure,20849522924982e9,338
"varlabs <- data.frame(varname = attributes(analysis_stata)$names,      varlab = attributes(analysis_stata)$var.labels)",import,20849522924982e9,338
varlabs <- data.table(varlabs),import,20849522924982e9,338
analysis <- data.table(analysis),import,20849522924982e9,338
analysis$stage.imputed <- factor(analysis$stage.imputed),data cleaning,20849522924982e9,338
analysis$sex <- factor(analysis$sex),data cleaning,20849522924982e9,338
analysis <- analysis[.st == 1],data cleaning,20849522924982e9,338
rm(list = ls()),setup,238193191587925e8,339
library(ggplot2),visualization,238193191587925e8,339
library(ggthemes),visualization,238193191587925e8,339
library(cowplot),visualization,238193191587925e8,339
"tickets <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_landings_data.RDS"")",import,238193191587925e8,339
"vessel_stats <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_stats.RDS"")",import,238193191587925e8,339
options(stringsAsFactors = F),data cleaning,969787730136886e8,340
library(dplyr),data cleaning,238193191587925e8,339
library(data.table),setup,969787730136886e8,340
library(vegan),visualization,238193191587925e8,339
library(rafalib),setup,969787730136886e8,340
"ports <- read.csv(""/Users/efuller/Desktop/CNH/processedData/spatial/ports/all_ports.csv"",      stringsAsFactors = FALSE)",import,238193191587925e8,339
"ports <- rename(ports, pcid = Pcid)",data cleaning,238193191587925e8,339
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",not sure,565064748749137e8,341
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",visualization,565064748749137e8,341
"coastwide <- ggplot(vessel_stats[which(vessel_stats$alaska ==      0 & !is.na(vessel_stats$type)), ], aes(x = type)) + geom_bar() +      ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,238193191587925e8,339
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",import,565064748749137e8,341
"by_zone <- ggplot(vessel_stats[which(vessel_stats$alaska == 0 &      !is.na(vessel_stats$type) & !is.na(vessel_stats$zone)), ],      aes(x = type)) + geom_bar() + facet_wrap(~zone, ncol = 1,      scales = ""free_y"") + ylab(""number of vessels"") + theme_pander() +      theme(panel.grid = element_blank())",visualization,238193191587925e8,339
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",import,565064748749137e8,341
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",import,565064748749137e8,341
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",import,565064748749137e8,341
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",import,565064748749137e8,341
"div_hist <- ggplot(subset(vessel_stats[which(!is.na(vessel_stats$zone) &      vessel_stats$alaska == 0), ], vessel_stats$eff.shannon_2010 >      1), aes(x = eff.shannon_2010)) + geom_histogram(aes(y = ..count..)) +      facet_wrap(~zone, ncol = 1, scales = ""free_y"") + xlab(""effective shannon diversity of revenue"") +      ylab(""number of vessels"") + theme_pander() + theme(panel.grid = element_blank())",visualization,238193191587925e8,339
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",import,565064748749137e8,341
"aid_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_WorldBank/data/locations_perturbed.csv"")",import,565064748749137e8,341
"aid_loc <- aid_loc[grepl(""Africa"", aid_loc$gazetteer_adm_name),      ]",data cleaning,565064748749137e8,341
"all_plot <- plot_grid(coastwide, by_zone, div_hist, labels = c(""A"",      ""B"", ""C""), ncol = 3, rel_widths = c(1, 1.2, 1.4))",visualization,238193191587925e8,339
"aid_proj <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_WorldBank/data/projects.csv"")",import,565064748749137e8,341
"ggplot2::ggsave(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/05_figures/fig_2.pdf"",      all_plot, width = 11.4, height = 7, units = ""cm"", scale = 2.5,      dpi = 300)",export,238193191587925e8,339
"port_df <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/port_stats.RDS"")",import,238193191587925e8,339
"source(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/02_define_participationPlot.R"")",setup,238193191587925e8,339
"port_df <- port_df[order(port_df$ic_pre, decreasing = TRUE),      ]",data cleaning,238193191587925e8,339
"port_df <- port_df[-grep(""other"", port_df$name), ]",data cleaning,238193191587925e8,339
"pdf(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/05_figures/fig_3c.pdf"",      width = 8, height = 2)",export,238193191587925e8,339
"par(bg = ""transparent"", cex = 0.75, cex = 1.2)",visualization,238193191587925e8,339
"paint = rep(""normal"", nrow(port_df))",modeling,238193191587925e8,339
"paint[port_df$pcid %in% c(""SB"", ""ERK"", ""OAK"")] <- ""example""",modeling,238193191587925e8,339
rootDir <- getwd(),setup,386380308307707e8,342
"analysisDir <- paste0(rootDir, ""/Analysis"")",setup,386380308307707e8,342
"setwd(""Analysis/Data"")",setup,386380308307707e8,342
"source(""Makefile.txt"")",import,386380308307707e8,342
setwd(analysisDir),setup,386380308307707e8,342
"source(""libraries.R"")",setup,386380308307707e8,342
"source(""Analysis.R"")",setup,386380308307707e8,342
"case.name = c(""fullread.70ind.over.2"", ""fullread.30ind.over.2"",      ""fullread.10ind.over.2"")",not sure,730157670332119e8,343
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/sum/f.overB.Robj""",export,730157670332119e8,343
num_id_matches <- idMatches(),exploratory,386380308307707e8,342
"ROC.file.name = ""ROC_overB.pdf""",export,730157670332119e8,343
"hist.file.name = ""hist_overB.pdf""",export,730157670332119e8,343
"ms.null = vector(""list"", length(case.name))",export,730157670332119e8,343
num_id_matches,exploratory,386380308307707e8,342
"paste(""The number of ID matched by joining GDP and EdStats datasets is "",      num_id_matches)",exploratory,386380308307707e8,342
gdpRank(13),exploratory,386380308307707e8,342
"paste(""The 13th smallest GDP country is: "", gdpRank(13))",exploratory,386380308307707e8,342
"paste(""Average group rankings for High income OECD and nonOECD groups"")",exploratory,386380308307707e8,342
grpAvgs <- groupRankAverages(),exploratory,386380308307707e8,342
"grpAvgs[grepl("".*OECD$"", grpAvgs$`Income Group`), ]",exploratory,386380308307707e8,342
"cols <- c(Emperical = ""#f04546"", Theoritical = ""#3591d1"")",visualization,386380308307707e8,342
"fun_args <- list(mean = mean(log10(gdpEduc$Gdp)), sd = sd(log10(gdpEduc$Gdp)))",modeling,386380308307707e8,342
"ggplot(gdpEduc, aes(x = log10(gdpEduc$Gdp))) + geom_histogram(aes(y = ..density..)) +      geom_density(aes(col = ""Emperical"")) + stat_function(fun = dnorm,      args = fun_args, aes(col = ""Theoritical"")) + theme_classic() +      scale_color_manual(name = ""Normal Curves"", values = cols) +      labs(x = ""log GDP"") + ggtitle(""Log transformed GDP density plot"") +      theme(plot.title = element_text(hjust = 0.5, face = ""bold.italic"",          size = rel(0.8), color = ""darkblue""))",visualization,386380308307707e8,342
"ggplot(gdpEduc, aes(x = log10(Gdp), col = factor(`Income Group`),      fill = factor(`Income Group`))) + geom_histogram(binwidth = 0.7,      alpha = 0.5) + facet_grid(. ~ factor(`Income Group`)) + theme_dark() +      theme(legend.position = ""none"", strip.text = element_text(size = rel(0.4))) +      labs(x = ""log10(Gdp)"") + ggtitle(""count vs log GDP faceted by Income groups"") +      theme(plot.title = element_text(hjust = 0.5, face = ""bold.italic"",          size = rel(0.8), color = ""darkblue""))",visualization,386380308307707e8,342
"ggplot(gdpEduc, aes(x = log10(Gdp), fill = factor(`Income Group`))) +      geom_density(col = NA, alpha = 0.35) + theme_light() + theme(legend.text = element_text(size = rel(0.5))) +      labs(x = ""GDP log transformed"") + scale_fill_discrete(name = ""Income Group"") +      ggtitle(""Overlaying density plots for log GDP"") + theme(plot.title = element_text(hjust = 0.5,      face = ""bold.italic"", size = rel(0.8), color = ""darkblue""))",visualization,386380308307707e8,342
"ggplot(gdpEduc, aes(x = factor(`Income Group`), y = log10(Gdp))) +      stat_summary(geom = ""point"", fun.y = mean, col = ""blue"") +      stat_summary(geom = ""errorbar"", fun.data = mean_sdl, fun.args = list(mult = 1),          col = ""blue"", width = 0.1) + theme(axis.text = element_text(angle = 45,      hjust = c(1), size = rel(0.6))) + labs(x = ""Income Groups"") +      ggtitle(""mean and 1 SD from mean"") + theme(plot.title = element_text(hjust = 0.5,      face = ""bold.italic"", size = rel(0.8), color = ""darkblue""))",visualization,386380308307707e8,342
"ggplot(gdpEduc, aes(x = factor(`Income Group`), y = log10(Gdp))) +      geom_point(colour = ""lightblue"", alpha = 0.9, position = ""identity"") +      geom_boxplot(outlier.size = 0, alpha = 0.2) + theme_light() +      theme(axis.text = element_text(angle = 45, hjust = c(1),          size = rel(0.6))) + labs(x = ""Income Groups"") + ggtitle(""Box plot overlayed with actual values"") +      theme(plot.title = element_text(hjust = 0.5, face = ""bold.italic"",          size = rel(0.8), color = ""darkblue""))",visualization,386380308307707e8,342
"descStatsGDP <- describeBy(gdpEduc$Gdp, gdpEduc$`Income Group`,      mat = TRUE)",modeling,386380308307707e8,342
"descStatsGDP %>% select(-item, -vars, -mad) %>% print(row.names = FALSE)",exploratory,386380308307707e8,342
gdpEducTemp <- gdpEduc,data cleaning,386380308307707e8,342
"gdpEducTemp %>% mutate(quantiles = quantileCut(gdpEduc$Ranking,      5, labels = c(""Q1"", ""Q2"", ""Q3"", ""Q4"", ""Q5""))) %>% filter(as.character(quantiles) ==      ""Q1"", `Income Group` == ""Lower middle income"") %>% select(CountryCode,      Economy, Ranking, `Income Group`, quantiles)",data cleaning,386380308307707e8,342
setwd(rootDir),setup,386380308307707e8,342
"selectionBarplot <- ggplot(tidyData, aes(x = fatigue)) + geom_bar(aes(fill = result),      position = ""dodge"") + scale_y_discrete(name = ""Correct selection"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,361533931689337e8,344
"ggsave(""./Data/Selection_Barplot_without_zeros.pdf"", selectionBarplot)",export,361533931689337e8,344
"tab1 <- table(tidyData$fatigue, tidyData$result)",exploratory,361533931689337e8,344
"comparison <- epi.2by2(tab1, method = ""cohort.count"", conf.level = 0.9)",modeling,361533931689337e8,344
"write.xlsx(tab1, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Table"")",export,361533931689337e8,344
"confidenceBarplot <- ggplot(tidyData, aes(x = fatigue)) + geom_bar(aes(fill = confidence),      position = ""dodge"") + scale_y_discrete(name = ""Selection confidence"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,361533931689337e8,344
"ggsave(""./Data/Confidence_Barplot_without_zeros.pdf"", confidenceBarplot)",export,361533931689337e8,344
"tab2 <- table(tidyData$confidence, tidyData$fatigue)",exploratory,361533931689337e8,344
"wilcox <- wilcox.test(as.numeric(confidence) ~ fatigue, data = tidyData,      conf.level = 0.9, alternative = ""two.sided"")",modeling,361533931689337e8,344
"write.xlsx(tab2, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Table confidence"", append = TRUE)",export,361533931689337e8,344
"write.xlsx(wilcox$p.value, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Wilcox confindence p-value"",      append = TRUE)",export,361533931689337e8,344
"perPersonBoxplot <- ggplot(perPersonData, aes(x = fatigue, y = ratio)) +      geom_boxplot() + scale_y_continuous(name = ""Ratio Number wrong Selections / Total Number of Selected Studies"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,361533931689337e8,344
"ggsave(""./Data/Per_Person_Boxplot.pdf"", perPersonBoxplot)",export,361533931689337e8,344
normality <- shapiro.test(perPersonData$ratio),modeling,361533931689337e8,344
"wilcox <- wilcox.test(ratio ~ fatigue, data = perPersonData,      conf.level = 0.9, alternative = ""two.sided"")",modeling,361533931689337e8,344
"write.xlsx(wilcox$p.value, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Wilcox Per Person p-value"",      append = TRUE)",export,361533931689337e8,344
"write.xlsx(normality$p.value, file = paste(""./Data/Analysis_"",      Sys.Date(), "".xlsx"", sep = """"), sheetName = ""Normality Per Person p-value"",      append = TRUE)",export,361533931689337e8,344
"source(""/Users/Seth/Documents/TrumpDiscourse/Analysis/trump-cleaning.R"")",setup,679275823524222e8,345
"source(""/Users/Seth/Documents/TrumpDiscourse/Analysis/trump-plotting.R"")",setup,679275823524222e8,345
library(plotly),setup,679275823524222e8,345
library(reshape2),setup,679275823524222e8,345
"setwd(""/Users/Seth/Documents/TrumpDiscourse/modelOutput/newDocsLogs"")",setup,679275823524222e8,345
"rawdf <- read.csv(""newDocsPredictions-coco_3_cv_3_netAng_30_twc_15_tfidfNoPro_pronounFrac_bin_1-H9FJGD.csv"",      stringsAsFactors = F)",import,679275823524222e8,345
df <- cleanTrumpPredictions(rawdf),data cleaning,679275823524222e8,345
"topicize <- function(sampleText) {     sampleText <- as.character(sampleText)     if (grepl(""Briti|Iran|Middle East|Terror"", sampleText)) {         topic <- ""Foreign Policy""     }     else if (grepl(""Immigrat|Visa|Refuge|Amnesty|Border"", sampleText)) {         topic <- ""Immigration""     }     else if (grepl(""Clinton|Cruz|Sanders|Kasich|Graham"", sampleText)) {         topic <- ""Opponents""     }     else if (grepl("" at .+ in "", sampleText)) {         topic <- ""campaign trail""     }     else {         topic <- ""other""     }     topic }",data cleaning,679275823524222e8,345
df$Topic <- character(nrow(df)),data cleaning,679275823524222e8,345
for (i in 1:nrow(df)) {     df$Topic[i] <- topicize(df$title[i]) },data cleaning,679275823524222e8,345
"moddf <- melt(df, id = c(""type"", ""title"", ""date"", ""Topic""), variable_name = ""Pred"")",data cleaning,679275823524222e8,345
"names(moddf)[5:6] <- c(""Model"", ""Prediction"")",modeling,679275823524222e8,345
"ggplotly(tpm(moddf), tooltip = c(""x"", ""title"", ""y""))",visualization,679275823524222e8,345
"library(""rjson"")",setup,645292269298807e8,346
"ggplotly(tpm(moddf, date = ""2016-04-01""), tooltip = c(""x"", ""title"",      ""y""))",visualization,679275823524222e8,345
"ggplotly(tpm(moddf, model = ""class"", date = ""2016-04-01""), tooltip = c(""x"",      ""title"", ""y""))",visualization,679275823524222e8,345
"ggplotly(tpt(moddf, ""both"", ""svmClass"", ""min"", title = ""SVM Predictions""),      tooltip = c(""x"", ""title"", ""y""))",visualization,679275823524222e8,345
"ggplotly(tpt(moddf, ""both"", ""rfClass"", ""min"", title = ""Random Forest Predictions""),      tooltip = c(""x"", ""title"", ""y""))",visualization,679275823524222e8,345
"ggplotly(tpm(moddf, type = ""TrumpStatements"", model = ""class""),      tooltip = c(""x"", ""title"", ""y""))",visualization,679275823524222e8,345
"ggplotly(tptop(moddf, model = ""svmClass"", date = ""2016-04-01""))",visualization,679275823524222e8,345
"ggplotly(tptop(moddf, model = ""rfClass"", date = ""2016-04-01""))",visualization,679275823524222e8,345
"ggplotly(tptop(moddf, model = ""svmReg"", date = ""2016-04-01""))",visualization,679275823524222e8,345
"source(""C:\\Users\\Kitsune\\Documents\\GitHub\\VersionClassifier\\Analysis\\analysisScript1.R"")",setup,645292269298807e8,346
"mobileJsonCyc = getFiledata(""CyclesMobile.json"")",import,645292269298807e8,346
"desktopJsonCyc = getFiledata(""CyclesDesktop.json"")",import,645292269298807e8,346
"siblingJsonCyc = getFiledata(""CyclesSibling.json"")",import,645292269298807e8,346
"sibMobJsonCyc = getFiledata(""CyclesSibMob.json"")",import,645292269298807e8,346
"sibDeskJsonCyc = getFiledata(""CyclesSibDesk.json"")",import,645292269298807e8,346
mobileCyc = mobileJsonCyc$Cycle$Data,exploratory,645292269298807e8,346
desktopCyc = desktopJsonCyc$Cycle$Data,exploratory,645292269298807e8,346
siblingCyc = siblingJsonCyc$Cycle$Data,exploratory,645292269298807e8,346
sibMobCyc = sibMobJsonCyc$Cycle$Data,exploratory,645292269298807e8,346
"source(""analysis/data_cleanup.R"")",data cleaning,70857867365703e8,347
library(ggplot2),visualization,70857867365703e8,347
ls(),exploratory,70857867365703e8,347
rm(list = ls()),data cleaning,70857867365703e8,347
"gdp_education_data <- read.csv(""analysis/data/tidy_gdp_educ_data.csv"",      header = TRUE)",import,70857867365703e8,347
"sapply(gdp_education_data, class)",evaluation,70857867365703e8,347
head(gdp_education_data),exploratory,70857867365703e8,347
ls(gdp_education_data),exploratory,70857867365703e8,347
matching_cases <- nrow(gdp_education_data),evaluation,70857867365703e8,347
matching_cases,communication,70857867365703e8,347
"gdp_education_data <- gdp_education_data[order(gdp_education_data$GDP_US_dollars),      ]",evaluation,70857867365703e8,347
"thirteenth_ranked_country <- gdp_education_data[13, ]",evaluation,70857867365703e8,347
class(thirteenth_ranked_country),communication,70857867365703e8,347
as.vector(thirteenth_ranked_country$economy),communication,70857867365703e8,347
"high_income_groups <- subset(gdp_education_data, Income.Group ==      ""High income: OECD"" | Income.Group == ""High income: nonOECD"")",data cleaning,70857867365703e8,347
str(high_income_groups),communication,70857867365703e8,347
as.vector(unique(high_income_groups$Income.Group)),communication,70857867365703e8,347
length(as.vector(unique(high_income_groups$Income.Group))),communication,70857867365703e8,347
"aggregate(high_income_groups$GDP_rank, list(high_income_groups$Income.Group),      FUN = mean)",communication,70857867365703e8,347
library(plyr),setup,418617147719487e8,348
library(dplyr),setup,418617147719487e8,348
"ggplot(data = gdp_education_data, aes(x = economy, y = GDP_US_dollars,      fill = Income.Group)) + geom_bar(stat = ""identity"")",visualization,70857867365703e8,347
library(lme4),setup,418617147719487e8,348
library(lmerTest),setup,418617147719487e8,348
"plot(gdp_education_data$GDP_rank, gdp_education_data$GDP_US_dollars)",visualization,70857867365703e8,347
"seq(0, 1, 0.2)",communication,70857867365703e8,347
"gdp_education_data$GDP_quantile <- cut(gdp_education_data$GDP_rank,      quantile(gdp_education_data$GDP_rank, probs = c(0, 0.2, 0.4,          0.6, 0.8, 1)))",data cleaning,70857867365703e8,347
"myC = function(x) {     return(scale(x, scale = F)) }",data cleaning,418617147719487e8,348
"NAtoX = function(x, value) {     if (is.factor(x)) {         x = as.factor(ifelse(is.na(x), value, as.character(x)))     }     else {         x = ifelse(is.na(x), value, x)     } }",data cleaning,418617147719487e8,348
"setwd(""~/Dropbox/Backup_MyDoc_Jan2013/Teaching/BCS206:207/207_Spring2017/Data/Combined"")",setup,418617147719487e8,348
"df2 <- read.csv(""preprocessed-current-Exp1.csv"")",import,418617147719487e8,348
"targetRegionA <- subset(df2, df2$RelAdj >= 200 & df2$RelAdj <=      700)",data cleaning,418617147719487e8,348
library(ROntoTools),setup,719843501457944e8,349
emplog = function(x) {     log((sum(x) + 0.5)/(length(x) - sum(x) + 0.5)) },modeling,418617147719487e8,348
"kpg <- keggPathwayGraphs(""eco"", relPercThresh = 0, updateCache = TRUE,      verbose = TRUE)",visualization,719843501457944e8,349
rm(list = ls()),setup,883152025053278e8,350
"kpg <- setEdgeWeights(kpg, edgeTypeAttr = ""subtype"", edgeWeightByType = list(activation = 1,      inhibition = -1, expression = 1, repression = -1), defaultWeight = 0)",modeling,719843501457944e8,349
"new.d <- ddply(targetRegionA, c(""Subject"", ""Trial"", ""Audio"",      ""Speaker"", ""Contrast""), summarise, count.all = length(TargetFix),      count.T = sum(TargetFix), fixprop.T = count.T/count.all,      emplogs.T = emplog(fixprop.T))",modeling,418617147719487e8,348
"source(""latex/plotDefaults.R"")",import,883152025053278e8,350
"core <- read.csv(""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/best_strains_DEseq.csv"",      header = TRUE)",import,719843501457944e8,349
"source(""analysis/prepare_individual_series.R"")",import,883152025053278e8,350
"source(""analysis/make_series_stationary.R"")",import,883152025053278e8,350
"source(""analysis/model_identification.R"")",import,883152025053278e8,350
"source(""analysis/missing_values.R"")",import,883152025053278e8,350
"colnames(core)[1] <- ""bnum""",import,719843501457944e8,349
rm(list = ls(all = TRUE)),setup,883152025053278e8,350
"prepVars = function(d) {     d$Speaker = factor(d$Speaker, levels = c(""reliable"", ""unreliable_impairment""))     d$Contrast = factor(d$Contrast, levels = c(""One"", ""Two""))     contrasts(d$Speaker) = contr.sum(2)     contrasts(d$Contrast) = contr.sum(2)     d$cSpeaker = myC(ifelse(d$Speaker == ""reliable"", 1, 0))     d$cContrast = myC(ifelse(d$Contrast == ""One"", 1, 0))     return(d) }",data cleaning,418617147719487e8,348
"base::source(""./scripts/graphing/graph-presets.R"")",import,883152025053278e8,350
library(magrittr),import,883152025053278e8,350
library(ggplot2),import,883152025053278e8,350
"core <- core[complete.cases(core), ]",import,719843501457944e8,349
"requireNamespace(""dplyr"")",import,883152025053278e8,350
"lm1 = lmer(emplogs.T ~ cSpeaker * cContrast + (1 + cContrast |      Subject) + (1 + cSpeaker * cContrast | Audio), data = prepVars(new.d))",modeling,418617147719487e8,348
"kpn <- keggPathwayNames(""eco"")",import,719843501457944e8,349
options(show.signif.stars = F),setup,883152025053278e8,350
fc <- core$log2FoldChange[core$padj <= 0.01],import,719843501457944e8,349
summary(lm1),exploratory,418617147719487e8,348
"path_input <- ""./data-unshared/derived/ds2.csv""",setup,883152025053278e8,350
"names(fc) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",import,719843501457944e8,349
"df2 <- read.csv(""preprocessed-current-Exp2_RT.csv"")",import,418617147719487e8,348
pv <- core$padj[core$padj <= 0.01],import,719843501457944e8,349
ds0 <- readr::read_csv(path_input),import,883152025053278e8,350
"names(pv) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",import,719843501457944e8,349
"df2 <- subset(df2, df2$ReliabilityOfSpeaker != ""unreliable_bottomUp"")",exploratory,418617147719487e8,348
"kpg <- setNodeWeights(kpg, weights = alphaMLG(pv), defaultWeight = 1)",import,719843501457944e8,349
"df3 <- df2 %>% dplyr::group_by(Subject, Audio, Speaker, Contrast,      Trial, TrialType) %>% dplyr::summarise(meanRT = mean(ResponseTime))",exploratory,418617147719487e8,348
"ref <- paste0(""eco:"", core$bnum)",import,719843501457944e8,349
"ggplot(df3, aes(x = Trial, y = log(meanRT))) + coord_cartesian(ylim = c(7.9,      8.1)) + geom_point(shape = 1) + geom_smooth() + geom_smooth(method = ""lm"",      formula = y ~ x, color = ""red"", se = F) + geom_smooth(method = ""lm"",      formula = y ~ log(x), color = ""cyan"", se = F) + geom_smooth(method = ""lm"",      formula = y ~ sqrt(x), color = ""orange"", se = F) + geom_smooth(method = ""lm"",      formula = y ~ 1/x, color = ""black"", se = F)",visualization,418617147719487e8,348
"ds <- ds0 %>% dplyr::filter(!is.na(response_value)) %>% dplyr::mutate(qpretty = paste0(""["",      qid, ""] - "", qlabel), common_item_id = paste0(qid_fellow,      ""-"", qid_host, ""-"", qid_academic), common_item_label = paste0(""["",      common_item_id, ""] - "", qlabel), common_item_id = gsub(""NA"",      """", common_item_id), common_item_label = gsub(""NA"", """", common_item_label))",data cleaning,883152025053278e8,350
library(lme4),setup,418617147719487e8,348
"peRes <- pe(x = fc, graphs = kpg, ref = ref, nboot = 200, verbose = TRUE)",exploratory,719843501457944e8,349
"m.resid = lmer(meanRT ~ Trial + (1 + Trial | Subject), data = df3)",modeling,418617147719487e8,348
"s <- Summary(peRes, pathNames = kpn, totalAcc = FALSE, totalPert = FALSE,      pAcc = FALSE, order.by = ""pPert"")",exploratory,719843501457944e8,349
summary(m.resid),evaluation,418617147719487e8,348
"p <- peRes@pathways[[""path:eco00650""]]",exploratory,719843501457944e8,349
df3$rRT = residuals(m.resid),modeling,418617147719487e8,348
"g <- layoutGraph(p@map, layoutType = ""dot"")",visualization,719843501457944e8,349
graphRenderInfo(g) <- list(fixedsize = FALSE),visualization,719843501457944e8,349
"ggplot(df3, aes(x = Trial, y = rRT, color = Speaker)) + geom_point(shape = 1) +      geom_smooth()",visualization,418617147719487e8,348
edgeRenderInfo(g) <- peEdgeRenderInfo(p),visualization,719843501457944e8,349
nodeRenderInfo(g) <- peNodeRenderInfo(p),visualization,719843501457944e8,349
renderGraph(g),visualization,719843501457944e8,349
"library(""topGO"")",setup,719843501457944e8,349
"d.ForAnalysis <- df3 %>% dplyr::group_by(Subject) %>% filter(TrialType ==      ""critical"") %>% dplyr::mutate(ItemOrder = rank(Trial))",data cleaning,418617147719487e8,348
"library(""org.EcK12.eg.db"")",setup,719843501457944e8,349
"prepVars = function(d) {     d$Speaker = factor(d$Speaker, levels = c(""reliable"", ""unreliable_impairment""))     d$Contrast = factor(d$Contrast, levels = c(""One"", ""Two""))     contrasts(d$Speaker) = contr.sum(2)     contrasts(d$Contrast) = contr.sum(2)     d$cSpeaker = myC(ifelse(d$Speaker == ""reliable"", 0, 1))     d$cContrast = myC(ifelse(d$Contrast == ""One"", 0, 1))     return(d) }",data cleaning,418617147719487e8,348
"results <- ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/""",import,719843501457944e8,349
"goDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/gene_association.ecocyc.csv"",      row.names = 1, stringsAsFactors = F)",import,719843501457944e8,349
"m.main = lmer(rRT ~ cContrast * cSpeaker * ItemOrder + (1 + cContrast |      Subject) + (1 + cSpeaker * cContrast | Audio), data = prepVars(d.ForAnalysis))",modeling,418617147719487e8,348
"myDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/media_all_genes_edited.csv"",      row.names = 1, stringsAsFactors = F)",import,719843501457944e8,349
summary(m.main),evaluation,418617147719487e8,348
FCok <- which(abs(myDat$log2FoldChange) > 2),exploratory,719843501457944e8,349
"df2 <- read.csv(""preprocessed-current-Exp2.csv"")",import,418617147719487e8,348
"targetRegionA <- subset(df2, df2$RelAdj >= 200 & df2$RelAdj <=      700)",exploratory,418617147719487e8,348
FDRok <- which(myDat$padj < 0.05),exploratory,719843501457944e8,349
"DE <- intersect(FDRok, FCok)",exploratory,719843501457944e8,349
emplog = function(x) {     log((sum(x) + 0.5)/(length(x) - sum(x) + 0.5)) },data cleaning,418617147719487e8,348
geneNam <- as.vector(myDat$Name),exploratory,719843501457944e8,349
DEgeneNam <- as.vector(myDat$Name[DE]),exploratory,719843501457944e8,349
geneNam2 <- geneNam[which(geneNam %in% goDat$Symbol)],exploratory,719843501457944e8,349
DEgeneNam2 <- DEgeneNam[which(DEgeneNam %in% goDat$Symbol)],exploratory,719843501457944e8,349
"goDat2 <- goDat[which(goDat$Symbol %in% geneNam2), ]",exploratory,719843501457944e8,349
"EcoliGenes <- rep(0, length(geneNam2))",exploratory,719843501457944e8,349
EcoliGenes[which(geneNam2 %in% DEgeneNam2)] <- 1,exploratory,719843501457944e8,349
names(EcoliGenes) <- geneNam2,exploratory,719843501457944e8,349
DEcoli <- names(EcoliGenes)[which(EcoliGenes == 1)],exploratory,719843501457944e8,349
"new.d <- ddply(targetRegionA, c(""Subject"", ""Trial"", ""Audio"",      ""Speaker"", ""Contrast""), summarise, count.all = length(TargetFix),      count.T = sum(TargetFix), fixprop.T = count.T/count.all,      emplogs.T = emplog(fixprop.T))",exploratory,418617147719487e8,348
FacGenes <- as.factor(EcoliGenes),exploratory,719843501457944e8,349
"goBP <- goDat2[which(goDat2$category == ""P""), ]",exploratory,719843501457944e8,349
"goMF <- goDat2[which(goDat2$category == ""F""), ]",exploratory,719843501457944e8,349
"goCC <- goDat2[which(goDat2$category == ""C""), ]",exploratory,719843501457944e8,349
BPterms <- unique(goBP$GO),not sure,719843501457944e8,349
MFterms <- unique(goMF$GO),not sure,719843501457944e8,349
CCterms <- unique(goCC$GO),not sure,719843501457944e8,349
BPlist <- list(),not sure,719843501457944e8,349
"prepVars = function(d) {     d$Reliability = factor(d$Speaker, levels = c(""reliable"",          ""unreliable_bottomUp"", ""unreliable_impairment""))     d$Contrast = factor(d$Contrast, levels = c(""One"", ""Two""))     contrasts(d$Reliability) = cbind(`Reliable vs. Unreliable` = c(1,          -0.5, -0.5), `Unreliable(bottom up) vs. Unreliable(Both)` = c(0,          1, -1))     contrasts(d$Contrast) = contr.sum(2)     d$cContrast = myC(ifelse(d$Contrast == ""One"", 1, 0))     return(d) }",data cleaning,418617147719487e8,348
for (ii in 1:length(BPterms)) {     term <- BPterms[ii]     genes <- unique(goBP$Symbol[which(goBP$GO == term)])     BPlist[[ii]] <- genes },communication,719843501457944e8,349
names(BPlist) <- BPterms,communication,719843501457944e8,349
MFlist <- list(),communication,719843501457944e8,349
for (ii in 1:length(MFterms)) {     term <- MFterms[ii]     genes <- unique(goMF$Symbol[which(goMF$GO == term)])     MFlist[[ii]] <- genes },communication,719843501457944e8,349
library(lmerTest),evaluation,418617147719487e8,348
"lm2 = lmer(emplogs.T ~ Reliability * cContrast + (1 + cContrast |      Subject) + (1 + Reliability + cContrast | Audio), data = prepVars(new.d))",modeling,418617147719487e8,348
summary(lm2),evaluation,418617147719487e8,348
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,807383231818676e8,351
"df2 <- read.csv(""preprocessed-current-Exp2_RT.csv"")",import,418617147719487e8,348
"df3 <- df2 %>% dplyr::group_by(Subject, Audio, Speaker, Contrast,      Trial, TrialType) %>% dplyr::summarise(meanRT = mean(ResponseTime))",evaluation,418617147719487e8,348
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,807383231818676e8,351
"library(""multiseq"")",import,807383231818676e8,351
"library(""ashr"")",import,807383231818676e8,351
"df4 <- subset(df3, df3$TrialType == ""critical"")",data cleaning,418617147719487e8,348
"ggplot(df4, aes(x = meanRT, color = Contrast)) + geom_histogram(binwidth = 0.5,      colour = ""black"", fill = ""white"") + facet_wrap(~Speaker)",visualization,418617147719487e8,348
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",import,807383231818676e8,351
"source(paste0(multiscale.analysis.repodir, ""/src/R/utils.R""))",setup,807383231818676e8,351
"source(paste0(multiscale.analysis.repodir, ""/src/R/my.utils.R""))",setup,807383231818676e8,351
"tapply(df4$meanRT, df4$Speaker, mean)",data cleaning,418617147719487e8,348
"WaveQTL.repodir <- scan("".WaveQTL.repodir.txt"", what = character())",import,807383231818676e8,351
"info.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/tmp/Copper.2048.both.msOnly.info""",setup,807383231818676e8,351
"tapply(df4$meanRT, df4$Speaker, sd)",modeling,418617147719487e8,348
library(lme4),setup,418617147719487e8,348
"m.resid = lmer(meanRT ~ Trial + (1 + Trial | Subject), data = df3)",modeling,418617147719487e8,348
summary(m.resid),evaluation,418617147719487e8,348
df3$rRT = residuals(m.resid),evaluation,418617147719487e8,348
"d.ForAnalysis <- df3 %>% dplyr::group_by(Subject) %>% filter(TrialType ==      ""critical"") %>% dplyr::mutate(ItemOrder = rank(Trial))",evaluation,418617147719487e8,348
"prepVars = function(d) {     d$Reliability = factor(d$Speaker, levels = c(""reliable"",          ""unreliable_bottomUp"", ""unreliable_impairment""))     d$Contrast = factor(d$Contrast, levels = c(""One"", ""Two""))     contrasts(d$Reliability) = cbind(`Reliable vs. Unreliable` = c(1,          -0.5, -0.5), `Unreliable(bottom up) vs. Unreliable(Both)` = c(0,          1, -1))     contrasts(d$Contrast) = contr.sum(2)     d$cContrast = myC(ifelse(d$Contrast == ""One"", 1, 0))     return(d) }",data cleaning,418617147719487e8,348
"m.main2 = lmer(rRT ~ cContrast * Reliability * ItemOrder + (1 +      cContrast | Subject) + (1 + Reliability * cContrast | Audio),      data = prepVars(d.ForAnalysis))",modeling,418617147719487e8,348
summary(m.main2),evaluation,418617147719487e8,348
library(caret),setup,490236657904461e8,352
library(doMC),setup,490236657904461e8,352
"ID <- ""V""",not sure,771710885455832e8,353
library(mmadsenr),setup,490236657904461e8,352
library(futile.logger),setup,490236657904461e8,352
library(dplyr),setup,490236657904461e8,352
library(ggthemes),setup,490236657904461e8,352
numIND = 10,setup,418617147719487e8,348
"case.name = c(paste0(""fullread."", numIND, ""ind""), paste0(""fullread."",      numIND, ""ind.over""), paste0(""fullread."", numIND, ""ind.over.2""))",import,418617147719487e8,348
"dataSource <- paste0(""Data/player_data_"", ID)",setup,771710885455832e8,353
"ROC.file.name = paste0(""ROC_over"", numIND, "".pdf"")",import,418617147719487e8,348
"hist.file.name = paste0(""hist_over"", numIND, "".pdf"")",import,418617147719487e8,348
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",data cleaning,490236657904461e8,352
"ms.null = vector(""list"", length(case.name))",setup,418617147719487e8,348
"ms.alt = vector(""list"", length(case.name))",setup,418617147719487e8,348
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""tasampled-classification.log"")",import,490236657904461e8,352
"dataDirectory <- paste0(""Data/gameplay_data_"", ID, ""/"")",import,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",      case.name[1], "".Robj""))",import,418617147719487e8,348
"flog.appender(appender.file(log_file), name = ""cl"")",import,490236657904461e8,352
pval.alt = as.numeric(pval_list),data cleaning,418617147719487e8,348
clargs <- commandArgs(trailingOnly = TRUE),setup,490236657904461e8,352
done.alt = done_res,not sure,418617147719487e8,348
"player_data <- read.table(paste0(dataSource, "".tsv""), sep = ""\t"")",import,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",      case.name[1], "".Robj""))",import,418617147719487e8,348
rm(list = ls()),setup,344981121597812e8,354
pval.null = as.numeric(pval_list),not sure,418617147719487e8,348
done.null = done_res,not sure,418617147719487e8,348
sum(done.alt),exploratory,418617147719487e8,348
"txt_files <- list.files(dataDirectory, pattern = ""txt"")",import,771710885455832e8,353
"source(""./R/helper/00_helper_lib_load.R"")",setup,344981121597812e8,354
sum(done.null),exploratory,418617147719487e8,348
"source(""./R/helper/00_helper_model_fcts.R"")",setup,344981121597812e8,354
min(pval.alt),exploratory,418617147719487e8,348
"source(""./R/helper/00_helper_simulation_data.R"")",setup,344981121597812e8,354
max(pval.alt),exploratory,418617147719487e8,348
min(pval.null),exploratory,418617147719487e8,348
max(pval.null),exploratory,418617147719487e8,348
"source(""./R/helper/99_helper_diagnostics.R"")",setup,344981121597812e8,354
"source(""./R/helper/01_helper_cBPF_as.R"")",setup,344981121597812e8,354
"source(""./R/helper/02_helper_pgas.R"")",setup,344981121597812e8,354
ms.null[[1]] = pval.null,not sure,418617147719487e8,348
"source(""./R/01_cBPF_as.R"")",setup,344981121597812e8,354
"source(""./R/02_pgas.R"")",setup,344981121597812e8,354
ms.alt[[1]] = pval.alt,not sure,418617147719487e8,348
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,418617147719487e8,348
init_at_true <- TRUE,setup,344981121597812e8,354
pval.alt = as.numeric(pval_list),not sure,418617147719487e8,348
done.alt = done_res,not sure,418617147719487e8,348
"png_files <- list.files(dataDirectory, pattern = ""png"")",exploratory,771710885455832e8,353
pgas_run <- TRUE,setup,344981121597812e8,354
set.seed(123),setup,344981121597812e8,354
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test.R"")",setup,344981121597812e8,354
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test_init.R"")",setup,344981121597812e8,354
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,418617147719487e8,348
pval.null = as.numeric(pval_list),not sure,418617147719487e8,348
file_index <- 8,not sure,771710885455832e8,353
"source(""boilerplate.R"")",import,944856182206422e8,355
done.null = done_res,not sure,418617147719487e8,348
sum(done.alt),exploratory,418617147719487e8,348
sum(done.null),exploratory,418617147719487e8,348
min(pval.alt),exploratory,418617147719487e8,348
max(pval.alt),exploratory,418617147719487e8,348
min(pval.null),exploratory,418617147719487e8,348
max(pval.null),exploratory,418617147719487e8,348
analysis.outcome <- data.frame(),not sure,944856182206422e8,355
"file_path <- paste0(dataDirectory, txt_files[file_index])",setup,771710885455832e8,353
ms.null[[2]] = pval.null,not sure,418617147719487e8,348
ms.alt[[2]] = pval.alt,not sure,418617147719487e8,348
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,418617147719487e8,348
"gpg_data <- read.table(file_path, sep = ""\t"", header = TRUE)",import,771710885455832e8,353
pval.alt = as.numeric(pval_list),not sure,418617147719487e8,348
done.alt = done_res,not sure,418617147719487e8,348
attach(gpg_data),import,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,418617147719487e8,348
n <- dim(gpg_data)[1],exploratory,771710885455832e8,353
pval.null = as.numeric(pval_list),not sure,418617147719487e8,348
done.null = done_res,not sure,418617147719487e8,348
secs <- (millis - millis[1])/1000,exploratory,771710885455832e8,353
sum(done.alt),exploratory,418617147719487e8,348
sum(done.null),exploratory,418617147719487e8,348
min(pval.alt),exploratory,418617147719487e8,348
max(pval.alt),exploratory,418617147719487e8,348
min(pval.null),exploratory,418617147719487e8,348
max(pval.null),exploratory,418617147719487e8,348
pause <- NULL,not sure,771710885455832e8,353
ms.null[[3]] = pval.null,exploratory,418617147719487e8,348
ms.alt[[3]] = pval.alt,not sure,418617147719487e8,348
"wave.null = vector(""list"", length(case.name))",not sure,418617147719487e8,348
"wave.alt = vector(""list"", length(case.name))",import,418617147719487e8,348
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/sum/pval."",      case.name[1], "".Robj""))",import,418617147719487e8,348
for (i in 1:n) pause[i] <- secs[i + 1] - secs[i],exploratory,771710885455832e8,353
pval.alt = as.numeric(pval_list),not sure,418617147719487e8,348
done.alt = done_res,not sure,418617147719487e8,348
gpg_pauses <- ts(pause),exploratory,771710885455832e8,353
"rm(list = c(""pause"", ""secs"", ""i""))",exploratory,771710885455832e8,353
leftJoyX <- abs(anlgX) > 0,data cleaning,771710885455832e8,353
leftJoyY <- abs(anlgY) > 0,data cleaning,771710885455832e8,353
rightJoyX <- abs(anlgU) > 0,data cleaning,771710885455832e8,353
rightJoyY <- abs(anlgV) > 0,data cleaning,771710885455832e8,353
leftJoy <- leftJoyX & leftJoyY,data cleaning,771710885455832e8,353
rightJoy <- rightJoyX & rightJoyY,data cleaning,771710885455832e8,353
"gpg_keypresses <- data.frame(index = 1:n, red = as.logical(A1),      green = as.logical(A2), blue = as.logical(A3), opacity = as.logical(A4),      dispersion = as.logical(L1), position = as.logical(R2), size = as.logical(R1),      random = as.logical(L2), reset = as.logical(S1), saveIMG = as.logical(S2),      up = as.logical(up), down = as.logical(down), left = as.logical(left),      right = as.logical(right), leftJoy = leftJoy, rightJoy = rightJoy)",exploratory,771710885455832e8,353
"keypress_transactions <- as(gpg_keypresses[, -1], ""transactions"")",not sure,771710885455832e8,353
require(lme4),setup,723471253179014e8,356
"gpg_joysticks <- data.frame(index = 1:n, anlgX, anlgY, anlgU,      anlgV)",exploratory,771710885455832e8,353
"source(system.file(""utils"", ""allFit.R"", package = ""lme4""))",setup,723471253179014e8,356
left_Q1 <- anlgX > 0 & anlgY > 0,exploratory,771710885455832e8,353
"source(""./analysis/nursery_experiment_inundation/functions/index.R"")",import,723471253179014e8,356
left_Q2 <- anlgX < 0 & anlgY > 0,exploratory,771710885455832e8,353
left_Q3 <- anlgX < 0 & anlgY < 0,modeling,771710885455832e8,353
"survival_data <- read.table(""./analysis/nursery_experiment_inundation/data/nursery_experiment_data.txt"",      header = TRUE)",import,723471253179014e8,356
left_Q4 <- anlgX > 0 & anlgY < 0,modeling,771710885455832e8,353
right_Q1 <- anlgU > 0 & anlgV > 0,modeling,771710885455832e8,353
right_Q2 <- anlgU < 0 & anlgV > 0,modeling,771710885455832e8,353
right_Q3 <- anlgU < 0 & anlgV < 0,modeling,771710885455832e8,353
right_Q4 <- anlgU > 0 & anlgV < 0,modeling,771710885455832e8,353
"surv_model <- glmer(surv ~ sp + treat + dia + sp:treat + (1 |      mother) + (1 | block), data = survival_data, family = ""binomial"",      control = glmerControl(optimizer = ""nlminbw""))",data cleaning,723471253179014e8,356
"gpg_quadrants <- data.frame(index = 1:n, left_Q1, left_Q2, left_Q3,      left_Q4, right_Q1, right_Q2, right_Q3, right_Q4)",modeling,771710885455832e8,353
"quadrant_transactions <- as(gpg_quadrants[, -1], ""transactions"")",not sure,771710885455832e8,353
"surv_model2 <- update(surv_model, . ~ . - sp:treat)",modeling,723471253179014e8,356
"gpg_values <- data.frame(index = 1:n, red_val = red, green_val = green,      blue_val = blue, opacity_val = opacity, focalPointX_val = x_mean,      focalPointY_val = y_mean, dispersionX_val = dpX, dispersionY_val = dpY,      positionX_val = xpos, positionY_val = ypos, verticalDiameter_val = sX,      horizontalDiameter_val = sY)",modeling,771710885455832e8,353
"anova(surv_model, surv_model2)",evaluation,723471253179014e8,356
"rm(list = c(""leftJoy"", ""rightJoy"", ""leftJoyX"", ""leftJoyY"", ""rightJoyX"",      ""rightJoyY"", ""left_Q4"", ""left_Q3"", ""left_Q2"", ""left_Q1"",      ""right_Q4"", ""right_Q3"", ""right_Q2"", ""right_Q1""))",setup,771710885455832e8,353
detach(gpg_data),setup,771710885455832e8,353
library(pecanapi),setup,409245651448145e8,357
"surv_model1_residuals <- resid(surv_model, type = ""pearson"")",evaluation,723471253179014e8,356
library(tidyverse),data cleaning,409245651448145e8,357
surv_model1_fitted <- fitted(surv_model),evaluation,723471253179014e8,356
"ID <- ""V""",setup,771710885455832e8,353
"newbinplot(surv_model1_fitted, surv_model1_residuals)",visualization,723471253179014e8,356
"TCCZe <- readRDS(""./geo_data/processed/TCCZ_wtoppick.rdata"")",import,771710885455832e8,353
"wl <- readRDS(""./srs_data/processed/wl.rdata"")",import,771710885455832e8,353
"wlavg <- readRDS(""./srs_data/processed/wlavg.rdata"")",import,771710885455832e8,353
"wlp1988 <- wl[wl$MYEAR > 1987, ]",import,771710885455832e8,353
"wll2 <- split(wlp1988, wlp1988$MYEAR)",import,771710885455832e8,353
"source(""./analysis/raw_scripts/create_subsurface_parameters_vars.R"")",import,771710885455832e8,353
alphaloess1 <- 0.25,import,771710885455832e8,353
alphaloess2 <- 0.15,exploratory,771710885455832e8,353
"ranNorm(""mother"", slope = 1, model = surv_model)",modeling,723471253179014e8,356
alphaloesswl <- 0.25,not sure,771710885455832e8,353
"TCCZ.loess1 <- loess(TCCZ_top ~ EASTING + NORTHING, data = TCCZe,      degree = 2, span = alphaloess1, normalize = FALSE, method = c(""loess""),      control = lcontrol)",modeling,771710885455832e8,353
"ranNorm(""block"", slope = 1, model = surv_model)",modeling,723471253179014e8,356
"TCCZ.loess1b <- loess(TCCZ_top ~ EASTING + NORTHING, data = TCCZe,      degree = 2, span = alphaloess2, normalize = FALSE, method = c(""loess""),      control = lcontrol)",modeling,771710885455832e8,353
"TCCZ.lm <- lm(TCCZ_top ~ EASTING + NORTHING, data = TCCZe)",modeling,771710885455832e8,353
coef <- fixef(surv_model),modeling,723471253179014e8,356
"pre1 <- predict(TCCZ.loess1, se = TRUE)",modeling,771710885455832e8,353
"pre1b <- predict(TCCZ.loess1b, se = TRUE)",modeling,771710885455832e8,353
"pre1lm <- predict(TCCZ.lm, se = TRUE, interval = ""confidence"",      level = 0.95)",modeling,771710885455832e8,353
TCCZ.pred <- TCCZe,modeling,771710885455832e8,353
"slope_coef <- data.frame(sp = levels(survival_data$sp), p = c(coef[11],      coef[11] + coef[13:length(coef)]))",modeling,723471253179014e8,356
TCCZ.pred$TCCZ.fit <- pre1$fit,modeling,771710885455832e8,353
TCCZ.pred$TCCZ.se.fit <- pre1$se.fit,modeling,771710885455832e8,353
TCCZ.pred$TCCZ.fitb <- pre1b$fit,modeling,771710885455832e8,353
"write.table(slope_coef, file = ""analysis/nursery_experiment_inundation/data/survival_slope_coef.txt"")",export,723471253179014e8,356
TCCZ.pred$TCCZ.se.fitb <- pre1b$se.fit,modeling,771710885455832e8,353
"TCCZ.pred$TCCZ.fitlm <- pre1lm$fit[, 1]",modeling,771710885455832e8,353
TCCZ.pred$TCCZ.se.fitlm <- pre1lm$se.fit,modeling,771710885455832e8,353
"TCCZ.pred$TCCZ.fitlmupr <- pre1lm$fit[, 2]",modeling,771710885455832e8,353
"TCCZ.pred$TCCZ.fitlmlwr <- pre1lm$fit[, 3]",modeling,771710885455832e8,353
TCCZ.pred$ehat.l1 <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fit,evaluation,771710885455832e8,353
library(plyr),setup,723471253179014e8,356
TCCZ.pred$ehat.l1b <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fitb,modeling,771710885455832e8,353
TCCZ.pred$ehat.lm <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fitlm,modeling,771710885455832e8,353
"saveRDS(TCCZ.pred, ""./analysis/processed_data/TCCZloesspred.rdata"")",export,771710885455832e8,353
"data <- read.table(""Analysis/Data/ZillowDataSetX"", sep = "","",      stringsAsFactors = FALSE)",import,723471253179014e8,356
thperyear <- wl,not sure,771710885455832e8,353
"source(""Analysis/Data/ZillowAPICalls.R"")",import,723471253179014e8,356
"pre2 <- predict(TCCZ.loess1, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE)",modeling,771710885455832e8,353
"pre2b <- predict(TCCZ.loess1b, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE)",modeling,771710885455832e8,353
data$MergingCode <- data21$ZipCode,data cleaning,723471253179014e8,356
"pre2lm <- predict(TCCZ.lm, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE, interval = ""prediction"", level = 0.95)",modeling,771710885455832e8,353
thperyear$TCCZ.fit <- pre2$fit,modeling,771710885455832e8,353
thperyear$TCCZ.se.fit <- pre2$se.fit,modeling,771710885455832e8,353
thperyear$TCCZ.fitb <- pre2b$fit,modeling,771710885455832e8,353
thperyear$TCCZ.se.fitb <- pre2b$se.fit,modeling,771710885455832e8,353
"thperyear$TCCZ.fitlm <- pre2lm$fit[, 1]",modeling,771710885455832e8,353
thperyear$TCCZ.se.fitlm <- pre2lm$se.fit,modeling,771710885455832e8,353
"a <- ddply(data, ~MergingCode, summarise, MeanZestimateAmount = mean(ZestimateAmount,      na.rm = TRUE), MeanZestimateLowValueRange = mean(ZestimateAmount,      na.rm = TRUE) - (mean(ZestimateHighValueRange, na.rm = TRUE) -      mean(ZestimateAmount, na.rm = TRUE)), MeanZestimateHighValueRange = mean(ZestimateHighValueRange,      na.rm = TRUE), MeanRZestimateAmount = mean(RZestimateAmount,      na.rm = TRUE), MeanRZestimateLowValueRange = mean(RZestimateLowValueRange,      na.rm = TRUE), MeanRZestimateHighValueRange = mean(RZestimateHighValueRange,      na.rm = TRUE), Count = length(zpid))",data cleaning,723471253179014e8,356
"thperyear$TCCZ.fitlmupr <- pre2lm$fit[, 2]",modeling,771710885455832e8,353
"thperyear$TCCZ.fitlmlwr <- pre2lm$fit[, 3]",modeling,771710885455832e8,353
"data <- merge(data, a, by = ""MergingCode"")",data cleaning,723471253179014e8,356
"thperyear[thperyear$TCCZ.fitb < 0, c(""STATION_ID"", ""EASTING"",      ""NORTHING"", ""mean"", ""TCCZ.fit"", ""TCCZ.fitb"", ""TCCZ.fitlm"")]",modeling,771710885455832e8,353
"thperyear[thperyear$TCCZ.se.fitb > 200, ]",data cleaning,771710885455832e8,353
thperyear$h <- thperyear$mean - thperyear$TCCZ.fit,data cleaning,771710885455832e8,353
thperyear$hb <- thperyear$mean - thperyear$TCCZ.fitb,data cleaning,771710885455832e8,353
thperyear$hlm <- thperyear$mean - thperyear$TCCZ.fitlm,data cleaning,771710885455832e8,353
"thperyear$hse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fit^2)",data cleaning,771710885455832e8,353
"thperyear$hbse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fitb^2)",data cleaning,771710885455832e8,353
"thperyear$hlmse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fitlm^2)",data cleaning,771710885455832e8,353
summary(thperyear),evaluation,771710885455832e8,353
"data[data$ResponseCode == ""508"" | is.na(data$zpid) == TRUE |      data$AddressZipCode == 999, c(""ZestimateAmount"", ""ZestimateLowValueRange"",      ""ZestimateHighValueRange"", ""RZestimateAmount"", ""RZestimateLowValueRange"",      ""RZestimateHighValueRange"")] <- data[data$ResponseCode ==      ""508"" | is.na(data$zpid) == TRUE | data$AddressZipCode ==      999, c(""MeanZestimateAmount"", ""MeanZestimateLowValueRange"",      ""MeanZestimateHighValueRange"", ""MeanRZestimateAmount"", ""MeanRZestimateLowValueRange"",      ""MeanRZestimateHighValueRange"")]",data cleaning,723471253179014e8,356
thperyear$h[thperyear$h <= 0] <- NA,evaluation,771710885455832e8,353
"data <- subset(data, select = -c(MergingCode, MeanZestimateAmount,      MeanZestimateLowValueRange, MeanZestimateHighValueRange,      MeanRZestimateAmount, MeanRZestimateLowValueRange, MeanRZestimateHighValueRange,      Count))",data cleaning,723471253179014e8,356
thperyear$hb[thperyear$hb <= 0] <- NA,evaluation,771710885455832e8,353
thperyear$hlm[thperyear$hlm <= 0] <- NA,evaluation,771710885455832e8,353
"thperyear.cleanh <- thperyear[!is.na(thperyear$h), ]",data cleaning,771710885455832e8,353
"write.table(data, file = ""Analysis/Data/ZillowDataSetX"", sep = "","")",export,723471253179014e8,356
"thperyear.cleanhb <- thperyear[!is.na(thperyear$hb), ]",data cleaning,771710885455832e8,353
"thperyear.cleanhlm <- thperyear[!is.na(thperyear$hlm), ]",data cleaning,771710885455832e8,353
thperyear.cleanh$hserel <- thperyear.cleanh$hse/thperyear.cleanh$h,evaluation,771710885455832e8,353
thperyear.cleanhb$hbserel <- thperyear.cleanhb$hbse/thperyear.cleanhb$hb,evaluation,771710885455832e8,353
thperyear.cleanhlm$hlmserel <- thperyear.cleanhlm$hlmse/thperyear.cleanhlm$hlm,evaluation,771710885455832e8,353
"th.avg.peryearh <- ddply(thperyear.cleanh, c(""MYEAR""), function(x) c(counth = nrow(x),      h.mean = mean(x$h), h.median = median(x$h), h.sd = sd(x$h),      h.mad = mad(x$h), h.min = min(x$h), h.max = max(x$h)))",modeling,771710885455832e8,353
"th.avg.peryearhb <- ddply(thperyear.cleanhb, c(""MYEAR""), function(x) c(counthb = nrow(x),      hb.mean = mean(x$hb), hb.median = median(x$hb), hb.sd = sd(x$hb),      hb.mad = mad(x$hb), hb.min = min(x$hb), hb.max = max(x$hb)))",modeling,771710885455832e8,353
"th.avg.peryearhlm <- ddply(thperyear.cleanhlm, c(""MYEAR""), function(x) c(counthlm = nrow(x),      hlm.mean = mean(x$hlm), hlm.median = median(x$hlm), hlm.sd = sd(x$hlm),      hlm.mad = mad(x$hlm), hlm.min = min(x$hlm), hlm.max = max(x$hlm)))",modeling,771710885455832e8,353
"pre3 <- predict(TCCZ.loess1, newdata = interpolation.grid, se = TRUE)",modeling,771710885455832e8,353
"pre3b <- predict(TCCZ.loess1b, newdata = interpolation.grid,      se = TRUE)",modeling,771710885455832e8,353
"pre3lm <- predict(TCCZ.lm, newdata = interpolation.grid, se = TRUE,      interval = ""prediction"", level = 0.95)",modeling,771710885455832e8,353
thicknessUAZ <- interpolation.grid,modeling,771710885455832e8,353
"DistrictData$Foundations_cat <- cut(DistrictData$FoundationsTotal,      breaks = c(0, 15, 26, 44, 1194), labels = c(""1stQu"", ""2ndQu"",          ""3rdQu"", ""4thQu""))",data cleaning,723471253179014e8,356
dim(pre3$fit),evaluation,771710885455832e8,353
"names(DistrictData)[names(DistrictData) == ""murderAndManslaughter""] <- ""Murder""",data cleaning,723471253179014e8,356
thicknessUAZ$TCCZfit <- as.vector(pre3$fit),evaluation,771710885455832e8,353
thicknessUAZ$TCCZfitb <- as.vector(pre3b$fit),evaluation,771710885455832e8,353
"thicknessUAZ$TCCZfitlm <- as.vector(pre3lm$fit[, 1])",evaluation,771710885455832e8,353
thicknessUAZ$TCCZsefit <- as.vector(pre3$se.fit),evaluation,771710885455832e8,353
DistrictData$TotalPopulation <- DistrictData$TotalPopulation/1e+05,data cleaning,723471253179014e8,356
thicknessUAZ$TCCZsefitb <- as.vector(pre3b$se.fit),evaluation,771710885455832e8,353
DistrictData <- na.omit(DistrictData),data cleaning,723471253179014e8,356
summary(DistrictData$FoundationsDensity100k),exploratory,723471253179014e8,356
summary(DistrictData$FlowPercentage),exploratory,723471253179014e8,356
summary(DistrictData$TurnoutPercentage),exploratory,723471253179014e8,356
summary(DistrictData$ForeignerPercentage),exploratory,723471253179014e8,356
summary(DistrictData$MarriagePercentage),exploratory,723471253179014e8,356
summary(DistrictData$MalePercentage),exploratory,723471253179014e8,356
summary(DistrictData$YouthPercentage),exploratory,723471253179014e8,356
summary(DistrictData$UnemployedPercentage),exploratory,723471253179014e8,356
summary(DistrictData$TotalPopulation),exploratory,723471253179014e8,356
summary(DistrictData$EastWest),exploratory,723471253179014e8,356
"histMurder <- ggplot(DistrictData, aes(MurderRate)) + geom_histogram(binwidth = 1,      colour = ""black"", fill = ""white"")",visualization,723471253179014e8,356
"OLSNonViolent <- lm(NonViolentCrimeRate ~ FoundationsDensity100k +      FlowPercentage + TurnoutPercentage + ForeignerPercentage +      MarriagePercentage + MalePercentage + YouthPercentage + UnemployedPercentage +      EastWest, data = DistrictData)",modeling,723471253179014e8,356
summary(OLSNonViolent),exploratory,723471253179014e8,356
"OLSViolent <- lm(ViolentCrimeRate ~ FoundationsDensity100k +      FlowPercentage + TurnoutPercentage + ForeignerPercentage +      MarriagePercentage + MalePercentage + YouthPercentage + UnemployedPercentage +      EastWest, data = DistrictData)",modeling,723471253179014e8,356
summary(OLSViolent),exploratory,723471253179014e8,356
"OLSMurderRate <- lm(MurderRate ~ FoundationsDensity100k + FlowPercentage +      TurnoutPercentage + ForeignerPercentage + MarriagePercentage +      MalePercentage + YouthPercentage + UnemployedPercentage +      EastWest, data = DistrictData)",modeling,723471253179014e8,356
summary(OLSMurderRate),exploratory,723471253179014e8,356
thicknessUAZ$TCCZsefitlm <- as.vector(pre3lm$se.fit),evaluation,771710885455832e8,353
"OLSMurder <- lm(Murder ~ FoundationsDensity100k + FlowPercentage +      TurnoutPercentage + ForeignerPercentage + MarriagePercentage +      MalePercentage + YouthPercentage + UnemployedPercentage +      TotalPopulation + EastWest, data = DistrictData)",modeling,723471253179014e8,356
ov <- dim(thicknessUAZ)[2],evaluation,771710885455832e8,353
nbparamUAZ <- 4,evaluation,771710885455832e8,353
summary(OLSMurder),exploratory,723471253179014e8,356
"nbnegthickvals <- vector(mode = ""integer"", length = length(wll2))",evaluation,771710885455832e8,353
DistrictData$district <- as.factor(DistrictData$district),data cleaning,723471253179014e8,356
"nbNAthickvals <- vector(mode = ""integer"", length = length(wll2))",evaluation,771710885455832e8,353
DistrictData$Murder <- as.integer(DistrictData$Murder),data cleaning,723471253179014e8,356
DistrictData$EastWest <- as.integer(DistrictData$EastWest),data cleaning,723471253179014e8,356
"for (kk in 1:length(wll2)) {     w.loess <- loess(mean ~ EASTING + NORTHING, data = wll2[[kk]],          degree = 1, span = alphaloesswl)     predw <- predict(w.loess, newdata = interpolation.grid, se = TRUE)     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 1] <- as.vector(predw$fit)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 1] <- paste0(""wl"",          names(wll2)[kk])     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 2] <- as.vector(predw$se.fit)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 2] <- paste0(""se.wl"",          names(wll2)[kk])     thickness <- as.vector(predw$fit) - thicknessUAZ$TCCZfitb     nbnegthickvals[kk] <- sum(thickness < 0, na.rm = TRUE)     thickness[thickness < 0] <- NA     nbNAthickvals[kk] <- sum(is.na(thickness))     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 3] <- thickness     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 3] <- paste0(""e"",          names(wll2)[kk])     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 4] <- sqrt(thicknessUAZ[nbparamUAZ *          (kk - 1) + ov + 2]^2 + thicknessUAZ$TCCZsefitb^2)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 4] <- paste0(""se.e"",          names(wll2)[kk]) }",modeling,771710885455832e8,353
"poisson.glm1 <- glm(Murder ~ FoundationsDensity100k + FlowPercentage +      TurnoutPercentage + ForeignerPercentage + MarriagePercentage +      MalePercentage + YouthPercentage + UnemployedPercentage +      TotalPopulation + EastWest, data = DistrictData, family = poisson())",modeling,723471253179014e8,356
disp.test <- dispersiontest(poisson.glm1),modeling,723471253179014e8,356
interpolation.gridC <- interpolation.grid,modeling,771710885455832e8,353
thicknessLAZ <- interpolation.gridC,modeling,771710885455832e8,353
disp.test.z <- disp.test[1],data cleaning,723471253179014e8,356
thicknessLAZ$e.in.m <- Cth,modeling,771710885455832e8,353
disp.test.z <- as.numeric(disp.test.z),data cleaning,723471253179014e8,356
disp.test.p <- disp.test[2],data cleaning,723471253179014e8,356
disp.test.p <- as.numeric(disp.test.p),data cleaning,723471253179014e8,356
disp.test.est <- disp.test[3],data cleaning,723471253179014e8,356
disp.test.est <- as.numeric(disp.test.est),data cleaning,723471253179014e8,356
rm(interpolation.gridC),setup,771710885455832e8,353
summary(poisson.glm1),exploratory,723471253179014e8,356
"thickness.regression.diagnostics <- as.data.frame(cbind(nbnegthickvals,      nbNAthickvals))",exploratory,771710885455832e8,353
"saveRDS(thicknessUAZ, file = ""./analysis/processed_data/thicknessUAZ.rdata"")",export,771710885455832e8,353
"saveRDS(thicknessLAZ, file = ""./analysis/processed_data/thicknessLAZ.rdata"")",export,771710885455832e8,353
"poisson.est1 <- cbind(Estimate = coef(poisson.glm1), confint(poisson.glm1))",data cleaning,723471253179014e8,356
"saveRDS(thickness.regression.diagnostics, file = ""./analysis/processed_data/diagnostics/thickness.regression.diagnostics.rdata"")",export,771710885455832e8,353
incidentrate1 <- exp(poisson.est1),data cleaning,723471253179014e8,356
"quasipoisson.glm1 <- glm(Murder ~ FoundationsDensity100k + FlowPercentage +      TurnoutPercentage + ForeignerPercentage + MarriagePercentage +      MalePercentage + YouthPercentage + UnemployedPercentage +      TotalPopulation + EastWest, data = DistrictData, family = quasipoisson())",modeling,723471253179014e8,356
"est.qpoisson <- cbind(Estimate = coef(quasipoisson.glm1), confint(quasipoisson.glm1))",data cleaning,723471253179014e8,356
"Make.trim.mofo <- function(fn) {     stopifnot(file.exists(fn))     df <- read.csv(fn)     df$db.session <- substr(fn, 1:5)     df$db.participant.id <- substr(fn, 7:10)     drops <- c(""iSess"", """")     df <- df[, 2] }",setup,771710885455832e8,353
incidentrate.qpoisson <- exp(est.qpoisson),data cleaning,723471253179014e8,356
"fl <- list.files(""analysis/data/csv-bysession"", pattern = ""\\.csv$"",      full.names = TRUE)",setup,771710885455832e8,353
"if (is.null(fl)) {     stop(""No files in file list."") }",setup,771710885455832e8,353
"nb.glm1 <- glm.nb(Murder ~ FoundationsDensity100k + FlowPercentage +      TurnoutPercentage + ForeignerPercentage + MarriagePercentage +      MalePercentage + YouthPercentage + UnemployedPercentage +      TotalPopulation + EastWest, data = DistrictData)",modeling,723471253179014e8,356
"dfl <- lapply(fl, Make.trim.mofo)",setup,771710885455832e8,353
summary(nb.glm1),exploratory,723471253179014e8,356
"merged <- Reduce(f = function(x, y) merge(x, y, all = TRUE),      dfl)",setup,771710885455832e8,353
"source(""Analysis/SupportAnalysis/IncidentRates.R"")",import,723471253179014e8,356
"write.csv(merged, file = ""analysis/data/csv-aggregate/child-mofo-all.csv"",      row.names = FALSE)",export,771710885455832e8,353
"source(""Analysis/SupportAnalysis/PredictedProbabilities.R"")",import,723471253179014e8,356
library(ROntoTools),setup,771710885455832e8,353
"CV.glm <- cv.glm(data = DistrictData, glmfit = nb.glm1, K = 4)",modeling,723471253179014e8,356
CV.glm <- c(CV.glm$delta),modeling,723471253179014e8,356
"kpg <- keggPathwayGraphs(""eco"", relPercThresh = 0, updateCache = TRUE,      verbose = TRUE)",import,771710885455832e8,353
"kpg <- setEdgeWeights(kpg, edgeTypeAttr = ""subtype"", edgeWeightByType = list(activation = 1,      inhibition = -1, expression = 1, repression = -1), defaultWeight = 0)",exploratory,771710885455832e8,353
"core <- read.csv(""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/best_strains_DEseq.csv"",      header = TRUE)",import,771710885455832e8,353
"colnames(core)[1] <- ""bnum""",setup,771710885455832e8,353
"core <- core[complete.cases(core), ]",setup,771710885455832e8,353
"kpn <- keggPathwayNames(""eco"")",setup,771710885455832e8,353
fc <- core$log2FoldChange[core$padj <= 0.01],setup,771710885455832e8,353
"names(fc) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",setup,771710885455832e8,353
pv <- core$padj[core$padj <= 0.01],setup,771710885455832e8,353
"names(pv) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",setup,771710885455832e8,353
"kpg <- setNodeWeights(kpg, weights = alphaMLG(pv), defaultWeight = 1)",exploratory,771710885455832e8,353
"ref <- paste0(""eco:"", core$bnum)",exploratory,771710885455832e8,353
"peRes <- pe(x = fc, graphs = kpg, ref = ref, nboot = 200, verbose = TRUE)",exploratory,771710885455832e8,353
"s <- Summary(peRes, pathNames = kpn, totalAcc = FALSE, totalPert = FALSE,      pAcc = FALSE, order.by = ""pPert"")",exploratory,771710885455832e8,353
"p <- peRes@pathways[[""path:eco00650""]]",exploratory,771710885455832e8,353
"g <- layoutGraph(p@map, layoutType = ""dot"")",evaluation,771710885455832e8,353
graphRenderInfo(g) <- list(fixedsize = FALSE),evaluation,771710885455832e8,353
edgeRenderInfo(g) <- peEdgeRenderInfo(p),evaluation,771710885455832e8,353
nodeRenderInfo(g) <- peNodeRenderInfo(p),evaluation,771710885455832e8,353
renderGraph(g),evaluation,771710885455832e8,353
"library(""topGO"")",setup,771710885455832e8,353
"library(""org.EcK12.eg.db"")",setup,771710885455832e8,353
"results <- ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/""",import,771710885455832e8,353
"goDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/gene_association.ecocyc.csv"",      row.names = 1, stringsAsFactors = F)",import,771710885455832e8,353
"myDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/media_all_genes_edited.csv"",      row.names = 1, stringsAsFactors = F)",import,771710885455832e8,353
FCok <- which(abs(myDat$log2FoldChange) > 2),exploratory,771710885455832e8,353
FDRok <- which(myDat$padj < 0.05),exploratory,771710885455832e8,353
"DE <- intersect(FDRok, FCok)",exploratory,771710885455832e8,353
geneNam <- as.vector(myDat$Name),exploratory,771710885455832e8,353
DEgeneNam <- as.vector(myDat$Name[DE]),data cleaning,771710885455832e8,353
geneNam2 <- geneNam[which(geneNam %in% goDat$Symbol)],data cleaning,771710885455832e8,353
DEgeneNam2 <- DEgeneNam[which(DEgeneNam %in% goDat$Symbol)],data cleaning,771710885455832e8,353
"goDat2 <- goDat[which(goDat$Symbol %in% geneNam2), ]",data cleaning,771710885455832e8,353
"EcoliGenes <- rep(0, length(geneNam2))",data cleaning,771710885455832e8,353
EcoliGenes[which(geneNam2 %in% DEgeneNam2)] <- 1,data cleaning,771710885455832e8,353
names(EcoliGenes) <- geneNam2,data cleaning,771710885455832e8,353
DEcoli <- names(EcoliGenes)[which(EcoliGenes == 1)],data cleaning,771710885455832e8,353
FacGenes <- as.factor(EcoliGenes),data cleaning,771710885455832e8,353
"goBP <- goDat2[which(goDat2$category == ""P""), ]",data cleaning,771710885455832e8,353
"goMF <- goDat2[which(goDat2$category == ""F""), ]",data cleaning,771710885455832e8,353
"goCC <- goDat2[which(goDat2$category == ""C""), ]",data cleaning,771710885455832e8,353
BPterms <- unique(goBP$GO),data cleaning,771710885455832e8,353
MFterms <- unique(goMF$GO),data cleaning,771710885455832e8,353
CCterms <- unique(goCC$GO),data cleaning,771710885455832e8,353
BPlist <- list(),data cleaning,771710885455832e8,353
for (ii in 1:length(BPterms)) {     term <- BPterms[ii]     genes <- unique(goBP$Symbol[which(goBP$GO == term)])     BPlist[[ii]] <- genes },data cleaning,771710885455832e8,353
names(BPlist) <- BPterms,setup,771710885455832e8,353
MFlist <- list(),setup,771710885455832e8,353
for (ii in 1:length(MFterms)) {     term <- MFterms[ii]     genes <- unique(goMF$Symbol[which(goMF$GO == term)])     MFlist[[ii]] <- genes },data cleaning,771710885455832e8,353
"ms.null = vector(""list"", length(case.name))",setup,497074061306193e8,358
names(MFlist) <- MFterms,data cleaning,771710885455832e8,353
CClist <- list(),data cleaning,771710885455832e8,353
for (ii in 1:length(CCterms)) {     term <- CCterms[ii]     genes <- unique(goCC$Symbol[which(goCC$GO == term)])     CClist[[ii]] <- genes },data cleaning,771710885455832e8,353
"ms.alt = vector(""list"", length(case.name))",setup,497074061306193e8,358
names(CClist) <- CCterms,data cleaning,771710885455832e8,353
"topBP <- new(""topGOdata"", description = ""Ecoli BP"", ontology = ""BP"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = BPlist)",data cleaning,771710885455832e8,353
"topMF <- new(""topGOdata"", description = ""Ecoli MF"", ontology = ""MF"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = MFlist)",data cleaning,771710885455832e8,353
"topCC <- new(""topGOdata"", description = ""Ecoli CC"", ontology = ""CC"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = CClist)",data cleaning,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,497074061306193e8,358
BP.genes <- genesInTerm(topBP),data cleaning,771710885455832e8,353
logLR.alt = as.numeric(logLR_list),import,497074061306193e8,358
MF.genes <- genesInTerm(topMF),visualization,771710885455832e8,353
CC.genes <- genesInTerm(topCC),visualization,771710885455832e8,353
done.alt = done_res,exploratory,497074061306193e8,358
"BP.Fisher.elim <- runTest(topBP, algorithm = ""elim"", statistic = ""fisher"")",visualization,771710885455832e8,353
"BP.Fisher.elim.Table <- GenTable(topBP, elimFisher = BP.Fisher.elim,      topNodes = 1000)",visualization,771710885455832e8,353
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[which(BP.Fisher.elim.Table$elimFisher <      0.05), ]",evaluation,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,497074061306193e8,358
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(BP.Fisher.elim.Table) %in%      c(""Term""))]",evaluation,771710885455832e8,353
logLR.null = as.numeric(logLR_list),data cleaning,497074061306193e8,358
"if (nrow(BP.Fisher.elim.Table) > 0) {     goIDs <- BP.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(BP.genes[[which(names(BP.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(BP.genes[[which(names(BP.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(BP.Fisher.elim.Table, aDF)     write.csv(bDF, file = paste0(results, ""media_pathway_analysis_BP.csv"")) }",evaluation,771710885455832e8,353
done.null = done_res,exploratory,497074061306193e8,358
"MF.Fisher.elim <- runTest(topMF, algorithm = ""elim"", statistic = ""fisher"")",evaluation,771710885455832e8,353
"MF.Fisher.elim.Table <- GenTable(topMF, elimFisher = MF.Fisher.elim,      topNodes = 1000)",evaluation,771710885455832e8,353
sum(done.alt),evaluation,497074061306193e8,358
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[which(MF.Fisher.elim.Table$elimFisher <      0.05), ]",evaluation,771710885455832e8,353
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[, !(names(MF.Fisher.elim.Table) %in%      c(""Term""))]",evaluation,771710885455832e8,353
sum(done.null),evaluation,497074061306193e8,358
min(logLR.alt),exploratory,497074061306193e8,358
max(logLR.alt),exploratory,497074061306193e8,358
min(logLR.null),exploratory,497074061306193e8,358
max(logLR.null),exploratory,497074061306193e8,358
ms.null[[1]] = logLR.null,data cleaning,497074061306193e8,358
ms.alt[[1]] = logLR.alt,data cleaning,497074061306193e8,358
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,497074061306193e8,358
logLR.alt = as.numeric(logLR_list),data cleaning,497074061306193e8,358
done.alt = done_res,evaluation,497074061306193e8,358
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,497074061306193e8,358
logLR.null = as.numeric(logLR_list),data cleaning,497074061306193e8,358
done.null = done_res,evaluation,497074061306193e8,358
sum(done.alt),exploratory,497074061306193e8,358
sum(done.null),exploratory,497074061306193e8,358
min(logLR.alt),exploratory,497074061306193e8,358
max(logLR.alt),exploratory,497074061306193e8,358
min(logLR.null),exploratory,497074061306193e8,358
max(logLR.null),exploratory,497074061306193e8,358
ms.null[[2]] = logLR.null,evaluation,497074061306193e8,358
ms.alt[[2]] = logLR.alt,evaluation,497074061306193e8,358
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,497074061306193e8,358
logLR.alt = as.numeric(logLR_list),data cleaning,497074061306193e8,358
done.alt = done_res,evaluation,497074061306193e8,358
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,497074061306193e8,358
logLR.null = as.numeric(logLR_list),evaluation,497074061306193e8,358
done.null = done_res,evaluation,497074061306193e8,358
sum(done.alt),exploratory,497074061306193e8,358
sum(done.null),exploratory,497074061306193e8,358
min(logLR.alt),exploratory,497074061306193e8,358
max(logLR.alt),exploratory,497074061306193e8,358
min(logLR.null),exploratory,497074061306193e8,358
"if (nrow(MF.Fisher.elim.Table) > 0) {     goIDs <- MF.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(MF.genes[[which(names(MF.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(MF.genes[[which(names(MF.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(MF.Fisher.elim.Table, aDF)     write.csv(bDF, paste0(results, ""media_pathway_analysis_MF.csv"")) }",data cleaning,771710885455832e8,353
max(logLR.null),exploratory,497074061306193e8,358
ms.null[[3]] = logLR.null,evaluation,497074061306193e8,358
"CC.Fisher.elim <- runTest(topCC, algorithm = ""elim"", statistic = ""fisher"")",data cleaning,771710885455832e8,353
"CC.Fisher.elim.Table <- GenTable(topCC, elimFisher = CC.Fisher.elim,      topNodes = 200)",data cleaning,771710885455832e8,353
"CC.Fisher.elim.Table <- CC.Fisher.elim.Table[which(CC.Fisher.elim.Table$elimFisher <      0.05), ]",data cleaning,771710885455832e8,353
library(scater),setup,665794803993776e8,359
ms.alt[[3]] = logLR.alt,evaluation,497074061306193e8,358
"CC.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(CC.Fisher.elim.Table) %in%      c(""Term""))]",data cleaning,771710885455832e8,353
library(tidyverse),setup,665794803993776e8,359
"if (nrow(CC.Fisher.elim.Table) > 0) {     goIDs <- CC.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(CC.genes[[which(names(CC.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(CC.genes[[which(names(CC.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(CC.Fisher.elim.Table, aDF)     write.csv(bDF, paste0(results, ""media_pathway_analysis_CC.csv"")) }",data cleaning,771710885455832e8,353
library(magrittr),setup,665794803993776e8,359
library(RTCGA.clinical),setup,665794803993776e8,359
"wave.null = vector(""list"", length(case.name))",setup,497074061306193e8,358
"wave.alt = vector(""list"", length(case.name))",setup,497074061306193e8,358
"data(""OV.clinical"")",import,665794803993776e8,359
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[1], "".Robj""))",import,497074061306193e8,358
"ov <- read_tsv(""../data/TCGA_OV_tpm.tsv.gz"")",import,665794803993776e8,359
library(car),setup,771710885455832e8,353
logLR.alt = as.numeric(logLR_list),data cleaning,497074061306193e8,358
sample_names <- names(ov)[-1],import,665794803993776e8,359
library(lattice),setup,771710885455832e8,353
library(ppcor),setup,771710885455832e8,353
done.alt = done_res,evaluation,497074061306193e8,358
ov <- data.frame(ov),import,665794803993776e8,359
"names(ov)[1] <- ""feature_id""",import,665794803993776e8,359
library(ggplot2),setup,771710885455832e8,353
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[1], "".Robj""))",import,497074061306193e8,358
rm(list = ls()),setup,771710885455832e8,353
rownames(ov) <- ov$feature_id,import,665794803993776e8,359
"data <- read.table(file = ""order2size"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""order2tran"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""order2erep"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
ov$feature_id <- NULL,import,665794803993776e8,359
"data <- read.table(file = ""order2domain"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""order2dist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
names(ov) <- sample_names,import,665794803993776e8,359
"data <- read.table(file = ""order2expr"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"id_split <- strsplit(rownames(ov), ""|"", fixed = TRUE)",import,665794803993776e8,359
"data <- read.table(file = ""order2breadth"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""order2solo"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"feature_names <- sapply(id_split, function(x) paste0(x[1], ""_"",      x[6]))",import,665794803993776e8,359
"data <- read.table(file = ""exprtran"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""exprsize"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"gene_type <- sapply(id_split, `[`, 8)",import,665794803993776e8,359
"data <- read.table(file = ""exprerep"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""exprbreadth"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
rownames(ov) <- feature_names,import,665794803993776e8,359
"data <- read.table(file = ""exprdomain"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""exprexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""exprdist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""breadthsize"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""breadthtran"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"id_map <- read_csv(""../data/TCGA_ID_MAP.csv"") %>% filter(Disease ==      ""OV"")",import,665794803993776e8,359
"data <- read.table(file = ""breadtherep"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""breadthdomain"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""breadthexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"to_tcga_barcode <- function(x) tolower(paste(strsplit(x, ""-"",      fixed = T)[[1]][1:3], collapse = ""-""))",import,665794803993776e8,359
"data <- read.table(file = ""breadthdist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""sizetran"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"id_map %<>% mutate(patient_barcode = sapply(AliquotBarcode, to_tcga_barcode))",import,665794803993776e8,359
"data <- read.table(file = ""sizeorder_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""sizerep"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""sizedom_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""sizedist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""sizeexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""tranorder_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""tranerep"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""trandom"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""trandist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""tranexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""ordererep_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""orderdom_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""orderdist_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""orderexon_BIEN"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""erepdom"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"ov_clinical <- OV.clinical %>% filter(patient.bcr_patient_barcode %in%      id_map$patient_barcode) %>% select(patient_barcode = patient.bcr_patient_barcode,      patient.days_to_death, patient.age_at_initial_pathologic_diagnosis,      patient.days_to_last_followup, patient.days_to_tumor_progression,      patient.days_to_tumor_recurrence, patient.stage_event.clinical_stage,      patient.tumor_stage) %>% mutate(censored = is.na(patient.days_to_death))",import,665794803993776e8,359
"data <- read.table(file = ""erepdist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""erepexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""domdist"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""domexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data <- read.table(file = ""distexon"", header = TRUE, sep = ""\t"")",import,771710885455832e8,353
"data_subset <- subset(data, breadth == ""low"")",import,771710885455832e8,353
"ov_clinical %<>% inner_join(select(id_map, patient_barcode, CGHubAnalysisID,      AliquotBarcode), by = c(""patient_barcode""))",import,665794803993776e8,359
"mod2 = lm(data_subset[[""Ka_pos""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data_subset[[""Ka_neg""]] ~ data_subset[[""chr""]] + data_subset[[""recombination""]] +      data_subset[[""mutation""]] + data_subset[[""erep""]])",modeling,771710885455832e8,353
"for (covariate_index in grep(""days"", names(ov_clinical))) ov_clinical[[covariate_index]] <- as.numeric(ov_clinical[[covariate_index]])",import,665794803993776e8,359
summary(mod2),evaluation,771710885455832e8,353
"plate <- factor(sapply(strsplit(ov_clinical$AliquotBarcode, ""-""),      `[`, 6))",import,665794803993776e8,359
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"centre <- factor(sapply(strsplit(ov_clinical$AliquotBarcode,      ""-""), `[`, 7))",import,665794803993776e8,359
ov_clinical$plate <- plate,import,665794803993776e8,359
"data[[""mutation""]] = factor(data[[""mutation""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
ov_clinical$centre <- centre,import,665794803993776e8,359
"data[[""recombination""]] = factor(data[[""recombination""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
"ov_clinical <- ov_clinical[match(colnames(ov), ov_clinical$CGHubAnalysisID),      ]",import,665794803993776e8,359
"data[[""order""]] = factor(data[[""order2""]], levels = c(""low"",      ""high""))",evaluation,771710885455832e8,353
"data[[""size""]] = factor(data[[""size""]], levels = c(""low"", ""medium"",      ""high""))",evaluation,771710885455832e8,353
"data[[""transcripts""]] = factor(data[[""transcripts""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
"stopifnot(all.equal(colnames(ov), ov_clinical$CGHubAnalysisID))",import,665794803993776e8,359
ov_clinical_pd <- data.frame(ov_clinical),import,665794803993776e8,359
"data[[""distance""]] = factor(data[[""distance""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
rownames(ov_clinical_pd) <- ov_clinical_pd$CGHubAnalysisID,import,665794803993776e8,359
"data[[""exons""]] = factor(data[[""exons""]], levels = c(""low"", ""medium"",      ""high""))",evaluation,771710885455832e8,353
"sce <- newSCESet(tpmData = as.matrix(ov), phenoData = AnnotatedDataFrame(ov_clinical_pd))",import,665794803993776e8,359
"data[[""expression""]] = factor(data[[""expression""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
"data[[""breadth""]] = factor(data[[""breadth""]], levels = c(""low"",      ""medium"", ""high""))",evaluation,771710885455832e8,353
"sce <- sce[, sce$centre != 31]",import,665794803993776e8,359
sce$plate <- factor(as.character(sce$plate)),import,665794803993776e8,359
"save(sce, file = ""../data/sce_ovarian_kallisto.Rdata"")",import,665794803993776e8,359
"plotPCA(sce, colour_by = ""plate"", ncomponents = 3)",import,665794803993776e8,359
"plotQC(sce, type = ""find"", var = ""plate"")",import,665794803993776e8,359
"plotPCA(sce, colour_by = ""patient.days_to_birth"", ncomponents = 3)",import,665794803993776e8,359
"plotPCA(sce, colour_by = ""censored"", ncomponents = 3)",import,665794803993776e8,359
"plotQC(sce, type = ""find"", var = ""patient.days_to_birth"")",import,665794803993776e8,359
"plotQC(sce, type = ""find"", var = ""censored"")",import,665794803993776e8,359
is_exprs(sce) <- exprs(sce) > 0,import,665794803993776e8,359
sce <- calculateQCMetrics(sce),import,665794803993776e8,359
"sc <- sce[rowMeans(exprs(sce)) > 1 & matrixStats::rowVars(exprs(sce)) >      0, ]",not sure,665794803993776e8,359
"sc$random_two_factor <- sample(c(T, F), ncol(sc), replace = TRUE)",not sure,665794803993776e8,359
"plotQC(sc, type = ""find"", var = ""censored"")",not sure,665794803993776e8,359
"plotQC(sc, type = ""find"", var = ""random_two_factor"")",modeling,665794803993776e8,359
"plotQC(sc, type = ""expl"", var = c(""censored"", ""random_two_factor""))",modeling,665794803993776e8,359
qplot(matrixStats::rowVars(exprs(sce))),modeling,665794803993776e8,359
"data[[""erep""]] = factor(data[[""erep""]], levels = c(""low"", ""high""))",evaluation,771710885455832e8,353
"sc <- sce[matrixStats::rowVars(exprs(sce)) > 1, ]",modeling,665794803993776e8,359
batch <- sc$plate,modeling,665794803993776e8,359
"design <- model.matrix(~1, data = pData(sc))",modeling,665794803993776e8,359
"exprs_combat <- ComBat(exprs(sc), batch, design)",modeling,665794803993776e8,359
sc2 <- sc,modeling,665794803993776e8,359
exprs(sc2) <- exprs_combat,modeling,665794803993776e8,359
"plotPCA(sc2, ncomponents = 3, colour_by = ""plate"")",modeling,665794803993776e8,359
"plotPCA(sc2, ncomponents = 3, colour_by = ""censored"")",modeling,665794803993776e8,359
"plotPCA(sc2, ncomponents = 3, colour_by = ""patient.days_to_birth"")",modeling,665794803993776e8,359
"data[[""domain""]] = factor(data[[""domain""]], levels = c(""active"",      ""both"", ""inactive""))",evaluation,771710885455832e8,353
"data[[""order""]] = factor(data[[""order""]], levels = c(""low"", ""medium"",      ""high"", ""sup""))",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""order""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""domain""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""distance""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""size""]] + data[[""exons""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""order""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""distance""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""exons""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""order""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""order""]])",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""order""]])",modeling,771710885455832e8,353
"if (!require(""gplots"")) {     install.packages(""gplots"", dependencies = TRUE)     library(gplots) }",setup,363418078748509e8,360
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""order""]])",modeling,771710885455832e8,353
"if (!require(""RColorBrewer"")) {     install.packages(""RColorBrewer"", dependencies = TRUE)     library(RColorBrewer) }",setup,363418078748509e8,360
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""order""]])",modeling,771710885455832e8,353
"if (!require(""cluster"")) {     install.packages(""cluster"", dependencies = TRUE)     library(cluster) }",setup,363418078748509e8,360
summary(mod2),evaluation,771710885455832e8,353
"if (!require(""tidyverse"")) {     install.packages(""tidyverse"", dependencies = TRUE)     library(tidyverse) }",setup,363418078748509e8,360
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"if (!require(""reshape2"")) {     install.packages(""reshape2"", dependencies = TRUE)     library(reshape2) }",setup,363418078748509e8,360
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""order""]])",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""order""]])",modeling,771710885455832e8,353
"d897 <- read.csv(""analysis/clustering/kmeans/data/897_motor_nms.csv"",      comment.char = ""#"")",import,363418078748509e8,360
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""order""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""order""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""order""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""order""]])",modeling,771710885455832e8,353
d897_nms_domains9 = d897[68:76],data cleaning,363418078748509e8,360
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""erep""]] + data[[""domain""]])",modeling,771710885455832e8,353
"kmeans_nms_domains_models = vector(""list"", 11)",setup,363418078748509e8,360
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),modeling,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""size""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,771710885455832e8,353
"library(""ggplot2"")",setup,440647588577121e8,361
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,771710885455832e8,353
"library(""plyr"")",setup,440647588577121e8,361
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"library(""binom"")",setup,440647588577121e8,361
"library(""lme4"")",setup,440647588577121e8,361
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,771710885455832e8,353
"library(""arm"")",setup,440647588577121e8,361
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,771710885455832e8,353
"library(""sjPlot"")",setup,440647588577121e8,361
"library(""scales"")",setup,440647588577121e8,361
"library(""saccades"")",setup,440647588577121e8,361
summary(mod2),evaluation,771710885455832e8,353
"library(""boot"")",setup,440647588577121e8,361
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"library(""apaTables"")",setup,440647588577121e8,361
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""exons""]])",modeling,771710885455832e8,353
"data_dir = ""C:\\Users\\me\\Desktop\\learning_at_a_glance\\data""",import,440647588577121e8,361
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"analysis_dir = ""C:\\Users\\me\\Desktop\\learning_at_a_glance\\analysis""",import,440647588577121e8,361
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""distance""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""size""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""size""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"subjects = c(""Colleen"", ""Jeremy"", ""Tricia"", ""Wes"", ""Matt"", ""Tim"",      ""Heather"", ""Kelly"", ""Anja"", ""Steph"")",not sure,440647588577121e8,361
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""transcripts""]])",modeling,771710885455832e8,353
"learn_test = c(""*learn*"", ""*test*"")",exploratory,440647588577121e8,361
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""erep""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""erep""]])",modeling,771710885455832e8,353
"survey_data = read.csv(paste(data_dir, ""survey_data.csv"", sep = ""\\""))",import,440647588577121e8,361
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""erep""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""domain""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""domain""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""exons""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""exons""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""distance""]])",modeling,771710885455832e8,353
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""distance""]])",modeling,771710885455832e8,353
"for (lt in 1:2) {     for (s in 1:length(subjects)) {         csvlist = list.files(path = paste(data_dir, subjects[s],              sep = ""\\""), pattern = learn_test[lt])         for (i in 1:length(csvlist)) {             tmp = read.csv(paste(data_dir, subjects[s], csvlist[i],                  sep = ""\\""))             if (s == 1 & i == 1) {                 all_data = tmp             }             else {                 all_data = rbind(all_data, tmp)             }         }     }     if (lt == 1) {         learn_data = all_data     }     else {         test_data = all_data     } }",import,440647588577121e8,361
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""breadth""]] + data[[""distance""]])",modeling,771710885455832e8,353
summary(mod2),evaluation,771710885455832e8,353
"Anova(mod2, type = ""2"")",evaluation,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka"", outline = F)",visualization,771710885455832e8,353
"answer_data = subset(test_data, isAnswer == 1 & region >= 0)",data cleaning,440647588577121e8,361
"boxplot(data[[""Ka_neg""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"answer_data$isCorrect = mapply(function(x, y) x == y, answer_data$region,      answer_data$region_tested)",data cleaning,440647588577121e8,361
"boxplot(data[[""Ks""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ks"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ks"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka_pos"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka_neg"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""size""]], main = ""Size"", ylab = ""omega_A"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""size""]], main = ""Size"", ylab = ""alpha"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ks"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""breadth""]], main = ""Breadth"", ylab = ""Ka"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""breadth""]], main = ""Breadth"", ylab = ""Ks"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ks"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""order""]], main = ""Order"", ylab = ""Ka_pos"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""order""]], main = ""Order"", ylab = ""Ka"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""order""]], main = ""Order"", ylab = ""Ka_neg"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""order""]], main = ""Order"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""order""]], main = ""Order"", ylab = ""alpha"",      outline = F)",visualization,771710885455832e8,353
"accuracy <- ddply(answer_data, c(""stimulus"", ""input"", ""participant""),      summarise, acc = mean(isCorrect == 1), CI = 1.96 * sqrt(mean(isCorrect ==          1) * (1 - mean(isCorrect == 1))/length(isCorrect)))",exploratory,440647588577121e8,361
"boxplot(data[[""Ks""]] ~ data[[""order""]], main = ""Order"", ylab = ""Ks"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""Ka"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""erep""]], main = ""Inclusion levels"",      ylab = ""Ks"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_pos""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""Ka_pos"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka""]] ~ data[[""domain""]], main = ""Domain"", ylab = ""Ka"",      outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ka_neg""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""Ka_neg"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""omega_A""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""omega_A"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""alpha""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""alpha"", outline = F)",visualization,771710885455832e8,353
"boxplot(data[[""Ks""]] ~ data[[""domain""]], main = ""Domain"", ylab = ""Ks"",      outline = F)",visualization,771710885455832e8,353
"ggplot(data = accuracy, aes(x = stimulus, y = acc, fill = input)) +      geom_bar(stat = ""identity"", position = position_dodge()) +      geom_errorbar(aes(ymax = acc + CI, ymin = acc - CI), position = ""dodge"") +      facet_grid(. ~ participant)",visualization,440647588577121e8,361
"apa.2way.table(stimulus, input, acc, accuracy, filename = paste(analysis_dir,      ""accuracy_apatable.doc"", sep = ""\\""))",export,440647588577121e8,361
"ggplot(data = accuracy, aes(x = stimulus, y = acc, fill = input)) +      geom_bar(stat = ""identity"", position = position_dodge()) +      geom_errorbar(aes(ymax = acc + CI, ymin = acc - CI), position = ""dodge"")",visualization,440647588577121e8,361
library(mmadsenr),setup,771710885455832e8,353
library(caret),setup,771710885455832e8,353
library(doMC),setup,771710885455832e8,353
library(futile.logger),setup,771710885455832e8,353
library(dplyr),setup,771710885455832e8,353
library(ggthemes),setup,771710885455832e8,353
ptm <- proc.time(),setup,771710885455832e8,353
"accuracy <- ddply(answer_data, c(""input""), summarise, acc = mean(isCorrect ==      1), CI = 1.96 * sqrt(mean(isCorrect == 1) * (1 - mean(isCorrect ==      1))/length(isCorrect)))",exploratory,440647588577121e8,361
"gbm_grid <- expand.grid(interaction.depth = (1:6) * 2, n.trees = (2:10) *      50, shrinkage = 0.05, n.minobsinnode = 10)",import,771710885455832e8,353
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",import,771710885455832e8,353
"ggplot(data = accuracy, aes(x = input, y = acc, fill = input)) +      scale_fill_manual(name = """", values = c(""#b491b5"", ""#83bbe5"")) +      geom_bar(stat = ""identity"", position = position_dodge()) +      scale_color_manual(values = c(""#b491b5"", ""#83bbe5"")) + coord_cartesian(ylim = c(0.6,      0.8)) + labs(y = ""Accuracy"", x = ""Input"", title = paste(""Learning Effectiveness"",      """")) + theme(text = element_text(size = 35), legend.position = ""none"") +      ggsave(filename = paste(analysis_dir, ""\\"", ""overall_acc"",          "".png"", sep = """"), height = 20, width = 20, units = ""cm"")",visualization,440647588577121e8,361
seed_value <- 58132133,import,771710885455832e8,353
"apa.d.table(input, acc, accuracy, filename = paste(analysis_dir,      ""input_accuracy_d_table.doc"", sep = ""\\""))",export,440647588577121e8,361
set.seed(seed_value),setup,771710885455832e8,353
training_set_fraction <- 0.8,setup,771710885455832e8,353
test_set_fraction <- 1 - training_set_fraction,exploratory,771710885455832e8,353
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",setup,771710885455832e8,353
"learning_time <- ddply(learn_data, c(""input"", ""participant"",      ""stimulus""), summarise, total_time = (max(timestamp) - min(timestamp))/1000)",exploratory,440647588577121e8,361
"learning_time = ddply(learning_time, c(""input""), summarise, mean = mean(total_time))",exploratory,440647588577121e8,361
"get_experiment_names <- function(comparison_prefix, tassize_subsets) {     n <- nrow(tassize_subsets)     experiment_names <- character(n)     for (i in 1:n) {         experiment_names[i] <- paste0(comparison_prefix, "": Sample Size: "",              tassize_subsets[i, ""sample_size""], "" Duration: "",              tassize_subsets[i, ""ta_duration""])     }     experiment_names }",setup,771710885455832e8,353
"apa.2way.table(stimulus, input, total_time, learning_time, filename = paste(analysis_dir,      ""learningtime_apatable.doc"", sep = ""\\""))",export,440647588577121e8,361
"do_model_fit_and_test <- function(comparison, exp_name, ssize,      ta_dur, target_label, subset_df, gbm_grid, training_control,      exclude_columns) {     results <- NULL     model <- train_gbm_classifier(subset_df, training_set_fraction,          target_label, gbm_grid, training_control, exclude_columns,          verbose = FALSE)     test_data <- model$test_data     predictions <- predict(model$tunedmodel, newdata = test_data)     cm <- confusionMatrix(predictions, test_data[[target_label]])     stats <- get_parsed_binary_confusion_matrix_stats(cm)     roc <- calculate_roc_binary_classifier(model$tunedmodel,          model$test_data, target_label, exp_name)     stats$auc <- unlist(roc$auc@y.values)     stats$sample_size <- ssize     stats$ta_duration <- ta_dur     stats$elapsed <- model$elapsed     stats$experiments <- exp_name     stats$exp_group <- comparison     results$sample_size <- ssize     results$ta_duration <- ta_dur     results$cm <- cm     results$roc <- roc     results$model <- model     results$stats <- stats     results$elapsed <- model$elapsed     results }",setup,771710885455832e8,353
"ggplot(data = learning_time, aes(x = input, y = mean, fill = input)) +      scale_fill_manual(name = """", values = c(""#b491b5"", ""#83bbe5"")) +      geom_bar(stat = ""identity"", position = position_dodge()) +      scale_color_manual(values = c(""#b491b5"", ""#83bbe5"")) + coord_cartesian(ylim = c(80,      105)) + labs(y = ""Learning Time"", x = ""Input"", title = paste(""Learning Time"",      """")) + theme(text = element_text(size = 35), legend.position = ""none"") +      ggsave(filename = paste(analysis_dir, ""\\"", ""overall_speed"",          "".png"", sep = """"), height = 20, width = 20, units = ""cm"")",visualization,440647588577121e8,361
"ggplot(data = learning_time, aes(x = stimulus, y = total_time,      fill = input)) + geom_bar(stat = ""identity"", position = position_dodge())",visualization,440647588577121e8,361
"log_file <- ""/mnt/experiment-ctmixtures/equifinality-5/tasampled-classification.log""",import,771710885455832e8,353
"apa.d.table(input, total_time, learning_time, filename = paste(analysis_dir,      ""input_learningtime_d_table.doc"", sep = ""\\""))",export,440647588577121e8,361
"flog.appender(appender.file(log_file), name = ""cl"")",import,771710885455832e8,353
"flog.info(""================ TA and Sampled Classification Analysis ================="",      name = ""cl"")",import,771710885455832e8,353
"ggplot(data = learning_time, aes(x = stimulus, y = total_time,      fill = input)) + geom_bar()",visualization,440647588577121e8,361
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",import,771710885455832e8,353
"ggplot(data = learning_time, aes(x = input, y = total_time, fill = input)) +      stat_boxplot(geom = ""errorbar"") + geom_boxplot() + geom_point(position = ""jitter"",      size = 10, alpha = 0.5)",visualization,440647588577121e8,361
num_cores <- get_parallel_cores_given_os(dev = TRUE),import,771710885455832e8,353
"acc_diff <- ddply(answer_data, c(""input"", ""participant""), summarise,      acc = mean(isCorrect == 1))",evaluation,440647588577121e8,361
"acc_diff <- ddply(acc_diff, ""participant"", summarise, acc_increase = acc[input ==      ""gaze""] - acc[input == ""mouse""])",evaluation,440647588577121e8,361
"trigs <- ddply(learn_data, c(""input"", ""participant""), summarise,      trig_total = sum(triggered))",evaluation,440647588577121e8,361
"trigs <- ddply(trigs, ""participant"", summarise, trig_increase = trig_total[input ==      ""gaze""] - trig_total[input == ""mouse""])",evaluation,440647588577121e8,361
"just_input_participant = ddply(learning_time, c(""input"", ""participant""),      summarise, total_time = sum(total_time))",evaluation,440647588577121e8,361
"time_diff <- ddply(just_input_participant, ""participant"", summarise,      speedup = total_time[input == ""mouse""] - total_time[input ==          ""gaze""])",evaluation,440647588577121e8,361
"diff = merge(acc_diff, time_diff, by = ""participant"")",evaluation,440647588577121e8,361
"diff = merge(diff, trigs, by = ""participant"")",evaluation,440647588577121e8,361
"diff = merge(diff, survey_data, by = ""participant"")",evaluation,440647588577121e8,361
numIND = 4,setup,639499593526125e7,362
"case.name = c(paste0(""fullread."", numIND, ""ind""), paste0(""fullread."",      numIND, ""ind.over""), paste0(""fullread."", numIND, ""ind.over.2""))",setup,639499593526125e7,362
"ROC.file.name = paste0(""logLR_ROC_over"", numIND, "".pdf"")",setup,639499593526125e7,362
"hist.file.name = paste0(""logLR_hist_over"", numIND, "".pdf"")",setup,639499593526125e7,362
"ms.null = vector(""list"", length(case.name))",setup,639499593526125e7,362
"ms.alt = vector(""list"", length(case.name))",setup,639499593526125e7,362
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/logLR."",      case.name[1], "".Robj""))",setup,639499593526125e7,362
logLR.alt = as.numeric(logLR_list),setup,639499593526125e7,362
done.alt = done_res,setup,639499593526125e7,362
"source(""analysis/data_cleanup.R"")",setup,20538765960373e9,363
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,639499593526125e7,362
library(ggplot2),setup,20538765960373e9,363
logLR.null = as.numeric(logLR_list),data cleaning,639499593526125e7,362
done.null = done_res,data cleaning,639499593526125e7,362
ls(),exploratory,20538765960373e9,363
rm(list = ls()),setup,20538765960373e9,363
"gdp_education_data <- read.csv(""analysis/data/tidy_gdp_educ_data.csv"",      header = TRUE)",import,20538765960373e9,363
"sapply(gdp_education_data, class)",exploratory,20538765960373e9,363
head(gdp_education_data),exploratory,20538765960373e9,363
ls(gdp_education_data),exploratory,20538765960373e9,363
matching_cases <- nrow(gdp_education_data),exploratory,20538765960373e9,363
matching_cases,exploratory,20538765960373e9,363
"gdp_education_data <- gdp_education_data[order(gdp_education_data$GDP_US_dollars),      ]",data cleaning,20538765960373e9,363
"thirteenth_ranked_country <- gdp_education_data[13, ]",data cleaning,20538765960373e9,363
class(thirteenth_ranked_country),exploratory,20538765960373e9,363
as.vector(thirteenth_ranked_country$economy),data cleaning,20538765960373e9,363
"high_income_groups <- subset(gdp_education_data, Income.Group ==      ""High income: OECD"" | Income.Group == ""High income: nonOECD"")",data cleaning,20538765960373e9,363
str(high_income_groups),exploratory,20538765960373e9,363
as.vector(unique(high_income_groups$Income.Group)),evaluation,20538765960373e9,363
length(as.vector(unique(high_income_groups$Income.Group))),evaluation,20538765960373e9,363
"aggregate(high_income_groups$GDP_rank, list(high_income_groups$Income.Group),      FUN = mean)",data cleaning,20538765960373e9,363
library(synapser),setup,9276673856657e10,364
"ggplot(data = gdp_education_data, aes(x = economy, y = GDP_US_dollars,      fill = Income.Group)) + geom_bar(stat = ""identity"")",visualization,20538765960373e9,363
synLogin(),setup,9276673856657e10,364
"plot(gdp_education_data$GDP_rank, gdp_education_data$GDP_US_dollars)",visualization,20538765960373e9,363
"seq(0, 1, 0.2)",evaluation,20538765960373e9,363
"source(""../../bin/nf1TumorHarmonization.R"")",import,9276673856657e10,364
"prefix = paste(lubridate::today(), ""bioBank_glioma_cNF"", sep = ""-"")",data cleaning,9276673856657e10,364
"gdp_education_data$GDP_quantile <- cut(gdp_education_data$GDP_rank,      quantile(gdp_education_data$GDP_rank, probs = c(0, 0.2, 0.4,          0.6, 0.8, 1)))",data cleaning,20538765960373e9,363
"quantile_table <- aggregate(gdp_education_data$GDP_rank, list(gdp_education_data$Income.Group,      gdp_education_data$GDP_quantile), FUN = length)",data cleaning,20538765960373e9,363
"biobank = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study  FROM syn13363852 WHERE ( ( \""assay\"" = 'rnaSeq' ) AND ( \""fileFormat\"" = 'sf' ) )"")$asDataFrame()",import,9276673856657e10,364
library(knitr),import,867870299844071e8,365
quantile_table,evaluation,20538765960373e9,363
"gliomanf1 = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn11614207 WHERE ( ( \""assay\"" = 'rnaSeq' ) )"")$asDataFrame()",import,9276673856657e10,364
"cnf = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study FROM syn9702734 WHERE ( ( \""parentId\"" = 'syn5493036' ) AND ( \""assay\"" = 'rnaSeq' ) AND ( \""individualID\"" IS NOT NULL ) )"")$asDataFrame()",import,9276673856657e10,364
"nrow(highest_GDP_lowest_income_data <- subset(gdp_education_data,      Income.Group == ""Lower middle income"" & GDP_rank < 39))",data cleaning,20538765960373e9,363
"trackdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/tracks/""",setup,867870299844071e8,365
"full.metadata <- rbind(dplyr::select(biobank, c(id, age, sex,      tumorType, isCellLine, study)), dplyr::select(gliomanf1,      c(id, age, sex, tumorType, isCellLine, study)), dplyr::select(cnf,      c(id, age, sex, tumorType, isCellLine, study))) %>% mutate(Sex = tolower(sex))",data cleaning,9276673856657e10,364
"source(""boilerplate.R"")",import,511999619193375e8,366
"top_10 <- subset(gdp_education_data, GDP_rank < 11)",evaluation,20538765960373e9,363
"plot(top_10$GDP_US_dollar, top_10$economy, col = top_10$Income.Group)",visualization,20538765960373e9,363
rownames(full.metadata) <- full.metadata$id,data cleaning,9276673856657e10,364
"bottom_10 <- subset(gdp_education_data, GDP_rank > 180)",data cleaning,20538765960373e9,363
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,867870299844071e8,365
"plot(bottom_10$GDP_US_dollar, bottom_10$economy, col = bottom_10$Income.Group)",visualization,20538765960373e9,363
"fv.tab <- rbind(biobank, gliomanf1, cnf)",data cleaning,9276673856657e10,364
analysis.outcome <- data.frame(),not sure,511999619193375e8,366
bottom_10,evaluation,20538765960373e9,363
"tab.with.metadata <- plotMetadata(fv.tab, prefix)",communication,9276673856657e10,364
library(biomaRt),evaluation,9276673856657e10,364
"dataset <- get.correctness() %>% mutate(precision = (tp/(tp +      fp)), recall = (tp/(tp + fn))) %>% mutate(f = (2 * precision *      recall/(precision + recall)))",data cleaning,511999619193375e8,366
"analysis.dataset <- dataset %>% filter(type %in% c(""21"", ""21E"")) %>%      select(type, precision) %>% na.omit(.)",data cleaning,511999619193375e8,366
"population.one <- analysis.dataset %>% filter(type == ""21"")",data cleaning,511999619193375e8,366
"population.two <- analysis.dataset %>% filter(type == ""21E"")",data cleaning,511999619193375e8,366
"bdir = ""/Users/khuang/Box Sync/PhD/germline/PanCanAtlasGermline/analysis/hotspot3d""",setup,20538765960373e9,363
files <- list.files(path = diffdir),import,867870299844071e8,365
"wresult <- run.wilcox(population.one, population.two, ""precision"")",modeling,511999619193375e8,366
setwd(bdir),setup,20538765960373e9,363
"source(""../global_aes_out.R"")",import,20538765960373e9,363
"source(""../dependency_files.R"")",import,20538765960373e9,363
"cresult <- cliff.delta(precision ~ type, data = analysis.dataset)",modeling,511999619193375e8,366
exonSize = 49586385,setup,20538765960373e9,363
names <- files,import,867870299844071e8,365
nPath = nrow(pathVarP),setup,20538765960373e9,363
"numSomaticOverlap = nrow(pathVarP[pathVarP$colocalized_somatic_mutation_count >      2, ])",exploratory,20538765960373e9,363
"analysis.outcome <- rbind(analysis.outcome, data.frame(metric = ""Precision"",      p = sprintf(""%.4e"", wresult$wilcox.test.out$p.value), is.significant = wresult$is.significant,      lower.median = wresult$one.median, compare.median = wresult$median.ieq,      upper.median = wresult$two.median, lower.mean = wresult$one.mean,      compare.mean = wresult$mean.ieq, upper.mean = wresult$two.mean,      effect = cresult$magnitude, delta = cresult$estimate))",modeling,511999619193375e8,366
somaticMutRate = 68537/exonSize,evaluation,20538765960373e9,363
"analysis.dataset <- dataset %>% filter(type %in% c(""21"", ""21E"")) %>%      select(type, recall) %>% na.omit(.)",data cleaning,511999619193375e8,366
"poisson.test(numSomaticOverlap, T = nPath, r = somaticMutRate,      conf.level = 0.95, alternative = ""greater"")",evaluation,20538765960373e9,363
"split <- data.frame(strsplit(names, ""_""))",setup,867870299844071e8,365
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,590873348060995e8,367
"population.one <- analysis.dataset %>% filter(type == ""21"")",data cleaning,511999619193375e8,366
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,590873348060995e8,367
"population.two <- analysis.dataset %>% filter(type == ""21E"")",data cleaning,511999619193375e8,366
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,590873348060995e8,367
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,590873348060995e8,367
"numPCGPOverlap = nrow(pathVarP[pathVarP$PCGP, ])",evaluation,20538765960373e9,363
"wresult <- run.wilcox(population.one, population.two, ""recall"")",data cleaning,511999619193375e8,366
pcgpMutRate = (551 + 239)/exonSize,evaluation,20538765960373e9,363
"cresult <- cliff.delta(recall ~ type, data = analysis.dataset)",modeling,511999619193375e8,366
"analysis.outcome <- rbind(analysis.outcome, data.frame(metric = ""Recall"",      p = sprintf(""%.4e"", wresult$wilcox.test.out$p.value), is.significant = wresult$is.significant,      lower.median = wresult$one.median, compare.median = wresult$median.ieq,      upper.median = wresult$two.median, lower.mean = wresult$one.mean,      compare.mean = wresult$mean.ieq, upper.mean = wresult$two.mean,      effect = cresult$magnitude, delta = cresult$estimate))",modeling,511999619193375e8,366
"poisson.test(numPCGPOverlap, T = nPath, r = pcgpMutRate, conf.level = 0.95,      alternative = ""greater"")",modeling,20538765960373e9,363
"analysis.dataset <- dataset %>% filter(type %in% c(""21"", ""21E"")) %>%      select(type, f) %>% na.omit(.)",data cleaning,511999619193375e8,366
"population.one <- analysis.dataset %>% filter(type == ""21"")",data cleaning,511999619193375e8,366
"population.two <- analysis.dataset %>% filter(type == ""21E"")",data cleaning,511999619193375e8,366
"source(""./analysis/inundation_predicts_species_distributions/data/data_index.R"")",setup,590873348060995e8,367
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",setup,867870299844071e8,365
"pathVarP_hot = pathVarP[pathVarP$colocalized_somatic_mutation_count >      2 | pathVarP$PCGP, ]",setup,20538765960373e9,363
"wresult <- run.wilcox(population.one, population.two, ""f"")",data cleaning,511999619193375e8,366
"ggplot(riskratio, aes(x = dden, y = diff_mort)) + geom_point()",visualization,590873348060995e8,367
"write.table(file = ""out/colocalize_var.tsv"", pathVarP_hot, quote = F,      sep = ""\t"", row.names = F)",export,20538765960373e9,363
"model1 <- lm(diff_mort ~ dden, riskratio)",modeling,590873348060995e8,367
"adult_directories <- split[, which(split[4, ] == ""Adult"")]",data cleaning,867870299844071e8,365
"pathVarPOT_hot = pathVarPOT[pathVarPOT$colocalized_somatic_mutation_count >      2 | pathVarPOT$PCGP, ]",setup,20538765960373e9,363
"par(mfrow = c(2, 2))",visualization,590873348060995e8,367
setwd(trackdir),setup,867870299844071e8,365
table(pathVarPOT_hot$HUGO_Symbol),evaluation,20538765960373e9,363
plot(model1),visualization,590873348060995e8,367
"model2 <- lm(log(diff_mort) ~ log(dden), riskratio)",modeling,590873348060995e8,367
pathVarPOT_hot$somatic_count_plot = pathVarPOT_hot$colocalized_somatic_mutation_count,data cleaning,20538765960373e9,363
summary(model2),communication,590873348060995e8,367
"pathVarPOT_hot$HGVSp_short_plot = gsub(""p."", """", pathVarPOT_hot$HGVSp_short)",data cleaning,20538765960373e9,363
"cresult <- cliff.delta(f ~ type, data = analysis.dataset)",modeling,511999619193375e8,366
"p = ggplot(pathVarPOT_hot, aes(y = HUGO_Symbol, x = somatic_count_plot,      color = PCGP))",visualization,20538765960373e9,363
"analysis.outcome <- rbind(analysis.outcome, data.frame(metric = ""F-measure"",      p = sprintf(""%.4e"", wresult$wilcox.test.out$p.value), is.significant = wresult$is.significant,      lower.median = wresult$one.median, compare.median = wresult$median.ieq,      upper.median = wresult$two.median, lower.mean = wresult$one.mean,      compare.mean = wresult$mean.ieq, upper.mean = wresult$two.mean,      effect = cresult$magnitude, delta = cresult$estimate))",modeling,511999619193375e8,366
"p = p + facet_grid(Gene_Classification ~ ., drop = T, scale = ""free_y"",      space = ""free_y"")",visualization,20538765960373e9,363
p = p + geom_point(stroke = 0) + theme_bw(),visualization,20538765960373e9,363
"p = p + geom_text_repel(aes(label = ifelse(duplicated(HGVSp_short),      NA, HGVSp_short_plot)))",visualization,20538765960373e9,363
"p = p + theme(axis.title = element_text(size = 16), axis.text.x = element_text(colour = ""black"",      size = 14, angle = 90, vjust = 0.5), axis.text.y = element_text(colour = ""black"",      size = 14))",visualization,20538765960373e9,363
p = p + scale_x_log10(),visualization,20538765960373e9,363
p = p + expand_limits(x = 0),visualization,20538765960373e9,363
"p = p + labs(x = ""Co-localizing somatic mutation count"", y = ""Gene"")",visualization,20538765960373e9,363
p,evaluation,20538765960373e9,363
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",evaluation,771710885455832e8,353
"fn = ""out/pathVarP_spotlight.pdf""",setup,20538765960373e9,363
"ggsave(file = fn, width = 7, h = 5, useDingbats = FALSE)",export,20538765960373e9,363
registerDoMC(cores = num_cores),evaluation,771710885455832e8,353
clargs <- commandArgs(trailingOnly = TRUE),evaluation,771710885455832e8,353
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""equifinality-5-tasampled-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""equifinality-5-tasampled-data.rda"", args = clargs) }",data cleaning,771710885455832e8,353
"for (i in seq(1, (dim(adult_directories)[2]))) {     setwd(trackdir)     strain <- as.character(adult_directories[1, i])     timepoint <- ""Adult""     filename <- paste(adult_directories[, i], collapse = ""_"")     dir <- paste(diffdir, filename, sep = ""/"")     dir.create(filename)     print(filename)     print(dir)     print(strain)     setwd(filename)     knit2html(""../Track_vis.Rmd"", output = paste(filename, "".md"",          sep = """"), quiet = TRUE)     print(dir)     print(strain) }",export,867870299844071e8,365
"setwd(""/Users/Aron/dropbox/Middle-Range Theorizing/Second Paper/"")",setup,20538765960373e9,363
library(gdata),setup,20538765960373e9,363
library(poweRlaw),setup,20538765960373e9,363
library(knitr),setup,867870299844071e8,365
library(dunn.test),setup,20538765960373e9,363
"data <- read.csv(""middle_range_coding_v4_w_borrowing.csv"", header = TRUE,      fill = FALSE, fileEncoding = ""latin1"")",import,20538765960373e9,363
"data <- data[data$Year > 1994, ]",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Indiidual"",      replacement = ""Individual"")",data cleaning,20538765960373e9,363
"trackdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/tracks/""",setup,867870299844071e8,365
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Org$"",      replacement = ""Organization"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Firm"",      replacement = ""Organization"")",data cleaning,20538765960373e9,363
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,867870299844071e8,365
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Project"",      replacement = ""Group"")",data cleaning,20538765960373e9,363
setwd(diffdir),setup,867870299844071e8,365
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Group/Network"",      replacement = ""Network"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Network"",      replacement = ""Network"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Interorg"",      replacement = ""Network"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Technical"",      replacement = ""Artifact"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Database"",      replacement = ""Artifact"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Government/national level"",      replacement = ""Government"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Multilevel"",      replacement = ""Other"")",data cleaning,20538765960373e9,363
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Online Auction"",      replacement = ""Other"")",data cleaning,20538765960373e9,363
files <- list.files(),setup,867870299844071e8,365
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Computational "",      replacement = ""Computational"")",data cleaning,20538765960373e9,363
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Tool "",      replacement = ""Tool"")",data cleaning,20538765960373e9,363
names <- files,setup,867870299844071e8,365
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Nominal "",      replacement = ""Nominal"")",data cleaning,20538765960373e9,363
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Proxy "",      replacement = ""Proxy"")",data cleaning,20538765960373e9,363
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Ensemble "",      replacement = ""Ensemble"")",data cleaning,20538765960373e9,363
"pop_data_file <- ""/mnt/experiment-ctmixtures/equifinality-5/equifinality-5-tasampled-data.rda""",import,771710885455832e8,353
"data$Classification..Exploitation.Exploration[data$Primary..outside.of.IS..or.Secondary..inside.of.IS..borrowing. ==      ""Secondary""] <- ""Exploitation""",data cleaning,20538765960373e9,363
load(pop_data_file),import,771710885455832e8,353
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,865021632052958e7,368
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,865021632052958e7,368
"extending_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Extending"")",data cleaning,20538765960373e9,363
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,865021632052958e7,368
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,865021632052958e7,368
"flog.info(""Loaded data file %s with %.0f rows"", pop_data_file,      nrow(eq5_ta_sampled_df), name = ""cl"")",evaluation,771710885455832e8,353
"modifying_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Modifying"")",data cleaning,20538765960373e9,363
"eq5_neutral_conformist_df <- subset(eq5_ta_sampled_df, eq5_ta_sampled_df$model_class_label ==      ""neutral"" | eq5_ta_sampled_df$model_class_label == ""conformist"")",data cleaning,771710885455832e8,353
"instantiation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Instantiation"")",data cleaning,20538765960373e9,363
"exploitation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..Exploitation.Exploration == ""Exploitation"")",data cleaning,20538765960373e9,363
"eq5_neutral_conformist_df$two_class_label <- factor(eq5_neutral_conformist_df$model_class_label,      levels = unique(eq5_neutral_conformist_df$model_class_label))",exploratory,771710885455832e8,353
"exploration_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..Exploitation.Exploration == ""Exploration"")",data cleaning,20538765960373e9,363
"setwd(""~/M.S. Thesis/Data/GitHubProjects/LaSelvaSeedRain/Data/TidyData"")",visualization,865021632052958e7,368
"instantiation_total_cites <- subset(instantiation_total_cites,      instantiation_total_cites != 0)",data cleaning,20538765960373e9,363
"eq5_neutral_anticonformist_df <- subset(eq5_ta_sampled_df, eq5_ta_sampled_df$model_class_label ==      ""neutral"" | eq5_ta_sampled_df$model_class_label == ""anticonformist"")",data cleaning,771710885455832e8,353
"modifying_total_cites <- subset(modifying_total_cites, modifying_total_cites !=      0)",data cleaning,20538765960373e9,363
"extending_total_cites <- subset(extending_total_cites, extending_total_cites !=      0)",data cleaning,20538765960373e9,363
"eq5_neutral_anticonformist_df$two_class_label <- factor(eq5_neutral_anticonformist_df$model_class_label,      levels = unique(eq5_neutral_anticonformist_df$model_class_label))",data cleaning,771710885455832e8,353
"hist(instantiation_total_cites, breaks = 50, ylim = c(0, 30),      xlim = c(0, 750))",visualization,20538765960373e9,363
"hist(modifying_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,      750))",visualization,20538765960373e9,363
"hist(extending_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,      750))",visualization,20538765960373e9,363
library(ggplot2),visualization,865021632052958e7,368
library(car),import,865021632052958e7,368
library(lsmeans),modeling,865021632052958e7,368
"eq5_ta_sampled_df$two_class_label <- factor(ifelse(eq5_ta_sampled_df$model_class_label ==      ""neutral"", ""neutral"", ""biased""))",data cleaning,771710885455832e8,353
"wilcox.test(extending_total_cites, instantiation_total_cites,      probs = 0.05, alternative = c(""greater""))",modeling,20538765960373e9,363
"wilcox.test(extending_total_cites, modifying_total_cites, probs = 0.05,      alternative = c(""greater""))",modeling,20538765960373e9,363
sample_sizes <- unique(eq5_ta_sampled_df$sample_size),data cleaning,771710885455832e8,353
"wilcox.test(instantiation_total_cites, modifying_total_cites,      probs = 0.05, alternative = c(""less""))",modeling,20538765960373e9,363
ta_durations <- unique(eq5_ta_sampled_df$ta_dur),data cleaning,771710885455832e8,353
library(stats),import,865021632052958e7,368
"tassize_subsets <- expand.grid(sample_size = sample_sizes, ta_duration = ta_durations)",data cleaning,771710885455832e8,353
library(lme4),import,865021632052958e7,368
log_instantiation_total_cites <- log(instantiation_total_cites),data cleaning,20538765960373e9,363
library(dplyr),import,865021632052958e7,368
"flog.info(""tassize_subsets: number of subset combinations to analyze per experimental comparison: %.0f"",      nrow(tassize_subsets), name = ""cl"")",evaluation,771710885455832e8,353
log_modifying_total_cites <- log(modifying_total_cites),data cleaning,20538765960373e9,363
"flog.info(""Starting neutral vs. conformist subsets"", name = ""cl"")",evaluation,771710885455832e8,353
log_extending_total_cites <- log(extending_total_cites),data cleaning,20538765960373e9,363
library(readr),import,865021632052958e7,368
hist(log_instantiation_total_cites),visualization,20538765960373e9,363
library(multcomp),import,865021632052958e7,368
hist(log_modifying_total_cites),visualization,20538765960373e9,363
hist(log_extending_total_cites),visualization,20538765960373e9,363
tassize_neutral_conformist_results <- data.frame(),evaluation,771710885455832e8,353
library(ggResidpanel),import,865021632052958e7,368
length(log_instantiation_total_cites),evaluation,20538765960373e9,363
length(log_modifying_total_cites),evaluation,20538765960373e9,363
length(log_extending_total_cites),evaluation,20538765960373e9,363
tassize_neutral_conformist_roc <- NULL,setup,771710885455832e8,353
"t.test(log_extending_total_cites, log_instantiation_total_cites,      var.equal = FALSE)",modeling,20538765960373e9,363
tassize_neutral_conformist_roc_ssize_20 <- NULL,setup,771710885455832e8,353
"t.test(log_modifying_total_cites, log_instantiation_total_cites,      var.equal = FALSE)",modeling,20538765960373e9,363
tassize_neutral_conformist_roc_ssize_10 <- NULL,setup,771710885455832e8,353
"wind_a_analysis <- read.csv(""wind_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
"t.test(log_modifying_total_cites, log_extending_total_cites,      var.equal = FALSE)",modeling,20538765960373e9,363
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Classification..instantiation..modifying..or.extending),modeling,20538765960373e9,363
"posthoc <- TukeyHSD(x = a1, data$Classification..instantiation..modifying..or.extending,      conf.level = 0.95)",modeling,20538765960373e9,363
tassize_neutral_conformist_model <- NULL,setup,771710885455832e8,353
tassize_neutral_conformist_cm <- NULL,setup,771710885455832e8,353
str(wind_a_analysis),evaluation,865021632052958e7,368
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Total.Citations.by..ISI.Web.of.Science...SSCI. != ""-"")",data cleaning,20538765960373e9,363
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Total.Citations.by..ISI.Web.of.Science...SSCI. != """")",data cleaning,20538765960373e9,363
a0 <- aov(log(data$Total.Citations.by..ISI.Web.of.Science...SSCI.) ~      data$Classification..instantiation..modifying..or.extending),modeling,20538765960373e9,363
"posthoc <- TukeyHSD(x = a0, ""data$Classification..instantiation..modifying..or.extending"",      conf.level = 0.95)",modeling,20538765960373e9,363
"extending_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Extending"")",modeling,20538765960373e9,363
wind_a_analysis$block <- as.factor(wind_a_analysis$block),data cleaning,865021632052958e7,368
"modifying_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Modifying"")",data cleaning,20538765960373e9,363
"instantiation_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Instantiation"")",data cleaning,20538765960373e9,363
"instantiation_IS_cites <- subset(instantiation_IS_cites, instantiation_IS_cites !=      0)",data cleaning,20538765960373e9,363
"modifying_IS_cites <- subset(modifying_IS_cites, modifying_IS_cites !=      0)",data cleaning,20538765960373e9,363
"animal_a_analysis <- read.csv(""animal_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
"extending_IS_cites <- subset(extending_IS_cites, extending_IS_cites !=      0)",data cleaning,20538765960373e9,363
"experiment_names <- get_experiment_names(""Neutral vs Conformist"",      tassize_subsets)",evaluation,771710885455832e8,353
"wilcox.test(extending_IS_cites, instantiation_IS_cites, probs = 0.05,      alternative = c(""greater""))",evaluation,20538765960373e9,363
"comparison <- ""Neutral versus Conformist""",setup,771710885455832e8,353
animal_a_analysis$block <- as.factor(animal_a_analysis$block),data cleaning,865021632052958e7,368
"wilcox.test(extending_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""greater""))",evaluation,20538765960373e9,363
"wilcox.test(instantiation_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""less""))",evaluation,20538765960373e9,363
log_instantiation_IS_cites <- log10(instantiation_IS_cites),not sure,20538765960373e9,363
"for (i in 1:nrow(tassize_subsets)) {     exclude_columns <- c(""simulation_run_id"", ""innovation_rate"",          ""model_class_label"", ""sample_size"", ""ta_duration"")     target_label <- ""two_class_label""     exp_name <- experiment_names[i]     ssize <- tassize_subsets[i, ""sample_size""]     ta_dur <- tassize_subsets[i, ""ta_duration""]     subset_df <- get_tassize_subset_ssize_tadur(eq5_neutral_conformist_df,          ssize, ta_dur)     result <- do_model_fit_and_test(comparison, experiment_names[i],          ssize, ta_dur, target_label, subset_df, gbm_grid, training_control,          exclude_columns)     tassize_neutral_conformist_cm[[exp_name]] <- result$cm     tassize_neutral_conformist_model[[exp_name]] <- result$model     tassize_neutral_conformist_roc[[exp_name]] <- result$roc     tassize_neutral_conformist_results <- rbind(tassize_neutral_conformist_results,          result$stats)     if (ssize == 20) {         tassize_neutral_conformist_roc_ssize_20[[exp_name]] <- result$roc     }     if (ssize == 10) {         tassize_neutral_conformist_roc_ssize_10[[exp_name]] <- result$roc     }     logrow <- sprintf(""row %.0f:  sample size: %2.0f  ta duration: %3.0f numrows: %.0f  elapsed: %.4f"",          i, ssize, ta_dur, nrow(subset_df), result$elapsed)     flog.info(""%s"", logrow, name = ""cl"") }",data cleaning,771710885455832e8,353
"flog.info(""Starting neutral vs. anticonformist subsets"", name = ""cl"")",evaluation,771710885455832e8,353
str(animal_a_analysis),evaluation,865021632052958e7,368
log_modifying_IS_cites <- log10(modifying_IS_cites),evaluation,20538765960373e9,363
tassize_neutral_anticonformist_results <- data.frame(),evaluation,771710885455832e8,353
log_extending_IS_cites <- log10(extending_IS_cites),evaluation,20538765960373e9,363
"mech_a_analysis <- read.csv(""mech_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
tassize_neutral_anticonformist_roc <- NULL,setup,771710885455832e8,353
sqrt_instantiation_IS_cites <- sqrt(instantiation_IS_cites),evaluation,20538765960373e9,363
tassize_neutral_anticonformist_roc_ssize_20 <- NULL,setup,771710885455832e8,353
sqrt_modifying_IS_cites <- sqrt(modifying_IS_cites),evaluation,20538765960373e9,363
sqrt_extending_IS_cites <- sqrt(extending_IS_cites),evaluation,20538765960373e9,363
tassize_neutral_anticonformist_roc_ssize_10 <- NULL,setup,771710885455832e8,353
tassize_neutral_anticonformist_model <- NULL,setup,771710885455832e8,353
hist(log_instantiation_IS_cites),visualization,20538765960373e9,363
tassize_neutral_anticonformist_cm <- NULL,setup,771710885455832e8,353
hist(log_modifying_IS_cites),visualization,20538765960373e9,363
mech_a_analysis$block <- as.factor(mech_a_analysis$block),data cleaning,865021632052958e7,368
hist(log_extending_IS_cites),visualization,20538765960373e9,363
hist(sqrt_instantiation_IS_cites),visualization,20538765960373e9,363
hist(sqrt_modifying_IS_cites),visualization,20538765960373e9,363
hist(sqrt_extending_IS_cites),visualization,20538765960373e9,363
"experiment_names <- get_experiment_names(""Neutral vs Anticonformist"",      tassize_subsets)",data cleaning,771710885455832e8,353
"t.test(log_modifying_IS_cites, log_extending_IS_cites, var.equal = FALSE)",evaluation,20538765960373e9,363
"comparison <- ""Neutral versus Anticonformist""",data cleaning,771710885455832e8,353
"for (i in 1:nrow(tassize_subsets)) {     exclude_columns <- c(""simulation_run_id"", ""innovation_rate"",          ""model_class_label"", ""sample_size"", ""ta_duration"")     target_label <- ""two_class_label""     exp_name <- experiment_names[i]     ssize <- tassize_subsets[i, ""sample_size""]     ta_dur <- tassize_subsets[i, ""ta_duration""]     subset_df <- get_tassize_subset_ssize_tadur(eq5_neutral_anticonformist_df,          ssize, ta_dur)     result <- do_model_fit_and_test(comparison, experiment_names[i],          ssize, ta_dur, target_label, subset_df, gbm_grid, training_control,          exclude_columns)     tassize_neutral_anticonformist_cm[[exp_name]] <- result$cm     tassize_neutral_anticonformist_model[[exp_name]] <- result$model     tassize_neutral_anticonformist_roc[[exp_name]] <- result$roc     tassize_neutral_anticonformist_results <- rbind(tassize_neutral_anticonformist_results,          result$stats)     if (ssize == 20) {         tassize_neutral_anticonformist_roc_ssize_20[[exp_name]] <- result$roc     }     if (ssize == 10) {         tassize_neutral_anticonformist_roc_ssize_10[[exp_name]] <- result$roc     }     logrow <- sprintf(""row %.0f:  sample size: %2.0f  ta duration: %3.0f numrows: %.0f  elapsed: %.4f"",          i, ssize, ta_dur, nrow(subset_df), result$elapsed)     flog.info(""%s"", logrow, name = ""cl"") }",data cleaning,771710885455832e8,353
library(plyr),setup,20538765960373e9,363
str(mech_a_analysis),evaluation,865021632052958e7,368
"flog.info(""Starting neutral vs. biased subsets"", name = ""cl"")",evaluation,771710885455832e8,353
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,804689643904567e8,369
"data$Treatment.of.IT <- revalue(data$Treatment.of.IT, c(`Ensemble ` = ""Ensemble"",      `Tool ` = ""Tool"", `Computational ` = ""Computational"", `Nominal ` = ""Nominal"",      `Proxy ` = ""Proxy""))",data cleaning,20538765960373e9,363
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",setup,804689643904567e8,369
"WaveQTL.repodir <- scan("".WaveQTL.repodir.txt"", what = character())",setup,804689643904567e8,369
tassize_neutral_biased_results <- data.frame(),setup,771710885455832e8,353
"wd.path = paste0(multiscale.analysis.repodir, ""/analysis/simulation/sample_size/simulation_578/code/"")",setup,804689643904567e8,369
tassize_neutral_biased_roc <- NULL,setup,771710885455832e8,353
setwd(wd.path),setup,804689643904567e8,369
oneway.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),evaluation,20538765960373e9,363
kruskal.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),evaluation,20538765960373e9,363
"model <- aov(data = data, formula = Total.Citations.by..ISI.Web.of.Science...SSCI. ~      Treatment.of.IT)",evaluation,20538765960373e9,363
"TukeyHSD(model, which = ""Treatment.of.IT"", ordered = FALSE, conf.level = 0.95)",evaluation,20538765960373e9,363
"pdf(paste0(wd.path, ""effectsize_578_BAYES.pdf""), height = 5,      width = 7)",export,804689643904567e8,369
"mech_a_analysis <- mech_a_analysis[complete.cases(mech_a_analysis),      ]",data cleaning,865021632052958e7,368
tassize_neutral_biased_roc_ssize_20 <- NULL,setup,771710885455832e8,353
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      NA, 1)",data cleaning,20538765960373e9,363
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      0, 1)",data cleaning,20538765960373e9,363
tassize_neutral_biased_roc_ssize_10 <- NULL,setup,771710885455832e8,353
"abiotic_a_analysis <- read.csv(""abiotic_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~      data$Classification..Exploitation.Exploration),modeling,20538765960373e9,363
tassize_neutral_biased_model <- NULL,setup,771710885455832e8,353
"hdf5.data.path = ""/mnt/lustre/data/internal/genome_db/hg18/dnase/""",import,804689643904567e8,369
"hdf5.mapp.path = ""/mnt/lustre/data/internal/genome_db/hg18/mappability/roger_20bp_mapping_uniqueness.h5""",import,804689643904567e8,369
tassize_neutral_biased_cm <- NULL,setup,771710885455832e8,353
"experiment_names <- get_experiment_names(""Neutral vs Biased"",      tassize_subsets)",setup,771710885455832e8,353
"posthoc1 <- TukeyHSD(x = a1, ""data$Classification..Exploitation.Exploration"",      conf.level = 0.95)",modeling,20538765960373e9,363
str(abiotic_a_analysis),evaluation,865021632052958e7,368
"comparison <- ""Neutral versus Combined Biases""",setup,771710885455832e8,353
abiotic_a_analysis$block <- as.factor(abiotic_a_analysis$block),data cleaning,865021632052958e7,368
"for (i in 1:nrow(tassize_subsets)) {     exclude_columns <- c(""simulation_run_id"", ""innovation_rate"",          ""model_class_label"", ""sample_size"", ""ta_duration"")     target_label <- ""two_class_label""     exp_name <- experiment_names[i]     ssize <- tassize_subsets[i, ""sample_size""]     ta_dur <- tassize_subsets[i, ""ta_duration""]     subset_df <- get_tassize_subset_ssize_tadur(eq5_ta_sampled_df,          ssize, ta_dur)     result <- do_model_fit_and_test(comparison, experiment_names[i],          ssize, ta_dur, target_label, subset_df, gbm_grid, training_control,          exclude_columns)     tassize_neutral_biased_cm[[exp_name]] <- result$cm     tassize_neutral_biased_model[[exp_name]] <- result$model     tassize_neutral_biased_roc[[exp_name]] <- result$roc     tassize_neutral_biased_results <- rbind(tassize_neutral_biased_results,          result$stats)     if (ssize == 20) {         tassize_neutral_biased_roc_ssize_20[[exp_name]] <- result$roc     }     if (ssize == 10) {         tassize_neutral_biased_roc_ssize_10[[exp_name]] <- result$roc     }     logrow <- sprintf(""row %.0f:  sample size: %2.0f  ta duration: %3.0f numrows: %.0f  elapsed: %.4f"",          i, ssize, ta_dur, nrow(subset_df), result$elapsed)     flog.info(""%s"", logrow, name = ""cl"") }",data cleaning,771710885455832e8,353
"geno.info.dir.path = ""/mnt/lustre/home/shim/wavelets/data/DNase/geno_01_step1/geno/""",import,804689643904567e8,369
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Group""])",evaluation,20538765960373e9,363
hist(wind_a_analysis$seednum),visualization,865021632052958e7,368
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Artifact""])",communication,20538765960373e9,363
"if (length(clargs) == 0) {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""classification-ta-sampled-results-gbm.RData"")     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""classification-ta-sampled-results-gbm-dfonly.RData"") } else {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""classification-ta-sampled-results-gbm.RData"",          args = clargs)     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-5"",          filename = ""classification-ta-sampled-results-gbm-dfonly.RData"",          args = clargs) }",data cleaning,771710885455832e8,353
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Individual""])",communication,20538765960373e9,363
"flog.info(""Saving results of analysis to R environment snapshot: %s"",      image_file, name = ""cl"")",data cleaning,771710885455832e8,353
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Artifact""])",communication,20538765960373e9,363
"save(tassize_neutral_conformist_cm, tassize_neutral_conformist_results,      tassize_neutral_conformist_model, tassize_neutral_conformist_roc,      tassize_neutral_conformist_roc_ssize_10, tassize_neutral_conformist_roc_ssize_20,      tassize_neutral_anticonformist_results, tassize_neutral_anticonformist_model,      tassize_neutral_anticonformist_roc, tassize_neutral_anticonformist_roc_ssize_20,      tassize_neutral_anticonformist_roc_ssize_10, tassize_neutral_anticonformist_cm,      tassize_neutral_biased_results, tassize_neutral_biased_model,      tassize_neutral_biased_roc, tassize_neutral_biased_roc_ssize_20,      tassize_neutral_biased_roc_ssize_10, tassize_neutral_biased_cm,      file = image_file)",data cleaning,771710885455832e8,353
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Market""])",communication,20538765960373e9,363
"geno.dir.path = ""/mnt/lustre/home/shim/wavelets/data/DNase/geno_01_step1/geno_maf/""",setup,804689643904567e8,369
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Group""])",communication,20538765960373e9,363
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Individual""])",communication,20538765960373e9,363
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Market""])",communication,20538765960373e9,363
"flog.info(""Saving just data frame of results of analysis to R environment snapshot: %s"",      image_file_results, name = ""cl"")",evaluation,771710885455832e8,353
a2 <- aov(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),modeling,20538765960373e9,363
"save(tassize_neutral_conformist_results, tassize_neutral_anticonformist_results,      tassize_neutral_biased_results, file = image_file_results)",export,771710885455832e8,353
"locus.path = ""/mnt/lustre/home/shim/wavelets/data/DNase/region_01_sel_step1/""",not sure,804689643904567e8,369
"boxplot(wind_a_analysis$seednum ~ wind_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Seed abundance per treatment"")",visualization,865021632052958e7,368
"posthoc2 <- TukeyHSD(x = a2, ""data$Treatment.of.IT"", conf.level = 0.95)",modeling,20538765960373e9,363
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Computational""])",communication,20538765960373e9,363
"with(wind_a_analysis, plot(treatment, seednum))",visualization,865021632052958e7,368
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Proxy""])",communication,20538765960373e9,363
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Nominal""])",communication,20538765960373e9,363
"flog.info(""Analysis complete"", name = ""cl"")",evaluation,771710885455832e8,353
a3 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~      data$Classification..Exploitation.Exploration),modeling,20538765960373e9,363
total_time <- proc.time() - ptm,setup,771710885455832e8,353
"inds.IDs = scan(paste0(WaveQTL.repodir, ""/data/Shim_2014_etc/DNaseI.individuals.oneline.txt""),      what = """")",import,804689643904567e8,369
"flog.info(""Elapsed time in analysis: %.3f"", total_time[3], name = ""cl"")",evaluation,771710885455832e8,353
"vif(glm(seednum ~ treatment + block, data = wind_a_analysis))",evaluation,865021632052958e7,368
"source(paste0(multiscale.analysis.repodir, ""/src/R/prepare.DNase.funcs.R""))",data cleaning,804689643904567e8,369
"ggplot(wind_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,865021632052958e7,368
"posthoc3 <- TukeyHSD(x = a3, ""data$Classification..Exploitation.Exploration"",      conf.level = 0.95)",modeling,20538765960373e9,363
"data = read.table(""/mnt/lustre/home/shim/wavelets/revision/etc/simu.578.sites.txt"",      header = T)",import,804689643904567e8,369
"ggplot(wind_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,865021632052958e7,368
"ggplot(wind_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,865021632052958e7,368
chr.list = data$chr,exploratory,804689643904567e8,369
instantiation_total_cites[instantiation_total_cites == 0] <- 1,data cleaning,20538765960373e9,363
"ggplot(wind_a_analysis, aes(block, seednum, color = block)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,865021632052958e7,368
site.list = data$site,exploratory,804689643904567e8,369
genoIX.list = data$genoIX,exploratory,804689643904567e8,369
"with(wind_a_analysis, table(block, treatment))",visualization,865021632052958e7,368
m1 <- displ$new(instantiation_total_cites),data cleaning,20538765960373e9,363
"ggplot(wind_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,865021632052958e7,368
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",export,865021632052958e7,368
"wind_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() + geom_bar(aes(treatment,      fill = as.factor(treatment))) + facet_grid(plot ~ .) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,865021632052958e7,368
"ggplot(wind_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,865021632052958e7,368
"wind.abund.glm <- glmer(seednum ~ block + treatment + (1 | plot),      data = wind_a_analysis, family = poisson)",modeling,865021632052958e7,368
library(dplyr),setup,881048736628145e8,370
library(tidyr),setup,881048736628145e8,370
library(ggplot2),setup,881048736628145e8,370
library(scatterplot3d),setup,881048736628145e8,370
library(lme4),setup,881048736628145e8,370
"wind_resid <- resid_panel(resid(wind.abund.glm), fitted(wind.abund.glm),      bins = 20)",visualization,865021632052958e7,368
library(psych),setup,881048736628145e8,370
library(stats),setup,881048736628145e8,370
library(randomForest),setup,440178553108126e8,363
library(caret),setup,440178553108126e8,363
library(scales),setup,881048736628145e8,370
library(doMC),setup,440178553108126e8,363
library(mmadsenr),setup,440178553108126e8,363
library(smacof),setup,881048736628145e8,370
library(futile.logger),setup,440178553108126e8,363
library(dplyr),setup,440178553108126e8,363
library(ggthemes),setup,440178553108126e8,363
wind.abund.res <- resid(wind.abund.glm),export,865021632052958e7,368
rm(list = ls()),setup,881048736628145e8,370
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""population-classification.log"")",setup,440178553108126e8,363
dev.off(),setup,881048736628145e8,370
wind.abund.pred <- predict(wind.abund.glm),modeling,865021632052958e7,368
"flog.appender(appender.file(log_file), name = ""cl"")",setup,440178553108126e8,363
"plot(wind.abund.pred, wind.abund.res, ylab = ""Residuals"", xlab = ""predicted values"",      main = ""resid vs pred"")",visualization,865021632052958e7,368
clargs <- commandArgs(trailingOnly = TRUE),setup,440178553108126e8,363
"abline(0, 0)",visualization,865021632052958e7,368
"d = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_charmeans.csv"")[-1]",import,881048736628145e8,370
qqnorm(wind.abund.res),visualization,865021632052958e7,368
"qqline(wind.abund.res, col = ""red"")",visualization,865021632052958e7,368
hist(wind.abund.res),visualization,865021632052958e7,368
glimpse(d),exploratory,881048736628145e8,370
"anova(wind.abund.glm, test = ""Chi"")",modeling,865021632052958e7,368
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-4-population-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-4-population-data.rda"", args = clargs) }",setup,440178553108126e8,363
"dd = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_data_anonymized.csv"")[-1]",import,881048736628145e8,370
load(pop_data_file),import,440178553108126e8,363
summary(wind.abund.glm),exploratory,865021632052958e7,368
glimpse(dd),exploratory,881048736628145e8,370
"summary(glht(wind.abund.glm, mcp(treatment = ""Tukey"")))",exploratory,865021632052958e7,368
"d_white = d %>% filter(ethnicity == ""white"")",data cleaning,881048736628145e8,370
"dd_white = dd %>% filter(ethnicity == ""white"")",data cleaning,881048736628145e8,370
"flog.info(""Loaded data file: %s"", pop_data_file, name = ""cl"")",communication,440178553108126e8,363
"flog.info(""Beginning classification analysis of equifinality-4 data sets"",      name = ""cl"")",communication,440178553108126e8,363
"d_nonwhite = d %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,881048736628145e8,370
"1 - pf(1.4454, 3, 7)",evaluation,865021632052958e7,368
"dd_nonwhite = dd %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,881048736628145e8,370
"ptukey(abs(-0.748) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
"ptukey(abs(-2.469) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
"ptukey(0.562 * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
num_cores <- get_parallel_cores_given_os(dev = TRUE),setup,440178553108126e8,363
"ptukey(1.708 * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
"ptukey(0.128 * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
"flog.info(""Number of cores used in analysis: %s"", num_cores,      name = ""cl"")",communication,440178553108126e8,363
registerDoMC(cores = num_cores),setup,440178553108126e8,363
"ptukey(1.672 * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,865021632052958e7,368
hist(animal_a_analysis$seednum),visualization,865021632052958e7,368
"boxplot(animal_a_analysis$seednum ~ animal_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Animal seed dispersed abundance per treatment"")",visualization,865021632052958e7,368
"with(animal_a_analysis, plot(treatment, seednum))",visualization,865021632052958e7,368
"gbm_grid <- expand.grid(.interaction.depth = (1:6) * 2, .n.trees = (2:10) *      50, .shrinkage = 0.05)",setup,440178553108126e8,363
"vif(glm(seednum ~ treatment + block, data = animal_a_analysis))",evaluation,865021632052958e7,368
"ggplot(animal_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,865021632052958e7,368
"ggplot(animal_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,865021632052958e7,368
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",modeling,440178553108126e8,363
"ggplot(animal_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,865021632052958e7,368
"ggplot(animal_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,865021632052958e7,368
seed_value <- 58132133,setup,440178553108126e8,363
set.seed(seed_value),setup,440178553108126e8,363
"flog.info(""RNG seed to replicate this analysis: %s"", seed_value,      name = ""cl"")",communication,440178553108126e8,363
"with(animal_a_analysis, table(block, treatment))",exploratory,865021632052958e7,368
training_set_fraction <- 0.8,setup,440178553108126e8,363
"ggplot(animal_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,865021632052958e7,368
test_set_fraction <- 1 - training_set_fraction,setup,440178553108126e8,363
"experiment_names <- c(""Population Census"")",setup,440178553108126e8,363
popsampled_results <- data.frame(),setup,440178553108126e8,363
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",communication,865021632052958e7,368
results_roc <- NULL,setup,440178553108126e8,363
results_model <- NULL,setup,440178553108126e8,363
results_cm <- NULL,setup,440178553108126e8,363
"flog.info(""Starting analysis of population census data"", name = ""cl"")",communication,440178553108126e8,363
"animal_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() +      geom_bar(aes(treatment, fill = as.factor(treatment))) + facet_grid(plot ~      .) + scale_fill_manual(values = cbPalette) + theme(legend.position = ""none"")",visualization,865021632052958e7,368
"ggplot(animal_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,865021632052958e7,368
i <- 1,setup,440178553108126e8,363
"animal.abund.glm <- glmer(seednum ~ block + treatment + (1 |      plot), data = animal_a_analysis, family = poisson)",modeling,865021632052958e7,368
exp_name <- experiment_names[i],data cleaning,440178553108126e8,363
"animal_resid <- resid_panel(resid(animal.abund.glm), fitted(animal.abund.glm),      bins = 20)",visualization,865021632052958e7,368
"valdata$two_class_label <- factor(ifelse(valdata$model_class_label ==      ""allneutral"", ""neutral"", ""biased""))",setup,440178553108126e8,363
"exclude_columns <- c(""simulation_run_id"", ""model_class_label"",      ""innovation_rate"")",setup,440178553108126e8,363
"model <- train_gbm_classifier(valdata, training_set_fraction,      ""two_class_label"", gbm_grid, training_control, exclude_columns,      verbose = FALSE)",modeling,440178553108126e8,363
animal_resid,exploratory,865021632052958e7,368
animal.abund.res <- resid(animal.abund.glm),modeling,865021632052958e7,368
"results_model[[""population_census""]] <- model$tunedmodel",data cleaning,440178553108126e8,363
animal.abund.pred <- predict(animal.abund.glm),modeling,865021632052958e7,368
"plot(animal.abund.pred, animal.abund.res, ylab = ""Residuals"",      xlab = ""predicted values"", main = ""resid vs pred"")",visualization,865021632052958e7,368
"predictions <- predict(model$tunedmodel, newdata = model$test_data)",modeling,440178553108126e8,363
"abline(0, 0)",visualization,865021632052958e7,368
"cm <- confusionMatrix(predictions, model$test_data$two_class_label)",modeling,440178553108126e8,363
qqnorm(animal.abund.res),evaluation,865021632052958e7,368
"qqline(animal.abund.res, col = ""red"")",visualization,865021632052958e7,368
hist(animal.abund.res),visualization,865021632052958e7,368
"anova(animal.abund.glm, test = ""F"")",modeling,865021632052958e7,368
results <- get_parsed_binary_confusion_matrix_stats(cm),evaluation,440178553108126e8,363
summary(animal.abund.glm),evaluation,865021632052958e7,368
results$experiments <- exp_name,evaluation,440178553108126e8,363
"1 - pf(2.5371, 3, 7)",evaluation,865021632052958e7,368
results$elapsed <- model$elapsed,evaluation,440178553108126e8,363
"summary(glht(animal.abund.glm, mcp(treatment = ""Tukey"")))",exploratory,865021632052958e7,368
"results_cm[[""population_census""]] <- cm",data cleaning,440178553108126e8,363
"ptukey(abs(0.314) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(abs(0.01) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(abs(-2.235) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(abs(-0.305) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"population_roc <- calculate_roc_binary_classifier(model$tunedmodel,      model$test_data, ""two_class_label"", exp_name)",modeling,440178553108126e8,363
"ptukey(abs(-2.52) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(abs(-2.244) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
results$auc <- unlist(population_roc$auc@y.values),evaluation,440178553108126e8,363
hist(mech_a_analysis$seednum),visualization,865021632052958e7,368
"boxplot(mech_a_analysis$seednum ~ mech_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Mechanical seed dispersed abundance per treatment"")",visualization,865021632052958e7,368
"ggplot(mech_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,865021632052958e7,368
"ggplot(mech_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,865021632052958e7,368
"ggplot(mech_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,865021632052958e7,368
"ggplot(mech_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,865021632052958e7,368
hist(abiotic_a_analysis$seednum),visualization,865021632052958e7,368
"results_roc[[""population_census""]] <- population_roc",data cleaning,440178553108126e8,363
"boxplot(abiotic_a_analysis$seednum ~ abiotic_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Seed abundance per treatment"")",visualization,865021632052958e7,368
"with(abiotic_a_analysis, plot(treatment, seednum))",visualization,865021632052958e7,368
"vif(glm(seednum ~ treatment + block, data = abiotic_a_analysis))",evaluation,865021632052958e7,368
"results <- rbind(popsampled_results, results)",not sure,440178553108126e8,363
"ggplot(abiotic_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,865021632052958e7,368
"ggplot(abiotic_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,865021632052958e7,368
"ggplot(abiotic_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,865021632052958e7,368
"ggplot(abiotic_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,865021632052958e7,368
"if (length(clargs) == 0) {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""classification-population-results-gbm.RData"")     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""classification-population-results-gbm-dfOnly.RData"") } else {     image_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""classification-population-results-gbm.RData"",          args = clargs)     image_file_results <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""classification-population-results-gbm-dfOnly.RData"",          args = clargs) }",setup,440178553108126e8,363
"flog.info(""Saving results of analysis to R environment snapshot: %s"",      image_file, name = ""cl"")",communication,440178553108126e8,363
"with(abiotic_a_analysis, table(block, treatment))",exploratory,865021632052958e7,368
"ggplot(abiotic_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,865021632052958e7,368
"save(results, results_model, results_roc, results_cm, file = image_file)",export,440178553108126e8,363
"flog.info(""Saving just data frame of results of analysis to R environment snapshot: %s"",      image_file_results, name = ""cl"")",communication,440178553108126e8,363
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",not sure,865021632052958e7,368
"save(results, file = image_file_results)",export,440178553108126e8,363
"flog.info(""Analysis complete"", name = ""cl"")",communication,440178553108126e8,363
"abiotic_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() +      geom_bar(aes(treatment, fill = as.factor(treatment))) + facet_grid(plot ~      .) + scale_fill_manual(values = cbPalette) + theme(legend.position = ""none"")",visualization,865021632052958e7,368
"ggplot(abiotic_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,865021632052958e7,368
"abiotic.abund.glm <- glmer(seednum ~ block + treatment + (1 |      plot), data = abiotic_a_analysis, family = poisson)",modeling,865021632052958e7,368
"abiotic_resid <- resid_panel(resid(abiotic.abund.glm), fitted(abiotic.abund.glm),      bins = 20)",modeling,865021632052958e7,368
require(plyr),setup,440178553108126e8,363
"TCCZe <- readRDS(""./geo_data/processed/TCCZ_wtoppick.rdata"")",import,440178553108126e8,363
"wl <- readRDS(""./srs_data/processed/wl.rdata"")",import,440178553108126e8,363
"wlavg <- readRDS(""./srs_data/processed/wlavg.rdata"")",import,440178553108126e8,363
"wlp1988 <- wl[wl$MYEAR > 1987, ]",data cleaning,440178553108126e8,363
abiotic_resid,exploratory,865021632052958e7,368
"wll2 <- split(wlp1988, wlp1988$MYEAR)",data cleaning,440178553108126e8,363
abiotic.abund.res <- resid(abiotic.abund.glm),export,865021632052958e7,368
"source(""./analysis/raw_scripts/create_subsurface_parameters_vars.R"")",setup,440178553108126e8,363
abiotic.abund.pred <- predict(abiotic.abund.glm),export,865021632052958e7,368
"plot(abiotic.abund.pred, abiotic.abund.res, ylab = ""Residuals"",      xlab = ""predicted values"", main = ""resid vs pred"")",visualization,865021632052958e7,368
"abline(0, 0)",visualization,865021632052958e7,368
alphaloess1 <- 0.25,setup,440178553108126e8,363
alphaloess2 <- 0.15,setup,440178553108126e8,363
qqnorm(abiotic.abund.res),evaluation,865021632052958e7,368
alphaloesswl <- 0.25,setup,440178553108126e8,363
"qqline(abiotic.abund.res, col = ""red"")",evaluation,865021632052958e7,368
hist(abiotic.abund.res),visualization,865021632052958e7,368
"TCCZ.loess1 <- loess(TCCZ_top ~ EASTING + NORTHING, data = TCCZe,      degree = 2, span = alphaloess1, normalize = FALSE, method = c(""loess""),      control = lcontrol)",modeling,440178553108126e8,363
"anova(abiotic.abund.glm, test = ""F"")",modeling,865021632052958e7,368
"TCCZ.loess1b <- loess(TCCZ_top ~ EASTING + NORTHING, data = TCCZe,      degree = 2, span = alphaloess2, normalize = FALSE, method = c(""loess""),      control = lcontrol)",modeling,440178553108126e8,363
summary(abiotic.abund.glm),evaluation,865021632052958e7,368
"TCCZ.lm <- lm(TCCZ_top ~ EASTING + NORTHING, data = TCCZe)",modeling,440178553108126e8,363
"1 - pf(2.2037, 3, 7)",evaluation,865021632052958e7,368
"summary(glht(abiotic.abund.glm, mcp(treatment = ""Tukey"")))",evaluation,865021632052958e7,368
"ptukey(abs(-0.761) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(abs(-2.467) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"pre1 <- predict(TCCZ.loess1, se = TRUE)",evaluation,440178553108126e8,363
"ptukey(0.583 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(1.708 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(0.104 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"ptukey(1.648 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,865021632052958e7,368
"pre1b <- predict(TCCZ.loess1b, se = TRUE)",evaluation,440178553108126e8,363
"pre1lm <- predict(TCCZ.lm, se = TRUE, interval = ""confidence"",      level = 0.95)",evaluation,440178553108126e8,363
"liana_a_analysis <- read.csv(""liana_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
TCCZ.pred <- TCCZe,not sure,440178553108126e8,363
"liana_a_analysis <- liana_a_analysis[complete.cases(liana_a_analysis),      ]",data cleaning,865021632052958e7,368
TCCZ.pred$TCCZ.fit <- pre1$fit,not sure,440178553108126e8,363
rm(list = ls()),setup,98804941563867e9,371
liana_a_analysis$block <- as.factor(liana_a_analysis$block),data cleaning,865021632052958e7,368
TCCZ.pred$TCCZ.se.fit <- pre1$se.fit,not sure,440178553108126e8,363
"tree_a_analysis <- read.csv(""tree_abund_tidy.csv"", header = TRUE)",import,865021632052958e7,368
TCCZ.pred$TCCZ.fitb <- pre1b$fit,data cleaning,440178553108126e8,363
TCCZ.pred$TCCZ.se.fitb <- pre1b$se.fit,data cleaning,440178553108126e8,363
"load(""~/Desktop/vote_analysis/read/analysis_data.Rdata"")",import,98804941563867e9,371
"TCCZ.pred$TCCZ.fitlm <- pre1lm$fit[, 1]",data cleaning,440178553108126e8,363
TCCZ.pred$TCCZ.se.fitlm <- pre1lm$se.fit,data cleaning,440178553108126e8,363
library(smacof),setup,98804941563867e9,371
"TCCZ.pred$TCCZ.fitlmupr <- pre1lm$fit[, 2]",data cleaning,440178553108126e8,363
"TCCZ.pred$TCCZ.fitlmlwr <- pre1lm$fit[, 3]",data cleaning,440178553108126e8,363
TCCZ.pred$ehat.l1 <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fit,evaluation,440178553108126e8,363
TCCZ.pred$ehat.l1b <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fitb,evaluation,440178553108126e8,363
TCCZ.pred$ehat.lm <- TCCZ.pred$TCCZ_top - TCCZ.pred$TCCZ.fitlm,evaluation,440178553108126e8,363
"saveRDS(TCCZ.pred, ""./analysis/processed_data/TCCZloesspred.rdata"")",export,440178553108126e8,363
thperyear <- wl,setup,440178553108126e8,363
"keep <- !indieners %in% c(""NOT KNOWN"", ""NOT APPLICABLE"", """")",data cleaning,98804941563867e9,371
"pre2 <- predict(TCCZ.loess1, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE)",evaluation,440178553108126e8,363
"pre2b <- predict(TCCZ.loess1b, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE)",evaluation,440178553108126e8,363
"pre2lm <- predict(TCCZ.lm, newdata = wl[, c(""EASTING"", ""NORTHING"")],      se = TRUE, interval = ""prediction"", level = 0.95)",evaluation,440178553108126e8,363
"results <- results[keep, ]",data cleaning,98804941563867e9,371
thperyear$TCCZ.fit <- pre2$fit,data cleaning,440178553108126e8,363
indieners <- indieners[keep],data cleaning,98804941563867e9,371
vote.id <- vote.id[keep],data cleaning,98804941563867e9,371
thperyear$TCCZ.se.fit <- pre2$se.fit,data cleaning,440178553108126e8,363
thperyear$TCCZ.fitb <- pre2b$fit,data cleaning,440178553108126e8,363
thperyear$TCCZ.se.fitb <- pre2b$se.fit,data cleaning,440178553108126e8,363
"thperyear$TCCZ.fitlm <- pre2lm$fit[, 1]",data cleaning,440178553108126e8,363
thperyear$TCCZ.se.fitlm <- pre2lm$se.fit,data cleaning,440178553108126e8,363
"thperyear$TCCZ.fitlmupr <- pre2lm$fit[, 2]",data cleaning,440178553108126e8,363
"thperyear$TCCZ.fitlmlwr <- pre2lm$fit[, 3]",data cleaning,440178553108126e8,363
dist.mat <- dist(t(results)),modeling,98804941563867e9,371
"mds.sol <- mds(dist.mat, ndim = 2, type = ""mspline"")",modeling,98804941563867e9,371
"thperyear[thperyear$TCCZ.fitb < 0, c(""STATION_ID"", ""EASTING"",      ""NORTHING"", ""mean"", ""TCCZ.fit"", ""TCCZ.fitb"", ""TCCZ.fitlm"")]",data cleaning,440178553108126e8,363
mds.sol,modeling,98804941563867e9,371
"thperyear[thperyear$TCCZ.se.fitb > 200, ]",data cleaning,440178553108126e8,363
thperyear$h <- thperyear$mean - thperyear$TCCZ.fit,data cleaning,440178553108126e8,363
"plot(mds.sol, ""Shepard"")",visualization,98804941563867e9,371
thperyear$hb <- thperyear$mean - thperyear$TCCZ.fitb,evaluation,440178553108126e8,363
thperyear$hlm <- thperyear$mean - thperyear$TCCZ.fitlm,evaluation,440178553108126e8,363
"thperyear$hse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fit^2)",evaluation,440178553108126e8,363
"thperyear$hbse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fitb^2)",evaluation,440178553108126e8,363
"thperyear$hlmse <- sqrt(pmax(1, thperyear$sd, na.rm = TRUE)^2 +      thperyear$TCCZ.se.fitlm^2)",evaluation,440178553108126e8,363
summary(thperyear),communication,440178553108126e8,363
thperyear$h[thperyear$h <= 0] <- NA,data cleaning,440178553108126e8,363
thperyear$hb[thperyear$hb <= 0] <- NA,data cleaning,440178553108126e8,363
thperyear$hlm[thperyear$hlm <= 0] <- NA,data cleaning,440178553108126e8,363
"thperyear.cleanh <- thperyear[!is.na(thperyear$h), ]",data cleaning,440178553108126e8,363
"thperyear.cleanhb <- thperyear[!is.na(thperyear$hb), ]",data cleaning,440178553108126e8,363
"thperyear.cleanhlm <- thperyear[!is.na(thperyear$hlm), ]",data cleaning,440178553108126e8,363
thperyear.cleanh$hserel <- thperyear.cleanh$hse/thperyear.cleanh$h,data cleaning,440178553108126e8,363
thperyear.cleanhb$hbserel <- thperyear.cleanhb$hbse/thperyear.cleanhb$hb,evaluation,440178553108126e8,363
thperyear.cleanhlm$hlmserel <- thperyear.cleanhlm$hlmse/thperyear.cleanhlm$hlm,evaluation,440178553108126e8,363
"th.avg.peryearh <- ddply(thperyear.cleanh, c(""MYEAR""), function(x) c(counth = nrow(x),      h.mean = mean(x$h), h.median = median(x$h), h.sd = sd(x$h),      h.mad = mad(x$h), h.min = min(x$h), h.max = max(x$h)))",data cleaning,440178553108126e8,363
"th.avg.peryearhb <- ddply(thperyear.cleanhb, c(""MYEAR""), function(x) c(counthb = nrow(x),      hb.mean = mean(x$hb), hb.median = median(x$hb), hb.sd = sd(x$hb),      hb.mad = mad(x$hb), hb.min = min(x$hb), hb.max = max(x$hb)))",evaluation,440178553108126e8,363
"th.avg.peryearhlm <- ddply(thperyear.cleanhlm, c(""MYEAR""), function(x) c(counthlm = nrow(x),      hlm.mean = mean(x$hlm), hlm.median = median(x$hlm), hlm.sd = sd(x$hlm),      hlm.mad = mad(x$hlm), hlm.min = min(x$hlm), hlm.max = max(x$hlm)))",evaluation,440178553108126e8,363
"pre3 <- predict(TCCZ.loess1, newdata = interpolation.grid, se = TRUE)",evaluation,440178553108126e8,363
"pre3b <- predict(TCCZ.loess1b, newdata = interpolation.grid,      se = TRUE)",evaluation,440178553108126e8,363
"pre3lm <- predict(TCCZ.lm, newdata = interpolation.grid, se = TRUE,      interval = ""prediction"", level = 0.95)",evaluation,440178553108126e8,363
thicknessUAZ <- interpolation.grid,setup,440178553108126e8,363
dim(pre3$fit),evaluation,440178553108126e8,363
thicknessUAZ$TCCZfit <- as.vector(pre3$fit),data cleaning,440178553108126e8,363
thicknessUAZ$TCCZfitb <- as.vector(pre3b$fit),data cleaning,440178553108126e8,363
"thicknessUAZ$TCCZfitlm <- as.vector(pre3lm$fit[, 1])",data cleaning,440178553108126e8,363
thicknessUAZ$TCCZsefit <- as.vector(pre3$se.fit),data cleaning,440178553108126e8,363
thicknessUAZ$TCCZsefitb <- as.vector(pre3b$se.fit),data cleaning,440178553108126e8,363
thicknessUAZ$TCCZsefitlm <- as.vector(pre3lm$se.fit),data cleaning,440178553108126e8,363
ov <- dim(thicknessUAZ)[2],data cleaning,440178553108126e8,363
nbparamUAZ <- 4,setup,440178553108126e8,363
"nbnegthickvals <- vector(mode = ""integer"", length = length(wll2))",evaluation,440178553108126e8,363
"nbNAthickvals <- vector(mode = ""integer"", length = length(wll2))",evaluation,440178553108126e8,363
"for (kk in 1:length(wll2)) {     w.loess <- loess(mean ~ EASTING + NORTHING, data = wll2[[kk]],          degree = 1, span = alphaloesswl)     predw <- predict(w.loess, newdata = interpolation.grid, se = TRUE)     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 1] <- as.vector(predw$fit)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 1] <- paste0(""wl"",          names(wll2)[kk])     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 2] <- as.vector(predw$se.fit)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 2] <- paste0(""se.wl"",          names(wll2)[kk])     thickness <- as.vector(predw$fit) - thicknessUAZ$TCCZfitb     nbnegthickvals[kk] <- sum(thickness < 0, na.rm = TRUE)     thickness[thickness < 0] <- NA     nbNAthickvals[kk] <- sum(is.na(thickness))     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 3] <- thickness     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 3] <- paste0(""e"",          names(wll2)[kk])     thicknessUAZ[nbparamUAZ * (kk - 1) + ov + 4] <- sqrt(thicknessUAZ[nbparamUAZ *          (kk - 1) + ov + 2]^2 + thicknessUAZ$TCCZsefitb^2)     names(thicknessUAZ)[nbparamUAZ * (kk - 1) + ov + 4] <- paste0(""se.e"",          names(wll2)[kk]) }",modeling,440178553108126e8,363
interpolation.gridC <- interpolation.grid,data cleaning,440178553108126e8,363
thicknessLAZ <- interpolation.gridC,data cleaning,440178553108126e8,363
thicknessLAZ$e.in.m <- Cth,data cleaning,440178553108126e8,363
rm(interpolation.gridC),not sure,440178553108126e8,363
"thickness.regression.diagnostics <- as.data.frame(cbind(nbnegthickvals,      nbNAthickvals))",data cleaning,440178553108126e8,363
"saveRDS(thicknessUAZ, file = ""./analysis/processed_data/thicknessUAZ.rdata"")",export,440178553108126e8,363
"saveRDS(thicknessLAZ, file = ""./analysis/processed_data/thicknessLAZ.rdata"")",export,440178553108126e8,363
"saveRDS(thickness.regression.diagnostics, file = ""./analysis/processed_data/diagnostics/thickness.regression.diagnostics.rdata"")",export,440178553108126e8,363
"data <- read.table(""data/forestplot_160_spatial_data_UPDATE.txt"",      header = TRUE)",import,440178553108126e8,363
"species <- read.table(""data/dden_adult_new.txt"", header = TRUE)$sp",import,440178553108126e8,363
"occurance <- rep(0, dim(data)[1])",setup,440178553108126e8,363
fun <- function(i) {     occurance[which(data$sp == as.character(i))] <- 1     data$occurance <- occurance     data$species <- i     return(data) },setup,440178553108126e8,363
"species_occurance_data <- foreach(i = species, .combine = rbind) %do%      fun(i)",evaluation,440178553108126e8,363
str(species_occurance_data),communication,440178553108126e8,363
"ggplot(species_occurance_data, aes(x = elev, y = occurance, color = species)) +      facet_wrap(~species) + geom_point() + stat_smooth()",visualization,440178553108126e8,363
"write.table(species_occurance_data, file = ""./analysis/adult_distribution_analysis/data/species_occurance_data.txt"")",export,440178553108126e8,363
library(drake),setup,440178553108126e8,363
library(magrittr),setup,440178553108126e8,363
library(ggplot2),setup,440178553108126e8,363
rm(list = ls()),setup,287216875934973e8,372
"pkgconfig::set_config(`drake::strings_in_dots` = ""literals"")",setup,440178553108126e8,363
"devtools::load_all(""."")",setup,440178553108126e8,363
"expose_imports(""hector.permafrost.emit"")",setup,440178553108126e8,363
"rcps <- paste0(""RCP"", c(""26"", ""45"", ""6"", ""85""))",setup,440178553108126e8,363
"gcam_root <- getOption(""gcam_root"")",setup,440178553108126e8,363
"stopifnot(!is.null(gcam_root), file.exists(gcam_root))",setup,440178553108126e8,363
"gcam_climate <- file.path(gcam_root, ""input"", ""climate"")",setup,440178553108126e8,363
"gcam_exe <- file.path(gcam_root, ""exe"")",setup,440178553108126e8,363
mtco2_gtc <- (12/48) * (1/1000),evaluation,440178553108126e8,363
mtch4_gtc <- (12/16) * (1/1000),evaluation,440178553108126e8,363
"schaefer_template <- drake_plan(schaefer_file = file_in(""analysis/data/raw_data/schaefer_teb_rpc_ZZZ.csv""),      schaefer = read_and_interpolate(schaefer_file_ZZZ, 2050,          2100) %>% dplyr::mutate(value = c(0, diff(value)), exo_ch4_emissions = 0) %>%          dplyr::select(Date = year, exo_emissions = value, exo_ch4_emissions))",data cleaning,440178553108126e8,363
"schaefer_plan <- evaluate_plan(schaefer_template, rules = list(ZZZ = c(""min"",      ""mean"", ""max"")))",modeling,440178553108126e8,363
"hope_template <- drake_plan(hope_ch4_file = file_in(""analysis/data/raw_data/hope_2016_MtCH4_ZZZ.csv""),      hope_co2_file = file_in(""analysis/data/raw_data/hope_2016_MtCO2_ZZZ.csv""),      hope = dplyr::full_join(read_and_interpolate(hope_co2_file_ZZZ,          2012, 2100, scale = mtco2_gtc), read_and_interpolate(hope_ch4_file_ZZZ,          2012, 2100, scale = 1), by = ""year"") %>% dplyr::select(Date = year,          exo_emissions = value.x, exo_ch4_emissions = value.y))",data cleaning,440178553108126e8,363
"hope_plan <- evaluate_plan(hope_template, rules = list(ZZZ = c(""lo"",      ""mean"", ""hi"")))",evaluation,440178553108126e8,363
"scenarios_plan <- bind_plans(schaefer_plan, hope_plan) %>% bind_plans(drake_plan(no_permafrost = tibble::tibble(Date = 2012:2100,      exo_emissions = 0, exo_ch4_emissions = 0)))",data cleaning,440178553108126e8,363
"combined_plan <- scenarios_plan %>% dplyr::filter(!grepl(""_file_"",      target)) %>% gather_plan(target = ""scenario_list"") %>% bind_plans(drake_plan(all_scenarios = dplyr::bind_rows(scenario_list,      .id = ""scenario"")))",data cleaning,440178553108126e8,363
"run_template <- drake_plan(results = run_hector_emissions(rcp__,      emissions__, name = paste0(""emissions__"", ""."", ""RCPrcp__"")))",modeling,440178553108126e8,363
"scenario_names <- c(""no_permafrost"", paste0(""hope_"", c(""lo"",      ""mean"", ""hi"")), paste0(""schaefer_"", c(""min"", ""mean"", ""max"")))",setup,440178553108126e8,363
"run_plan <- evaluate_plan(run_template, list(emissions__ = scenario_names,      rcp__ = c(""26"", ""45"", ""60"", ""85"")))",evaluation,440178553108126e8,363
"results_plan <- bind_plans(gather_plan(run_plan, target = ""results_list""),      drake_plan(all_results = results_list %>% dplyr::bind_rows(.id = ""id"") %>%          tibble::as_tibble() %>% tidyr::separate(scenario, c(""permafrost"",          ""RCP""), sep = ""\\."") %>% dplyr::mutate(permafrost = forcats::fct_inorder(permafrost),          RCP = forcats::fct_inorder(RCP))))",data cleaning,440178553108126e8,363
"gcam_plan <- drake_plan(csv = readr::write_csv(ZZZ, file_out(""CLIM/ZZZ.csv"")),      ini = make_ini(file_in(""CLIM/ZZZ.csv""), file_in(""CLIM/hector-gcam.ini""),          file_out(""CLIM/ZZZ.ini"")), xml = make_xmls(ini_ZZZ, file_in(""GCAM/input/gcamdata/xml/hector.xml""),          file_in(""EXE/configuration_ref.xml""), file_out(""GCAM/input/gcamdata/xml/hector_ZZZ.xml""),          file_out(""EXE/config_ZZZ.xml""), gcam_scenario_name = ""ZZZ"")) %>%      evaluate_plan(rules = list(ZZZ = scenario_names)) %>% evaluate_plan(rules = list(GCAM = gcam_root,      EXE = gcam_exe, CLIM = gcam_climate), rename = FALSE)",not sure,440178553108126e8,363
"plot_plan <- drake_plan(gcam_project = rgcam::loadProject(file_in(""gcam-output/permafrost.dat"")),      gcam_results = c(Ca = ""CO2 concentrations"", Ftot = ""Climate forcing"",          Tgav = ""Global mean temperature"") %>% purrr::imap_dfr(function(x,          n) purrr::map_dfr(gcam_project, x) %>% dplyr::mutate(variable = n,          RCP = ""GCAM"")) %>% dplyr::rename(permafrost = scenario,          units = Units), combined_results = suppressWarnings(dplyr::bind_rows(all_results,          gcam_results)), climate_plot = combined_results %>% dplyr::filter(year >          2000, year <= 2100, !grepl(""schaefer"", permafrost), variable ==          c(""Tgav"")) %>% dplyr::mutate(variable = factor(variable,          c(""Tgav"", ""Ca"", ""Ftot"")) %>% forcats::fct_recode(`Global temperature` = ""Tgav"",          `Atmospheric CO2` = ""Ca"", `Total forcing` = ""Ftot""),          permafrost = forcats::fct_inorder(permafrost) %>% forcats::fct_rev(),          RCP = forcats::fct_reorder(RCP, value, .fun = max, .desc = TRUE)) %>%          ggplot() + aes(x = year, y = value, linetype = permafrost,          color = RCP) + geom_line() + scale_linetype_manual(values = rev(c(""solid"",          ""longdash"", ""dashed"", ""dotted""))) + ylab(expression(""Global mean"" ~          Delta * T)) + theme(legend.position = c(0.02, 0.98),          legend.justification = c(0, 1)), climate_plot_png = ggsave(file_out(""analysis/figures/climate_results.png""),          climate_plot, width = 7, height = 7, units = ""in""))",visualization,440178553108126e8,363
"plan <- bind_plans(scenarios_plan, combined_plan, run_plan, results_plan,      plot_plan)",data cleaning,440178553108126e8,363
config <- drake_config(plan),setup,440178553108126e8,363
make(plan),evaluation,440178553108126e8,363
"source(""analysis/InitialSetup.R"")",import,463806232437491e8,373
require(picante),setup,463806232437491e8,373
require(png),setup,463806232437491e8,373
require(grid),setup,463806232437491e8,373
"matched.phylo.water <- readRDS(file = ""data/matched.phylo.water.rda"")",import,463806232437491e8,373
"matched.phylo.sed <- readRDS(file = ""data/matched.phylo.sed.rda"")",import,463806232437491e8,373
water.phy <- matched.phylo.water$phy,import,463806232437491e8,373
water.comm <- matched.phylo.water$comm,data cleaning,463806232437491e8,373
sed.phy <- matched.phylo.sed$phy,data cleaning,463806232437491e8,373
sed.comm <- matched.phylo.sed$comm,data cleaning,463806232437491e8,373
"mntds.water <- (comdistnt(water.comm, cophenetic(water.phy),      abundance.weighted = T))",data cleaning,463806232437491e8,373
"mntds.sed <- (comdistnt(sed.comm, cophenetic(sed.phy), abundance.weighted = T))",data cleaning,463806232437491e8,373
"saveRDS(mntds.water, file = ""data/mntds-water.rda"")",export,463806232437491e8,373
"saveRDS(mntds.sed, file = ""data/mntds-sed.rda"")",export,463806232437491e8,373
mntd.null.water <- NULL,data cleaning,463806232437491e8,373
"write(paste(""i"", "","", ""bMNTDvalue.water"", sep = """"), file = ""./analysis/logs/11mntd.water.null.log"")",export,463806232437491e8,373
"for (i in 1:999) {     print(paste(""creating null community "", i, "" of 999""))     temp.mntd <- liste(comdistnt(water.comm, cophenetic(tipShuffle(water.phy)),          abundance.weighted = T))[, 3]     mntd.null.water[i] <- mean(temp.mntd)     write(paste(i, "","", mntd.null.water[i], sep = """"), file = ""./analysis/logs/11mntd.water.null.log"",          append = T) }",export,463806232437491e8,373
"saveRDS(mntd.null.water, file = ""data/11mntds-water-null-dist.rda"")",export,463806232437491e8,373
mntd.null.sed <- NULL,data cleaning,463806232437491e8,373
"case.name = c(""fullread.4ind.over"", ""2fullread.4ind.over"", ""4fullread.4ind.over"")",setup,872083705849946e8,374
"write(paste(""i"", "","", ""bMNTDvalue.sed"", sep = """"), file = ""./analysis/logs/11mntd.sed.null.log"")",export,463806232437491e8,373
"for (i in 1:999) {     print(paste(""creating null community "", i, "" of 999""))     temp.mntd <- liste(comdistnt(sed.comm, cophenetic(tipShuffle(sed.phy)),          abundance.weighted = T))[, 3]     mntd.null.sed[i] <- mean(temp.mntd)     write(paste(i, "","", mntd.null.sed[i], sep = """"), file = ""./analysis/logs/11mntd.sed.null.log"",          append = T) }",export,463806232437491e8,373
"saveRDS(mntd.null.sed, file = ""data/11mntds-sed-null-dist.rda"")",export,463806232437491e8,373
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/sum/logLR.overS.RD.4ind.Robj""",export,872083705849946e8,374
"source(file = ""analysis/library_fun_directories.R"", chdir = FALSE)",exploratory,897353229811415e8,375
"source(file = ""analysis/imagej_run_script.R"", chdir = FALSE)",visualization,897353229811415e8,375
"DirMacro <- function(name) {     dir.macro <- paste(DirWindowsToLinux(GLOBAL.dir.work), ""macros"",          sep = ""\\"")     paste(dir.macro, name, sep = ""\\"") }",setup,897353229811415e8,375
"DirOutput <- function(name, dir.output) {     output <- paste(paste(dir.output, name, sep = ""\\""), ""\\\\"",          sep = """")     DirCheckAndCreate(output)     output }",export,897353229811415e8,375
"DirInput <- function(name, dir.input) {     paste(paste(dir.input, name, sep = ""\\""), ""\\\\"", sep = """") }",setup,897353229811415e8,375
"imagej.MergeAndConnect <- function(input = ""Experiment\\Analysis.nuclei.15.80\\Data\\D"",      output = ""Experiment\\Analysis.nuclei.15.80\\ImageJ\\D"",      channelA = ""CHA"", channelB = ""CHB"", channelC = ""PrimaryOutlineNuclei"",      channelD = ""plot_densities"", dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      numbers = c(), texts = c(), index = """", memory = 1276, stack.name = ""stack"") {     macro.name <- ""mergeAndConnectNoChannelB.ijm""     text <- paste(texts, collapse = ""|"")     number <- paste(numbers, collapse = ""|"")     command.get <- function(macro, args) {         args <- paste(args, collapse = "";"")         paste(""java"", paste(""-Xms"", memory, ""m"", sep = """"), paste(""-Xmx"",              memory, ""m"", sep = """"), ""-cp"", ""ij.jar"", ""ij.ImageJ"",              ""-batchpath"", paste(""\"""", macro, ""\"""", sep = """"),              paste(""\"""", args, ""\"""", sep = """"), sep = ""  "")     }     dir.macro.full <- DirMacro(macro.name)     dir.input.full <- DirInput(name = input, dir.input = dir.input)     dir.output.full <- DirOutput(name = output, dir.output = dir.output)     command <- command.get(dir.macro.full, c(dir.input.full,          dir.output.full, channelA, channelB, channelC, channelD,          number, text, index, stack.name))     print(paste(""Running IMAGE J"", macro.name, ""task :"", index,          sep = "" ""))     run.imagej(command)     print(paste(""Close IMAGE J"", macro.name, ""task :"", index,          sep = "" "")) }",visualization,897353229811415e8,375
"imagej.GetHyperstack <- function(input = ""Experiment\\Analysis.nuclei.15.80\\Data\\"",      output = ""Experiment\\Analysis.nuclei.15.80\\ImageJ\\"", dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      stack.name = ""stack"", stack.numbers = c(), stack.frames = 12,      hyperstack.name = ""ConcatenateStacks.tif"", memory = 1276) {     macro.name <- ""createHyperstack.ijm""     dir.macro.full <- paste(""\"""", DirMacro(macro.name), ""\"""",          sep = """")     dirs <- sapply(stack.numbers, function(l) {         paste(""\"""", DirOutput(output, dir.output), ""\\"", stack.name,              l, "".tif"", ""\"""", sep = """")     })     output.hyperstack <- paste(""\"""", DirOutput(output, dir.output),          hyperstack.name, ""\"""", sep = """")     dirs.connected <- paste(c(output.hyperstack, stack.frames,          dirs), collapse = "";"")     command <- paste(""java"", paste(""-Xms"", memory, ""m"", sep = """"),          paste(""-Xmx"", memory, ""m"", sep = """"), ""-cp  ij.jar  ij.ImageJ  -batchpath"",          dir.macro.full, dirs.connected, sep = "" "")     print(paste(""Running IMAGE J"", macro.name, sep = "" ""))     run.imagej(command)     print(paste(""Close IMAGE J"", macro.name, sep = "" "")) }",visualization,897353229811415e8,375
"imagej.OriginalHyperstack <- function(dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output\\Experiment\\Analysis.nuclei.15.80\\Data\\"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output\\Experiment\\Analysis.nuclei.15.80\\ImageJ\\"",      input.names = c(), hyperstack.channel = 1, hyperstack.frames = 1,      hyperstack.slices = length(input.names), hyperstack.displays = ""Grayscale"",      hyperstack.name = ""OriginalHyperstack.tif"", titles.display = FALSE,      titles.font = 50, titles = c(), memory = 1276) {     macro.name <- ""visualise.ijm""     dir.macro.full <- paste(""\"""", DirMacro(macro.name), ""\"""",          sep = """")     command.input <- paste(input.names, collapse = "","")     command.input.dir <- paste(""\"""", dir.input, ""\"""", sep = """")     command.output <- paste(""\"""", dir.output, hyperstack.name,          ""\"""", sep = """")     command.args <- paste(command.output, command.input.dir,          command.input, hyperstack.channel, hyperstack.slices,          hyperstack.frames, hyperstack.displays, sep = "";"")     if (titles.display) {         command.titles <- paste(titles, collapse = "","")         command.args <- paste(command.args, 1, command.titles,              titles.font, sep = "";"")     }     command <- paste(""java"", paste(""-Xms"", memory, ""m"", sep = """"),          paste(""-Xmx"", memory, ""m"", sep = """"), ""-cp  ij.jar  ij.ImageJ  -batchpath"",          dir.macro.full, command.args, sep = "" "")     print(paste(""Running IMAGE J"", macro.name, sep = "" ""))     run.imagej(command)     print(paste(""Close IMAGE J"", macro.name, sep = "" "")) }",visualization,897353229811415e8,375
"imagej.OriginalHyperstackNames <- function(args.ind = args.ind,      input = ""CHA"", output = ""CHA-SD"", prefix = ""tif"") {     input.names <- sapply(as.vector(t(args.ind)), function(i) {         if (i < 10) {             ind <- paste(""000"", i, sep = """")         }         else {             ind <- paste(""00"", i, sep = """")         }         paste(input, ind, ""."", prefix, sep = """")     })     output.names <- sapply(as.vector(t(args.ind)), function(i) {         if (i < 10) {             ind <- paste(""000"", i, sep = """")         }         else {             ind <- paste(""00"", i, sep = """")         }         paste(output, ind, ""."", prefix, sep = """")     })     data.frame(input = input.names, output = output.names) }",visualization,897353229811415e8,375
library(ggplot2),import,952776435762644e8,376
library(dplyr),import,952776435762644e8,376
library(rstan),import,952776435762644e8,376
"imagej.ApplyCommand <- function(input, output, dir.input = ""C:\\Documents and Settings\\knt\\Documents\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Documents\\CellProfiler\\Output"",      ij.command, ij.command.args, titles = c(), memory = 1276) {     macro.name <- ""applyCommand.ijm""     dir.macro.full <- paste(""\"""", DirMacro(macro.name), ""\"""",          sep = """")     command.ij.command <- paste(""\"""", ij.command, ""\"""", sep = """")     command.ij.command.args <- paste(""\"""", ij.command.args, ""\"""",          sep = """")     command.input <- paste(input.names, collapse = "","")     command.output <- paste(output.names, collapse = "","")     command.input.dir <- paste(""\"""", dir.input, ""\"""", sep = """")     command.output.dir <- paste(""\"""", dir.output, ""\"""", sep = """")     command.args <- paste(command.ij.command, command.ij.command.args,          command.input, command.input.dir, command.output, command.output.dir,          sep = "";"")     command <- paste(""java"", paste(""-Xms"", memory, ""m"", sep = """"),          paste(""-Xmx"", memory, ""m"", sep = """"), ""-cp  ij.jar  ij.ImageJ  -batchpath"",          dir.macro.full, command.args, sep = "" "")     print(paste(""Running IMAGE J"", macro.name, sep = "" ""))     run.imagej(command)     print(paste(""Close IMAGE J"", macro.name, sep = "" "")) }",visualization,897353229811415e8,375
"imagej.Analysis <- function(input = ""Experiment\\Analysis.nuclei.15.80\\Data\\"",      output = ""Experiment\\Analysis.nuclei.15.80\\ImageJ\\"", dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      stack.name = ""stack"", stack.numbers = c(), stack.frames = 12,      hyperstack.name = ""ConcatenateStacks.tif"", byrow = TRUE,      args.ind, texts = c(), channelA = ""CHA"", channelB = ""CHB"",      channelC = ""PrimaryOutlineNuclei"", channelD = ""plot_densities"",      hyperstack = TRUE, memory = 1276) {     ind.i <- nrow(args.ind)     ind.j <- ncol(args.ind)     if (!byrow) {         ind.i <- ncol(args.ind)         ind.j <- nrow(args.ind)     }     sapply(1:ind.i, function(i) {         numbers <- args.ind[i, ]         if (!byrow) {             numbers <- args.ind[, i]         }         texts.tmp <- texts[i, ]         if (!byrow) {             texts.tmp <- texts[, i]         }         which.args <- !is.na(numbers)         numbers <- numbers[which.args]         texts.tmp <- texts.tmp[which.args]         imagej.MergeAndConnect(input = input, output = output,              dir.input = dir.input, dir.output = dir.output, texts = texts.tmp,              channelA = channelA, channelB = channelB, channelC = channelC,              channelD = channelD, numbers = numbers, index = i,              memory = memory, stack.name = stack.name)     })     if (hyperstack) {         imagej.GetHyperstack(input = input, output = output,              dir.input = dir.input, dir.output = dir.output, stack.name = stack.name,              stack.numbers = 1:ind.i, stack.frames = ind.j, hyperstack.name = hyperstack.name,              memory = memory)     } }",visualization,897353229811415e8,375
rstan_options(auto_write = TRUE),setup,952776435762644e8,376
"imagej.MergeChannels <- function(input = ""Experiment\\Analysis.nuclei.15.80\\Data\\"",      output = ""Experiment\\Analysis.nuclei.15.80\\ImageJ\\"", dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      stack.name = ""stack"", stack.numbers = c(), stack.frames = 12,      byrow = TRUE, args.ind, texts = c(), channelA = ""CHA"", channelB = ""CHB"",      hyperstack.name = paste(""MergedChannels"", ""-"", channelA,          ""-"", channelB, "".tif"", sep = """"), hyperstack = TRUE,      memory = 1276) {     ind.i <- nrow(args.ind)     ind.j <- ncol(args.ind)     if (!byrow) {         ind.i <- ncol(args.ind)         ind.j <- nrow(args.ind)     }     sapply(1:ind.i, function(i) {         numbers <- args.ind[i, ]         if (!byrow) {             numbers <- args.ind[, i]         }         which.args <- !is.na(numbers)         numbers <- numbers[which.args]         imagej.MergeChannelsAndConnect(input = input, output = output,              dir.input = dir.input, dir.output = dir.output, texts = ""texts"",              channelA = channelA, channelB = channelB, numbers = numbers,              index = i, memory = memory, stack.name = stack.name)     })     if (hyperstack) {         imagej.GetHyperstack(input = input, output = output,              dir.input = dir.input, dir.output = dir.output, stack.name = stack.name,              stack.numbers = 1:ind.i, stack.frames = ind.j, hyperstack.name = hyperstack.name,              memory = memory)     } }",visualization,897353229811415e8,375
"imagej.MergeChannelsAndConnect <- function(input = ""Experiment\\Analysis.nuclei.15.80\\Data\\D"",      output = ""Experiment\\Analysis.nuclei.15.80\\ImageJ\\D"",      channelA = ""CHA"", channelB = ""CHB"", dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Output"",      numbers = c(), texts = c(), index = """", memory = 1276, stack.name = ""stack"") {     macro.name <- ""mergeChannelsAndConnect.ijm""     text <- paste(texts, collapse = ""|"")     number <- paste(numbers, collapse = ""|"")     command.get <- function(macro, args) {         args <- paste(args, collapse = "";"")         paste(""java"", paste(""-Xms"", memory, ""m"", sep = """"), paste(""-Xmx"",              memory, ""m"", sep = """"), ""-cp"", ""ij.jar"", ""ij.ImageJ"",              ""-batchpath"", paste(""\"""", macro, ""\"""", sep = """"),              paste(""\"""", args, ""\"""", sep = """"), sep = ""  "")     }     dir.macro.full <- DirMacro(macro.name)     dir.input.full <- DirInput(name = input, dir.input = dir.input)     dir.output.full <- DirOutput(name = output, dir.output = dir.output)     command <- command.get(dir.macro.full, c(dir.input.full,          dir.output.full, channelA, channelB, number, text, index,          stack.name))     print(paste(""Running IMAGE J"", macro.name, ""task :"", index,          sep = "" ""))     run.imagej(command)     print(paste(""Close IMAGE J"", macro.name, ""task :"", index,          sep = "" "")) }",visualization,897353229811415e8,375
options(mc.cores = parallel::detectCores()),setup,952776435762644e8,376
"imagej.StackToImages <- function(input, output, dir.input = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Input"",      dir.output = ""C:\\Documents and Settings\\knt\\Desktop\\CellProfiler\\Input"",      channelA.save = 1, channelA.name = ""DAPI"", channelB.save = 0,      channelB.name = """", channelC.save = 1, channelC.name = ""Alexa"",      macro.name = ""StackToChannels.ijm"", memory = 1276) {     command.channel <- function(save, name) {         ifelse(save == 1, paste(""1"", name, sep = "",""), ""0"")     }     dir.macro.full <- DirMacro(macro.name)     dir.input.full <- DirInput(name = input, dir.input = dir.input)     dir.output.full <- DirOutput(name = output, dir.output = dir.output)     command.channelA <- command.channel(channelA.save, channelA.name)     command.channelB <- command.channel(channelB.save, channelB.name)     command.channelC <- command.channel(channelC.save, channelC.name)     command.args <- paste(dir.input.full, dir.output.full, command.channelA,          command.channelB, command.channelC, collapse = "";"", sep = "";"")     run.imagej.command(macro = dir.macro.full, args = command.args,          memory.xms = memory, memory.xmx = memory) }",visualization,897353229811415e8,375
"path2read = ""~/Desktop/gitHub/protracted_sp/analysis/R/""",import,957786386599764e8,377
"path2data = ""~/Desktop/gitHub/protracted_sp/analysis/data/""",import,957786386599764e8,377
"path2plot = ""~/Desktop/gitHub/protracted_sp/analysis/output/""",import,957786386599764e8,377
"load(""analysis/rdata-tmp/britdat.RData"")",setup,952776435762644e8,376
library(ogbox),setup,827236091718078e8,378
"load(""analysis/rdata-tmp/old-pseudopassives.RData"")",setup,952776435762644e8,376
"source(paste0(path2read, ""plot_functions.R""))",visualization,957786386599764e8,377
"harmonic = ""1F1""",modeling,897353229811415e8,375
"brit.pas <- subset(britdat, Voice == ""PAS"" & NVerb != ""SEND"" &      NVerb != ""NONREC"")",data cleaning,952776435762644e8,376
"par = get_param(output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",evaluation,957786386599764e8,377
"source(""R/rnaSeqTresh.R"")",not sure,827236091718078e8,378
p_thresh = 5e-04,evaluation,897353229811415e8,375
"recpas <- subset(brit.pas, Envir %in% c(""Recipient Passive (oblique)"",      ""Recipient Passive Theme Topicalisation (oblique)"", ""Recipient Passive"",      ""Recipient Passive Theme Topicalisation""))",data cleaning,952776435762644e8,376
plot_titles = TRUE,visualization,897353229811415e8,375
head(par),exploratory,957786386599764e8,377
str(par),exploratory,957786386599764e8,377
recpas$isNom <- factor(recpas$Envir),data cleaning,952776435762644e8,376
"rnaSeq = read.table(""data/linnarsonSingleCell/mouseRNASeq_Zeisel 2015.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = F)",import,827236091718078e8,378
"condition = ""Direction""",exploratory,897353229811415e8,375
"study = ""MOFO""",exploratory,897353229811415e8,375
"levels(recpas$isNom) <- c(0, 0, 1, 1)",data cleaning,952776435762644e8,376
"group = ""child""",exploratory,897353229811415e8,375
recpas$isNom <- as.numeric(as.character(recpas$isNom)),data cleaning,952776435762644e8,376
"rnaMeta = rnaSeq[1:10, 3:ncol(rnaSeq)]",data cleaning,827236091718078e8,378
dpi = 300,export,897353229811415e8,375
"pdat <- data.frame(Year = pseu.old$Year, Val = pseu.old$Val,      Type = ""Pseudopassive"")",data cleaning,952776435762644e8,376
n_top = 9,exploratory,897353229811415e8,375
rnaMeta = as.data.frame(t(rnaMeta)),data cleaning,827236091718078e8,378
"bdat <- data.frame(Year = recpas$year, Val = recpas$isNom, Type = ""Recipient Passive"")",data cleaning,952776435762644e8,376
"joint.data <- as.data.frame(rbind(pdat, bdat))",data cleaning,952776435762644e8,376
"analysis_path <- ""child-tuning/analysis/""",modeling,897353229811415e8,375
joint.data$zYear <- (joint.data$Year - mean(joint.data$Year))/sd(joint.data$Year),data cleaning,952776435762644e8,376
"colnames(rnaMeta) = rnaSeq[1:10, 2]",data cleaning,827236091718078e8,378
"pseuscale <- mean(joint.data$Val[joint.data$Year >= 1700 & joint.data$Type ==      ""Pseudopassive""], na.rm = T)",data cleaning,952776435762644e8,376
"ditscale <- mean(joint.data$Val[joint.data$Year >= 1700 & joint.data$Type ==      ""Recipient Passive""], na.rm = T)",data cleaning,952776435762644e8,376
"x1 <- joint.data$zYear[joint.data$Type == ""Pseudopassive""]",data cleaning,952776435762644e8,376
"x2 <- joint.data$zYear[joint.data$Type == ""Recipient Passive""]",data cleaning,952776435762644e8,376
"y1 <- joint.data$Val[joint.data$Type == ""Pseudopassive""]",data cleaning,952776435762644e8,376
"y2 <- joint.data$Val[joint.data$Type == ""Recipient Passive""]",data cleaning,952776435762644e8,376
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",data cleaning,827236091718078e8,378
"data_path <- paste(analysis_path, ""data/"", sep = """")",modeling,897353229811415e8,375
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",setup,952776435762644e8,376
"rnaExp = apply(rnaExp, 2, as.numeric)",data cleaning,827236091718078e8,378
"figs_path <- ""child-tuning/figs/""",export,897353229811415e8,375
library(fpp),import,566111714346334e8,379
"data_fn <- ""child-mofo-all.csv""",import,897353229811415e8,375
"stan.dat <- list(PseudoP = pseuscale, DitP = ditscale, priorSD = parameters$prior_sd,      N1 = length(x1), N2 = length(x2), x1 = x1, x2 = x2, y1 = y1,      y2 = y2)",data cleaning,952776435762644e8,376
"egi_fn <- ""egi.csv""",import,897353229811415e8,375
library(tidyverse),setup,308248673798516e8,380
"clean_as_is_data <- read.csv(""Analysis/data/tidy_as_is_data.csv"")",import,566111714346334e8,379
"glm1 <- glm(y1 ~ x1, family = ""binomial"")",modeling,952776435762644e8,376
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",data cleaning,827236091718078e8,378
"clean_plan_data <- read.csv(""Analysis/data/tidy_plan_data.csv"")",import,566111714346334e8,379
"glm2 <- glm(y2 ~ x2, family = ""binomial"")",modeling,952776435762644e8,376
"clean_indicator_data <- read.csv(""Analysis/data/tidy_indicator_data.csv"")",import,566111714346334e8,379
"topo_fn <- ""topoplog.png""",import,897353229811415e8,375
colnames(clean_as_is_data),exploratory,566111714346334e8,379
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",data cleaning,827236091718078e8,378
"fn_path <- paste(data_path, data_fn, sep = """")",setup,897353229811415e8,375
"asis_data <- subset(clean_as_is_data, year <= 2013)",data cleaning,566111714346334e8,379
"egi_path <- paste(data_path, egi_fn, sep = """")",setup,897353229811415e8,375
"plan_data <- subset(clean_plan_data, year <= 2013)",data cleaning,566111714346334e8,379
"topo_path <- paste(figs_path, ""topoplot.png"", sep = """")",setup,897353229811415e8,375
library(ggplot2),setup,897353229811415e8,375
"sapply(asis_data, class)",data cleaning,566111714346334e8,379
library(dplyr),setup,897353229811415e8,375
library(png),setup,897353229811415e8,375
library(gridExtra),setup,897353229811415e8,375
options(row.names = FALSE),setup,308248673798516e8,380
library(tidyr),setup,897353229811415e8,375
"stan.init <- list(Int = coef(glm1)[1], Slope = coef(glm1)[2],      DitInt = coef(glm2)[1] - coef(glm1)[1], DitSlope = coef(glm2)[2] -          coef(glm1)[2])",data cleaning,952776435762644e8,376
library(knitr),setup,897353229811415e8,375
blue_etel_as_is_vect <- asis_data$blue_etel_as_is,exploratory,566111714346334e8,379
library(DescTools),setup,897353229811415e8,375
library(heplots),setup,897353229811415e8,375
library(Cairo),setup,897353229811415e8,375
"rnaCelIDs = as.numeric(as.character(rnaSeq[12:nrow(rnaSeq), 2]))",data cleaning,827236091718078e8,378
inits <- list(),setup,952776435762644e8,376
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",data cleaning,827236091718078e8,378
"direction_conds <- c(1, 2, 3, 6, 7, 8)",data cleaning,897353229811415e8,375
"coherence.conds <- c(4, 9)",data cleaning,897353229811415e8,375
for (i in 1:parameters$nchains) {     inits[[letters[i]]] <- stan.init },setup,952776435762644e8,376
"fig.only.conds <- c(5, 10)",visualization,897353229811415e8,375
"tresh <- rnaSeqTresh(rnaExp, ""analysis/02.Mouse Single Cell/tresholds"",      cores = 16)",not sure,827236091718078e8,378
"if (parameters$prior_dist == ""cauchy"") {     fit <- stan(file = ""analysis/src-analysis/stan-models/Pseudo-cauchy.stan"",          data = stan.dat, iter = parameters$iters, chains = parameters$nchains,          init = inits, seed = parameters$seed, verbose = T) } else if (parameters$prior_dist == ""normal"") {     fit <- stan(file = ""analysis/src-analysis/stan-models/Pseudo-normal.stan"",          data = stan.dat, iter = parameters$iters, chains = parameters$nchains,          init = inits, seed = parameters$seed, verbose = T) }",modeling,952776435762644e8,376
"saveRDS(fit, file = ""analysis/mcmc-runs/Pseudo-old-Stan-Fit.RDS"")",export,952776435762644e8,376
rn(rnaExp),not sure,827236091718078e8,378
"d = read.csv(""/Users/chrisnavarro/Desktop/MQP/analysis/results/data.csv"",      header = TRUE, sep = "","")",setup,952776435762644e8,376
"barplot(as.integer(d$score), width = 5, names.arg = d$postId)",visualization,952776435762644e8,376
"tresholds = matrix(rep(1, len(rn(rnaExp))))",modeling,827236091718078e8,378
"png(filename = ""/Users/chrisnavarro/Desktop/MQP/analysis/results/bartest.png"")",export,952776435762644e8,376
rownames(tresholds) = rn(rnaExp),data cleaning,827236091718078e8,378
"write.table(tresholds, file = ""analysis/02.Mouse Single Cell/noTresh"",      col.names = F, row.names = T, quote = F)",export,827236091718078e8,378
library(ogbox),setup,827236091718078e8,378
"local <- yelp_data[yelp_data[, ""user_is_local""], ""user_review""]",data cleaning,827236091718078e8,378
"nonlocal <- yelp_data[!yelp_data[, ""user_is_local""], ""user_review""]",data cleaning,827236091718078e8,378
"sm_local <- sample(local, 5000)",exploratory,827236091718078e8,378
"sm_nonlocal <- sample(nonlocal, 5000)",exploratory,827236091718078e8,378
"local_text <- paste(sm_local, collapse = "" "")",data cleaning,827236091718078e8,378
"nonlocal_text <- past(sm_nonlocal, collapse = "" "")",data cleaning,827236091718078e8,378
local_source <- VectorSource(local_text),not sure,827236091718078e8,378
nonlocal_source <- VectorSource(nonlocal_text),not sure,827236091718078e8,378
local_corpus <- Corpus(local_source),data cleaning,827236091718078e8,378
nonlocal_corpus <- Corpus(nonlocal_source),data cleaning,827236091718078e8,378
"local_corpus <- tm_map(local_corpus, tolower)",data cleaning,827236091718078e8,378
"nonlocal_corpus <- tm_map(nonlocal_corpus, tolower)",data cleaning,827236091718078e8,378
"local_corpus <- tm_map(local_corpus, removePunctuation)",data cleaning,827236091718078e8,378
"nonlocal_corpus <- tm_map(nonlocal_corpus, removePunctuation)",data cleaning,827236091718078e8,378
"local_corpus <- tm_map(local_corpus, stripWhitespace)",data cleaning,827236091718078e8,378
"nonlocal_corpus <- tm_map(nonlocal_corpus, stripWhitespace)",data cleaning,827236091718078e8,378
"local_corpus <- tm_map(local_corpus, removeWords, stopwords(""english""))",data cleaning,827236091718078e8,378
"nonlocal_corpus <- tm_map(nonlocal_corpus, removeWords, stopwords(""english""))",data cleaning,827236091718078e8,378
local_dtm <- DocumentTermMatrix(local_corpus),modeling,827236091718078e8,378
nonlocal_dtm <- DocumentTermMatrix(nonlocal_corpus),modeling,827236091718078e8,378
local_dtm <- as.matrix(local_dtm),modeling,827236091718078e8,378
nonlocal_dtm <- as.matrix(nonlocal_dtm),modeling,827236091718078e8,378
local_freq <- colSums(local_dtm),modeling,827236091718078e8,378
nonlocal_freq <- colSums(nonlocal_dtm),modeling,827236091718078e8,378
"local_freq <- sort(local_frequency, decreasing = TRUE)",modeling,827236091718078e8,378
"nonlocal_freq <- sort(nonlocal_frequency, decreasing = TRUE)",modeling,827236091718078e8,378
local_words <- names(local_freq),modeling,827236091718078e8,378
nonlocal_words <- names(nonlocal_freq),modeling,827236091718078e8,378
head(local_freq),exploratory,827236091718078e8,378
head(nonlocal_freq),exploratory,827236091718078e8,378
local_freq[1:100],exploratory,827236091718078e8,378
nonlocal_freq[1:100],exploratory,827236091718078e8,378
"library(""plyr"")",data cleaning,959925830829888e7,381
"wordcloud(local_words, local_freq, scale = c(8, 0.3), min.freq = 2,      max.words = 100, random.order = F, rot.per = 0.15, colors = pal,      vfont = c(""sans serif"", ""plain""))",visualization,827236091718078e8,378
"wordcloud(nonlocal_words, nonlocal_freq, scale = c(8, 0.3), min.freq = 2,      max.words = 100, random.order = F, rot.per = 0.15, colors = pal,      vfont = c(""sans serif"", ""plain""))",visualization,827236091718078e8,378
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,362273845588788e8,382
"setwd(""/home/I864741/TCC/Analysis/"")",setup,959925830829888e7,381
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_04.R"",      echo = FALSE)",import,362273845588788e8,382
"mn.rentals <- mn.sale[which(grepl(""RENTALS"", mn.sale$building.class.category)),      ]",import,362273845588788e8,382
"hgcn.nomenclature <- read.delim(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/HGCN_completeSet.txt"",      stringsAsFactors = FALSE)",import,959925830829888e7,381
genename.map <- NULL,data cleaning,959925830829888e7,381
names <- NULL,setup,959925830829888e7,381
rm(list = ls()),setup,711198403732851e8,383
"prototypes <- read.table(""../prototypes_0.txt"")",setup,711198403732851e8,383
"for (ii in 1:dim(hgcn.nomenclature)[1]) {     temp <- hgcn.nomenclature[ii, ""alias_symbol""]     if (temp != """") {         x <- unlist(strsplit(temp, ""\\|""))         names <- c(names, x)         genename.map <- c(genename.map, rep(hgcn.nomenclature[ii,              ""symbol""], length(x)))     }     names <- c(names, hgcn.nomenclature[ii, ""symbol""])     genename.map <- c(genename.map, hgcn.nomenclature[ii, ""symbol""])     temp <- hgcn.nomenclature[ii, ""prev_symbol""]     if (temp != """") {         x <- unlist(strsplit(temp, ""\\|""))         names <- c(names, x)         genename.map <- c(genename.map, rep(hgcn.nomenclature[ii,              ""symbol""], length(x)))     } }",data cleaning,959925830829888e7,381
names(genename.map) <- names,data cleaning,959925830829888e7,381
"manualfix <- read.csv(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/HGCN_symbols_included.csv"",      stringsAsFactors = FALSE, header = FALSE)",import,959925830829888e7,381
"names <- manualfix[, 1]",data cleaning,959925830829888e7,381
"temp <- manualfix[, 2]",data cleaning,959925830829888e7,381
names(temp) <- names,data cleaning,959925830829888e7,381
"genename.map <- c(genename.map, temp)",data cleaning,959925830829888e7,381
"standardizeGeneSymbols <- function(geneList, mapFunction, uppercase = FALSE) {     if (uppercase) {         geneList <- toupper(geneList)     }     temp <- mapFunction[as.character(geneList)]     temp <- as.character(temp)     return(temp) }",modeling,959925830829888e7,381
"rm(names, temp, x, hgcn.nomenclature, ii, manualfix)",setup,959925830829888e7,381
"mirna.mature.v21 <- read.delim(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/mirna_mature_v21.txt"",      header = FALSE)",import,959925830829888e7,381
"mirna.mature.v21 <- mirna.mature.v21[grep(""hsa"", mirna.mature.v21[,      2]), ]",data cleaning,959925830829888e7,381
"mirna.mature.v21[] <- apply(mirna.mature.v21, 2, as.character)",data cleaning,959925830829888e7,381
map.mirnas.v21 <- NULL,data cleaning,959925830829888e7,381
names.prev <- NULL,data cleaning,959925830829888e7,381
"for (ii in 1:nrow(mirna.mature.v21)) {     temp <- unlist(strsplit(mirna.mature.v21[ii, 3], "";""))     names.prev <- c(names.prev, temp)     names.prev <- c(names.prev, mirna.mature.v21[ii, 2])     map.mirnas.v21 <- c(map.mirnas.v21, rep(mirna.mature.v21[ii,          2], (length(temp) + 1)))     rm(temp) }",data cleaning,959925830829888e7,381
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,251658468041569e7,384
names(map.mirnas.v21) <- names.prev,data cleaning,959925830829888e7,381
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,251658468041569e7,384
rm(names.prev),data cleaning,959925830829888e7,381
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,251658468041569e7,384
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,251658468041569e7,384
"load(""/home/I864741/TCC/Analysis/processInteractionData_output/miRBasev21_MapFunction.RData"")",import,959925830829888e7,381
"source(""analysis/utils.R"")",data cleaning,251658468041569e7,384
"source(""analysis/analysis.R"")",data cleaning,251658468041569e7,384
"load(""/home/I864741/TCC/Analysis/processInteractionData_output/HGCN_MapFunction.RData"")",import,959925830829888e7,381
library(dplyr),data cleaning,251658468041569e7,384
"analyze_database <- function(database_file_path) {     components <- stringr::str_split(basename(tools::file_path_sans_ext(database_file_path)),          ""-"", 2)[[1]]     db <- src_sqlite(database_file_path)     jumps <- db %>% tbl(""jumps"") %>% collect     list(call_depth = jumps %>% group_by(call_depth) %>% count %>%          as.data.frame, promise_depth = jumps %>% group_by(promise_depth) %>%          count %>% as.data.frame, depth = jumps %>% mutate(depth = call_depth +          promise_depth) %>% group_by(depth) %>% count %>% as.data.frame,          restarts = jumps %>% group_by(restart) %>% count %>%              as.data.frame %>% mutate(restart = as.logical(restart))) }",data cleaning,251658468041569e7,384
"summarize_analyses <- function(analyses) {     list(call_depth = analyses$call_depth %>% group_by(call_depth) %>%          summarise(number = sum(n)) %>% mutate(percent = (100 *          number/sum(number))), promise_depth = analyses$promise_depth %>%          group_by(promise_depth) %>% summarise(number = sum(n)) %>%          mutate(percent = (100 * number/sum(number))), depth = analyses$depth %>%          group_by(depth) %>% summarise(number = sum(n)) %>% mutate(percent = (100 *          number/sum(number))), restarts = analyses$restarts %>%          group_by(restart) %>% summarise(number = sum(n)) %>%          mutate(percent = (100 * number/sum(number)))) }",data cleaning,251658468041569e7,384
"standardizeGeneSymbols <- function(geneList, mapFunction, uppercase = FALSE) {     if (uppercase) {         geneList <- toupper(geneList)     }     temp <- mapFunction[as.character(geneList)]     temp <- as.character(temp)     return(temp) }",data cleaning,959925830829888e7,381
"tarbase <- read.csv(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/TarBase_v7.0.csv"",      header = TRUE, stringsAsFactors = FALSE, sep = ""\t"")",import,959925830829888e7,381
"tarbase <- tarbase[which(tarbase$species == ""Homo sapiens""),      ]",data cleaning,959925830829888e7,381
tarbase$mirna <- as.character(map.mirnas.v21[as.character(tarbase$mirna)]),data cleaning,959925830829888e7,381
"tarbase$geneName <- standardizeGeneSymbols(tarbase$geneName,      genename.map, uppercase = FALSE)",data cleaning,959925830829888e7,381
"tarbase <- tarbase[-union(which(is.na(tarbase$geneName)), which(is.na(tarbase$mirna))),      ]",data cleaning,959925830829888e7,381
"tarbase.positive <- tarbase[which(tarbase$positive_negative ==      ""POSITIVE""), ]",data cleaning,959925830829888e7,381
"tarbase.positive <- tarbase.positive[which(tarbase.positive$direct_indirect ==      ""DIRECT""), ]",data cleaning,959925830829888e7,381
"tarbase.positive <- tarbase.positive[which(tarbase.positive$up_down ==      ""DOWN""), ]",data cleaning,959925830829888e7,381
"tarbase.positive <- tarbase.positive[-which(tarbase.positive$method %in%      c(""HITS-CLIP"", ""PAR-CLIP"")), ]",data cleaning,959925830829888e7,381
"tarbase.positive <- unique(tarbase.positive[, c(""mirna"", ""geneName"",      ""geneId"")])",data cleaning,959925830829888e7,381
"tarbase.negative <- tarbase[which(tarbase$positive_negative ==      ""NEGATIVE""), ]",data cleaning,959925830829888e7,381
"tarbase.negative <- unique(tarbase.negative[, c(""mirna"", ""geneName"",      ""geneId"")])",data cleaning,959925830829888e7,381
"intersect(paste0(tarbase.positive$geneId, tarbase.positive$mirna),      paste0(tarbase.negative$geneId, tarbase.negative$mirna))",data cleaning,959925830829888e7,381
"remove.from.negatives <- which(is.element(paste0(tarbase.negative$geneId,      tarbase.negative$mirna), paste0(tarbase.positive$geneId,      tarbase.positive$mirna)))",data cleaning,959925830829888e7,381
"remove.from.positives <- which(is.element(paste0(tarbase.positive$geneId,      tarbase.positive$mirna), paste0(tarbase.negative$geneId,      tarbase.negative$mirna)))",data cleaning,959925830829888e7,381
"tarbase.positive <- tarbase.positive[-remove.from.positives,      ]",data cleaning,959925830829888e7,381
"tarbase.negative <- tarbase.negative[-remove.from.negatives,      ]",data cleaning,959925830829888e7,381
"rm(remove.from.negatives, remove.from.positives)",data cleaning,959925830829888e7,381
"mirtarbase <- read.delim(""/home/I864741/TCC/Analysis/IDs_and_interaction_data/mirtarbase_hsa_MTI_release6.1.txt"",      sep = ""\t"", header = TRUE)",import,959925830829888e7,381
"mirtarbase <- mirtarbase[which(mirtarbase$Species..miRNA. ==      ""Homo sapiens""), ]",data cleaning,959925830829888e7,381
mirtarbase$miRNA <- as.character(map.mirnas.v21[as.character(mirtarbase$miRNA)]),data cleaning,959925830829888e7,381
"mirtarbase$Target.Gene <- standardizeGeneSymbols(mirtarbase$Target.Gene,      genename.map, uppercase = FALSE)",data cleaning,959925830829888e7,381
args = (commandArgs(TRUE)),setup,506494930712506e8,385
"mirtarbase <- mirtarbase[-union(which(is.na(mirtarbase$miRNA)),      which(is.na(mirtarbase$Target.Gene))), ]",data cleaning,959925830829888e7,381
"mirtarbase.positive <- mirtarbase[which(mirtarbase$Support.Type ==      ""Functional MTI""), ]",data cleaning,959925830829888e7,381
"mirtarbase.negative <- mirtarbase[which(mirtarbase$Support.Type ==      ""Non-Functional MTI""), ]",data cleaning,959925830829888e7,381
"intersect(paste0(mirtarbase.positive$miRNA, mirtarbase.positive$Target.Gene),      paste0(mirtarbase.negative$miRNA, mirtarbase.negative$Target.Gene))",data cleaning,959925830829888e7,381
eval(parse(text = args[[1]])),evaluation,506494930712506e8,385
"remove.from.negatives <- which(is.element(paste0(mirtarbase.negative$miRNA,      mirtarbase.negative$Target.Gene), paste0(mirtarbase.positive$miRNA,      mirtarbase.positive$Target.Gene)))",data cleaning,959925830829888e7,381
"setwd(""~/WaveQTL/R"")",evaluation,506494930712506e8,385
"remove.from.positives <- which(is.element(paste0(mirtarbase.positive$miRNA,      mirtarbase.positive$Target.Gene), paste0(mirtarbase.negative$miRNA,      mirtarbase.negative$Target.Gene)))",data cleaning,959925830829888e7,381
"mirtarbase.positive <- mirtarbase.positive[-remove.from.positives,      ]",data cleaning,959925830829888e7,381
"mirtarbase.negative <- mirtarbase.negative[-remove.from.negatives,      ]",data cleaning,959925830829888e7,381
"mirtarbase.negative <- unique(mirtarbase.negative[, c(""miRNA"",      ""Target.Gene"", ""Target.Gene..Entrez.Gene.ID."")])",data cleaning,959925830829888e7,381
"mirtarbase.positive <- unique(mirtarbase.positive[, c(""miRNA"",      ""Target.Gene"", ""Target.Gene..Entrez.Gene.ID."")])",data cleaning,959925830829888e7,381
rm(list = ls()),setup,74510195874609e9,386
"Wmat_1024 = read.table(""../data/DWT/Wmat_1024"", as.is = TRUE)",import,506494930712506e8,385
"rm(tarbase, mirtarbase)",data cleaning,959925830829888e7,381
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_05.R"",      echo = FALSE)",import,651398960500956e8,387
"prototypes <- read.table(""../prototypes_0.txt"")",import,74510195874609e9,386
"save.image(""preprocessed_data_mirTarBasev6.1_TarBasev7.RData"")",export,959925830829888e7,381
library(data.table),setup,959925830829888e7,381
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/getmode.R"",      echo = FALSE)",modeling,651398960500956e8,387
library(plyr),setup,959925830829888e7,381
"setwd(""C:/Users/Amir/Documents/GitHub/structural_prediction_of_ER/"")",setup,219803816871718e8,388
"setwd(""/Users/Hannah-Cutler/Desktop/summer-2016/Microsoft/data-collection-civic-graph/Analysis/General analysis"")",setup,959925830829888e7,381
dim(mn.rentals),exploratory,651398960500956e8,387
"blog <- read.csv(""blog_entities.csv"", sep = "","")",import,959925830829888e7,381
"graph <- read.csv(""cg_entities.csv"", sep = "","")",import,959925830829888e7,381
"data_1RD8_AB = read.csv(""correlation_analysis/combined_data/data_1RD8_AB.csv"")",import,219803816871718e8,388
count(is.na(mn.rentals$gross.sqft)),exploratory,651398960500956e8,387
"data_2FP7_B = read.csv(""correlation_analysis/combined_data/data_2FP7_B.csv"")",import,219803816871718e8,388
d1 <- data.frame(blog),data cleaning,959925830829888e7,381
d2 <- data.frame(graph),data cleaning,959925830829888e7,381
"uber.proto <- prototypes[1, 2:length(prototypes[1, ])]",exploratory,74510195874609e9,386
count(is.na(mn.rentals$land.sqft)),exploratory,651398960500956e8,387
W2mat_1024 = Wmat_1024 * Wmat_1024,exploratory,506494930712506e8,385
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",data cleaning,959925830829888e7,381
summary(mn.rentals$sale.price.n),exploratory,651398960500956e8,387
"write.csv(both, ""both.csv"", row.names = FALSE, quote = FALSE)",export,959925830829888e7,381
no.features <- length(uber.proto),exploratory,74510195874609e9,386
getmode(mn.rentals$sale.price.n),modeling,651398960500956e8,387
"bNOTg <- read.csv(""blog_not_graph.csv"", sep = "","")",import,959925830829888e7,381
hist(log10(mn.rentals$sale.price.n)),visualization,651398960500956e8,387
"no.agents <- length(prototypes[, 1]) - 1",exploratory,74510195874609e9,386
d3 <- data.frame(bNOTg),data cleaning,959925830829888e7,381
"WaveQTL.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/WaveQTL/""",setup,506494930712506e8,385
"d.0 <- read.table(""../history_0.txt"", skip = 2)",import,74510195874609e9,386
"source(""https://bioconductor.org/biocLite.R"")",import,959925830829888e7,381
"wd.path = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/prepareData/""",setup,506494930712506e8,385
setwd(wd.path),setup,506494930712506e8,385
"biocLite(""ChIPseeker"")",import,959925830829888e7,381
"biocLite(""TxDb.Hsapiens.UCSC.hg38.knownGene"")",import,959925830829888e7,381
"biocLite(""clusterProfiler"")",import,959925830829888e7,381
"biocLite(""org.Hs.eg.db"")",import,959925830829888e7,381
"outputs <- d.0[(no.agents + 1):length(d.0[, 1]), (4 + no.features +      1):(4 + no.features + 1 + no.features - 1)]",data cleaning,74510195874609e9,386
"biocLite(""ReactomePA"")",import,959925830829888e7,381
"path.fig = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/fig/ES/""",setup,506494930712506e8,385
"path.output = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/data/""",setup,506494930712506e8,385
library(ChIPseeker),setup,959925830829888e7,381
"path.data = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/""",setup,506494930712506e8,385
library(TxDb.Hsapiens.UCSC.hg19.knownGene),setup,959925830829888e7,381
library(TxDb.Hsapiens.UCSC.hg38.knownGene),setup,959925830829888e7,381
library(clusterProfiler),setup,959925830829888e7,381
library(org.Hs.eg.db),setup,959925830829888e7,381
library(ReactomePA),setup,959925830829888e7,381
"source(""analysis/analysis_find_nonzero_configurations.R"")",setup,762871272163466e8,389
tx19 <- TxDb.Hsapiens.UCSC.hg19.knownGene,data cleaning,959925830829888e7,381
tx38 <- TxDb.Hsapiens.UCSC.hg38.knownGene,data cleaning,959925830829888e7,381
csim <- function(x1) {     x <- as.numeric(x1)     y <- as.numeric(uber.proto)     c <- x %*% y/sqrt(x %*% x * y %*% y)     return(c) },modeling,74510195874609e9,386
"promoter <- getPromoters(TxDb = tx38, upstream = 3000, downstream = 3000)",data cleaning,959925830829888e7,381
"d.sim <- apply(outputs, 1, csim)",modeling,74510195874609e9,386
"phenoD = as.matrix(read.table(paste0(path.data, ""pheno.dat."",      ss), as.is = TRUE))",import,506494930712506e8,385
"setwd(""~/Documents/Bioinformatics analysis/ChIP analysis/A549-SREBP1/MACS"")",setup,959925830829888e7,381
library(dplyr),setup,572861015098169e8,390
library(ggplot2),setup,572861015098169e8,390
"files <- list(A549.SREBP1 = ""~/Documents/Bioinformatics analysis/ChIP analysis/A549-SREBP1/MACS/A549-merged-SREBP1-Input_peaks.narrowPeak"",      A549.SREBP2 = ""~/Documents/Bioinformatics analysis/ChIP analysis/A549-SREBP1/MACS/A549-merged-SREBP2-Input_peaks.narrowPeak"",      A549.YY1 = ""~/Documents/Bioinformatics analysis/ChIP analysis/A549-SREBP1/MACS/A549-merged-YY1-Input_peaks.narrowPeak"",      A549.Jun = ""~/Documents/Bioinformatics analysis/ChIP analysis/A549-SREBP1/MACS/A549-merged-Jun-Input_peaks.narrowPeak"")",setup,959925830829888e7,381
library(tidyr),setup,572861015098169e8,390
"genoD = scan(paste0(path.data, ""orig.geno.dat."", ss), what = double())",import,506494930712506e8,385
print(files),communication,959925830829888e7,381
"tickets <- readRDS(""processedData/catch/1_cleaningData/tickets.RDS"")",import,572861015098169e8,390
genoR = as.numeric(round(genoD)),data cleaning,506494930712506e8,385
"peak1 <- readPeakFile(files[[""A549.SREBP1""]])",import,959925830829888e7,381
"dscrp <- read.csv(""processedData/catch/3_exploreBuildwebs/ref_tables/metier_descrp.csv"",      stringsAsFactors = FALSE)",import,572861015098169e8,390
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"")",visualization,74510195874609e9,386
peak1,export,959925830829888e7,381
"peak1.tagMatrix <- getTagMatrix(peak1, windows = promoter)",data cleaning,959925830829888e7,381
"dscrp$name <- paste(dscrp$Major_species, dscrp$Major_gear)",data cleaning,572861015098169e8,390
"tagHeatmap(peak1.tagMatrix, xlim = c(-3000, 3000), color = ""red"")",visualization,959925830829888e7,381
wh0 = which(genoR == 0),exploratory,506494930712506e8,385
"dscrp <- rename(dscrp, metier.2010 = Metier)",data cleaning,572861015098169e8,390
covplot(peak1),visualization,959925830829888e7,381
wh1 = which(genoR == 1),exploratory,506494930712506e8,385
"peakHeatmap(peak1, TxDb = tx38, upstream = 3000, downstream = 3000,      color = ""red"")",visualization,959925830829888e7,381
wh2 = which(genoR == 2),exploratory,506494930712506e8,385
"tickets <- left_join(tickets, dscrp[, c(""metier.2010"", ""name"")])",data cleaning,572861015098169e8,390
"plotAvgProf(peak1.tagMatrix, xlim = c(-3000, 3000), xlab = ""Genomic Region (5'->3')"",      ylab = ""Read Count Frequency"")",visualization,959925830829888e7,381
"plotAvgProf(peak1.tagMatrix, xlim = c(-3000, 3000), conf = 0.95,      resample = 1000)",visualization,959925830829888e7,381
"tickets$tdate <- as.Date(tickets$tdate, format = ""%d-%b-%y"")",data cleaning,572861015098169e8,390
rm(list = ls()),setup,74510195874609e9,386
"tickets$doy <- as.numeric(format(tickets$tdate, ""%j""))",data cleaning,572861015098169e8,390
"peakAnno <- annotatePeak(peak1, tssRegion = c(-3000, 3000), TxDb = tx38,      annoDb = ""org.Hs.eg.db"")",visualization,959925830829888e7,381
plotAnnoPie(peakAnno),visualization,959925830829888e7,381
vennpie(peakAnno),visualization,959925830829888e7,381
upsetplot(peakAnno),visualization,959925830829888e7,381
"upsetplot(peakAnno, vennpie = TRUE)",visualization,959925830829888e7,381
"plotDistToTSS(peakAnno, title = ""Distribution of transcription factor-binding loci\nrelative to TSS"")",visualization,959925830829888e7,381
"fig3a <- tickets %>% filter(metier.2010 %in% c(""POT_1"", ""HKL_2"",      ""TWL_1"", ""NET_2"", ""TLS_1"", ""TLS_2"", ""HKL_12"", ""TWS_1"")) %>%      group_by(name, metier.2010, tdate) %>% summarize(n_trips = length(unique(trip_id))) %>%      ggplot(aes(x = tdate, y = n_trips)) + geom_bar(stat = ""identity"") +      facet_wrap(~name, scale = ""free"", ncol = 1) + theme_classic() +      theme(axis.line.x = element_line(size = 0.5, color = ""black""),          axis.line.y = element_line(size = 0.5, color = ""black""),          strip.background = element_rect(size = 0)) + xlab(""date landed"") +      ylab(""number of trips"")",visualization,572861015098169e8,390
eval(parse(text = args[[1]])),import,74510195874609e9,386
"pathway1 <- enrichPathway(as.data.frame(peakAnno)$geneId, pvalueCutoff = 0.05)",modeling,959925830829888e7,381
"ggsave(fig3a, filename = ""Analysis/new_analysis/metiers/tables_figures/fig3a.png"",      height = 10, width = 5, dpi = 300)",export,572861015098169e8,390
"head(pathway1, 2)",data cleaning,959925830829888e7,381
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,74510195874609e9,386
dotplot(pathway1),visualization,959925830829888e7,381
"if ((length(wh0) > 2) & (length(wh1) > 2)) {     sig0 = apply(phenoD[wh0, ], 2, mean)     sig1 = apply(phenoD[wh1, ], 2, mean)     library(wavethresh)     sig.all = c(sig0, sig1)     sig.all.smooth = BAYES.THR(sig.all)     sig0.smooth = sig.all.smooth[1:1024]     sig1.smooth = sig.all.smooth[1025:2048]     val = 6     cut.thresh = val/70     delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh)     sig1.smooth[delix] = sig0.smooth[delix]     wh.zero = which(sig0.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig0.smooth[wh.zero] = 1/70     }     wh.zero = which(sig1.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig1.smooth[wh.zero] = 1/70     }     beta_mean_path = paste0(WaveQTL.path, ""output/res."", ss,          "".fph.mean.txt"")     beta_var_path = paste0(WaveQTL.path, ""output/res."", ss, "".fph.var.txt"")     sel_geno_IX = 1     beta_mean = as.numeric(read.table(beta_mean_path)[sel_geno_IX,          2:1025])     beta_dataS = as.vector(-matrix(data = beta_mean, nr = 1,          nc = 1024) %*% as.matrix(Wmat_1024))     beta_var = as.numeric(read.table(beta_var_path)[sel_geno_IX,          2:1025])     beta_var_dataS = as.vector(matrix(data = beta_var, nr = 1,          nc = 1024) %*% as.matrix(W2mat_1024))     beta_sd_dataS = sqrt(beta_var_dataS)     WaveQTL.mean = beta_dataS     WaveQTL.sd = beta_sd_dataS     wh = which(abs(WaveQTL.mean) < 2 * WaveQTL.sd)     WaveQTL.mean.sig2 = WaveQTL.mean     WaveQTL.mean.sig2[wh] = 0     wh = which(abs(WaveQTL.mean) < 3 * WaveQTL.sd)     WaveQTL.mean.sig3 = WaveQTL.mean     WaveQTL.mean.sig3[wh] = 0     raw.data = phenoD     raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))     wh = which(raw.data.T == 0)     this.path = paste0(path.output, ""smooth.ratio.2."", ss)     res = 1 + 70 * WaveQTL.mean.sig2/raw.data.T     res[wh] = 1     write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,          quote = FALSE)     this.path = paste0(path.output, ""smooth.ratio.3."", ss)     res = 1 + 70 * WaveQTL.mean.sig3/raw.data.T     res[wh] = 1     write.table(res, file = this.path, row.names = FALSE, col.names = FALSE,          quote = FALSE)     png(paste0(path.fig, ""ESWaveQTL"", ss, "".png""), height = 4,          width = 7, units = ""in"", res = 300)     numBPs = 1024     xmin = 1     xmax = numBPs     xval = xmin:xmax     nf <- layout(matrix(1:3, 3, 1, byrow = TRUE))     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Major Homozygotes, dark green from multiseq"")     lines(xval, sig0, type = ""l"", col = ""orange"")     lines(xval, sig0.smooth, type = ""l"", col = ""red"")     axis(2, font = 2)     box()     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Heterozygotes"")     lines(xval, sig1, type = ""l"", col = ""skyblue"")     lines(xval, sig1.smooth, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,          WaveQTL.mean)     ymin = min(sig1.smooth - sig0.smooth, WaveQTL.mean.sig3,          WaveQTL.mean)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Major Homozygotes - Heterozygotes, effect size from WaveQTL (0, 2, 3 sd)"")     lines(xval, sig1.smooth - sig0.smooth, type = ""l"", col = ""green"")     lines(xval, WaveQTL.mean, type = ""l"", col = ""orange"")     lines(xval, WaveQTL.mean.sig2, type = ""l"", col = ""red"")     lines(xval, WaveQTL.mean.sig3, type = ""l"", col = ""blue"")     abline(h = 0)     axis(2, font = 2)     box()     dev.off()     png(paste0(path.fig, ""ESsimuWaveQTL"", ss, "".png""), height = 4,          width = 7, units = ""in"", res = 300)     nf <- layout(matrix(1:4, 4, 1, byrow = TRUE))     raw.data = phenoD     raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))     mu0.sig = rep(1/70, 1024)     sig0.WaveQTL = mu0.sig * raw.data.T     sig1.WaveQTL = sig0.WaveQTL - WaveQTL.mean.sig3     wh = which(sig1.WaveQTL < 0)     sig1.WaveQTL[wh] = 0     sig0 = sig0.WaveQTL     sig1 = sig1.WaveQTL     ymax = max(raw.data.T)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Raw data"")     lines(xval, raw.data.T, type = ""l"", col = ""black"")     axis(2, font = 2)     box()     ymax = max(sig0, sig1)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Expected mean g0: red g1: blue [WaveQTL]"")     lines(xval, sig0, type = ""l"", col = ""red"")     lines(xval, sig1, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig1 - sig0)     ymin = min(sig1 - sig0)     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected difference (g1 - g0) [WaveQTL]"")     lines(xval, sig1 - sig0, type = ""l"", col = ""green"")     abline(h = 0)     axis(2, font = 2)     box()     wh1 = which(sig1 == 0)     wh0 = which(sig0 == 0)     min.val = min(sig1[-wh1], sig0[-wh0])     sig1[wh1] = min.val     sig0[wh0] = min.val     ymax = max(log(sig1) - log(sig0))     ymin = min(log(sig1) - log(sig0))     par(mar = c(1, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Expected log ratio (log(g1) - log(g0)) [WaveQTL]"")     lines(xval, log(sig1) - log(sig0), type = ""l"", col = ""green"")     abline(h = 0)     axis(2, font = 2)     box()     dev.off() } else {     cat("""", file = paste0(path.fig, ""NG."", ss)) }",not sure,506494930712506e8,385
"all_ports <- read.csv(""processedData/spatial/ports/all_ports.csv"",      stringsAsFactors = FALSE) %>% rename(pcid = Pcid)",import,572861015098169e8,390
"tickets <- tickets %>% left_join(all_ports[, c(""pcid"", ""lat"")],      by = ""pcid"")",import,572861015098169e8,390
"barplot(pathway1, showCategory = 20)",visualization,959925830829888e7,381
"gene <- seq2gene(peak1, tssRegion = c(-3000, 3000), flankDistance = 3000,      TxDb = tx38)",data cleaning,959925830829888e7,381
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",import,74510195874609e9,386
"tickets$bin_lat <- cut(tickets$lat, breaks = seq(32, 49, 0.2))",data cleaning,572861015098169e8,390
"pathway2 <- enrichPathway(gene, pvalueCutoff = 0.05)",modeling,959925830829888e7,381
"source(paste0(multiscale.analysis.repodir, ""/src/R/my.utils.R""))",import,74510195874609e9,386
"head(pathway2, 2)",data cleaning,959925830829888e7,381
"fig3b <- tickets %>% filter(metier.2010 %in% c(""POT_1"", ""POT_2""),      !is.na(lat)) %>% group_by(trip_id, bin_lat, name) %>% summarize(rev = sum(adj_revenue)) %>%      ggplot(aes(x = bin_lat, y = rev, fill = name)) + geom_bar(stat = ""identity"") +      scale_fill_manual(values = c(""grey20"", ""grey80"")) + theme_classic() +      coord_flip() + xlab(""latitude"") + ylab(""revenue ($)"") + scale_y_reverse() +      theme(axis.line.x = element_line(color = ""black"", size = 0.5),          axis.line.y = element_line(color = ""black"", size = 0.5),          axis.text.y = element_blank(), axis.ticks.y = element_blank(),          axis.title.y = element_blank())",visualization,572861015098169e8,390
"library(""multiseq"")",import,74510195874609e9,386
dotplot(pathway2),visualization,959925830829888e7,381
"barplot(pathway2, showCategory = 50)",visualization,959925830829888e7,381
"library(""ashr"")",import,74510195874609e9,386
"enrichMap(pathway2, layout = igraph::layout.kamada.kawai, vertex.label.cex = 1)",visualization,959925830829888e7,381
"pathway1 <- enrichPathway(as.data.frame(peakAnno)$geneId, pvalueCutoff = 0.05)",modeling,959925830829888e7,381
"ggsave(fig3b, filename = ""Analysis/new_analysis/metiers/tables_figures/fig3b.png"",      height = 10, width = 5, dpi = 300)",export,572861015098169e8,390
"wd.path = paste0(multiscale.analysis.repodir, ""/analysis/simulation/sample_size/simulation_manydsQTL_v2/prepareData/"")",setup,74510195874609e9,386
p <- covplot(peak),modeling,959925830829888e7,381
print(p),communication,959925830829888e7,381
setwd(wd.path),setup,74510195874609e9,386
"tagMatrixList <- lapply(files, getTagMatrix, windows = promoter)",data cleaning,959925830829888e7,381
"load(""processedData/spatial/2_coastline.Rdata"")",import,572861015098169e8,390
"plotAvgProf(tagMatrixList, xlim = c(-3000, 3000))",visualization,959925830829888e7,381
"tagHeatmap(tagMatrixList, xlim = c(-3000, 3000), color = NULL)",visualization,959925830829888e7,381
"png(filename = ""Analysis/new_analysis/metiers/tables_figures/fig3b_map.png"",      height = 960, width = 400)",export,572861015098169e8,390
"path.WaveQTL = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v3/WaveQTL/""",setup,74510195874609e9,386
"peakAnnoList <- lapply(files, annotatePeak, TxDb = tx38, tssRegion = c(-3000,      3000), verbose = FALSE)",visualization,959925830829888e7,381
plotAnnoBar(peakAnnoList),visualization,959925830829888e7,381
"par(mai = rep(0, 4), bg = ""transparent"")",setup,572861015098169e8,390
plotDistToTSS(peakAnnoList),visualization,959925830829888e7,381
"path.fig = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v2/fig/ES/""",setup,74510195874609e9,386
"path.output = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v2/data/""",setup,74510195874609e9,386
"plot(WC, col = ""black"")",visualization,572861015098169e8,390
"genes = lapply(peakAnnoList, function(i) as.data.frame(i)$geneId)",data cleaning,959925830829888e7,381
"path.data = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/""",setup,74510195874609e9,386
vennplot(genes),data cleaning,959925830829888e7,381
dev.off(),export,572861015098169e8,390
"names(genes) = sub(""_"", ""\n"", names(genes))",data cleaning,959925830829888e7,381
"phenoD = as.matrix(read.table(paste0(path.data, ""pheno.dat."",      ss), as.is = TRUE))",import,74510195874609e9,386
"compKEGG <- compareCluster(geneCluster = genes, fun = ""enrichPathway"",      pvalueCutoff = 0.01, pAdjustMethod = ""BH"")",modeling,959925830829888e7,381
"plot(compKEGG, showCategory = 15, title = ""Pathway Enrichment Analysis"")",visualization,959925830829888e7,381
vennplot(genes),visualization,959925830829888e7,381
"enrichPeakOverlap(queryPeak = files[[1]], targetPeak = unlist(files[1:3]),      TxDb = tx38, pAdjustMethod = ""BH"", nShuffle = 1000, chainFile = NULL,      verbose = FALSE)",visualization,959925830829888e7,381
"genoD = scan(paste0(path.data, ""orig.geno.dat."", ss), what = double())",import,74510195874609e9,386
"enrichAnnoOverlap(files[[1]], unlist(files[1:3]), TxDb = NULL,      pAdjustMethod = ""BH"", chainFile = NULL, distanceToTSS_cutoff = NULL)",data cleaning,959925830829888e7,381
genoR = as.numeric(round(genoD)),data cleaning,74510195874609e9,386
"setwd(""~/Documents/Bioinformatics tools/ChIPseeker/hg19"")",setup,959925830829888e7,381
wh0 = which(genoR == 0),exploratory,74510195874609e9,386
wh1 = which(genoR == 1),exploratory,74510195874609e9,386
"hg19 <- getGEOInfo(genome = ""hg19"", simplify = TRUE)",data cleaning,959925830829888e7,381
wh2 = which(genoR == 2),exploratory,74510195874609e9,386
head(hg19),data cleaning,959925830829888e7,381
"hg38 <- getGEOInfo(genome = ""hg38"", simplify = TRUE)",data cleaning,959925830829888e7,381
head(hg38),data cleaning,959925830829888e7,381
"downloadGSMbedFiles(""GSM733656"", destDir = ""hg19"")",export,959925830829888e7,381
"K562_hg19_H3k27ac <- ""GSM733656_hg19_wgEncodeBroadHistoneK562H3k27acStdPk.broadPeak""",import,959925830829888e7,381
K562_hg19_H3k27ac <- readPeakFile(K562_hg19_H3k27ac),import,959925830829888e7,381
"downloadGSMbedFiles(""GSM733778"", destDir = ""hg19"")",export,959925830829888e7,381
"K562_hg19_H3k9ac <- ""GSM733778_hg19_wgEncodeBroadHistoneK562H3k9acStdPk.broadPeak""",import,959925830829888e7,381
K562_hg19_H3k9ac <- readPeakFile(K562_hg19_H3k9ac),import,959925830829888e7,381
"downloadGSMbedFiles(""GSM1003574"", destDir = ""hg19"")",export,959925830829888e7,381
"K562_hg19_Cbp <- ""GSM1003574_hg19_wgEncodeBroadHistoneK562Cbpsc369Pk.broadPeak""",import,959925830829888e7,381
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,959925830829888e7,381
"downloadGSMbedFiles(""GSM1003583"", destDir = ""hg19"")",export,959925830829888e7,381
"K562_hg19_P300 <- ""GSM1003583_hg19_wgEncodeBroadHistoneK562P300StdPk.broadPeak""",import,959925830829888e7,381
"if ((length(wh0) > 2) & (length(wh1) > 2)) {     sig0 = apply(phenoD[wh0, ], 2, mean)     sig1 = apply(phenoD[wh1, ], 2, mean)     library(wavethresh)     sig.all = c(sig0, sig1)     sig.all.smooth = BAYES.THR(sig.all)     sig0.smooth = sig.all.smooth[1:1024]     sig1.smooth = sig.all.smooth[1025:2048]     val = 6     cut.thresh = val/70     delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh)     sig1.smooth[delix] = sig0.smooth[delix]     wh.zero = which(sig0.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig0.smooth[wh.zero] = 1/70     }     wh.zero = which(sig1.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig1.smooth[wh.zero] = 1/70     }     numPerm = NULL     numSig = 10     if (length(wh2) > 0) {         genoF = genoR[-wh2]         phenoF = phenoD[-wh2, ]     }     else {         genoF = genoR         phenoF = phenoD     }     write.table(phenoF, file = paste0(path.WaveQTL, ""/phenoD."",          ss), row.names = FALSE, col.names = FALSE, quote = FALSE)     path.this = paste0(path.WaveQTL, ""/genoD."", ss)     cat(""rs A T "", file = path.this)     cat(genoF, file = path.this, append = TRUE)     res.ES = multiseq(x = as.matrix(phenoF), g = genoF, read.depth = NULL)     if (length(res.ES$effect.mean) == 1024) {         multiseq.mean = res.ES$effect.mean         multiseq.sd = sqrt(res.ES$effect.var)         multiseq.base.mean = res.ES$baseline.mean         wh = which(abs(multiseq.mean) < 2 * multiseq.sd)         multiseq.mean.sig2 = multiseq.mean         multiseq.mean.sig2[wh] = 0         wh = which(abs(multiseq.mean) < 3 * multiseq.sd)         multiseq.mean.sig3 = multiseq.mean         multiseq.mean.sig3[wh] = 0         this.path = paste0(path.output, ""smooth.ratio.2."", ss)         write.table(exp(multiseq.mean.sig2), file = this.path,              row.names = FALSE, col.names = FALSE, quote = FALSE)         this.path = paste0(path.output, ""smooth.ratio.3."", ss)         write.table(exp(multiseq.mean.sig3), file = this.path,              row.names = FALSE, col.names = FALSE, quote = FALSE)         png(paste0(path.fig, ""ESmultiseq"", ss, "".png""), height = 4,              width = 7, units = ""in"", res = 300)         numBPs = 1024         xmin = 1         xmax = numBPs         xval = xmin:xmax         nf <- layout(matrix(1:3, 3, 1, byrow = TRUE))         ymax = max(sig0, sig0.smooth, sig1, sig1.smooth, exp(multiseq.base.mean))         par(mar = c(3, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(0, ymax), axes = FALSE,              main = ""Major Homozygotes, dark green from multiseq"")         lines(xval, sig0, type = ""l"", col = ""orange"")         lines(xval, sig0.smooth, type = ""l"", col = ""red"")         lines(xval, exp(multiseq.base.mean), type = ""l"", col = ""darkgreen"")         axis(2, font = 2)         box()         ymax = max(sig0, sig0.smooth, sig1, sig1.smooth, exp(multiseq.base.mean))         par(mar = c(3, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(0, ymax), axes = FALSE,              main = ""Heterozygotes"")         lines(xval, sig1, type = ""l"", col = ""skyblue"")         lines(xval, sig1.smooth, type = ""l"", col = ""blue"")         axis(2, font = 2)         box()         ymax = max(log(sig1.smooth) - log(sig0.smooth), multiseq.mean)         ymin = min(log(sig1.smooth) - log(sig0.smooth), multiseq.mean)         par(mar = c(3, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(ymin, ymax), axes = FALSE,              main = ""log(Heterozygotes) - log(Major Homozygotes), effect size from multiseq (0, 2, 3 sd)"")         lines(xval, log(sig1.smooth) - log(sig0.smooth), type = ""l"",              col = ""green"")         lines(xval, multiseq.mean, type = ""l"", col = ""orange"")         lines(xval, multiseq.mean.sig2, type = ""l"", col = ""red"")         lines(xval, multiseq.mean.sig3, type = ""l"", col = ""blue"")         abline(h = 0)         axis(2, font = 2)         box()         dev.off()         png(paste0(path.fig, ""ESsimumultiseq"", ss, "".png""), height = 4,              width = 7, units = ""in"", res = 300)         nf <- layout(matrix(1:4, 4, 1, byrow = TRUE))         raw.data = phenoD         raw.data.T = ceiling(as.numeric(apply(raw.data, 2, sum)))         mu0.sig = rep(1/70, 1024)         mu1.sig = mu0.sig * exp(multiseq.mean.sig3)         trunc.fun = function(x) {             x = max(0, x)             return(min(1, x))         }         mu0.sig = sapply(mu0.sig, trunc.fun)         mu1.sig = sapply(mu1.sig, trunc.fun)         sig0 = mu0.sig * raw.data.T         sig1 = mu1.sig * raw.data.T         ymax = max(raw.data.T)         par(mar = c(1, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(0, ymax), axes = FALSE,              main = ""Raw data"")         lines(xval, raw.data.T, type = ""l"", col = ""black"")         axis(2, font = 2)         box()         ymax = max(sig0, sig1)         par(mar = c(1, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(0, ymax), axes = FALSE,              main = ""Expected mean g0: red g1: blue [multiseq]"")         lines(xval, sig0, type = ""l"", col = ""red"")         lines(xval, sig1, type = ""l"", col = ""blue"")         axis(2, font = 2)         box()         ymax = max(sig1 - sig0)         ymin = min(sig1 - sig0)         par(mar = c(1, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(ymin, ymax), axes = FALSE,              main = ""Expected difference (g1 - g0) [multiseq]"")         lines(xval, sig1 - sig0, type = ""l"", col = ""green"")         abline(h = 0)         axis(2, font = 2)         box()         wh1 = which(sig1 == 0)         wh0 = which(sig0 == 0)         min.val = min(sig1[-wh1], sig0[-wh0])         sig1[wh1] = min.val         sig0[wh0] = min.val         ymax = max(log(sig1) - log(sig0))         ymin = min(log(sig1) - log(sig0))         par(mar = c(1, 3, 1, 1))         plot(1, 1, type = ""n"", xlab = ""position"", ylab = """",              xlim = c(xmin, xmax), ylim = c(ymin, ymax), axes = FALSE,              main = ""Expected log ratio (log(g1) - log(g0)) [multiseq]"")         lines(xval, log(sig1) - log(sig0), type = ""l"", col = ""green"")         abline(h = 0)         axis(2, font = 2)         box()         dev.off()     }     else {         cat("""", file = paste0(path.fig, ""NG."", ss))     } } else {     cat("""", file = paste0(path.fig, ""NG."", ss)) }",not sure,74510195874609e9,386
K562_hg19_P300 <- readPeakFile(K562_hg19_P300),import,959925830829888e7,381
"downloadGSMbedFiles(""GSM1003578"", destDir = ""hg19"")",export,959925830829888e7,381
"A549_hg19_H3k27ac <- ""GSM1003578_hg19_wgEncodeBroadHistoneA549H3k27acEtoh02Pk.broadPeak""",import,959925830829888e7,381
A549_hg19_H3k27ac <- readPeakFile(A549_hg19_H3k27ac),import,959925830829888e7,381
library(dplyr),import,74510195874609e9,386
library(ggplot2),import,74510195874609e9,386
GSM1003578,communication,959925830829888e7,381
"df_analysis = read.table(file = ""../../../multiple_types/hp/data/scaling_perf_max.dat"",      header = T)",import,74510195874609e9,386
"Cbp & P300 <- enrichPeakOverlap(hg19_Cbp, hg19_P300, TxDb = NULL,      pAdjustMethod = ""BH"", nShuffle = 1000, chainFile = NULL,      pool = TRUE, mc.cores = detectCores() - 1, verbose = TRUE)",modeling,959925830829888e7,381
print(df_analysis),communication,74510195874609e9,386
"K562_hg19_Cbp <- ""GSM1003574_hg19_wgEncodeBroadHistoneK562Cbpsc369Pk.broadPeak""",import,959925830829888e7,381
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,959925830829888e7,381
"K562_hg19_Cbp.tagMatrix <- getTagMatrix(K562_hg19_Cbp, windows = promoter)",modeling,959925830829888e7,381
"tagHeatmap(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), color = ""red"")",visualization,959925830829888e7,381
"df_total = df_analysis %>% group_by(jobId) %>% select(jobId,      len) %>% ungroup() %>% distinct() %>% summarise(total = sum(len))",exploratory,74510195874609e9,386
peak <- K562_hg19_Cbp,data cleaning,959925830829888e7,381
peak,data cleaning,959925830829888e7,381
rm(list = ls(all = TRUE)),data cleaning,612014478538185e8,391
"peakHeatmap(K562_hg19_Cbp, TxDb = txdb, upstream = 3000, downstream = 3000,      color = ""red"")",visualization,959925830829888e7,381
"plotAvgProf(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), xlab = ""Genomic Region (5'->3')"",      ylab = ""Read Count Frequency"")",visualization,959925830829888e7,381
library(sp),setup,612014478538185e8,391
dfp = df_analysis %>% group_by(flavor) %>% summarise(occ = sum(n)) %>%      cbind(data.frame(df_total)) %>% mutate(freq = occ/total),data cleaning,74510195874609e9,386
"plotAvgProf(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), conf = 0.95,      resample = 1000)",visualization,959925830829888e7,381
library(raster),setup,612014478538185e8,391
"peakAnno <- annotatePeak(K562_hg19_Cbp, tssRegion = c(-3000,      3000), TxDb = txdb, annoDb = ""org.Hs.eg.db"")",visualization,959925830829888e7,381
"write.table(dfp, file = ""../data/hp/4a_flavor_occurence-hp-data.dat"",      row.names = F)",export,74510195874609e9,386
plotAnnoPie(peakAnno),visualization,959925830829888e7,381
library(rgdal),import,612014478538185e8,391
vennpie(peakAnno),visualization,959925830829888e7,381
njobs = length(unique(df_analysis$jobId)),exploratory,74510195874609e9,386
upsetplot(peakAnno),visualization,959925830829888e7,381
library(rgeos),import,612014478538185e8,391
library(geosphere),import,612014478538185e8,391
"upsetplot(peakAnno, vennpie = TRUE)",visualization,959925830829888e7,381
siteSize = 2048,visualization,733296239981428e8,392
"plotDistToTSS(peakAnno, title = ""Distribution of transcription factor-binding loci\nrelative to TSS"")",visualization,959925830829888e7,381
pathway1 <- enrichPathway(as.data.frame(peakAnno)$geneId),data cleaning,959925830829888e7,381
"head(pathway1, 2)",data cleaning,959925830829888e7,381
"dfp = df_analysis %>% group_by(jobId) %>% summarise(nflavor = n()) %>%      ungroup() %>% group_by(nflavor) %>% summarise(occ = n()) %>%      mutate(total = njobs, freq = occ/njobs)",exploratory,74510195874609e9,386
"treatment = ""Copper""",evaluation,733296239981428e8,392
"write.table(dfp, file = ""../data/hp/4a_flavor_number_occurence-hp-data.dat"",      row.names = F)",export,74510195874609e9,386
"gene <- seq2gene(peak, tssRegion = c(-1000, 1000), flankDistance = 3000,      TxDb = txdb)",data cleaning,959925830829888e7,381
pathway2 <- enrichPathway(gene),modeling,959925830829888e7,381
"head(pathway2, 2)",data cleaning,959925830829888e7,381
dotplot(pathway2),visualization,959925830829888e7,381
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,959925830829888e7,381
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,959925830829888e7,381
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,959925830829888e7,381
"south_african_rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/South_africa.shp"")",import,959925830829888e7,381
"south_african_rails@data <- rails@data[1:length(south_african_rails),      ]",data cleaning,959925830829888e7,381
south_african_rails@data[1] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[2] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[3] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[4] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[5] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[6] <- NA,data cleaning,959925830829888e7,381
south_african_rails@data[7] <- NA,data cleaning,959925830829888e7,381
"south_african_rails <- spTransform(south_african_rails, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,959925830829888e7,381
"rails <- spTransform(rails, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,959925830829888e7,381
"write_bib(""devtools"")",communication,912664148956537e8,393
"sink(""analysis/materialforpaper/test.bib"")",not sure,912664148956537e8,393
knitr::write_bib(),communication,912664148956537e8,393
"knitr::write_bib(""devtools"")",communication,912664148956537e8,393
sink(),not sure,912664148956537e8,393
"sink(""analysis/materialforpaper/projectmetadata.tex"")",not sure,912664148956537e8,393
temp = t(Projects_metadata),data cleaning,912664148956537e8,393
temp = as.data.frame(temp),data cleaning,912664148956537e8,393
"Pmeta2 = xtable::xtable(temp, align = ""|p{0.35\\linewidth}|p{0.55\\linewidth}|"",      caption = ""Master metadata information."", label = ""tab:project_metadata"")",communication,912664148956537e8,393
"print(Pmeta2, table.placement = ""!htpb"", include.colnames = F)",export,912664148956537e8,393
sink(),not sure,912664148956537e8,393
"table_categorisation <- read.csv(""analysis/materialforpaper/table_categorisation.csv"")",import,912664148956537e8,393
"sink(""analysis/materialforpaper/tablecat2.tex"")",not sure,912664148956537e8,393
"print(xtable::xtable(table_categorisation, align = ""|l|l|l|l|"",      label = ""cat_table"", caption = ""The initial 45 columns were pooled into 18 and 10 categories.""),      include.rownames = FALSE, table.placement = ""!htbp"")",communication,912664148956537e8,393
sink(),not sure,912664148956537e8,393
"fit.plot.clust <- function(wp.group, scale.factor, image.metric,      clust.method, k) {     stat.val <- compute.image.metric(group = wp.group, sf = scale.factor,          duplicates = TRUE, frame = FALSE, FUN = image.metric,          analysis.dir = ""analysis/"")     d <- dist(1 - stat.val)     fit <- fit.clust(d, cluster.method, dim = k)     plot.clust(fit, cluster.method) }",visualization,912664148956537e8,393
"selectionBarplot <- ggplot(tidyData, aes(x = fatigue)) + geom_bar(aes(fill = result),      position = ""dodge"") + scale_y_discrete(name = ""Correct selection"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,912664148956537e8,393
"ggsave(""./Data/Selection_Barplot_without_zeros.pdf"", selectionBarplot)",export,912664148956537e8,393
"tab1 <- table(tidyData$fatigue, tidyData$result)",exploratory,912664148956537e8,393
"comparison <- epi.2by2(tab1, method = ""cohort.count"", conf.level = 0.9)",exploratory,912664148956537e8,393
"write.xlsx(tab1, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Table"")",export,912664148956537e8,393
"confidenceBarplot <- ggplot(tidyData, aes(x = fatigue)) + geom_bar(aes(fill = confidence),      position = ""dodge"") + scale_y_discrete(name = ""Selection confidence"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,912664148956537e8,393
"ggsave(""./Data/Confidence_Barplot_without_zeros.pdf"", confidenceBarplot)",export,912664148956537e8,393
"tab2 <- table(tidyData$confidence, tidyData$fatigue)",exploratory,912664148956537e8,393
"wilcox <- wilcox.test(as.numeric(confidence) ~ fatigue, data = tidyData,      conf.level = 0.9, alternative = ""two.sided"")",modeling,912664148956537e8,393
"write.xlsx(tab2, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Table confidence"", append = TRUE)",export,912664148956537e8,393
"write.xlsx(wilcox$p.value, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Wilcox confindence p-value"",      append = TRUE)",export,912664148956537e8,393
"perPersonBoxplot <- ggplot(perPersonData, aes(x = fatigue, y = ratio)) +      geom_boxplot() + scale_y_continuous(name = ""Ratio Number wrong Selections / Total Number of Selected Studies"") +      scale_x_discrete(name = ""Fatigue level"") + theme(legend.position = ""bottom"",      legend.direction = ""horizontal"", legend.title = element_blank()) +      theme(axis.text.x = element_text())",visualization,912664148956537e8,393
"all_rails <- rbind(rails, south_african_rails)",data cleaning,959925830829888e7,381
"ggsave(""./Data/Per_Person_Boxplot.pdf"", perPersonBoxplot)",export,912664148956537e8,393
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,959925830829888e7,381
normality <- shapiro.test(perPersonData$ratio),modeling,912664148956537e8,393
opt_loc$dist2rail <- NA,data cleaning,959925830829888e7,381
"wilcox <- wilcox.test(ratio ~ fatigue, data = perPersonData,      conf.level = 0.9, alternative = ""two.sided"")",modeling,912664148956537e8,393
opt_loc$id_closest_rail <- NA,data cleaning,959925830829888e7,381
"for (i in 1:nrow(opt_loc)) {     loc <- c(opt_loc$x[i], opt_loc$y[i])     dist <- dist2Line(loc, all_rails)     opt_loc$dist2rail[i] <- dist[1]/1000     opt_loc$id_closest_rail[i] <- dist[4]     print(i) }",data cleaning,959925830829888e7,381
"write.xlsx(wilcox$p.value, file = paste(""./Data/Analysis_"", Sys.Date(),      "".xlsx"", sep = """"), sheetName = ""Wilcox Per Person p-value"",      append = TRUE)",export,912664148956537e8,393
"write.xlsx(normality$p.value, file = paste(""./Data/Analysis_"",      Sys.Date(), "".xlsx"", sep = """"), sheetName = ""Normality Per Person p-value"",      append = TRUE)",export,912664148956537e8,393
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,959925830829888e7,381
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,959925830829888e7,381
"chr.list = c(17, 17, 12, 2, 1, 2, 7, 8, 19, 4, 6, 7, 9, 19)",import,912664148956537e8,393
library(dplyr),import,255246851360425e8,126
"site.list = c(570, 570, 171, 1617, 166, 106, 762, 965, 3142,      1258, 1240, 738, 1761, 1668)",import,912664148956537e8,393
library(ggplot2),import,255246851360425e8,126
"genoIX.list = c(11, 11, 19, 12, 21, 10, 4, 7, 8, 11, 15, 9, 14,      8)",import,912664148956537e8,393
library(scales),import,255246851360425e8,126
"df <- opt_loc[!is.na(opt_loc$zeta), ]",data cleaning,959925830829888e7,381
library(stringr),import,255246851360425e8,126
library(tidyr),import,255246851360425e8,126
case.list = 1:14,import,912664148956537e8,393
"dir.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/""",setup,912664148956537e8,393
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null > x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null < x))         }, statistic.null = statistic.null)     }     numEqual = sapply(statistic.alt, function(x, statistic.null) {         return(sum(statistic.null == x))     }, statistic.null = statistic.null)     Uval = runif(length(statistic.alt))     pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +          1)     return(pval.list) }",evaluation,381903285160661e8,394
ss = 1,import,912664148956537e8,393
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",evaluation,381903285160661e8,394
"dgg = read.table(file = ""data/google/5a_ar_correction_analysis-google-data.dat"",      header = T) %>% mutate(label = paste(""Google"", scP)) %>%      select(-scP)",import,255246851360425e8,126
siteSize = 2048,evaluation,381903285160661e8,394
"treatment = ""Copper""",evaluation,381903285160661e8,394
"dhp = read.table(file = ""data/hp/5a_ar_correction_analysis-hp-data.dat"",      header = T) %>% mutate(label = ""HP"")",import,255246851360425e8,126
chr = chr.list[ss],data cleaning,912664148956537e8,393
site = site.list[ss],data cleaning,912664148956537e8,393
"dfp = rbind(dgg, dhp)",data cleaning,255246851360425e8,126
genoIX = genoIX.list[ss],data cleaning,912664148956537e8,393
"factors = c(""HP"", ""Google 1:1"", ""Google 1:4"")",data cleaning,255246851360425e8,126
null = FALSE,setup,381903285160661e8,394
"path = paste(""/mnt/lustre/home/shim/wavelets/data/DNase/region_01_sel_step1/chr"",      chr, "".loc"", sep = """")",setup,912664148956537e8,393
"loc_dat = read.table(path, as.is = TRUE)",setup,912664148956537e8,393
row.names(df) <- 1:nrow(df),data cleaning,959925830829888e7,381
"st.posi = as.numeric(loc_dat[site.list[ss], 2])",data cleaning,912664148956537e8,393
"en.posi = as.numeric(loc_dat[site.list[ss], 3])",data cleaning,912664148956537e8,393
"dfp$label = factor(dfp$label, levels = factors)",data cleaning,255246851360425e8,126
"path = paste(""/mnt/lustre/home/shim/wavelets/data/DNase/sel_data_01_step1/DNase."",      chr, ""."", site, "".txt"", sep = """")",setup,912664148956537e8,393
DNase_in = read.table(path),import,912664148956537e8,393
"limits <- aes(ymax = s1, ymin = s2)",visualization,255246851360425e8,126
DNase.Roger = DNase_in,data cleaning,912664148956537e8,393
"strand = ""both""",communication,381903285160661e8,394
dodge <- position_dodge(width = 0.9),visualization,255246851360425e8,126
"dir_map_path = paste(""/mnt/lustre/home/shim/wavelets/data/DNase/sel_data_map_01_step1/DNase."",      chr, sep = """")",setup,912664148956537e8,393
window.size = 100,visualization,381903285160661e8,394
"map_path = paste(dir_map_path, site, ""txt"", sep = ""."")",setup,912664148956537e8,393
dat_map = read.table(map_path),import,912664148956537e8,393
"dfp$class = factor(dfp$class, levels = c(""AR"", ""AR 25"", ""AR 50"",      ""AR 100""))",data cleaning,255246851360425e8,126
map.Roger = dat_map,import,912664148956537e8,393
numSam = 6,communication,381903285160661e8,394
"geno.path = paste0(""/mnt/lustre/home/shim/wavelets/data/DNase/geno_01_step1/geno_maf/chr"",      chr, ""."", site, "".geno"")",setup,912664148956537e8,393
"dfp = dfp %>% mutate(metric_pt = ifelse(metric == ""Cost"", ""Custo"",      ""Violaes de SLO""))",data cleaning,255246851360425e8,126
"genoF = read.table(geno.path, as.is = TRUE)",import,912664148956537e8,393
setwd(wd.path),setup,381903285160661e8,394
"genoD = genoF[genoIX, 4:73]",data cleaning,912664148956537e8,393
"p = ggplot(dfp, aes(label, resp, fill = class)) + geom_bar(stat = ""identity"",      position = ""dodge"", alpha = 0.7) + geom_errorbar(limits,      position = dodge, width = 0.25, size = 1)",visualization,255246851360425e8,126
genoR = as.numeric(round(genoD)),data cleaning,912664148956537e8,393
"p = p + scale_y_continuous(labels = percent) + facet_wrap(~metric_pt,      scales = ""free"")",visualization,255246851360425e8,126
numBPs = 1025,setup,912664148956537e8,393
numINDs = 70,setup,912664148956537e8,393
"p = p + scale_fill_brewer(""Abordagem de predio:"", palette = ""Set1"")",visualization,255246851360425e8,126
filter.cut = 0,data cleaning,381903285160661e8,394
"p = p + theme_bw(base_size = 32) + theme(legend.position = ""top"")",visualization,255246851360425e8,126
"map = rep(0, numBPs * 2)",import,912664148956537e8,393
"p = p + xlab(""Dado de referncia"") + ylab(NULL)",visualization,255246851360425e8,126
"setwd(""~/Analysis/lambda/AliAnalysisLambda/Fitting/FemtoFitting/FitResults/RAnalysis/Analysis"")",import,12392307841219e9,395
"p = p + theme(legend.position = ""top"", legend.key.size = unit(1,      ""cm""))",visualization,255246851360425e8,126
"wh = which(map.Roger[1, ] == 1)",data cleaning,912664148956537e8,393
"p = p + theme(axis.title.y = element_text(vjust = 1.5), axis.title.x = element_text(vjust = 3.1))",visualization,255246851360425e8,126
p,visualization,255246851360425e8,126
"rmsStdDev <- read.csv(""SystematicsCutVariationErrors.csv"")",import,12392307841219e9,395
"map[wh] = rep(1, length(wh))",setup,912664148956537e8,393
"png(filename = ""img/5a_ar_correction_analysis-all.png"", width = 1200,      height = 500)",export,255246851360425e8,126
"sepData <- read.csv(""FitTableSepFitFree.csv"", row.names = 1)",import,12392307841219e9,395
"t_dat = matrix(data = 0, nr = numINDs, nc = numBPs * 2)",data cleaning,912664148956537e8,393
"source(""analysis/JGLibrary.R"")",not sure,176149684935808e8,396
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",import,381903285160661e8,394
"source(""analysis/data_utils_2.R"")",not sure,176149684935808e8,396
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",import,381903285160661e8,394
"t_dat[, wh] = as.matrix(DNase.Roger[, wh])",data cleaning,912664148956537e8,393
print(p),communication,255246851360425e8,126
"results <- sepData[, c(""Type"", ""Mean"", ""RMSError"", ""Sigma"")]",data cleaning,12392307841219e9,395
"phenoD = t_dat[, 1:(numBPs - 1)] + t_dat[, (numBPs + 1):(numBPs +      numBPs - 1)]",data cleaning,912664148956537e8,393
dev.off(),visualization,255246851360425e8,126
"names(results)[names(results) == ""Type""] <- ""Parameter""",data cleaning,12392307841219e9,395
wh0 = which(genoR == 0),exploratory,912664148956537e8,393
"names(results)[names(results) == ""Sigma""] <- ""SigmaFit""",data cleaning,12392307841219e9,395
wh1 = which(genoR == 1),exploratory,912664148956537e8,393
wh2 = which(genoR == 2),exploratory,912664148956537e8,393
library(ggplot2),setup,438302679918706e8,397
length(wh0),exploratory,912664148956537e8,393
length(wh1),exploratory,912664148956537e8,393
length(wh2),exploratory,912664148956537e8,393
library(ggthemes),setup,438302679918706e8,397
"compiledResults <- merge(results, rmsStdDev, by = ""Parameter"",      all = TRUE)",data cleaning,12392307841219e9,395
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,381903285160661e8,394
compiledResults$SigmaTot <- sqrt(compiledResults$SigmaFit^2 +      compiledResults$SigmaCut^2),data cleaning,12392307841219e9,395
library(magrittr),setup,438302679918706e8,397
"write.csv(compiledResults, ""CompiledResults.csv"", row.names = FALSE)",data cleaning,12392307841219e9,395
"dfp %>% filter(class == ""AR"", metric_pt == ""Violaes de SLO"")",data cleaning,255246851360425e8,126
"sig0 = apply(phenoD[wh0, ], 2, mean)",exploratory,912664148956537e8,393
"sig1 = apply(phenoD[wh1, ], 2, mean)",exploratory,912664148956537e8,393
"dfp %>% filter(class != ""AR"", metric_pt == ""Custo"") %>% mutate(V = resp *      100)",data cleaning,255246851360425e8,126
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_hosts.rda""))",import,438302679918706e8,397
"source(""analysis/celline_2_tcga_pipeline.R"")",not sure,176149684935808e8,396
library(wavethresh),setup,912664148956537e8,393
"sepFitFree <- read.csv(""FitTableSepFitFree.csv"", row.names = 1)",import,12392307841219e9,395
"dfa = read.table(file = ""data/hp/5a_ar_correction_analysis-hp-data-raw.dat"",      header = T)",import,255246851360425e8,126
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",data cleaning,381903285160661e8,394
"sig.all = c(sig0, sig1)",data cleaning,912664148956537e8,393
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_applicants.rda""))",import,438302679918706e8,397
"dfb = read.table(file = ""data/google/5a_ar_correction_analysis-google-data-raw.dat"",      header = T)",import,255246851360425e8,126
"source(""analysis/miscFunctions.R"")",not sure,176149684935808e8,396
sig.all.smooth = BAYES.THR(sig.all),modeling,912664148956537e8,393
sig0.smooth = sig.all.smooth[1:1024],exploratory,912664148956537e8,393
"da = dfa %>% filter(class == ""AR"", metric == ""Cost"")",data cleaning,255246851360425e8,126
sig1.smooth = sig.all.smooth[1025:2048],exploratory,912664148956537e8,393
"db = dfb %>% filter(class == ""AR"", metric == ""Cost"")",data cleaning,255246851360425e8,126
"wilcox.test(da$value, alternative = ""less"")",modeling,255246851360425e8,126
"wilcox.test(db$value, alternative = ""less"")",modeling,255246851360425e8,126
computer_subjects <- c(),import,438302679918706e8,397
"source(""analysis/cellline_2_tcga_mutationImporter.R"")",import,176149684935808e8,396
"for (val in c(2, 6, 10)) {     cut.thresh = val/70     delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh)     sig1.smooth[delix] = sig0.smooth[delix]     wh.zero = which(sig0.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig0.smooth[wh.zero] = 1/70     }     wh.zero = which(sig1.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig1.smooth[wh.zero] = 1/70     }     smooth.ratio = sig1.smooth/sig0.smooth     output = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/data/""     write.table(smooth.ratio, file = paste0(output, ""smooth.ratio."",          val), col.names = FALSE, row.names = FALSE, quote = FALSE)     output = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/fig/effectsize/""     png(paste0(output, ""FootprintSignal"", val, "".png""), height = 4,          width = 7, units = ""in"", res = 300)     numBPs = 1024     map = rep(0, numBPs)     wh = which((dat_map[1, 1:numBPs] == 1) | (dat_map[1, (1 +          1025):(numBPs + 1025)] == 1))     map[wh] = rep(1, length(wh))     xmin = st.posi     xmax = en.posi - 1     xval = xmin:xmax     xval_mapp = xval[which(map == 1)]     nf <- layout(matrix(1:4, 4, 1, byrow = TRUE))     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Major Homozygotes"")     axis(1, at = xval_mapp, labels = xval_mapp)     lines(xval, sig0, type = ""l"", col = ""orange"")     lines(xval, sig0.smooth, type = ""l"", col = ""red"")     axis(2, font = 2)     box()     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = ""Heterozygotes"")     axis(1, at = xval_mapp, labels = xval_mapp)     lines(xval, sig1, type = ""l"", col = ""skyblue"")     lines(xval, sig1.smooth, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(0, ymax), axes = FALSE, main = """")     axis(1, at = xval_mapp, labels = xval_mapp)     lines(xval, sig0.smooth, type = ""l"", col = ""red"")     lines(xval, sig1.smooth, type = ""l"", col = ""blue"")     axis(2, font = 2)     box()     ymax = max(sig0.smooth - sig1.smooth)     ymin = min(sig0.smooth - sig1.smooth)     par(mar = c(3, 3, 1, 1))     plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,          xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Major Homozygotes - Heterozygotes"")     axis(1, at = xval_mapp, labels = xval_mapp)     lines(xval, sig0.smooth - sig1.smooth, type = ""l"", col = ""darkgreen"")     abline(h = 0)     axis(2, font = 2)     box()     dev.off() }",not sure,912664148956537e8,393
"da = dfa %>% filter(class != ""AR"", metric == ""Violation"")",data cleaning,255246851360425e8,126
num.tests = length(deseq.alt),setup,381903285160661e8,394
"db = dfb %>% filter(class != ""AR"", metric == ""Violation"")",data cleaning,255246851360425e8,126
summary(da),exploratory,255246851360425e8,126
summary(db),exploratory,255246851360425e8,126
numSites = 578,setup,912664148956537e8,393
"summary(c(da$value, db$value))",exploratory,255246851360425e8,126
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/""",setup,912664148956537e8,393
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/""",setup,912664148956537e8,393
library(synapseClient),setup,176149684935808e8,396
"for (subject in ucas_applicants$`Subject Group (Detailed Level)` %>%      unique()) {     lowerSubject <- subject %>% tolower()     if ((grepl(""compu"", lowerSubject) || grepl(""cyber"", lowerSubject) ||          grepl(""engineer"", lowerSubject) || grepl(""software"",          lowerSubject)) && (!grepl(""comb"", lowerSubject) & !grepl(""other"",          lowerSubject) & !grepl(""any"", lowerSubject) & !grepl(""general"",          lowerSubject) & !grepl(""audio"", lowerSubject) & !grepl(""aerospace"",          lowerSubject) & !grepl(""civil"", lowerSubject) & !grepl(""mechanical"",          lowerSubject) & !grepl(""manufact"", lowerSubject) & !grepl(""chemical"",          lowerSubject))) {         computer_subjects %<>% append(subject)     } }",data cleaning,438302679918706e8,397
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",setup,912664148956537e8,393
"pval.deseq.100.0 = rep(NA, num.tests)",setup,381903285160661e8,394
"done_list_alt = vector(""list"", length(case.name))",setup,912664148956537e8,393
"done_list_null = vector(""list"", length(case.name))",setup,912664148956537e8,393
"filters <- list(subjects = computer_subjects, applicationRoute = ""'Insurance choice'"",      domicile = ""'Northern Ireland'"")",data cleaning,438302679918706e8,397
library(plyr),setup,255246851360425e8,126
library(gdata),setup,255246851360425e8,126
sessionInfo(),setup,255246851360425e8,126
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.alt, case.name[cc], "".output/res."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[1])) {                   logLR_list[IX] = as.numeric(dat[1])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_alt[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.alt, ""sum/logLR."",          case.name[cc], "".Robj"")) }",not sure,912664148956537e8,393
ucas_data <- ucas_applicants %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Applicant Domicile (High Level)` == filters$domicile),data cleaning,438302679918706e8,397
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.null, case.name[cc], "".output/res."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[1])) {                   logLR_list[IX] = as.numeric(dat[1])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.null, ""sum/logLR."",          case.name[cc], "".Robj"")) }",not sure,912664148956537e8,393
"setwd(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data"")",setup,255246851360425e8,126
hostEntrants <- ucas_hosts %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Provider Country` == filters$domicile),data cleaning,438302679918706e8,397
"mn <- read.csv(""rollingsales_manhattan.csv"", skip = 4, header = TRUE)",import,255246851360425e8,126
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,912664148956537e8,393
allYears <- ucas_data$`Cycle Year` %>% unique(),data cleaning,438302679918706e8,397
files <- list.files(path = diffdir),setup,912664148956537e8,393
head(mn),exploratory,255246851360425e8,126
files[1] <- NA,setup,912664148956537e8,393
files[8] <- NA,setup,912664148956537e8,393
summary(mn),exploratory,255246851360425e8,126
totalYears <- totalHostYears <- c(),data cleaning,438302679918706e8,397
files[29] <- NA,setup,912664148956537e8,393
str(mn),exploratory,255246851360425e8,126
files[30] <- NA,data cleaning,912664148956537e8,393
files[31] <- NA,data cleaning,912664148956537e8,393
files <- files[!is.na(files)],data cleaning,912664148956537e8,393
"synapseLogin(""justin.guinney@sagebase.org"", ""marley"")",setup,176149684935808e8,396
"mn$SALE.PRICE.N <- as.numeric(gsub(""[^[:digit:]]"", """", mn$SALE.PRICE))",data cleaning,255246851360425e8,126
names <- files,data cleaning,912664148956537e8,393
ix.final = (1:num.tests)[-del.ix.deseq],data cleaning,381903285160661e8,394
"split <- data.frame(strsplit(names, ""_""))",data cleaning,912664148956537e8,393
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,912664148956537e8,393
"for (year in allYears) {     sub <- subset(ucas_data, `Cycle Year` == year)     totalYears %<>% append(sum(sub$`Number of Acceptances`))     subHosts <- subset(hostEntrants, `Cycle Year` == year)     totalHostYears %<>% append(sum(subHosts$`Number of Acceptances`)) }",data cleaning,438302679918706e8,397
"write.csv(mn, file = ""rollingsales_manhattan_salespriceN.csv"")",export,255246851360425e8,126
"mat <- matrix(nrow = dim(split)[2], ncol = 4)",data cleaning,912664148956537e8,393
sanger <- getSanger_MetaGenomics(),import,176149684935808e8,396
data = data.frame(mat),data cleaning,912664148956537e8,393
str(mn),exploratory,255246851360425e8,126
"colnames(data) <- c(""strain"", ""timepoint"", ""filename"", ""dir"")",data cleaning,912664148956537e8,393
"df <- data.frame(years = allYears, totalApplicationYears = totalYears,      totalHostYears = totalHostYears, stringsAsFactors = FALSE)",data cleaning,438302679918706e8,397
ccle <- getCCLE_MetaGenomics(),import,176149684935808e8,396
"for (i in seq(1, (dim(split)[2]))) {     data$strain[i] <- as.character(split[1, i])     data$timepoint[i] <- as.character(split[4, i])     filename <- paste(split[, i], collapse = ""_"")     data$filename[i] <- filename     data$dir[i] <- paste(diffdir, filename, sep = ""/"") }",data cleaning,912664148956537e8,393
"ggplot(data = df) + geom_line(aes(x = years, y = totalApplicationYears,      colour = ""Applications"")) + geom_point(aes(x = years, y = totalApplicationYears,      colour = ""Applications"")) + geom_line(aes(x = years, y = totalHostYears,      colour = ""Acceptances"")) + geom_point(aes(x = years, y = totalHostYears,      colour = ""Acceptances"")) + scale_colour_discrete(name = """",      labels = c(""UCAS Acceptances"", ""UCAS Applications"")) + ylab(""Number"") +      xlab(""Years"") + labs(title = ""Number of UCAS applications from NI students to UK firms &\n number of UCAS acceptancs by NI universities in EEECS subjects"") +      theme_minimal()",visualization,438302679918706e8,397
"write.table(data, ""autoanalysisInfo.csv"", sep = "","")",export,912664148956537e8,393
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-applications-insurance.png""),      device = ""png"")",export,438302679918706e8,397
"source(""../../bin/singleDrugAnalysis.R"")",setup,255246851360425e8,126
"source(""../../bin/ctrpSingleAgentScreens.R"")",setup,255246851360425e8,126
"dat <- read.csv(""autoanalysisInfo.csv"", header = TRUE, stringsAsFactors = FALSE)",import,912664148956537e8,393
"source(""../../bin/ncatsSingleAgentScreens.R"")",setup,255246851360425e8,126
pval.deseq.100.0[ix.final] = pval.deseq,export,381903285160661e8,394
i <- as.numeric(as.character(commandArgs(TRUE)[1])),data cleaning,912664148956537e8,393
ucas_data$demandSupplyDiff <- ucas_data$`Number of Acceptances` -      hostEntrants$`Number of Acceptances`,data cleaning,438302679918706e8,397
length(del.ix.deseq),setup,381903285160661e8,394
filename <- dat$filename[i],setup,912664148956537e8,393
"ucas_data$vacanciesRecorded <- c(540, 505, 530, 560, 610, 635,      700, 775, 760, 715, 785, 745)",import,438302679918706e8,397
"fs = synapseQuery(""select name,id from entity where parentId=='syn5674273'"")",import,255246851360425e8,126
filter.cut = 0,setup,381903285160661e8,394
print(filename),communication,912664148956537e8,393
print(dat$strain[i]),communication,912664148956537e8,393
"fs = fs[grep(""csv"", fs[, 1]), ]",data cleaning,255246851360425e8,126
"ucas_application_chart <- ggplot(data = ucas_data, aes(x = `Cycle Year`,      y = `Number of Acceptances`, fill = `Subject Group (Detailed Level)`)) +      geom_area(colour = ""black"", size = 0.2, alpha = 0.4) + labs(title = paste0(""UK university applications by all "",      filters$applicationRoute, "" NI applicants (2007-2018)"")) +      ylab(""Number of acceptances"") + xlab(""Year"") + scale_fill_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,438302679918706e8,397
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.full.pval."",      filter.cut, "".txt""))[, 1])",import,381903285160661e8,394
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-applications-insurance.png""),      plot = ucas_application_chart, device = ""png"")",export,438302679918706e8,397
dir.create(filename),export,912664148956537e8,393
"for (sid in fs[, 2]) synDelete(sid)",import,255246851360425e8,126
"ucas_acceptance_chart <- ggplot(data = hostEntrants, aes(x = `Cycle Year`,      y = `Number of Acceptances`, fill = `Subject Group (Detailed Level)`)) +      geom_area(colour = ""black"", size = 0.2, alpha = 0.4) + labs(title = paste0(""All NI University acceptances by all "",      filters$applicationRoute, "" applicants (2007--2018)"")) +      ylab(""Number of acceptances"") + xlab(""Year"") + scale_fill_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,438302679918706e8,397
setwd(filename),setup,912664148956537e8,393
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-acceptance.png""),      plot = ucas_acceptance_chart, device = ""png"")",export,438302679918706e8,397
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.full.pval."",      filter.cut, "".txt""))[, 1])",import,381903285160661e8,394
"knit2html(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/StrainTemplate.Rmd"",      output = paste(filename, "".md"", sep = """"), quiet = TRUE)",communication,912664148956537e8,393
library(knitr),setup,912664148956537e8,393
"afiles = list.files(""../2016-02-17"")",communication,255246851360425e8,126
"analysisdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/""",setup,912664148956537e8,393
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,912664148956537e8,393
"ucas_gap_chart <- ggplot(data = ucas_data, aes(x = `Cycle Year`)) +      geom_point(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      geom_line(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      labs(title = paste0(""Difference between number of University applications and number of acceptances (2007--2018)"")) +      ylab(""Demand / supply difference"") + xlab(""Year"") + scale_colour_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,438302679918706e8,397
setwd(diffdir),setup,912664148956537e8,393
files <- list.files(),setup,912664148956537e8,393
names <- files,setup,912664148956537e8,393
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-demand-suplus.png""),      plot = ucas_gap_chart, device = ""png"")",export,438302679918706e8,397
"cluster.dir = ""syn5730130""",setup,255246851360425e8,126
"split <- data.frame(strsplit(names, ""_""))",data cleaning,912664148956537e8,393
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,912664148956537e8,393
"csvs = afiles[grep(""csv"", afiles)]",setup,255246851360425e8,126
"adult_directories <- split[, which(split[4, ] == ""Adult"")]",data cleaning,912664148956537e8,393
setwd(analysisdir),setup,912664148956537e8,393
"this.script = ""https://raw.githubusercontent.com/Sage-Bionetworks/NTAP/master/pnfCellLines/analysis/2016-02-17/testClusterParams.R""",setup,255246851360425e8,126
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,381903285160661e8,394
"ncats.script = ""https://raw.githubusercontent.com/Sage-Bionetworks/NTAP/master/pnfCellLines/bin/ncatsSingleAgentScreens.R""",setup,255246851360425e8,126
"for (i in seq(1, (dim(adult_directories)[2]))) {     setwd(analysisdir)     strain <- as.character(adult_directories[1, i])     timepoint <- ""Adult""     filename <- paste(adult_directories[, i], collapse = ""_"")     dir <- paste(diffdir, filename, sep = ""/"")     dir.create(filename)     print(filename)     print(dir)     print(strain)     setwd(filename)     knit2html(""../StrainTemplate.Rmd"", output = paste(filename,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain)     setwd(analysisdir) }",setup,912664148956537e8,393
library(knitr),setup,912664148956537e8,393
"ctrp.script = ""https://raw.githubusercontent.com/Sage-Bionetworks/NTAP/master/pnfCellLines/bin/ctrpSingleAgentScreens.R""",setup,255246851360425e8,126
"analysis.script = ""https://raw.githubusercontent.com/Sage-Bionetworks/NTAP/master/pnfCellLines/bin/singleDrugAnalysis.R""",setup,255246851360425e8,126
"analysisdir <- ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/""",setup,912664148956537e8,393
"diffdir <- ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs""",setup,912664148956537e8,393
setwd(diffdir),setup,912664148956537e8,393
files <- list.files(),setup,912664148956537e8,393
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",data cleaning,381903285160661e8,394
names <- files,setup,912664148956537e8,393
"split <- data.frame(strsplit(names, ""_""))",data cleaning,912664148956537e8,393
"rownames(split) <- c(""strain"", ""vs"", ""wt"", ""timepoint"")",data cleaning,912664148956537e8,393
"embryonic_directories <- split[, which(split[4, ] == ""Embryonic"")]",data cleaning,912664148956537e8,393
setwd(analysisdir),setup,912664148956537e8,393
"for (i in seq(1, (dim(embryonic_directories)[2]))) {     strain <- as.character(embryonic_directories[1, i])     timepoint <- ""Embryonic""     filename <- paste(embryonic_directories[, i], collapse = ""_"")     dir <- paste(diffdir, filename, sep = ""/"")     dir.create(filename)     print(filename)     print(dir)     print(strain)     setwd(filename)     knit2html(""../StrainTemplate.Rmd"", output = paste(filename,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain)     setwd(analysisdir) }",not sure,912664148956537e8,393
"for (csv in csvs) {     csv = paste(""../2016-02-17"", csv, sep = ""/"")     if (length(grep(""ncats"", csv)) > 0) {         if (length(grep(""rescored"", csv)) > 0) {             uf = ""syn5637634""         }         else {             uf = ""syn5522627""         }         sf = File(csv, parentId = cluster.dir)         synStore(sf, used = list(list(url = this.script, wasExecuted = TRUE),              list(url = ncats.script, wasExecuted = TRUE), list(url = analysis.script,                  wasExecuted = TRUE), list(entity = uf, wasExecuted = FALSE)),              activityName = ""drug AUC Clustering"")     }     else if (length(grep(""ctrp"", csv)) > 0) {         if (length(grep(""rescored"", csv)) > 0) {             uf = ""syn5622708""         }         else {             uf = ""syn5632189""         }         sf = File(csv, parentId = cluster.dir)         synStore(sf, used = list(list(url = this.script, wasExecuted = TRUE),              list(url = ctrp.script, wasExecuted = TRUE), list(url = analysis.script,                  wasExecuted = TRUE), list(entity = uf, wasExecuted = FALSE)),              activityName = ""drug AUC Clustering"")     }     else {         sf = File(csv, parentId = cluster.dir)         synStore(sf, used = list(list(url = this.script, wasExecuted = TRUE),              list(url = ncats.script, wasExecuted = TRUE), list(url = ctrp.script,                  wasExecuted = TRUE), list(url = analysis.script,                  wasExecuted = TRUE)), activityName = ""drug AUC Clustering Summary"")     } }",import,255246851360425e8,126
library(pecanapi),setup,912664148956537e8,393
library(tidyverse),setup,912664148956537e8,393
args = (commandArgs(TRUE)),setup,255246851360425e8,126
eval(parse(text = args[[1]])),communication,255246851360425e8,126
num.tests = length(deseq.alt),communication,381903285160661e8,394
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,255246851360425e8,126
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",import,255246851360425e8,126
"wd.path = paste0(multiscale.analysis.repodir, ""/analysis/simulation/sample_size/simulation_simple_v2/prepareData/"")",setup,255246851360425e8,126
setwd(wd.path),setup,255246851360425e8,126
"path.output = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_simple_v2/data/""",export,255246851360425e8,126
"path.data = ""~/multiscale_analysis/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/""",setup,255246851360425e8,126
"pval.deseq.full.0 = rep(NA, num.tests)",setup,381903285160661e8,394
"phenoD = as.matrix(read.table(paste0(path.data, ""pheno.dat."",      ss), as.is = TRUE))",import,255246851360425e8,126
"genoD = scan(paste0(path.data, ""orig.geno.dat."", ss), what = double())",import,255246851360425e8,126
ix.final = (1:num.tests)[-del.ix.deseq],data cleaning,381903285160661e8,394
genoR = as.numeric(round(genoD)),data cleaning,255246851360425e8,126
workflow_id <- 99000000066,setup,912664148956537e8,393
wh0 = which(genoR == 0),data cleaning,255246851360425e8,126
"outdir <- file.path(""analysis"", ""data"", ""model_output"", workflow_id)",setup,912664148956537e8,393
wh1 = which(genoR == 1),data cleaning,255246851360425e8,126
wh2 = which(genoR == 2),data cleaning,255246851360425e8,126
"dir.create(outdir, recursive = TRUE, showWarnings = FALSE)",export,912664148956537e8,393
"years <- seq(1902, 1990)",data cleaning,912664148956537e8,393
"run_ids <- readLines(output_url(workflow_id, ""run/runs.txt""))",import,912664148956537e8,393
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,315324341645464e8,398
"for (runid in run_ids) {     message(""Run ID: "", runid)     rundir <- file.path(outdir, runid)     dir.create(rundir, recursive = TRUE, showWarnings = FALSE)     pb <- progress::progress_bar$new(total = length(years))     for (year in years) {         pb$tick()         ncfile <- paste0(year, "".nc"")         target_file <- file.path(rundir, ncfile)         if (!file.exists(target_file)) {             tryCatch(download.file(run_url(workflow_id, ncfile,                  runid), target_file, quiet = TRUE), error = function(e) {                 message(""Failed to download. Skipping to next file."")             })         }         analysis_file <- paste0(""analysis-T-"", year, ""-00-00-000000-g01.h5"")         analysis_full_file <- file.path(rundir, analysis_file)         if (!file.exists(analysis_full_file)) {             tryCatch(download.file(run_url(workflow_id, analysis_file,                  runid), analysis_full_file, quiet = TRUE), error = function(e) {                 message(""Failed to download. Skipping to next file."")             })         }         y_file <- paste0(""analysis-Y-"", year, ""-00-00-000000-g01.h5"")         y_full_file <- file.path(rundir, y_file)         if (!file.exists(y_full_file)) {             tryCatch(download.file(run_url(workflow_id, y_file,                  runid), y_full_file, quiet = TRUE), error = function(e) {                 message(""Failed to download. Skipping to next file."")             })         }     } }",not sure,912664148956537e8,393
"source(""/Users/Seth/Documents/TrumpDiscourse/Analysis/trump-cleaning.R"")",import,315324341645464e8,398
"source(""/Users/Seth/Documents/TrumpDiscourse/Analysis/trump-plotting.R"")",import,315324341645464e8,398
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null > x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null < x))         }, statistic.null = statistic.null)     }     numEqual = sapply(statistic.alt, function(x, statistic.null) {         return(sum(statistic.null == x))     }, statistic.null = statistic.null)     Uval = runif(length(statistic.alt))     pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +          1)     return(pval.list) }",modeling,912664148956537e8,393
library(plotly),setup,315324341645464e8,398
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,912664148956537e8,393
library(reshape2),setup,315324341645464e8,398
"if ((length(wh0) > 2) & (length(wh1) > 2)) {     sig0 = apply(phenoD[wh0, ], 2, mean)     sig1 = apply(phenoD[wh1, ], 2, mean)     library(wavethresh)     sig.all = c(sig0, sig1)     sig.all.smooth = BAYES.THR(sig.all)     sig0.smooth = sig.all.smooth[1:1024]     sig1.smooth = sig.all.smooth[1025:2048]     val = 6     cut.thresh = val/70     delix = which(abs(sig0.smooth - sig1.smooth) <= cut.thresh)     sig1.smooth[delix] = sig0.smooth[delix]     wh.zero = which(sig0.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig0.smooth[wh.zero] = 0     }     wh.zero = which(sig1.smooth <= 1/70)     if (length(wh.zero) > 0) {         sig1.smooth[wh.zero] = 0     }     sig.mat = cbind(sig0.smooth, sig1.smooth)     null.sig = apply(sig.mat, 1, mean)     write.table(sig0.smooth, file = paste0(path.output, ""alt.sig0."",          ss), col.names = FALSE, row.names = FALSE, quote = FALSE)     write.table(sig1.smooth, file = paste0(path.output, ""alt.sig1."",          ss), col.names = FALSE, row.names = FALSE, quote = FALSE)     write.table(null.sig, file = paste0(path.output, ""null.sig0."",          ss), col.names = FALSE, row.names = FALSE, quote = FALSE)     write.table(null.sig, file = paste0(path.output, ""null.sig1."",          ss), col.names = FALSE, row.names = FALSE, quote = FALSE) } else {     cat("""", file = paste0(path.output, ""NG."", ss)) }",export,255246851360425e8,126
siteSize = 2048,setup,912664148956537e8,393
"setwd(""/Users/Seth/Documents/TrumpDiscourse/modelOutput/newDocsLogs"")",import,315324341645464e8,398
"treatment = ""Copper""",setup,912664148956537e8,393
null = FALSE,setup,912664148956537e8,393
"strand = ""both""",setup,912664148956537e8,393
window.size = 100,setup,912664148956537e8,393
numSam = 6,setup,912664148956537e8,393
setwd(wd.path),setup,912664148956537e8,393
filter.cut = 0,setup,912664148956537e8,393
"calc_vessel_vars <- function() {     library(dplyr)     library(tidyr)     library(vegan)     vessel_landings <- readRDS(""Analysis/new_analysis/catch_shares/Analysis/vessel_landings_data.RDS"")     cg1 <- read.csv(""rawData/Catch/vessel_registration/CG_2009-2012_woc_141210_three.csv"",          stringsAsFactors = FALSE, skip = 2)     cg2 <- read.csv(""rawData/Catch/vessel_registration/CG_2013_woc_141210_three.csv"",          stringsAsFactors = FALSE, skip = 2)     cg <- rbind(cg1, cg2)     rm(cg1, cg2)     cg <- cg[-which(cg$pubyr < 2006 | cg$pubyr > 2014), ]     cg_vessels <- unique(cg[, c(""hull_number"", ""vessel_id"", ""vessel_name"",          ""pubyr"", ""length"", ""horsepower"", ""hp_main_astern"", ""breadth"",          ""depth"")])     sv <- read.csv(""rawData/Catch/vessel_registration/SV_2009-2013_woc_141210_two.csv"",          stringsAsFactors = FALSE, skip = 2)     colnames(sv)[1] <- ""year""     sv$year <- as.integer(sv$year)     sv <- sv[-which(is.na(sv$year)), ]     sv_vessels <- unique(sv[, c(""year"", ""svid"", ""plate"", ""name"",          ""length"", ""weight"", ""horsepower"", ""charterboat"")])     sv_cg <- merge(sv_vessels, cg_vessels, by.x = c(""svid"", ""year""),          by.y = c(""vessel_id"", ""pubyr""), all.x = TRUE, all.y = TRUE)     sv_cg <- rename(sv_cg, drvid = svid)     length_data <- sv_cg[which(sv_cg$drvid %in% unique(vessel_landings$drvid)),          ]     length_ref <- length_data %>% group_by(drvid) %>% summarize(len = mean(length.x,          length.y, na.rm = TRUE, trim = 0), hp = mean(horsepower.x,          horsepower.y, hp_main_astern, trim = 0, na.rm = TRUE),          weight = mean(weight, na.rm = T, trim = 0), breadth = mean(breadth,              na.rm = T, trim = 0), depth = mean(depth, na.rm = T,              trim = 0))     ports <- read.csv(""processedData/spatial/ports/all_ports.csv"",          stringsAsFactors = FALSE)     ports <- rename(ports, pcid = Pcid)     loc_ref <- vessel_landings %>% left_join(ports, by = ""pcid"") %>%          dplyr::select(drvid, trip_id, lat, year) %>% distinct() %>%          mutate(period = ifelse(year < 2011, ""before"", ""after"")) %>%          group_by(drvid, period) %>% summarize(average_lat = mean(lat,          na.rm = T)) %>% spread(period, average_lat) %>% group_by(drvid) %>%          mutate(overall.lat = mean(c(before, after), na.rm = T)) %>%          rename(after.lat = after, before.lat = before)     rev_ref <- vessel_landings %>% mutate(period = ifelse(year <          2011, ""before"", ""after"")) %>% group_by(drvid, period) %>%          summarize(rev = sum(adj_revenue, na.rm = T)) %>% spread(period,          rev) %>% group_by(drvid) %>% mutate(overall.rev = mean(c(before,          after), na.rm = T)) %>% rename(after.rev = after, before.rev = before)     ak <- read.csv(""Analysis/new_analysis/catch_shares/Analysis/WC_drvids_alaska.csv"",          stringsAsFactors = FALSE)     ak <- filter(ak, drvid %in% unique(vessel_landings$drvid))     twl_prior = vessel_landings %>% dplyr::select(trip_id, drvid,          metier.2010, year) %>% distinct() %>% filter(year < 2011) %>%          group_by(drvid) %>% summarize(twl_prior = ifelse(any(metier.2010 %in%          c(""TWL_1"", ""TWL_5"", ""TWL_7"", ""TWL_8"", ""TWL_9"", ""TWL_10"",              ""TWL_11"", ""TWL_12"", ""TWL_13"")), 1, 0))     quota_post = vessel_landings %>% dplyr::select(trip_id, drvid,          fleet, year) %>% distinct() %>% filter(year > 2011) %>%          group_by(drvid) %>% summarize(itq_post = ifelse(any(fleet ==          ""LE""), 1, 0))     twl_partip = full_join(twl_prior, quota_post, by = ""drvid"")     twl_partip$ifq_flag = NA     twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & twl_partip$itq_post ==          0)] = ""general fleet""     twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & twl_partip$itq_post ==          1)] = ""itq entrant: general fleet""     twl_partip$ifq_flag[which(twl_partip$twl_prior == 0 & is.na(twl_partip$itq_post))] = ""general fleet exit""     twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & twl_partip$itq_post ==          0)] = ""LE gf exit, still fish""     twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & twl_partip$itq_post ==          1)] = ""itq stay on""     twl_partip$ifq_flag[which(twl_partip$twl_prior == 1 & is.na(twl_partip$itq_post))] = ""LE gf total exit""     twl_partip$ifq_flag[which(is.na(twl_partip$twl_prior) & twl_partip$itq_post ==          1)] = ""itq entrant""     twl_partip$ifq_flag[which(is.na(twl_partip$twl_prior) & twl_partip$itq_post ==          0)] = ""general fleet entrant""     twl_partip <- dplyr::select(twl_partip, drvid, ifq_flag)     period_ref <- vessel_landings %>% dplyr::select(drvid, both.periods) %>%          distinct()     c.halibut_ref <- vessel_landings %>% dplyr::select(trip_id,          drvid, metier.2010, year) %>% distinct() %>% filter(year <          2011) %>% group_by(drvid) %>% summarize(c.halibut = ifelse(any(metier.2010 ==          ""TWL_2""), 1, 0))     library(vegan)     metier10_div <- vessel_landings %>% filter(both.periods ==          1) %>% mutate(period = ifelse(year < 2011, 0, 1)) %>%          group_by(drvid, period, metier.2010) %>% summarize(revenue = sum(adj_revenue)) %>%          group_by(drvid, period) %>% summarize(shannon = vegan::diversity(revenue,          index = ""shannon""), simpson = vegan::diversity(revenue,          index = ""simpson""), eff.shannon = exp(vegan::diversity(revenue,          index = ""shannon"")), eff.simpson = 1/(1 - vegan::diversity(revenue,          index = ""simpson""))) %>% group_by(drvid) %>% mutate(delta.shannon = diff(shannon),          delta.simpson = diff(simpson), delta.eff.shannon = diff(eff.shannon),          delta.eff.simpson = diff(eff.simpson)) %>% filter(period ==          0) %>% dplyr::select(-period)     colnames(metier10_div) <- paste(colnames(metier10_div), ""2010"",          sep = ""_"")     colnames(metier10_div)[which(colnames(metier10_div) == ""drvid_2010"")] <- ""drvid""     div_metrics <- vessel_landings %>% filter(both.periods ==          1) %>% mutate(period = ifelse(year < 2011, 0, 1)) %>%          group_by(drvid, period, metier.2012) %>% summarize(revenue = sum(adj_revenue)) %>%          group_by(drvid, period) %>% summarize(shannon_2012 = vegan::diversity(revenue,          index = ""shannon""), simpson_2012 = vegan::diversity(revenue,          index = ""simpson""), eff.shannon_2012 = exp(vegan::diversity(revenue,          index = ""shannon"")), eff.simpson_2012 = 1/(1 - vegan::diversity(revenue,          index = ""simpson""))) %>% group_by(drvid) %>% mutate(delta.shannon_2012 = diff(shannon_2012),          delta.simpson_2012 = diff(simpson_2012), delta.eff.shannon_2012 = diff(eff.shannon_2012),          delta.eff.simpson_2012 = diff(eff.simpson_2012)) %>%          filter(period == 0) %>% dplyr::select(-period) %>% left_join(metier10_div)     le_boats <- vessel_landings %>% filter(both.periods == 1) %>%          mutate(period = ifelse(year < 2011, 0, 1)) %>% group_by(drvid,          period, metier.2010) %>% summarize(ntrips = length(unique(trip_id)),          nrev = sum(adj_revenue), nlbs = sum(pounds)) %>% group_by(drvid,          period) %>% summarize(nfisheries = length(unique(metier.2010)),          rev = sum(nrev), lbs = sum(nlbs)) %>% group_by(drvid) %>%          summarize(delta.nfisheries = diff(nfisheries))     comp <- vessel_landings %>% filter(both.periods == 1) %>%          mutate(period = ifelse(year < 2011, 0, 1)) %>% select(drvid,          period, metier.2010) %>% distinct() %>% group_by(drvid) %>%          summarize(composition = ifelse(all(metier.2010[period ==              0] %in% metier.2010[period == 1]) & all(metier.2010[period ==              1] %in% metier.2010[period == 0]), ""unchanged"", ifelse(any(!(metier.2010[period ==              0] %in% metier.2010[period == 1])) & any(!(metier.2010[period ==              1] %in% metier.2010[period == 0])), ""added and lost"",              ifelse(any(!(metier.2010[period == 0] %in% metier.2010[period ==                  1])) & all(metier.2010[period == 1] %in% metier.2010[period ==                  0]), ""lost"", ifelse(any(!(metier.2010[period ==                  1] %in% metier.2010[period == 0])) & all(metier.2010[period ==                  0] %in% metier.2010[period == 1]), ""gained"",                  NA))))) %>% left_join(le_boats)     vessel_stats <- ak %>% full_join(twl_partip) %>% full_join(length_ref) %>%          full_join(loc_ref) %>% full_join(rev_ref) %>% full_join(period_ref) %>%          full_join(c.halibut_ref) %>% full_join(div_metrics) %>%          full_join(comp)     vessel_stats$alaska[is.na(vessel_stats$alaska)] <- 0     vessel_stats$zone <- cut(x = vessel_stats$overall.lat, breaks = rev(c(32,          36, 40, 43, 49)), labels = c(""N. Cape Blanco"", ""Cape Blanco - Cape Mendocino"",          ""Cape Mendocino - Point Sur"", ""S. Point Sur""), include.lowest = TRUE)     vessel_stats$type <- ifelse(vessel_stats$eff.shannon_2010 ==          1, ""specialist"", ""generalist"")     saveRDS(vessel_stats, ""Analysis/new_analysis/catch_shares/Analysis/vessel_stats.RDS"")     return(vessel_stats) }",import,207004600437358e8,399
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",data cleaning,912664148956537e8,393
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",data cleaning,912664148956537e8,393
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,912664148956537e8,393
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",modeling,912664148956537e8,393
"setwd(""C:/Users/mcolvin/Documents/projects/Collaborations/Noxubee-Bats/analysis"")",setup,941605825442821e8,400
num.tests = length(deseq.alt),exploratory,912664148956537e8,393
"source(""./src/1_global.R"")",setup,941605825442821e8,400
"pval.deseq.100.0 = rep(NA, num.tests)",exploratory,912664148956537e8,393
"source(""./src/2_functions.R"")",setup,941605825442821e8,400
ix.final = (1:num.tests)[-del.ix.deseq],exploratory,912664148956537e8,393
"source(""./src/3_load.R"")",setup,941605825442821e8,400
"source(""./src/4_clean.R"")",setup,941605825442821e8,400
"source(""./src/5_tables.R"")",setup,941605825442821e8,400
"source(""./src/6_figures.R"")",setup,941605825442821e8,400
"source(""./src/7_analysis.R"")",setup,941605825442821e8,400
pval.deseq.100.0[ix.final] = pval.deseq,data cleaning,912664148956537e8,393
length(del.ix.deseq),exploratory,912664148956537e8,393
filter.cut = 0,exploratory,912664148956537e8,393
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.full.pval."",      filter.cut, "".txt""))[, 1])",data cleaning,912664148956537e8,393
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.full.pval."",      filter.cut, "".txt""))[, 1])",data cleaning,912664148956537e8,393
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",exploratory,912664148956537e8,393
"knit2html(""./src/build.Rmd"", fragment.only = TRUE)",export,941605825442821e8,400
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,686162692727521e8,401
library(ogbox),setup,941605825442821e8,400
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,686162692727521e8,401
library(purrr),setup,941605825442821e8,400
library(gplots),setup,941605825442821e8,400
library(glue),setup,941605825442821e8,400
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",modeling,912664148956537e8,393
num.tests = length(deseq.alt),exploratory,912664148956537e8,393
"pval.deseq.full.0 = rep(NA, num.tests)",setup,912664148956537e8,393
ix.final = (1:num.tests)[-del.ix.deseq],exploratory,912664148956537e8,393
pval.deseq.full.0[ix.final] = pval.deseq,exploratory,912664148956537e8,393
length(del.ix.deseq),exploratory,912664148956537e8,393
"library(""data.table"")",data cleaning,686162692727521e8,401
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,912664148956537e8,393
"save(""pval.deseq.100.0"", ""pval.deseq.full.0"", file = out.path)",export,912664148956537e8,393
"setwd("""")",setup,912664148956537e8,393
"library(""vcfR"")",setup,912664148956537e8,393
"library(""poppr"")",setup,912664148956537e8,393
"library(""ggplot2"")",setup,912664148956537e8,393
"library(""dplyr"")",setup,686162692727521e8,401
"cat(""\f"")",not sure,26490974589251e9,402
"load(""../adegenet_dapc_analysis/gl_1990_rmNA_LD.Rdata"")",import,912664148956537e8,393
"library(""jsonlite"")",setup,686162692727521e8,401
"load(""../adegenet_dapc_analysis/gl_2015_rmNA_LD.Rdata"")",import,912664148956537e8,393
"library(""textcat"")",setup,686162692727521e8,401
rm(list = ls(all = TRUE)),setup,26490974589251e9,402
library(BGLR),setup,26490974589251e9,402
library(doParallel),setup,26490974589251e9,402
library(gdata),setup,26490974589251e9,402
library(Rcpp),setup,26490974589251e9,402
"con <- file.path(""./data/all_participants_all_data_2002_2014_2.json"")",import,686162692727521e8,401
library(RcppArmadillo),setup,26490974589251e9,402
library(RcppParallel),setup,26490974589251e9,402
"ia_1990 <- samp.ia(gl_1990_rmNA_LD, n.snp = 10000L, reps = 100L)",exploratory,912664148956537e8,393
data <- fromJSON(con),import,686162692727521e8,401
"ia_2015 <- samp.ia(gl_2015_rmNA_LD, n.snp = 10000L, reps = 100L)",exploratory,912664148956537e8,393
"sourceCpp(""~/Dropbox/Columbia Radiogenomics/Software/Kernel_Functions.cpp"")",import,26490974589251e9,402
mello_data <- as_data_frame(data),import,686162692727521e8,401
"sex <- glSim(30, 1282703, ploid = 2, LD = T)",not sure,912664148956537e8,393
"load(""~/Dropbox/Columbia Radiogenomics/Data/MRI_ECs.RData"")",import,26490974589251e9,402
"clone_50 <- glSim(30, 1282703, n.snp.struc = 641352, ploid = 2,      LD = T)",not sure,912664148956537e8,393
"clone_75 <- glSim(30, 1282703, n.snp.struc = 962027, ploid = 2,      LD = T)",not sure,912664148956537e8,393
"clone_100 <- glSim(30, 1282703, n.snp.struc = 1282703, ploid = 2,      LD = T)",not sure,912664148956537e8,393
nrot = ncol(MRI_list[[1]]$EC),exploratory,26490974589251e9,402
"ia.sex <- samp.ia(sex, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
stepsize = nrow(MRI_list[[1]]$EC),exploratory,26490974589251e9,402
"ia.clone.50 <- samp.ia(clone_50, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia.clone.75 <- samp.ia(clone_75, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
mello_data <- tbl_dt(mello_data),exploratory,686162692727521e8,401
"ia.clone.100 <- samp.ia(clone_100, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"d1 <- data.frame(ia_1990, rep(""1990_dataset"", length(ia_1990)))",data cleaning,912664148956537e8,393
"d2 <- data.frame(ia_2015, rep(""2015_dataset"", length(ia_2015)))",data cleaning,912664148956537e8,393
"d3 <- data.frame(ia.sex, rep(""sexual"", length(ia.sex)))",data cleaning,912664148956537e8,393
"d4 <- data.frame(ia.clone.50, rep(""clone_50"", length(ia.clone.50)))",data cleaning,912664148956537e8,393
"mello_data[language == """" & lyrics != """", `:=`(language, textcat(lyrics))]",data cleaning,686162692727521e8,401
"d5 <- data.frame(ia.clone.75, rep(""clone_75"", length(ia.clone.75)))",data cleaning,912664148956537e8,393
"d6 <- data.frame(ia.clone.100, rep(""clone_100"", length(ia.clone.100)))",data cleaning,912664148956537e8,393
"mello_data[language == ""scots"", `:=`(language, ""english"")]",data cleaning,686162692727521e8,401
"colnames(d1) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
"ECs = matrix(nrow = length(MRI_list), ncol = nrot * stepsize)",setup,26490974589251e9,402
"colnames(d2) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
"colnames(d3) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
"colnames(d4) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
"colnames(d5) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
"colnames(d6) <- c(""ia"", ""dset"")",data cleaning,912664148956537e8,393
rownames(ECs) = 1:nrow(ECs),data cleaning,26490974589251e9,402
mello_data <- tbl_df(mello_data),exploratory,686162692727521e8,401
"ia.total <- rbind(d1, d2, d3, d4, d5, d6)",data cleaning,912664148956537e8,393
dim(ECs),data cleaning,26490974589251e9,402
"frames <- list(as.data.frame(d1), as.data.frame(d2), as.data.frame(d3),      as.data.frame(d4), as.data.frame(d5), as.data.frame(d6))",data cleaning,912664148956537e8,393
normality <- list(),setup,912664148956537e8,393
"for (i in 1:length(frames)) {     normality[[i]] <- shapiro.test(frames[[i]][, ""ia""]) }",modeling,912664148956537e8,393
library(agricolae),setup,912664148956537e8,393
"kruskal.test(ia ~ dset, ia.total)",modeling,912664148956537e8,393
"k.test <- with(ia.total, kruskal(ia, dset, group = T, p.adj = ""bon""))",modeling,912664148956537e8,393
"no_bt_1990 <- popsub(gl_1990_rmNA_LD, ""NO BT"")",not sure,912664148956537e8,393
"bt_1990 <- popsub(gl_1990_rmNA_LD, ""BT"")",not sure,912664148956537e8,393
"mn_bt_1990 <- popsub(gl_1990_rmNA_LD, ""MN BT"")",not sure,912664148956537e8,393
"no_bt_2015 <- popsub(gl_2015_rmNA_LD, ""NO BT"")",not sure,912664148956537e8,393
"bt_2015 <- popsub(gl_2015_rmNA_LD, ""BT"")",not sure,912664148956537e8,393
"mn_bt_2015 <- popsub(gl_2015_rmNA_LD, ""MN BT"")",not sure,912664148956537e8,393
"ia_no_bt_1990 <- samp.ia(no_bt_1990, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_bt_1990 <- samp.ia(bt_1990, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_mn_bt_1990 <- samp.ia(mn_bt_1990, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_no_bt_2015 <- samp.ia(no_bt_2015, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_bt_2015 <- samp.ia(bt_2015, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_mn_bt_2015 <- samp.ia(mn_bt_2015, n.snp = 10000L, reps = 100L)",not sure,912664148956537e8,393
"ia_no_bt_1990_df <- data.frame(as.data.frame(ia_no_bt_1990),      ""NO BT"", 1990)",data cleaning,912664148956537e8,393
"colnames(ia_no_bt_1990_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"ia_bt_1990_df <- data.frame(as.data.frame(ia_bt_1990), ""BT"",      1990)",data cleaning,912664148956537e8,393
"colnames(ia_bt_1990_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,318712170235813e8,403
"ia_mn_bt_1990_df <- data.frame(as.data.frame(ia_mn_bt_1990),      ""MN BT"", 1990)",data cleaning,912664148956537e8,393
"colnames(ia_mn_bt_1990_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"ia_no_bt_2015_df <- data.frame(as.data.frame(ia_no_bt_2015),      ""NO BT"", 2015)",data cleaning,912664148956537e8,393
"colnames(ia_no_bt_2015_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"ia_bt_2015_df <- data.frame(as.data.frame(ia_bt_2015), ""BT"",      2015)",data cleaning,912664148956537e8,393
"colnames(ia_bt_2015_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"ia_mn_bt_2015_df <- data.frame(as.data.frame(ia_mn_bt_2015),      ""MN BT"", 2015)",data cleaning,912664148956537e8,393
"colnames(ia_mn_bt_2015_df) <- c(""rbarD"", ""Population"", ""Year"")",data cleaning,912664148956537e8,393
"ia_pop_df <- rbind(ia_no_bt_1990_df, ia_bt_1990_df, ia_mn_bt_1990_df,      ia_no_bt_2015_df, ia_bt_2015_df, ia_mn_bt_2015_df)",data cleaning,912664148956537e8,393
library(lme4),modeling,318712170235813e8,403
"ia_pop_df_1990 <- rbind(ia_no_bt_1990_df, ia_bt_1990_df, ia_mn_bt_1990_df)",data cleaning,912664148956537e8,393
"ia_pop_df_2015 <- rbind(ia_no_bt_2015_df, ia_bt_2015_df, ia_mn_bt_2015_df)",data cleaning,912664148956537e8,393
"kruskal.test(rbarD ~ Population, ia_pop_df)",modeling,912664148956537e8,393
"k.test <- with(ia_pop_df_1990, kruskal(rbarD, Population, group = T,      p.adj = ""bon""))",modeling,912664148956537e8,393
"k.test <- with(ia_pop_df_2015, kruskal(rbarD, Population, group = T,      p.adj = ""bon""))",modeling,912664148956537e8,393
"try(setwd(""U:/Pragmatics/New/Analysis/""))",setup,318712170235813e8,403
"theme_set(theme_classic() + theme(legend.text = element_text(size = 11),      axis.text = element_text(size = 10), axis.title = element_text(size = 15),      strip.text.y = element_blank(), strip.background = element_blank(),      strip.text.x = element_text(size = 13)))",setup,912664148956537e8,393
"try(setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis""))",setup,318712170235813e8,403
"byYear_plot <- ggplot(ia.total, aes(x = dset, y = ia, color = as.factor(dset))) +      geom_boxplot() + scale_x_discrete(labels = c(""1990"", ""2015"",      ""Sexual"", ""50% Linkage"", ""75% Linkage"", ""100% Linkage"")) +      scale_y_continuous(limits = c(0, 0.075)) + scale_color_manual(values = c(""black"",      ""red"", rep(""grey"", 4))) + theme(legend.position = ""none"") +      labs(x = """", y = expression(italic(bar(""r"")[""d""])))",visualization,912664148956537e8,393
"pdf(""ia_byYear.pdf"")",export,912664148956537e8,393
byYear_plot,communication,912664148956537e8,393
"source(""RestrictionsApplied.R"")",not sure,318712170235813e8,403
dev.off(),export,912664148956537e8,393
"byPop_plot <- ggplot(ia_pop_df, aes(x = Population, y = rbarD,      color = as.factor(Population))) + geom_boxplot() + scale_color_manual(values = c(`NO BT` = ""#E69F00"",      `MN BT` = ""#56B4E9"", BT = ""#D55E00"")) + theme(legend.title = element_blank(),      panel.grid.major.y = element_line(color = ""black""), axis.text.x = element_blank()) +      labs(x = ""Population"", y = expression(italic(bar(""r"")[""d""]))) +      facet_wrap(~Year)",visualization,912664148956537e8,393
"pdf(""ia_byPop.pdf"")",export,912664148956537e8,393
"source(""grammars.R"")",setup,318712170235813e8,403
byPop_plot,visualization,912664148956537e8,393
dev.off(),export,912664148956537e8,393
"source(""~/selection/code/lib/mh_plot_lib.R"")",import,912664148956537e8,393
"source(""makeDataVariables.R"")",setup,318712170235813e8,403
"results <- read.table(""~/selection/analysis/s_estimates/ALL_s_estimates.txt"",      as.is = TRUE, header = FALSE)",import,912664148956537e8,393
"colnames(results) <- c(""ID"", ""s.est"", ""p"", ""ci.lower"", ""ci.upper"")",data cleaning,912664148956537e8,393
"e.initial = getWordListEntropy(d.wh.possible.initial.m, firstSegment = T)",setup,318712170235813e8,403
"data <- read.table(""~/data/v6/use/v61kg_europe2names.snp"", as.is = TRUE)",import,912664148956537e8,393
df$bl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
"e.non.initial = getWordListEntropy(d.wh.possible.non.initial.m,      firstSegment = T)",setup,318712170235813e8,403
df$tl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
"data <- data[, c(1, 2, 4)]",data cleaning,912664148956537e8,393
"colnames(data) <- c(""ID"", ""CHR"", ""POS"")",data cleaning,912664148956537e8,393
df$br_x <- df$x + 0.25,data cleaning,959925830829888e7,381
"results.tag <- """"",setup,912664148956537e8,393
df$tr_x <- df$x + 0.25,data cleaning,959925830829888e7,381
"source(""Analysis/01_SM_load.R"")",not sure,746643975842744e8,404
df$bl_y <- df$y - 0.25,data cleaning,959925830829888e7,381
"png(paste0(""~/selection/analysis/s_estimates/qq_plot"", results.tag,      "".png""), width = 800, height = 400)",export,912664148956537e8,393
"source(""Analysis/02_SM_clean.R"")",not sure,746643975842744e8,404
df$tl_y <- df$y + 0.25,data cleaning,959925830829888e7,381
"source(""Analysis/03_SM_func.R"")",not sure,746643975842744e8,404
df$br_y <- df$y - 0.25,data cleaning,959925830829888e7,381
df$tr_y <- df$y + 0.25,data cleaning,959925830829888e7,381
qq.exp.pts <- rexp(NROW(results))/log(10),data cleaning,912664148956537e8,393
"dx = data.frame(lang = c(names(e.initial), names(e.non.initial)),      e = c(e.initial, e.non.initial), family = c(families.d.wh.possible.initial,          families.d.wh.possible.non.initial), area = c(areas.d.wh.possible.initial,          areas.d.wh.possible.non.initial), initial = c(rep(T,          length(e.initial)), rep(F, length(e.non.initial))))",import,318712170235813e8,403
"qqplot(qq.exp.pts, -log10(results$p), pch = 1, col = ""red"", xlab = ""Expected"",      ylab = ""Observed"", bty = ""n"", cex = 0.5)",visualization,912664148956537e8,393
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,959925830829888e7,381
"abline(0, 1, col = ""black"")",visualization,912664148956537e8,393
"plotmeans(e ~ initial, data = dx)",exploratory,318712170235813e8,403
dev.off(),export,912664148956537e8,393
"res <- data.frame(ID = results$ID, PVAL = results$p)",data cleaning,912664148956537e8,393
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,959925830829888e7,381
"res <- merge(res, data, by = ""ID"")",data cleaning,912664148956537e8,393
"m0 = lmer(e ~ 1 + (1 | area), data = dx)",modeling,318712170235813e8,403
"res <- res[order(res$CHR, res$POS), ]",data cleaning,912664148956537e8,393
opt_loc$RailKM <- NA,data cleaning,959925830829888e7,381
"res <- res[!is.na(res$PVAL), ]",data cleaning,912664148956537e8,393
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,746643975842744e8,404
"m1 = lmer(e ~ 1 + initial + (1 | area), data = dx)",modeling,318712170235813e8,403
"png(paste0(""~/selection/analysis/s_estimates/mh_plot"", results.tag,      "".png""), width = 800, height = 400)",export,912664148956537e8,393
"ggsave(""Output/Fig1.png"", ephsurvplot_lognorm)",export,746643975842744e8,404
"anova(m0, m1)",modeling,318712170235813e8,403
"par(mar = c(2, 4, 1, 1))",setup,912664148956537e8,393
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, all_rails)) {         intersect <- gIntersection(single_cell, all_rails)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""RailKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""RailKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""RailKM""] <- 0     } }",data cleaning,959925830829888e7,381
"save_plot(""Output/SuplFig2.png"", km22plot, ncol = 2, nrow = 2,      base_aspect_ratio = 2)",export,746643975842744e8,404
MH.plot(res),visualization,912664148956537e8,393
"e.initial = getWordListEntropy(d.unanalyzable.wh.initial.m, firstSegment = T)",setup,318712170235813e8,403
"abline(h = 6.79, col = ""red"", lty = 2)",visualization,912664148956537e8,393
"ggsave(""Output/SuplFig3.png"", int_plot)",export,746643975842744e8,404
dev.off(),export,912664148956537e8,393
"e.non.initial = getWordListEntropy(d.unanalyzable.wh.non.initial.m,      firstSegment = T)",setup,318712170235813e8,403
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,959925830829888e7,381
library(strucchange),setup,912664148956537e8,393
library(dplyr),setup,912664148956537e8,393
library(ggplot2),setup,912664148956537e8,393
library(lubridate),setup,912664148956537e8,393
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,959925830829888e7,381
"dx = data.frame(lang = c(names(e.initial), names(e.non.initial)),      e = c(e.initial, e.non.initial), family = c(families.d.unanalyzable.wh.initial,          families.d.unanalyzable.wh.non.initial), area = c(areas.d.unanalyzable.wh.initial,          areas.d.unanalyzable.wh.non.initial), initial = c(rep(T,          length(e.initial)), rep(F, length(e.non.initial))))",import,318712170235813e8,403
library(forecast),setup,912664148956537e8,393
library(stringr),setup,746643975842744e8,404
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,959925830829888e7,381
library(vegan),setup,746643975842744e8,404
"plotmeans(e ~ initial, data = dx)",exploratory,318712170235813e8,403
library(reshape2),setup,746643975842744e8,404
library(scales),setup,746643975842744e8,404
"df <- opt_loc[!is.na(opt_loc$zeta), ]",data cleaning,959925830829888e7,381
library(plyr),setup,746643975842744e8,404
library(RColorBrewer),setup,746643975842744e8,404
row.names(df) <- 1:nrow(df),data cleaning,959925830829888e7,381
"ports <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/port_stats.RDS"")",import,183825093088672e8,170
df$bl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
"path1 <- ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-01/""",setup,746643975842744e8,404
"m0 = lmer(e ~ 1 + (1 | area), data = dx)",modeling,318712170235813e8,403
df$tl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
"path2 <- ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/predicted_metiers/2010/""",setup,746643975842744e8,404
"monthly.df <- tbl_df(data.frame(year = rep(2000:2010, 12), month = c(rep(1,      11), rep(2, 11), rep(3, 11), rep(4, 11), rep(5, 11), rep(6,      11), rep(7, 11), rep(8, 11), rep(9, 11), rep(10, 11), rep(11,      11), rep(12, 11)))) %>% mutate(jan = ifelse(month == 1, 1,      0), feb = ifelse(month == 2, 1, 0), march = ifelse(month ==      3, 1, 0), april = ifelse(month == 4, 1, 0), may = ifelse(month ==      5, 1, 0), june = ifelse(month == 6, 1, 0), july = ifelse(month ==      7, 1, 0), aug = ifelse(month == 8, 1, 0), sept = ifelse(month ==      9, 1, 0), oct = ifelse(month == 10, 1, 0), nov = ifelse(month ==      11, 1, 0), dec = ifelse(month == 12, 1, 0)) %>% mutate(beta1 = ifelse(year <      2005, 10, 20), beta2 = ifelse(year < 2005, 20, 40), beta3 = ifelse(year <      2005, 30, 60), beta4 = ifelse(year < 2005, 40, 80), beta5 = ifelse(year <      2005, 50, 100), beta6 = ifelse(year < 2005, 60, 120), beta7 = ifelse(year <      2005, 70, 140), beta8 = ifelse(year < 2005, 80, 160), beta9 = ifelse(year <      2005, 90, 180), beta10 = ifelse(year < 2005, 100, 200), beta11 = ifelse(year <      2005, 25, 50), beta12 = ifelse(year < 2005, 15, 30), e = rnorm(132,      10, 20)) %>% mutate(trips = (jan * beta1) + (feb * beta2) +      (march * beta3) + (april * beta4) + (may * beta5) + (june *      beta6) + (july * beta7) + (aug * beta8) + (sept * beta9) +      (oct * beta10) + (nov * beta11) + (dec * beta12) + e) %>%      mutate(date = as.Date(paste(year, ""-"", month, ""-"", ""01"",          sep = """"), format = ""%Y-%m-%d"")) %>% arrange(year, month)",data cleaning,912664148956537e8,393
df$br_x <- df$x + 0.25,data cleaning,959925830829888e7,381
"path3 <- ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/metier_lists/""",setup,746643975842744e8,404
"m1 = lmer(e ~ 1 + initial + (1 | area), data = dx)",modeling,318712170235813e8,403
"vessels <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_stats.RDS"")",import,183825093088672e8,170
df$tr_x <- df$x + 0.25,data cleaning,959925830829888e7,381
"landings <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/vessel_landings_data.RDS"")",import,183825093088672e8,170
df$bl_y <- df$y - 0.25,data cleaning,959925830829888e7,381
"ggplot(monthly.df, aes(x = date, y = trips)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
df$tl_y <- df$y + 0.25,data cleaning,959925830829888e7,381
"anova(m0, m1)",evaluation,318712170235813e8,403
library(dplyr),setup,183825093088672e8,170
df$br_y <- df$y - 0.25,data cleaning,959925830829888e7,381
"filtered_ftl <- readRDS(paste0(path1, ""filtered_ftl.RDS""))",import,746643975842744e8,404
df$tr_y <- df$y + 0.25,data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df)",modeling,912664148956537e8,393
plot(f_statistics),visualization,912664148956537e8,393
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,959925830829888e7,381
files <- list.files(path = path2),import,746643975842744e8,404
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,959925830829888e7,381
"summary(breakpoints(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df))",exploratory,912664148956537e8,393
"port_link <- landings %>% group_by(drvid, pcid) %>% summarize(revenue = sum(adj_revenue,      na.rm = T)) %>% filter(revenue > 0) %>% mutate(percent.rev = revenue/sum(revenue)) %>%      filter(revenue == max(revenue)) %>% dplyr::select(-revenue) %>%      left_join(vessels) %>% dplyr::select(drvid, pcid, eff.shannon_2010,      delta.eff.shannon_2010) %>% left_join(ports) %>% filter(!is.na(ic_pre)) %>%      filter(!is.na(eff.shannon_2010))",data cleaning,183825093088672e8,170
opt_loc$RailKM_military <- 0,data cleaning,959925830829888e7,381
library(MASS),setup,183825093088672e8,170
"monthly.df <- tbl_df(data.frame(year = rep(2000:2010, 12), month = c(rep(1,      11), rep(2, 11), rep(3, 11), rep(4, 11), rep(5, 11), rep(6,      11), rep(7, 11), rep(8, 11), rep(9, 11), rep(10, 11), rep(11,      11), rep(12, 11)))) %>% mutate(jan = 1, feb = ifelse(month ==      2, 1, 0), march = ifelse(month == 3, 1, 0), april = ifelse(month ==      4, 1, 0), may = ifelse(month == 5, 1, 0), june = ifelse(month ==      6, 1, 0), july = ifelse(month == 7, 1, 0), aug = ifelse(month ==      8, 1, 0), sept = ifelse(month == 9, 1, 0), oct = ifelse(month ==      10, 1, 0), nov = ifelse(month == 11, 1, 0), dec = ifelse(month ==      12, 1, 0)) %>% mutate(int = 100, t = year - 1999, beta1 = 2000 -      20 * t, beta2 = 20, beta3 = 30, beta4 = 40, beta5 = 50, beta6 = 60,      beta7 = 70, beta8 = 80, beta9 = 90, beta10 = 100, beta11 = 25,      beta12 = 15, e = rnorm(132, 20, 20)) %>% mutate(trips = (jan *      beta1) + (feb * beta2) + (march * beta3) + (april * beta4) +      (may * beta5) + (june * beta6) + (july * beta7) + (aug *      beta8) + (sept * beta9) + (oct * beta10) + (nov * beta11) +      (dec * beta12) + e) %>% mutate(date = as.Date(paste(year,      ""-"", month, ""-"", ""01"", sep = """"), format = ""%Y-%m-%d"")) %>%      arrange(year, month)",data cleaning,912664148956537e8,393
opt_loc$RailKM_mining <- 0,data cleaning,959925830829888e7,381
"k <- kde2d(port_link$eff.shannon_2010, port_link$ic_pre)",import,183825093088672e8,170
"ggplot(monthly.df, aes(x = date, y = trips)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
library(RColorBrewer),setup,183825093088672e8,170
"predicteds <- do.call(rbind, lapply(paste0(path2, files), readRDS))",data cleaning,746643975842744e8,404
"for (i in 1:nrow(polygon_dataframe)) {     if (opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""RailKM""] >          0 & !is.na(opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],          ""RailKM""])) {         single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==              polygon_dataframe@data$ID[i]), ]         if (gIntersects(single_cell, all_rails[all_rails@data$military ==              1, ])) {             intersect <- gIntersection(single_cell, all_rails[all_rails@data$military ==                  1, ])             if (!(""coords"" %in% slotNames(intersect))) {                 if (""lineobj"" %in% slotNames(intersect)) {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_military""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                      function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                        longlat = T))))                   print(c(i, ""with multiple""))                 }                 else {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_military""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                      longlat = T)                   print(i)                 }             }         }         if (gIntersects(single_cell, all_rails[all_rails@data$mining ==              1, ])) {             intersect <- gIntersection(single_cell, all_rails[all_rails@data$mining ==                  1, ])             if (!(""coords"" %in% slotNames(intersect))) {                 if (""lineobj"" %in% slotNames(intersect)) {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_mining""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                      function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                        longlat = T))))                   print(c(i, ""with multiple""))                 }                 else {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_mining""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                      longlat = T)                   print(i)                 }             }         }     } }",data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df)",modeling,912664148956537e8,393
"png(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/05_figures/fig_S3.png"",      width = 5, height = 5, units = ""in"", res = 500, bg = ""transparent"")",visualization,183825093088672e8,170
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,959925830829888e7,381
"plot(port_link$ic_pre, port_link$eff.shannon_2010, cex = 0.45,      col = ""black"", pch = 3, bty = ""n"", xlab = expression(C[pre]),      ylab = expression(H[pre]))",visualization,183825093088672e8,170
plot(f_statistics),visualization,912664148956537e8,393
"setwd(""../"")",setup,318712170235813e8,403
dev.off(),visualization,183825093088672e8,170
other_files <- list.files(path = path3),import,746643975842744e8,404
"summary(breakpoints(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df))",exploratory,912664148956537e8,393
library(scales),setup,959925830829888e7,381
"plot(ic_pre ~ before.nves, port_link, cex = 0.45, pch = 3, bty = ""n"")",visualization,183825093088672e8,170
"other_files <- other_files[grep(2010, other_files)]",import,746643975842744e8,404
"plot(eff.shannon_2010 ~ before.nves, port_link, cex = 0.45, pch = 3,      bty = ""n"")",visualization,183825093088672e8,170
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month) + t, data = monthly.df)",modeling,912664148956537e8,393
"abline(lm(ic_pre ~ before.nves, port_link))",visualization,183825093088672e8,170
"versions = try(system(""git tag"", intern = TRUE))",setup,318712170235813e8,403
"display(lm(ic_pre ~ before.nves, port_link))",visualization,183825093088672e8,170
plot(f_statistics),visualization,912664148956537e8,393
"if (class(versions) == ""try-error"") {     versions = list.files(""../.git/refs/tags"") }",setup,318712170235813e8,403
"predicteds$predicted_metier <- paste0(predicteds$predicted_metier,      str_sub(predicteds$trip_id, start = -4))",data cleaning,746643975842744e8,404
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/Railroads.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",export,959925830829888e7,381
version = versions[length(versions)],setup,318712170235813e8,403
"classifieds <- do.call(rbind, lapply(paste0(path3, other_files),      read.csv))",data cleaning,746643975842744e8,404
"print(plot(polygon_dataframe, lwd = 0.5, border = alpha(""black"",      0.5)))",export,959925830829888e7,381
library(shiny),setup,318712170235813e8,403
library(plotly),setup,318712170235813e8,403
"summary(breakpoints(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month) + t, data = monthly.df))",exploratory,912664148956537e8,393
classifieds$X <- NULL,data cleaning,746643975842744e8,404
require(shinyFiles),setup,318712170235813e8,403
library(randomForest),setup,318712170235813e8,403
"classifieds$metier <- paste0(classifieds$metier, 2010)",data cleaning,746643975842744e8,404
"print(plot(all_rails, lwd = 1.5, col = ""red"", add = T))",visualization,959925830829888e7,381
"monthly.1d <- monthly.df %>% ungroup() %>% arrange(year, month) %>%      mutate(first.diff = trips - lag(trips))",data cleaning,912664148956537e8,393
library(ica),setup,318712170235813e8,403
"classifieds$ftid <- paste0(classifieds$ftid, 2010)",data cleaning,746643975842744e8,404
library(e1071),setup,318712170235813e8,403
"d <- kde2d(port_link$ic_delta, port_link$delta.eff.shannon_2010)",modeling,183825093088672e8,170
"colnames(classifieds) <- c(""trip_id"", ""metier"")",data cleaning,746643975842744e8,404
require(Hmisc),setup,318712170235813e8,403
"colnames(predicteds) <- c(""trip_id"", ""metier"")",data cleaning,746643975842744e8,404
"tsdisplay(diff(ts(monthly.1d$trips, frequency = 12, start = c(2000,      1))))",exploratory,912664148956537e8,393
library(osfr),setup,318712170235813e8,403
image(d),visualization,183825093088672e8,170
dev.off(),visualization,959925830829888e7,381
library(tidyverse),setup,318712170235813e8,403
"ggplot(monthly.1d, aes(x = date, y = first.diff)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
"contour(d, add = T, col = ""grey10"")",visualization,183825093088672e8,170
"metiers <- rbind(classifieds, predicteds)",data cleaning,746643975842744e8,404
"points(port_link$ic_delta, port_link$delta.eff.shannon_2010,      cex = 0.15, col = ""steelblue"")",visualization,183825093088672e8,170
library(stringr),setup,318712170235813e8,403
library(gridExtra),setup,318712170235813e8,403
"placebo <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Placebo/placebo_1916_1922.TAB"")",import,959925830829888e7,381
monthly.1d <- monthly.1d %>% filter(year > 2000),data cleaning,912664148956537e8,393
"tickets <- merge(filtered_ftl, metiers, by = ""trip_id"")",data cleaning,746643975842744e8,404
library(RGraphics),setup,318712170235813e8,403
"source(""Rcode/functions.r"")",setup,318712170235813e8,403
"f_statistics <- Fstats(ts(first.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.1d)",visualization,912664148956537e8,393
"south_african_placebo <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/South_Africa_placebo.shp"")",import,959925830829888e7,381
"source(""../Softwareheader.R"")",setup,318712170235813e8,403
plot(f_statistics),visualization,912664148956537e8,393
length(unique(tickets$trip_id)) == length(unique(metiers$trip_id)),data cleaning,746643975842744e8,404
"summary(breakpoints(ts(first.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.1d))",exploratory,912664148956537e8,393
"south_african_placebo@data <- as.data.frame(placebo@data[1:length(south_african_placebo),      ])",data cleaning,959925830829888e7,381
"tickets$veid_year <- paste0(tickets$veid, tickets$year)",data cleaning,746643975842744e8,404
"monthly.dsea <- monthly.df %>% ungroup() %>% arrange(year, month) %>%      mutate(sea.diff = trips - lag(trips, 12))",data cleaning,912664148956537e8,393
"tickets$metier <- str_sub(tickets$metier, end = -4)",data cleaning,746643975842744e8,404
"colnames(south_african_placebo@data) <- ""placebo_year""",data cleaning,959925830829888e7,381
south_african_placebo@data[1] <- NA,data cleaning,959925830829888e7,381
"saveRDS(tickets, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/tickets.RDS"")",export,746643975842744e8,404
"source = function(file, local = TRUE, echo = verbose, print.eval = echo,      exprs, spaced = use_file, verbose = getOption(""verbose""),      prompt.echo = getOption(""prompt""), max.deparse.length = 150,      width.cutoff = 60L, deparseCtrl = ""showAttributes"", chdir = FALSE,      encoding = getOption(""encoding""), continue.echo = getOption(""continue""),      skip.echo = 0, keep.source = getOption(""keep.source"")) {     envir <- if (isTRUE(local))          parent.frame()     else if (identical(local, FALSE))          .GlobalEnv     else if (is.environment(local))          local     else stop(""'local' must be TRUE, FALSE or an environment"")     if (!missing(echo)) {         if (!is.logical(echo))              stop(""'echo' must be logical"")         if (!echo && verbose) {             warning(""'verbose' is TRUE, 'echo' not; ... coercing 'echo <- TRUE'"")             echo <- TRUE         }     }     if (verbose) {         cat(""'envir' chosen:"")         print(envir)     }     if (use_file <- missing(exprs)) {         ofile <- file         from_file <- FALSE         srcfile <- NULL         if (is.character(file)) {             have_encoding <- !missing(encoding) && encoding !=                  ""unknown""             if (identical(encoding, ""unknown"")) {                 enc <- utils::localeToCharset()                 encoding <- enc[length(enc)]             }             else enc <- encoding             if (length(enc) > 1L) {                 encoding <- NA                 owarn <- options(warn = 2)                 for (e in enc) {                   if (is.na(e))                      next                   zz <- file(file, encoding = e)                   res <- tryCatch(readLines(zz, warn = FALSE),                      error = identity)                   close(zz)                   if (!inherits(res, ""error"")) {                     encoding <- e                     break                   }                 }                 options(owarn)             }             if (is.na(encoding))                  stop(""unable to find a plausible encoding"")             if (verbose)                  cat(gettextf(""encoding = \""%s\"" chosen"", encoding),                    ""\n"", sep = """")             if (file == """") {                 file <- stdin()                 srcfile <- ""<stdin>""             }             else {                 filename <- file                 file <- file(filename, ""r"", encoding = encoding)                 on.exit(close(file))                 if (isTRUE(keep.source)) {                   lines <- readLines(file, warn = FALSE)                   on.exit()                   close(file)                   srcfile <- srcfilecopy(filename, lines, file.mtime(filename)[1],                      isFile = TRUE)                 }                 else {                   from_file <- TRUE                   srcfile <- filename                 }                 loc <- utils::localeToCharset()[1L]                 encoding <- if (have_encoding)                    switch(loc, `UTF-8` = ""UTF-8"", `ISO8859-1` = ""latin1"",                      ""unknown"")                 else ""unknown""             }         }         else {             lines <- readLines(file, warn = FALSE)             srcfile <- if (isTRUE(keep.source))                  srcfilecopy(deparse(substitute(file)), lines)             else deparse(substitute(file))         }         exprs <- if (!from_file) {             if (length(lines))                  .Internal(parse(stdin(), n = -1, lines, ""?"",                    srcfile, encoding))             else expression()         }         else .Internal(parse(file, n = -1, NULL, ""?"", srcfile,              encoding))         on.exit()         if (from_file)              close(file)         if (verbose)              cat(""--> parsed"", length(exprs), ""expressions; now eval(.)ing them:\n"")         if (chdir) {             if (is.character(ofile)) {                 if (grepl(""^(ftp|http|file)://"", ofile))                    warning(""'chdir = TRUE' makes no sense for a URL"")                 else if ((path <- dirname(ofile)) != ""."") {                   owd <- getwd()                   if (is.null(owd))                      stop(""cannot 'chdir' as current directory is unknown"")                   on.exit(setwd(owd), add = TRUE)                   setwd(path)                 }             }             else {                 warning(""'chdir = TRUE' makes no sense for a connection"")             }         }     }     else {         if (!missing(file))              stop(""specify either 'file' or 'exprs' but not both"")         if (!is.expression(exprs))              exprs <- as.expression(exprs)     }     Ne <- length(exprs)     if (echo) {         sd <- ""\""""         nos <- ""[^\""]*""         oddsd <- paste0(""^"", nos, sd, ""("", nos, sd, nos, sd,              "")*"", nos, ""$"")         trySrcLines <- function(srcfile, showfrom, showto) {             tryCatch(suppressWarnings(getSrcLines(srcfile, showfrom,                  showto)), error = function(e) character())         }     }     yy <- NULL     lastshown <- 0     srcrefs <- attr(exprs, ""srcref"")     if (verbose && !is.null(srcrefs)) {         cat(""has srcrefs:\n"")         utils::str(srcrefs)     }     for (i in seq_len(Ne + echo)) {         tail <- i > Ne         if (!tail) {             if (verbose)                  cat(""\n>>>> eval(expression_nr."", i, "")\n\t\t =================\n"")             ei <- exprs[i]         }         if (echo) {             nd <- 0             srcref <- if (tail)                  attr(exprs, ""wholeSrcref"")             else if (i <= length(srcrefs))                  srcrefs[[i]]             if (!is.null(srcref)) {                 if (i == 1)                    lastshown <- min(skip.echo, srcref[3L] - 1)                 if (lastshown < srcref[3L]) {                   srcfile <- attr(srcref, ""srcfile"")                   dep <- trySrcLines(srcfile, lastshown + 1,                      srcref[3L])                   if (length(dep)) {                     leading <- if (tail)                        length(dep)                     else srcref[1L] - lastshown                     lastshown <- srcref[3L]                     while (length(dep) && grepl(""^[[:blank:]]*$"",                        dep[1L])) {                       dep <- dep[-1L]                       leading <- leading - 1L                     }                     dep <- paste0(rep.int(c(prompt.echo, continue.echo),                        c(leading, length(dep) - leading)), dep,                        collapse = ""\n"")                     nd <- nchar(dep, ""c"")                   }                   else srcref <- NULL                 }             }             if (is.null(srcref)) {                 if (!tail) {                   dep <- substr(paste(deparse(ei, width.cutoff = width.cutoff,                      control = deparseCtrl), collapse = ""\n""),                      12L, 1000000L)                   dep <- paste0(prompt.echo, gsub(""\n"", paste0(""\n"",                      continue.echo), dep))                   nd <- nchar(dep, ""c"") - 1L                 }             }             if (nd) {                 do.trunc <- nd > max.deparse.length                 dep <- substr(dep, 1L, if (do.trunc)                    max.deparse.length                 else nd)                 cat(if (spaced)                    ""\n"", dep, if (do.trunc)                    paste(if (grepl(sd, dep) && grepl(oddsd, dep))                      "" ...\"" ...""                   else "" ...."", ""[TRUNCATED] ""), ""\n"", sep = """")             }         }         if (!tail) {             yy <- withVisible(eval(ei, envir))             i.symbol <- mode(ei[[1L]]) == ""name""             if (!i.symbol) {                 curr.fun <- ei[[1L]][[1L]]                 if (verbose) {                   cat(""curr.fun:"")                   utils::str(curr.fun)                 }             }             if (verbose >= 2) {                 cat("".... mode(ei[[1L]])="", mode(ei[[1L]]), ""; paste(curr.fun)="")                 utils::str(paste(curr.fun))             }             if (print.eval && yy$visible) {                 if (isS4(yy$value))                    methods::show(yy$value)                 else print(yy$value)             }             if (verbose)                  cat("" .. after "", sQuote(deparse(ei, control = unique(c(deparseCtrl,                    ""useSource"")))), ""\n"", sep = """")         }     }     invisible(yy) }",setup,318712170235813e8,403
"over_years <- ddply(tickets, .(year), summarize, num_metiers = length(unique(metier)))",data cleaning,746643975842744e8,404
"PMeta = paste0(""http://www.osf.io/download/"", ""myxcv"")",setup,318712170235813e8,403
"tsdisplay(ts(monthly.dsea$sea.diff, frequency = 12, start = c(2000,      1)))",not sure,912664148956537e8,393
"ports <- readRDS(""/Users/efuller/Desktop/CNH/Analysis/Metiers/bin/04_data_output/port_stats.RDS"")",import,183825093088672e8,170
"south_african_placebo <- spTransform(south_african_placebo, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,959925830829888e7,381
range(over_years$num_metiers),exploratory,746643975842744e8,404
Projects_metadata <- read_csv(PMeta),import,318712170235813e8,403
"ggplot(monthly.dsea, aes(x = date, y = sea.diff)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
"placebo <- spTransform(placebo, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,959925830829888e7,381
monthly.dsea <- monthly.dsea %>% filter(year > 2000),data cleaning,912664148956537e8,393
"rmarkdown::render(""analysis/by-channel-across-participants.Rmd"",      output_format = ""github_document"", output_file = ""2F1-by-channel-across-participants.md"",      output_dir = ""analysis/results/2F1"", params = list(harmonic = ""2F1"",          p_thresh = 0.01))",export,183825093088672e8,170
NO_svm = FALSE,setup,318712170235813e8,403
"all_placebo <- rbind(placebo, south_african_placebo)",data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ts(sea.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.dsea)",modeling,912664148956537e8,393
"rmarkdown::render(""analysis/by-channel-across-participants.Rmd"",      output_format = ""github_document"", output_dir = ""analysis/results/3F1"",      output_file = ""3F1-by-channel-across-participants.md"", params = list(harmonic = ""3F1"",          p_thresh = 0.01))",export,183825093088672e8,170
"neffort <- ddply(tickets, .(metier, year), summarize, ntrips = length(unique(trip_id)),      nves = length(unique(veid)))",data cleaning,746643975842744e8,404
"nodes <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/EMST_Lines/nodes.TAB"")",import,959925830829888e7,381
plot(f_statistics),visualization,912664148956537e8,393
"rmarkdown::render(""analysis/by-channel-across-participants.Rmd"",      output_format = ""github_document"", output_dir = ""analysis/results/4F1"",      output_file = ""4F1-by-channel-across-participants.md"", params = list(harmonic = ""4F1"",          p_thresh = 0.01))",export,183825093088672e8,170
"ui <- fluidPage(theme = ""bootstrapsolar.css"", titlePanel(title = paste0(""BSeq_analyser, "",      version)), source(""../Softwareheader.R""), sidebarLayout(sidebarPanel(sliderInput(""Npermutation"",      ""Number of permutations to perform for the statistics:"",      min = 1, max = 600, value = 1), checkboxInput(""RECREATEMINFILE"",      ""recreate the min_file even if one exists"", FALSE), checkboxInput(""perf_SVM"",      ""Perform the multidimensional analysis (takes time)"", TRUE),      radioButtons(""groupingby"", ""grouping variables following which categories"",          c(`Jhuang 10 categories` = ""Jhuang"", `Berlin 18 categories` = ""Berlin""),          ""Berlin""), shinyUI(bootstrapPage(shinyDirButton(""STICK"",          ""Data_directory"", ""Choose the directory containing all your HCS data (works only while running the app via Rstudio on your computer):""),          selectInput(""Name_project"", ""choose the project to analyse:"",              Projects_metadata$Proj_name, ""Ro_testdata""), textOutput(""text_1""),          a(""Open the report in a new tab"", target = ""_blank"",              href = ""report.html""), actionButton(""debug_go"", ""Get back to R to debug"")))),      mainPanel(tabsetPanel(tabPanel(""multidim_results"", ""If you do not choose the time windows to incorporate in the analysis, all time windows will be used.\n            "",          actionButton(""TWbutton"", ""Choose time windows""), tags$hr(),          DT::dataTableOutput(""TW""), actionButton(""goButton"", ""Do multidimensional analysis""),          htmlOutput(""includeHTML"", inline = TRUE)), tabPanel(""summary reports"",          ""Note that a pdf file with all figures is also produced and saved in the Routputs folder."",          actionButton(""plot_data"", ""Plotting hourly summary data""),          numericInput(""obs"", ""plot number:"", 1, min = 1, max = 20),          plotlyOutput(""plot""))), ""You need to indicate time indications (start of experiment, light off, light on) in the different metadata files. Work with minutes and hourly summary at the moment."")))",setup,318712170235813e8,403
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,959925830829888e7,381
"summary(breakpoints(ts(sea.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.dsea))",exploratory,912664148956537e8,393
"neffort <- neffort[order(neffort$nves, decreasing = T), ]",data cleaning,746643975842744e8,404
"rmarkdown::render(""analysis/by-channel-across-participants.Rmd"",      output_format = ""github_document"", output_dir = ""analysis/results/5F1"",      output_file = ""5F1-by-channel-across-participants.md"", params = list(harmonic = ""5F1"",          p_thresh = 0.01))",export,183825093088672e8,170
"rmarkdown::render(""analysis/by-channel-across-participants.Rmd"",      output_format = ""github_document"", output_dir = ""analysis/results/1F2"",      output_file = ""1F2-by-channel-across-participants.md"", params = list(harmonic = ""1F2"",          p_thresh = 0.01))",export,183825093088672e8,170
"cape <- c(18.598227, -34.10779)",data cleaning,959925830829888e7,381
"monthly.df <- tbl_df(data.frame(year = rep(2000:2010, 12), month = c(rep(1,      11), rep(2, 11), rep(3, 11), rep(4, 11), rep(5, 11), rep(6,      11), rep(7, 11), rep(8, 11), rep(9, 11), rep(10, 11), rep(11,      11), rep(12, 11)))) %>% mutate(jan = 1, feb = ifelse(month ==      2, 1, 0), march = ifelse(month == 3, 1, 0), april = ifelse(month ==      4, 1, 0), may = ifelse(month == 5, 1, 0), june = ifelse(month ==      6, 1, 0), july = ifelse(month == 7, 1, 0), aug = ifelse(month ==      8, 1, 0), sept = ifelse(month == 9, 1, 0), oct = ifelse(month ==      10, 1, 0), nov = ifelse(month == 11, 1, 0), dec = ifelse(month ==      12, 1, 0)) %>% mutate(int = 100, t = year - 1999, beta1 = 2000 -      20 * t, beta2 = ifelse(year < 2005, 20, 40), beta3 = ifelse(year <      2005, 30, 60), beta4 = ifelse(year < 2005, 40, 80), beta5 = ifelse(year <      2005, 50, 100), beta6 = ifelse(year < 2005, 60, 120), beta7 = ifelse(year <      2005, 70, 140), beta8 = ifelse(year < 2005, 80, 160), beta9 = ifelse(year <      2005, 90, 180), beta10 = ifelse(year < 2005, 100, 200), beta11 = ifelse(year <      2005, 25, 50), beta12 = ifelse(year < 2005, 15, 30), e = rnorm(132,      20, 20)) %>% mutate(trips = (jan * beta1) + (feb * beta2) +      (march * beta3) + (april * beta4) + (may * beta5) + (june *      beta6) + (july * beta7) + (aug * beta8) + (sept * beta9) +      (oct * beta10) + (nov * beta11) + (dec * beta12) + e) %>%      mutate(date = as.Date(paste(year, ""-"", month, ""-"", ""01"",          sep = """"), format = ""%Y-%m-%d"")) %>% arrange(year, month)",data cleaning,912664148956537e8,393
"beaufort_west <- c(22.561545, -32.305843)",data cleaning,959925830829888e7,381
"bleomfontain <- c(26.087945, -29.105537)",data cleaning,959925830829888e7,381
"ggplot(monthly.df, aes(x = date, y = trips)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
"server <- function(input, output, session) {     volumes = getVolumes(c(""(C:)""))     values <- reactiveValues()     values$Outputshtml <- ""reports/empty.html""     values$message = ""analyis not started (link will not work or show the report for a different analysis)""     shinyDirChoose(input, ""STICK"", roots = volumes, session = session,          restrictions = system.file(package = ""base""))     fileInput <- reactive({         filepath = (parseDirPath(volumes, input$STICK))         filepath     })     GObutton <- observeEvent(input$debug_go, {         browser()     })     GObutton <- observeEvent(input$goButton, {         withProgress({             setProgress(message = ""analysis started"")             dataoutput()             setProgress(message = ""analysis done"")             includeHTML1()             setProgress(message = ""you should see the report soon"")             values$message <- ""Click the link to see the whole report. NB the report was also saved in the analysis output folder""         })     })     TWbutton <- observeEvent(input$TWbutton, {         dataoutputTW()     })     startmessage <- reactive({         values$message <- ""analyis started""     })     dataoutput <- reactive({         RECREATEMINFILE <- input$RECREATEMINFILE         NO_svm <- !input$perf_SVM         groupingby <- input$groupingby         Npermutation <- input$Npermutation         STICK <- fileInput()         Name_project <- input$Name_project         selct_TW = input$TW_rows_selected         if (!length(selct_TW)) {             selct_TW = c(1:9)         }         values$message <- ""analysis finished""         values$Outputshtml = ""reports/multidim_anal_variable.html""         source(""master_shiny.R"")         file.copy(""reports/multidim_anal_variable.html"", paste0(""shiny__Analyse_data/www/report.html""),              overwrite = TRUE, copy.mode = TRUE, copy.date = FALSE)     })     dataoutputTW <- reactive({         RECREATEMINFILE <- input$RECREATEMINFILE         NO_svm <- !input$perf_SVM         groupingby <- input$groupingby         Npermutation <- input$Npermutation         STICK <- fileInput()         Name_project <- input$Name_project         selct_TW <- c(1:9)         values$message <- ""analyis started""         source(""Rcode/get_behav_gp.r"")         values$Timewindows = Timewindows     })     observe(output$outputshtml <- renderUI({         values$Outputshtml     }))     includeHTML1 <- reactive({         paste(readLines(values$Outputshtml), collapse = ""\n"")     })     output$includeHTML <- renderText(includeHTML1())     observe({         output$text_1 <- renderText({             values$message         })     })     GObuttonplot <- observeEvent(input$plot_data, {         dataoutput2()     })     dataoutput2 <- reactive({         RECREATEMINFILE <- input$RECREATEMINFILE         NO_svm <- !input$perf_SVM         groupingby <- input$groupingby         STICK <- fileInput()         Name_project <- input$Name_project         selct_TW = input$TW_rows_selected         if (!length(selct_TW))              selct_TW = c(1:9)         values$message <- ""analyis started""         source(""Rcode/get_behav_gp.R"")         source(""Rcode/plot5_hoursummaries.R"")         values$Outputspdf = paste0(plot.path, ""/14_Minutes_Behaviours_timedtolightoff.pdf"")         values$plot = pl     })     output$plot <- renderPlotly({         ggplotly(values$plot[[input$obs]])     })     output$TW <- DT::renderDataTable(values$Timewindows, server = TRUE) }",setup,318712170235813e8,403
"port_elizabeth <- c(25.670227, -33.844601)",data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df)",modeling,912664148956537e8,393
"johannesburg <- c(28.024229, -26.17397)",data cleaning,959925830829888e7,381
"shinyApp(ui = ui, server = server)",setup,318712170235813e8,403
"pretoria <- c(28.13889, -25.792591)",data cleaning,959925830829888e7,381
"eendekuil <- c(18.886597, -32.688726)",data cleaning,959925830829888e7,381
library(dplyr),setup,183825093088672e8,170
plot(f_statistics),visualization,912664148956537e8,393
"port_nolloth <- c(16.875627, -29.224785)",data cleaning,959925830829888e7,381
library(ggmcmc),setup,183825093088672e8,170
"de_aar <- c(23.974669, -30.668652)",data cleaning,959925830829888e7,381
"summary(breakpoints(ts(trips, frequency = 12, start = c(2000,      1)) ~ factor(month), data = monthly.df))",exploratory,912664148956537e8,393
"monthly.1d <- monthly.df %>% ungroup() %>% arrange(year, month) %>%      mutate(first.diff = trips - lag(trips))",data cleaning,912664148956537e8,393
"fitfiles <- list.files(path = ""."", , pattern = ""^[0-9]*_[0-9]*.rds"",      full.names = FALSE)",import,183825093088672e8,170
"characterize_metiers <- function(metier_choice, data = tickets) {     cat(""subsetting catch data\n"")     catch_data <- subset(tickets, metier == metier_choice, select = c(""spid"",          ""landed_wt"", ""trip_id"", ""veid"", ""ppp""))     trips <- unique(catch_data$trip_id)     max_species <- rep(NA, length(trips))     cat(""calculate maximum species per trip\n"")     max_species <- ddply(catch_data, .(trip_id), summarize, species = spid[which.max(landed_wt)],          .progress = ""text"")     metier_trips <- subset(filtered_ftl, trip_id %in% catch_data$trip_id,          select = c(""trip_id"", ""grid"", ""pcid"", ""year""))     tls_12 <- unique(metier_trips)     grid = sort(table(metier_trips$grid), decreasing = T)     pcid = sort(table(metier_trips$pcid), decreasing = T)     return(list(catch_data = catch_data, max_species = max_species,          grid = grid, pcid = pcid)) }",data cleaning,746643975842744e8,404
"george <- c(22.500869, -33.997303)",data cleaning,959925830829888e7,381
"tsdisplay(diff(ts(monthly.1d$trips, frequency = 12, start = c(2000,      1))))",not sure,912664148956537e8,393
"port_alfred <- c(26.867809, -33.624552)",data cleaning,959925830829888e7,381
"east_london <- c(27.890928, -33.04099)",data cleaning,959925830829888e7,381
"ggplot(monthly.1d, aes(x = date, y = first.diff)) + geom_line() +      geom_point(aes(color = factor(oct)))",visualization,912664148956537e8,393
mets <- unique(neffort$metier),data cleaning,746643975842744e8,404
"kimberley <- c(24.733504, -28.766301)",data cleaning,959925830829888e7,381
monthly.1d <- monthly.1d %>% filter(year > 2000),data cleaning,912664148956537e8,393
"vryburg <- c(24.755151, -26.932349)",data cleaning,959925830829888e7,381
"for (fit in fitfiles) {     outfile <- stringr::str_replace(fit, "".rds"", "".pdf"")     outfile <- paste0(""ggmcmc/"", outfile)     if (!file.exists(outfile)) {         fit1 <- readr::read_rds(fit)         S <- ggmcmc::ggs(fit1)         message(""Does not exist "", outfile)         ggmcmc(S, file = outfile)     } }",import,183825093088672e8,170
met_data <- list(),data cleaning,746643975842744e8,404
"f_statistics <- Fstats(ts(first.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.1d)",modeling,912664148956537e8,393
"sa_nodes <- rbind(cape, beaufort_west, bleomfontain, port_elizabeth,      johannesburg, pretoria, eendekuil, port_nolloth, de_aar,      george, port_alfred, east_london, kimberley, vryburg)",data cleaning,959925830829888e7,381
"incidfile <- ""data/processed/20122018_promed_loglinear_wide.csv""",import,183825093088672e8,170
plot(f_statistics),visualization,912664148956537e8,393
"metadatafile <- ""data/processed/all_african_centroids.csv""",import,183825093088672e8,170
"dta <- as.data.frame(rep(1, nrow(sa_nodes)))",data cleaning,959925830829888e7,381
for (i in 1:length(mets)) {     met_data[[mets[i]]] <- characterize_metiers(mets[i]) },data cleaning,746643975842744e8,404
"colnames(dta) <- ""node""",data cleaning,959925830829888e7,381
"places <- c(""LBR"", ""GIN"", ""SLE"")",data cleaning,183825093088672e8,170
df <- data.frame(Metier = names(met_data)),data cleaning,746643975842744e8,404
"summary(breakpoints(ts(first.diff, frequency = 12, start = c(2001,      1)) ~ factor(month), data = monthly.1d))",exploratory,912664148956537e8,393
"day0 <- readr::read_csv(incidfile, n_max = 1) %>% pull(date)",import,183825093088672e8,170
df$Major_species <- NA,data cleaning,746643975842744e8,404
"sa_pts <- SpatialPointsDataFrame(SpatialPoints(sa_nodes, proj4string = CRS(proj4string(nodes))),      data = dta)",data cleaning,959925830829888e7,381
"monthly.df <- monthly.df %>% ungroup() %>% arrange(year, month) %>%      mutate(trips.L1 = lag(trips, 1), trips.L2 = lag(trips, 2),          trips.L12 = lag(trips, 12))",data cleaning,912664148956537e8,393
"all_nodes <- rbind(nodes, sa_pts)",data cleaning,959925830829888e7,381
monthly.df <- monthly.df %>% filter(year > 2000),data cleaning,912664148956537e8,393
"dist_matrix <- matrix(0, nrow = length(all_nodes), ncol = length(all_nodes))",data cleaning,959925830829888e7,381
"twindows <- c(14, 28, 42)",not sure,183825093088672e8,170
df$Major_gear <- NA,data cleaning,746643975842744e8,404
"lm_s1 <- lm(trips ~ factor(month), data = monthly.df)",modeling,912664148956537e8,393
df$CA <- NA,data cleaning,746643975842744e8,404
"lm_s2 <- lm(trips ~ factor(month) + trips.L1, data = monthly.df)",modeling,912664148956537e8,393
df$OR <- NA,data cleaning,746643975842744e8,404
"lm_s3 <- lm(trips ~ factor(month) + trips.L1 + trips.L2, data = monthly.df)",modeling,912664148956537e8,393
df$WA <- NA,data cleaning,746643975842744e8,404
"lm_s4 <- lm(trips ~ factor(month) + trips.L1 + trips.L2 + trips.L12,      data = monthly.df)",modeling,912664148956537e8,393
"for (i in 1:length(all_nodes)) {     for (j in i:length(all_nodes)) {         dist_matrix[i, j] <- gdist(as.numeric(all_nodes@coords[i,              1]), as.numeric(all_nodes@coords[i, 2]), as.numeric(all_nodes@coords[j,              1]), as.numeric(all_nodes@coords[j, 2]), units = ""km"")         dist_matrix[j, i] <- dist_matrix[i, j]     } }",data cleaning,959925830829888e7,381
df$AK <- NA,data cleaning,746643975842744e8,404
df$At_sea <- NA,data cleaning,746643975842744e8,404
"anova(lm_s1, lm_s4)",modeling,912664148956537e8,393
df$CP_MS <- NA,data cleaning,746643975842744e8,404
n.dates.sim <- 28,not sure,183825093088672e8,170
"anova(lm_s2, lm_s4)",modeling,912664148956537e8,393
df$Other_ports <- NA,data cleaning,746643975842744e8,404
"connections <- as.data.frame(cbind(2:length(all_nodes), spantree(dist_matrix)$kid))",data cleaning,959925830829888e7,381
df$number_trips <- NA,data cleaning,746643975842744e8,404
"anova(lm_s3, lm_s4)",modeling,912664148956537e8,393
row.names(connections) <- 1:nrow(connections),data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ts(trips, frequency = 12, start = c(2001,      1)) ~ factor(month) + trips.L1 + trips.L2 + trips.L12, data = monthly.df)",modeling,912664148956537e8,393
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""^[0-9]*_[0-9]*.rds"",      )",import,183825093088672e8,170
df$multi_species <- NA,data cleaning,746643975842744e8,404
plot(f_statistics),visualization,912664148956537e8,393
df$number_vessels <- NA,data cleaning,746643975842744e8,404
"other_ports <- c(""DFO"", ""NWAFC"")",data cleaning,746643975842744e8,404
"my_emst <- (SpatialLinesDataFrame(SpatialLines(lapply(1:nrow(connections),      function(x) Lines(list(Line(rbind(cbind(as.numeric(all_nodes@coords[connections[x,          1], 1]), as.numeric(all_nodes@coords[connections[x, 1],          2])), cbind(as.numeric(all_nodes@coords[connections[x,          2], 1]), as.numeric(all_nodes@coords[connections[x, 2],          2]))))), paste(x))), proj4string = CRS(proj4string(nodes))),      connections))",data cleaning,959925830829888e7,381
"summary(breakpoints(ts(trips, frequency = 12, start = c(2001,      1)) ~ factor(month) + trips.L1 + trips.L2 + trips.L12, data = monthly.df))",exploratory,912664148956537e8,393
"spid <- read.csv(""/Users/efuller/1/CNH/Analysis/Metiers/data/spid.csv"",      stringsAsFactors = F)",import,746643975842744e8,404
"mtimes <- purrr::map(fitfiles, ~file.mtime(here::here(""data/stanfits"",      .x)) %>% as.Date)",data cleaning,183825093088672e8,170
opt_loc$dist2emst <- NA,data cleaning,959925830829888e7,381
library(tseries),setup,912664148956537e8,393
"grid <- read.csv(""/Users/efuller/1/CNH/Analysis/Metiers/data/grid.csv"",      stringsAsFactors = F)",import,746643975842744e8,404
"pcid <- read.csv(""/Users/efuller/1/CNH/Analysis/Metiers/data/pcid.csv"",      stringsAsFactors = F)",import,746643975842744e8,404
"idx <- purrr::map(mtimes, ~.x >= as.Date(""2018-12-28""))",data cleaning,183825093088672e8,170
x <- rnorm(100),import,912664148956537e8,393
fitfiles <- fitfiles[unlist(idx)],not sure,183825093088672e8,170
"for (i in 1:length(met_data)) {     df$Metier[i] <- names(met_data[i])     df$number_trips[i] <- with(met_data[[i]], length(unique(catch_data$trip_id)))     df$number_vessels[i] <- with(met_data[[i]], length(unique(catch_data$veid)))     tabs <- sort(table(met_data[[i]]$max_species$species), decreasing = T)     freqsp <- round(tabs/sum(tabs) * 100)     maj_species <- names(freqsp[which(freqsp > 50)])     df$multi_species[i] <- ""no""     if (length(maj_species) == 0) {         maj_species <- names(freqsp[which(freqsp >= 19)])         df$multi_species[i] <- ""yes""     }     maj_com <- tolower(spid$common_name[which(spid$SPID %in%          maj_species)])     maj_com <- gsub(pattern = ""nom. "", """", x = maj_com)     df$Major_species[i] <- paste(maj_com, collapse = "", "")     gear_tab <- with(met_data[[i]], round(100 * grid/sum(grid)))     maj_gear <- names(gear_tab[which(gear_tab > 50)])     if (length(maj_gear) == 0) {         maj_gear <- names(gear_tab[which(gear_tab >= 19)])     }     gear <- tolower(grid$Short.Name[which(grid$GRID %in% maj_gear)])     df$Major_gear[i] <- paste(gear, collapse = "", "")     by_port <- table(pcid$Agency[which(pcid$Pcid %in% with(met_data[[i]],          names(pcid)))])     df$CA[i] <- round(by_port[""CDFG""]/sum(by_port) * 100)     df$OR[i] <- round(by_port[""ODFW""]/sum(by_port) * 100)     df$WA[i] <- round(by_port[""WDFW""]/sum(by_port) * 100)     df$AK[i] <- round(by_port[""ADFG""]/sum(by_port) * 100)     df$At_sea[i] <- round(by_port[""AFSC""]/sum(by_port) * 100)     df$CP_MS[i] <- round(by_port[""AKR""]/sum(by_port) * 100)     op <- round(by_port[which(names(by_port) %in% other_ports)]/sum(by_port) *          100)     df$Other_ports[i] <- ifelse(length(op) == 0, NA, op) }",data cleaning,746643975842744e8,404
"rw <- tbl_df(data.frame(y = cumsum(x), t = seq(1:length(x)))) %>%      mutate(y.L1 = lag(y), ydiff.1 = y - y.L1)",data cleaning,912664148956537e8,393
"fitfiles <- stringr::str_replace(fitfiles, "".rds"", """")",not sure,183825093088672e8,170
"ggplot(rw, aes(x = t, y = y)) + geom_line()",visualization,912664148956537e8,393
"df <- df[order(df$number_trips, decreasing = T), ]",data cleaning,746643975842744e8,404
"for (i in 1:nrow(opt_loc)) {     loc <- c(opt_loc$x[i], opt_loc$y[i])     dist <- dist2Line(loc, my_emst)     opt_loc$dist2emst[i] <- dist[1]/1000     print(i) }",data cleaning,959925830829888e7,381
df$Other_ports <- NULL,data cleaning,746643975842744e8,404
"df_coords <- rbind(nodes@coords, sa_nodes)",data cleaning,959925830829888e7,381
df$AK <- NULL,data cleaning,746643975842744e8,404
df$At_sea <- NULL,data cleaning,746643975842744e8,404
adf.test(rw$y),modeling,912664148956537e8,393
row.names(df_coords) <- 1:nrow(df_coords),data cleaning,959925830829888e7,381
df$CP_MS <- NULL,data cleaning,746643975842744e8,404
"summary(lm(y ~ t + y.L1, data = rw))",modeling,912664148956537e8,393
opt_loc$isnode <- 0,data cleaning,959925830829888e7,381
row.names(df) <- NULL,data cleaning,746643975842744e8,404
"f_statistics <- Fstats(y ~ 1, data = rw)",modeling,912664148956537e8,393
"for (fit in fitfiles) {     message(""###############################"")     message(""Working on "", fit)     tproj <- strsplit(fit, split = ""_"")[[1]][1] %>% as.numeric()     twindow <- strsplit(fit, split = ""_"")[[1]][2] %>% as.numeric()     message(""working on "", tproj, ""_"", twindow)     rmarkdown::render(""analysis/projection_using_fitted.Rmd"",          params = list(tproj = tproj, twindow = twindow, n.dates.sim = n.dates.sim,              day0 = day0))     for (place in places) {         rmarkdown::render(""analysis/forecasts_assess.Rmd"", params = list(tproj = tproj,              twindow = twindow, incid = incidfile, n.dates.sim = n.dates.sim,              place = place))     } }",not sure,183825093088672e8,170
plot(f_statistics),visualization,912664148956537e8,393
"saveRDS(df, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/metier_descrp.RDS"")",export,746643975842744e8,404
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, all_nodes)) {         opt_loc[i, ""isnode""] <- 1     } }",data cleaning,959925830829888e7,381
"summary(breakpoints(y ~ 1, data = rw))",exploratory,912664148956537e8,393
"ggplot(rw, aes(x = t, y = ydiff.1)) + geom_line()",visualization,912664148956537e8,393
"f_statistics <- Fstats(ydiff.1 ~ 1, data = rw)",modeling,912664148956537e8,393
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,959925830829888e7,381
plot(f_statistics),visualization,912664148956537e8,393
library(igraph),setup,746643975842744e8,404
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,959925830829888e7,381
"summary(breakpoints(ydiff.1 ~ 1, data = rw))",exploratory,912664148956537e8,393
drift = 1,setup,912664148956537e8,393
variance = 40,setup,912664148956537e8,393
"df <- opt_loc[!is.na(opt_loc$zeta), ]",data cleaning,959925830829888e7,381
"for (tw in twindows) {     tproj <- seq(from = tw + 7, to = 656 - tw, by = 7)     for (p in places) {         message(""working on "", tw, "" and "", p)         rmarkdown::render(""analysis/forecasts_metrics_consolidate.Rmd"",              params = list(twindow = tw, tproj = tproj, incid = incidfile,                  n.dates.sim = 28, place = p))     } }",not sure,183825093088672e8,170
row.names(df) <- 1:nrow(df),data cleaning,959925830829888e7,381
"rw <- rw %>% mutate(ydrift = cumsum(rnorm(n = 100, mean = drift,      sd = sqrt(variance)))) %>% mutate(ydrift.L1 = lag(ydrift))",data cleaning,912664148956537e8,393
pars <- data.frame(),not sure,183825093088672e8,170
"ggplot(rw, aes(x = t, y = ydrift)) + geom_line()",visualization,912664148956537e8,393
df$bl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
df$tl_x <- df$x - 0.25,data cleaning,959925830829888e7,381
df$br_x <- df$x + 0.25,data cleaning,959925830829888e7,381
adf.test(rw$ydrift),evaluation,912664148956537e8,393
df$tr_x <- df$x + 0.25,data cleaning,959925830829888e7,381
df$bl_y <- df$y - 0.25,data cleaning,959925830829888e7,381
"summary(lm(ydrift ~ t + ydrift.L1, data = rw))",modeling,912664148956537e8,393
df$tl_y <- df$y + 0.25,data cleaning,959925830829888e7,381
df$br_y <- df$y - 0.25,data cleaning,959925830829888e7,381
"f_statistics <- Fstats(ydrift ~ 1, data = rw)",modeling,912664148956537e8,393
df$tr_y <- df$y + 0.25,data cleaning,959925830829888e7,381
"for (tw in twindows) {     for (i in 1:4) {         s1 <- seq(from = tw + (7 * i), to = 656 - tw, by = 28)         maxtproj <- 7 * floor((656 - tw)/7)         pars <- rbind(pars, expand.grid(maxtproj = maxtproj,              twindow = tw, tproj = list(s1)))     } }",not sure,183825093088672e8,170
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,959925830829888e7,381
plot(f_statistics),visualization,912664148956537e8,393
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,959925830829888e7,381
opt_loc$emstKM <- NA,data cleaning,959925830829888e7,381
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, my_emst)) {         intersect <- gIntersection(single_cell, my_emst)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""emstKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""emstKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""emstKM""] <- 0     } }",data cleaning,959925830829888e7,381
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,959925830829888e7,381
"for (place in places) {     for (row in seq_len(nrow(pars))) {         rmarkdown::render(""analysis/projections_viz_fixed_country.Rmd"",              params = list(tproj = pars$tproj[[row]], twindow = pars$twindow[row],                  incid = incidfile, n.dates.sim = 28, place = place,                  maxtproj = pars$maxtproj[[row]]))     } }",not sure,183825093088672e8,170
"buffer_emst <- spTransform(buffer(spTransform(my_emst, CRS(""+proj=robin +datum=WGS84"")),      width = 40000), CRS(""+proj=longlat +datum=WGS84""))",export,959925830829888e7,381
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""*_rquantiles_[0-9]*_[0-9]*.rds"",      )",import,183825093088672e8,170
"rails_in_buffer <- gIntersection(buffer_emst, all_rails)",export,959925830829888e7,381
"names(fitfiles) <- stringr::str_replace_all(fitfiles, "".rds"",      """")",data cleaning,183825093088672e8,170
opt_loc$bufferKM <- NA,data cleaning,959925830829888e7,381
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, rails_in_buffer)) {         intersect <- gIntersection(single_cell, rails_in_buffer)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""bufferKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""bufferKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""bufferKM""] <- 0     } }",data cleaning,959925830829888e7,381
"write.csv(opt_loc[, c(""ID"", ""bufferKM"")], file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/ID_bufferKM.csv"",      row.names = FALSE)",export,959925830829888e7,381
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_05.R"",      echo = FALSE)",setup,489437847863883e8,405
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/getmode.R"",      echo = FALSE)",setup,489437847863883e8,405
"summary(breakpoints(ydrift ~ 1, data = rw))",exploratory,912664148956537e8,393
"africa <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Territory/Africa.TAB"")",import,959925830829888e7,381
"montreal = read.table(""http://freakonometrics.free.fr/temp-montreal-monthly.txt"")",import,912664148956537e8,393
"rquantiles <- purrr::map_dfr(fitfiles, function(x) {     x <- here::here(""data/stanfits"", x)     out <- readr::read_rds(x)     out <- slice(out, n())     out }, .id = ""params"")",import,183825093088672e8,170
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/all_rails.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",visualization,959925830829888e7,381
summary(mn.homes$gross.sqft),exploratory,489437847863883e8,405
"M = as.matrix(montreal[, 2:13])",data cleaning,912664148956537e8,393
plot(africa),visualization,959925830829888e7,381
X = as.numeric(t(M)),data cleaning,912664148956537e8,393
"plot(all_rails, col = ""red"", add = T)",visualization,959925830829888e7,381
summary(mn.homes$land.sqft),exploratory,489437847863883e8,405
"plot(all_placebo, col = ""blue"", add = T, lty = 2)",visualization,959925830829888e7,381
summary(mn.homes$sale.price.n),exploratory,489437847863883e8,405
dev.off(),visualization,959925830829888e7,381
"rquantiles <- tidyr::separate(rquantiles, params, into = c(""country"",      ""what"", ""tproj"", ""twindow""), sep = ""_"")",data cleaning,183825093088672e8,170
"tsm = ts(X, start = 1948, freq = 12)",not sure,912664148956537e8,393
plot(tsm),visualization,912664148956537e8,393
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/emst.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",export,959925830829888e7,381
getmode(mn.homes$sale.price.n),exploratory,489437847863883e8,405
getmode(mn.homes$gross.sqft),exploratory,489437847863883e8,405
Xp1 = Xp2 = as.numeric(t(M)),data cleaning,912664148956537e8,393
plot(africa),visualization,959925830829888e7,381
getmode(mn.homes$land.sqft),exploratory,489437847863883e8,405
"rquantiles <- select(rquantiles, -what, -var)",modeling,183825093088672e8,170
"plot(my_emst, col = ""orange"", add = T)",visualization,959925830829888e7,381
"plot(buffer_emst, col = alpha(""orange"", 0.1), add = T, border = alpha(""grey"",      0.3))",visualization,959925830829888e7,381
hist(log10(mn.homes$sale.price.n)),visualization,489437847863883e8,405
"rquantiles <- mutate(rquantiles, ci = case_when(`2.5%` > 1 ~      ""ll_greater_than_1"", `97.5%` < 1 ~ ""ul_less_than_1"", TRUE ~      ""ci_includes_1""))",data cleaning,183825093088672e8,170
"for (t in 13:length(M)) {     Xp1[t] = Xp1[t - 12]     Xp2[t] = Xp2[t - 12] + rnorm(1, 0, 2) }",not sure,912664148956537e8,393
hist(log10(mn.homes$gross.sqft)),visualization,489437847863883e8,405
"plot(all_nodes, add = T, col = alpha(""red"", 0.5), pch = 20, cex = 0.5)",visualization,959925830829888e7,381
hist(log10(mn.homes$land.sqft)),visualization,489437847863883e8,405
"Xp1 = Xp1 + rnorm(length(Xp1), 0, 0.02)",not sure,912664148956537e8,393
dev.off(),visualization,959925830829888e7,381
"tsp1 = ts(Xp1, start = 1948, freq = 12)",not sure,912664148956537e8,393
"readr::write_csv(x = rquantiles, path = ""data/processed/rquantiles_projection.csv"")",export,183825093088672e8,170
"tsp2 = ts(Xp2, start = 1948, freq = 12)",not sure,912664148956537e8,393
"qqplot(mn.homes$gross.sqft, mn.homes$sale.price.n)",visualization,489437847863883e8,405
"qqplot(mn.homes$land.sqft, mn.homes$sale.price.n)",visualization,489437847863883e8,405
"par(mfrow = c(2, 1))",setup,912664148956537e8,393
"plot(mn.homes$gross.sqft, mn.homes$sale.price.n)",visualization,489437847863883e8,405
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""^[0-9]*_[0-9]*.rds"",      )",import,183825093088672e8,170
"plot(mn.homes$land.sqft, mn.homes$sale.price.n/10000, type = ""p"")",visualization,489437847863883e8,405
plot(tsp1),visualization,912664148956537e8,393
plot(tsp2),visualization,912664148956537e8,393
summary(mn.homes$sale.price.n),exploratory,489437847863883e8,405
"plot(mn.homes$gross.sqft, mn.homes$sale.price.n/1e+05, type = ""p"")",visualization,489437847863883e8,405
"fits <- purrr::map(fitfiles, ~readr::read_rds(here::here(""data/stanfits"",      .x)))",import,183825093088672e8,170
"root = ""~/ANALYSIS""",setup,489437847863883e8,405
"fitfiles <- stringr::str_replace_all(fitfiles, "".rds"", """")",data cleaning,183825093088672e8,170
"outdir <- ""data/stanfits/flow_matrices/""",export,183825093088672e8,170
d_threshold = 0.8,modeling,489437847863883e8,405
"for (i in 1:length(fits)) {     prefix <- fitfiles[[i]]     infile <- here::here(outdir, paste0(""flow_900_"", prefix,          "".rds""))     if (!file.exists(infile)) {         message(""running for "", i, "" and "", prefix)         res <- flow_mat_samples(i, fits = fits, nsim = 30)         message(""flow matrices for "", i)         message(""dumping them at "", prefix)         outfiles <- paste0(outdir, ""flow_"", seq_along(res), ""_"",              prefix, "".rds"")         purrr::walk2(res, outfiles, ~readr::write_rds(x = .x,              path = .y))     } }",export,183825093088672e8,170
"Plot_title = ""Perseids (EDMOND dataset: 2001 to 2015)""",visualization,489437847863883e8,405
Binsize = 0.002,visualization,489437847863883e8,405
"df <- readr::read_csv(""data/stanfits/still_running.csv"")",import,183825093088672e8,170
"D_Type = ""DD""",modeling,489437847863883e8,405
"prefix <- paste0(""*"", df$tproj, ""_"", df$twindow, ""*"")",not sure,183825093088672e8,170
"J_catalog = paste(root, ""/CONFIG/j8.csv"", sep = """")",setup,489437847863883e8,405
"oldfiles <- purrr::map(prefix, ~list.files(path = ""./data/stanfits.25122018/"",      pattern = .x, ))",import,183825093088672e8,170
"source(paste(root, ""/CONFIG/Lib_Config.r"", sep = """"))",setup,489437847863883e8,405
"file.copy(from = paste0(""data/stanfits.25122018/"", unlist(oldfiles)),      to = ""data/stanfits/"")",not sure,183825093088672e8,170
"source(paste(FuncDir, ""/common_functions.r"", sep = """"))",setup,489437847863883e8,405
"source(paste(FuncDir, ""/D_Criteria.r"", sep = """"))",setup,489437847863883e8,405
"oldflowmats <- purrr::map(prefix, ~list.files(path = ""./data/stanfits.25122018/flow_matrices/"",      pattern = .x, ))",import,183825093088672e8,170
"streamlist = read.csv(J_catalog, header = TRUE)",import,489437847863883e8,405
"streamlist <- streamlist[!is.na(streamlist$X_name) & !(streamlist$X_name ==      ""SPO""), ]",import,489437847863883e8,405
"file.copy(from = paste0(""data/stanfits.25122018/flow_matrices/"",      unlist(oldflowmats)), to = ""data/stanfits/flow_matrices/"")",not sure,183825093088672e8,170
setwd(WorkingDir),setup,489437847863883e8,405
library(dplyr),setup,183825093088672e8,170
library(rstan),setup,183825093088672e8,170
library(matrixStats),setup,183825093088672e8,170
mt <- read_ufo(),data cleaning,489437847863883e8,405
"fits <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit3.RDS"")",import,183825093088672e8,170
"mats <- data.frame(Int1 = NULL, Slope1 = NULL, Slope2 = NULL,      Int2 = NULL, lp__ = NULL, s = NULL)",setup,183825093088672e8,170
rows_read <- nrow(mt),exploratory,489437847863883e8,405
"for (i in 1:length(fits)) {     if (!(is.null(fits[[i]]))) {         tmpdat <- as.data.frame(extract(fits[[i]]))         tmpdat$s <- i         mats <- as.data.frame(rbind(mats, tmpdat))     } }",setup,183825093088672e8,170
"qs <- group_by(mats, s) %>% summarise(q = logSumExp(lp__) - log(n()))",exploratory,183825093088672e8,170
"if (rows_read == 0) {     stop(""No data in input file"") } else {     cat(paste(""*** Rows read from input file"", as.character(rows_read),          ""\n""))     mu <- filter_stream(mt, mtype = ""UNIFIED"")     if (nrow(mu) == 0) {         stop(""No data in UNIFIED dataframe"")     }     else {         if (Apply_QA) {             mu <- filter_apply_qa(mu)         }         rows_to_process <- nrow(mu)         if (rows_to_process == 0) {             stop(""No data to process - check QA filter settings"")         }         else {             mu$D_Value <- 9999             mu$D_Stream <- ""SPO""             for (ix in 1:nrow(streamlist)) {                 stream_name = as.factor(streamlist$X_name[ix])                 e = as.numeric(streamlist$X_e[ix])                 q = as.numeric(streamlist$X_q[ix])                 i = as.numeric(streamlist$X_incl[ix])                 n = as.numeric(streamlist$X_node[ix])                 p = as.numeric(streamlist$X_peri[ix])                 zlist <- DCalc(mu, e, q, i, n, p, D_Type = D_Type)                 idx <- (zlist$D_Value <= mu$D_Value) & (zlist$D_Value <=                    d_threshold)                 mu$D_Stream[idx] <- as.character(stream_name)                 mu$D_Value[idx] <- zlist$D_Value[idx]             }             mu_tab = table(mu$D_Stream, mu$X_stream)             result_tab <- NA             for (i in 1:nrow(mu_tab)) {                 for (j in 1:ncol(mu_tab)) {                   if (mu_tab[i, j] > 0) {                     result_tab <- rbind(result_tab, data.frame(rownames(mu_tab)[i],                        colnames(mu_tab)[j], mu_tab[i, j]))                   }                 }             }             colnames(result_tab) <- c(""D_ANALYSIS"", ""UFO"", ""Count"")             result_tab <- result_tab[with(result_tab, order(Count)),                  ]         }     } }",import,489437847863883e8,405
qs$p <- qs$q - logSumExp(qs$q),not sure,183825093088672e8,170
"mats <- merge(mats, qs)",setup,183825093088672e8,170
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,183825093088672e8,170
set.seed(parameters$seed),not sure,183825093088672e8,170
"newmcmc <- sample_n(mats, 8000, replace = T, weight = exp(mats$p))",modeling,183825093088672e8,170
"saveRDS(newmcmc, ""analysis/mcmc-runs/ToRaising-Stan-Fit3-resample.RDS"")",export,183825093088672e8,170
library(rstan),import,572759193833917e8,406
library(xtable),import,572759193833917e8,406
"load(""analysis/rdata-tmp/britdat.RData"")",import,572759193833917e8,406
"postscript(file = ""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Presentation\\Article\\figure\\Figure5.ps"",      horizontal = F, onefile = F, width = 3.27, height = 9.19,      family = ""Arial"", pointsize = 12)",visualization,183825093088672e8,170
"par(mfrow = c(2, 1))",visualization,183825093088672e8,170
"plot(nspm.2mo.tow.count.la, select = 1, shade = T, all.terms = T,      scale = 0, xlab = expression(paste(""Dissolved Oxygen"" ~ (mg ~          L^{             2         }))), ylab = ""Effect of Dissolved Oxygen"", ylim = c(-1.2,          0.22))",visualization,183825093088672e8,170
"text(0.55, 0.19, ""(a)"", cex = 1, font = 2)",visualization,183825093088672e8,170
"plot(nspm.2mo.tow.count.tx, select = 1, shade = T, all.terms = T,      scale = 0, xlab = expression(paste(""Dissolved Oxygen"" ~ (mg ~          L^{             2         }))), ylab = """")",visualization,183825093088672e8,170
"text(1.75, 0.35, ""(b)"", cex = 1, font = 2)",visualization,183825093088672e8,170
dev.off(),visualization,183825093088672e8,170
library(ggplot2),setup,183825093088672e8,170
"source(""config.worldbank.R"", local = TRUE)",import,183825093088672e8,170
"datasets <- read.csv(paste0(metaPath, ""worldbank.metadata"", ""."",      topic, ""."", refPeriod, "".csv""), header = T)",import,183825093088672e8,170
"cat(paste(""datasetX"", ""datasetY"", ""correlation"", ""pValue"", ""n"",      sep = "",""), file = paste0(summaryPath, ""correlation"", ""."",      topic, ""."", refPeriod, "".csv""), sep = ""\n"")",import,183825093088672e8,170
"cat(paste(""dataset"", ""time"", sep = "",""), file = paste0(summaryPath,      ""metadata"", ""."", topic, ""."", refPeriod, "".csv""), sep = ""\n"")",import,183825093088672e8,170
datasetLength <- nrow(datasets),exploratory,183825093088672e8,170
"for (i in 1:datasetLength) {     dtstart <- Sys.time()     for (j in 1:datasetLength) {         if (i <= j) {             datasetX <- datasets[i, ""identifier""]             datasetY <- datasets[j, ""identifier""]             plotPath <- paste0(basePath, ""plots/"", datasetX,                  ""-"", datasetY, ""."", topic, ""."", refPeriod, "".svg"")             dataX <- read.csv(paste0(observationPath, datasetX,                  ""."", topic, ""."", refPeriod, "".csv""), na.strings = """",                  header = T)             dataY <- read.csv(paste0(observationPath, datasetY,                  ""."", topic, ""."", refPeriod, "".csv""), na.strings = """",                  header = T)             data <- merge(dataX, dataY, by = ""refArea"")             n <- nrow(data)             if (n < 10 || sd(data$obsValue.x) == 0 || sd(data$obsValue.y) ==                  0) {                 NA             }             else {                 correlation <- cor(data$obsValue.x, data$obsValue.y,                    use = ""complete.obs"", method = correlationMethod)                 pValue <- cor.test(data$obsValue.x, data$obsValue.y,                    method = correlationMethod)$p.value                 analysisLine <- paste(datasetX, datasetY, correlation,                    pValue, n, sep = "","")                 cat(analysisLine, file = paste0(summaryPath,                    ""correlation"", ""."", topic, ""."", refPeriod,                    "".csv""), sep = ""\n"", append = TRUE)             }         }     }     dtend <- Sys.time()     duration <- as.numeric(dtend - dtstart, units = ""secs"")     cat(paste(datasetX, duration, sep = "",""), file = paste0(summaryPath,          ""metadata"", ""."", topic, ""."", refPeriod, "".csv""), sep = ""\n"",          append = TRUE) }",not sure,183825093088672e8,170
warnings(),exploratory,183825093088672e8,170
"source(""./analysis/nursery_experiment_inundation/functions/newbinplot.R"")",import,183825093088672e8,170
"source(""./analysis/nursery_experiment_inundation/functions/ranNorm.R"")",import,183825093088672e8,170
rm(list = ls()),setup,183825093088672e8,170
library(plyr),setup,183825093088672e8,170
library(dplyr),setup,183825093088672e8,170
library(reshape2),setup,183825093088672e8,170
"codedir <- ""code""",setup,183825093088672e8,170
"outputdir <- ""analysis/ramldb/output""",export,183825093088672e8,170
"tabledir <- ""analysis/ramldb/tables""",export,183825093088672e8,170
"sapply(list.files(codedir, "".R""), function(x) source(file.path(codedir,      x)))",import,183825093088672e8,170
"load(file.path(outputdir, ""RAMLDB_ricker.Rdata""))",import,183825093088672e8,170
ricker <- srfit,not sure,183825093088672e8,170
"load(file.path(outputdir, ""RAMLDB_ricker_sst.Rdata""))",import,183825093088672e8,170
ricker_sst <- srfit,not sure,183825093088672e8,170
"load(file.path(outputdir, ""RAMLDB_ricker_sst_lme.Rdata""))",import,183825093088672e8,170
ricker_sst_lme <- srfit,modeling,183825093088672e8,170
"models <- list(ricker, ricker_sst, ricker_sst_lme)",modeling,183825093088672e8,170
"names <- c(""Ricker"", ""SST-Ricker"", ""SST-LME-Ricker"")",modeling,183825093088672e8,170
"results <- compare_models(models, names)",modeling,183825093088672e8,170
"write.csv(results, file.path(tabledir, ""Table1_model_comparison_aic.csv""),      row.names = F)",export,183825093088672e8,170
elibrary(quickpsy),not sure,183825093088672e8,170
library(tidyverse),setup,183825093088672e8,170
library(circular),setup,183825093088672e8,170
library(cowplot),setup,183825093088672e8,170
library(PropCIs),setup,183825093088672e8,170
library(R.utils),setup,183825093088672e8,170
"sourceDirectory(""R"")",setup,183825093088672e8,170
"source(""graphical_parameters.R"")",import,183825093088672e8,170
"datpha <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = ""phase"",      session = as.character(1:4))",setup,183825093088672e8,170
"datpha$participant <- datpha$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,183825093088672e8,170
"datpha <- datpha %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,183825093088672e8,170
"avpha <- datpha %>% group_by(participant, freq) %>% summarise(n = n(),      k = sum(response)) %>% group_by(participant, freq) %>% do({     m <- .$k/.$n     ci <- exactci(.$k, .$n, 0.05)$conf.int     data.frame(m = m, inf = ci[1], sup = ci[2]) })",data cleaning,183825093088672e8,170
"dattrack <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = c(""tracking""),      session = as.character(1:4))",import,183825093088672e8,170
"dattrack$participant <- dattrack$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,183825093088672e8,170
"dattrack <- dattrack %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,183825093088672e8,170
"fit_psycho <- function(d, prob) {     quickpsy(d, freq, response, grouping = .(participant), fun = psychom,          parini = list(c(0.5, 4), c(0.05, 5), c(0, 0.5)), prob = prob,          bootstrap = ""none"") }",modeling,183825093088672e8,170
"fit70 <- fit_psycho(dattrack, 0.7)",modeling,183825093088672e8,170
"fit80 <- fit_psycho(dattrack, 0.8)",modeling,183825093088672e8,170
"fit90 <- fit_psycho(dattrack, 0.9)",modeling,183825093088672e8,170
"thres <- fit70$thresholds %>% bind_rows(fit80$thresholds) %>%      bind_rows(fit90$thresholds) %>% spread(key = prob, value = thre,      sep = ""_"")",modeling,183825093088672e8,170
"trackbinom <- fit70$averages %>% group_by(participant, freq) %>%      mutate(pvalue = binom.test(response, n)$p.value) %>% mutate(chance = ifelse(pvalue >      0.05, TRUE, FALSE))",modeling,183825093088672e8,170
"summarise(rayp = rayleigh.test(radFull)$p) %>% mutate(uniform = ifelse(rayp >      0.05, TRUE, FALSE))",modeling,183825093088672e8,170
"ptrack <- ggplot() + facet_wrap(~participant) + geom_ribbon(data = fit70$curves %>%      merge(fitthre) %>% filter(x > thre90 & x < thre70), aes(x = x,      ymin = 0.4, ymax = y), alpha = 0.1) + geom_point(data = fit70$averages,      size = 0.8, aes(x = freq, y = prob, color = ""Tracking"")) +      geom_line(data = fit70$curves, size = sizeLine1, aes(x = x,          y = y, color = ""Tracking"")) + geom_point(data = avpha,      size = 0.8, aes(x = freq, y = m, ymin = inf, ymax = sup,          color = ""Alignment"")) + geom_line(data = avpha, size = sizeLine1,      aes(x = freq, y = m, ymin = inf, ymax = sup, color = ""Alignment"")) +      geom_text(data = trackbinom %>% mutate(ast = if_else(chance,          """", ""*"")), aes(x = freq, label = ast), y = 0.5) + scale_color_brewer(palette = ""Set1"") +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          1)) + scale_y_continuous(breaks = seq(0.5, 1, 0.25)) +      labs(x = ""Frequency (rps)"", y = ""Probability of correct responses"")",visualization,183825093088672e8,170
ptrack,visualization,183825093088672e8,170
"save_plot(""analysis/figures/trackalig.pdf"", ptrack, base_width = twoColumnWidth)",export,183825093088672e8,170
"dat <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = c(""press""),      session = as.character(1:4))",import,183825093088672e8,170
"dat$participant <- dat$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,183825093088672e8,170
"dat <- dat %>% select(participant, direction, angleLandmark,      freq, response) %>% filter(response != 9999) %>% mutate(totalerror = direction *      (response - angleLandmark), degSemi = totalerror %>% totalerrorToDegSemi(),      degFull = degSemi %>% degSemiToDegFull(), radFull = degFull %>%          degFullToRadFull()) %>% group_by(participant, freq)",data cleaning,183825093088672e8,170
minfreq <- dat %>% group_by(participant) %>% summarise(freq = min(freq)),exploratory,183825093088672e8,170
allfreqs <- dat %>% group_by(participant) %>% do({     tibble(freqsim = unique(.$freq)) }),exploratory,183825093088672e8,170
"uniformity <- dat %>% summarise(rayp = rayleigh.test(radFull)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, "">.05"", ifelse(rayp >          0.01, ""<.05"", ifelse(rayp > 0.001, ""<.01"", ""<.001""))))",modeling,183825093088672e8,170
datuniformity <- dat %>% left_join(uniformity),data cleaning,183825093088672e8,170
"circmeans <- datuniformity %>% group_by(participant, freq, uniform) %>%      summarise(mrad = mean.circular(radFull), mdegSemi = mrad %>%          radFullToDegFull() %>% degFullToDegSemi()) %>% filter(!uniform)",modeling,183825093088672e8,170
"pmean <- ggplot(circmeans) + facet_wrap(~participant) + geom_point(data = datuniformity,      alpha = 0.4, aes(x = freq, y = degSemi, color = uniform)) +      geom_line(aes(x = freq, y = mdegSemi))",visualization,183825093088672e8,170
pmean,visualization,183825093088672e8,170
"save_plot(""analysis/figures/mean.pdf"", pmean, base_width = twoColumnWidth)",export,183825093088672e8,170
"anglestoplot <- tibble(n = 1:4, x = rep(3.6, 4), y = c(0, 45,      90, -45), angle = c(""0"", ""45"", "" 90\n-90"", ""-45""), participant = ""Participant 5"")",visualization,183825093088672e8,170
"zeroline <- tibble(participant = datuniformity$participant %>%      unique(), x = 0, xend = c(3.8, 3.8, 3.8, 3.2, 3.2, 3.2, 3.2,      3.2), y = 0, yend = 0)",data cleaning,183825093088672e8,170
"praw <- ggplot() + facet_wrap(~participant, ncol = 3) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.2, aes(xmin = thre70, xmax = thre90,          ymin = -90, ymax = 90)) + geom_point(data = datuniformity,      aes(x = freq, y = degSemi, color = uniform), size = 0.35,      alpha = 0.5, shape = 16) + geom_text(data = anglestoplot,      aes(x = x, y = y, label = angle, group = n), size = sizeText) +      geom_segment(data = zeroline, aes(y = y, yend = yend, x = x,          xend = xend), size = sizeLine1) + scale_color_manual(name = ""p"",      values = c(""#08519c"", ""#3182bd"", ""#6baed6"", ""#b30000"")) +      scale_x_continuous(breaks = seq(0, 3, 1), labels = as.character(0:3)) +      scale_y_continuous(breaks = seq(-45, 90, 45), limits = c(-90,          90), labels = c(""-45"", ""0"", ""45"", ""90"")) + xlab(""Frequency (rps)"") +      ylab(""Error (deg)"") + coord_polar(theta = ""y"", start = pi/2,      direction = -1) + theme(axis.text.x = element_blank(), axis.title.x = element_blank(),      axis.line.x = element_blank(), axis.line.y = element_line(size = sizeLine1),      panel.spacing = unit(-0.32, ""lines""), legend.key = element_blank(),      legend.key.height = unit(0.7, ""lines""), legend.position = c(0.85,          0.16)) + guides(colour = guide_legend(override.aes = list(size = 2)))",visualization,183825093088672e8,170
praw,visualization,183825093088672e8,170
"save_plot(""analysis/figures/raw.pdf"", praw, base_width = oneColumnWidth)",export,183825093088672e8,170
nonuniformspeed <- uniformity %>% filter(!uniform) %>% summarise(freq = max(freq)) %>%      rename(frequni = freq),evaluation,183825093088672e8,170
nontrackspeed <- trackbinom %>% group_by(participant) %>% filter(!chance) %>%      summarise(freq = max(freq)) %>% rename(freqtrack = freq),evaluation,183825093088672e8,170
freqs <- nonuniformspeed %>% left_join(nontrackspeed) %>% left_join(fitthre80),data cleaning,183825093088672e8,170
"ggplot(freqs, aes(frequni, thre90)) + geom_point() + geom_abline() +      coord_equal(xlim = c(0, 2.5), ylim = c(0, 2.5))",visualization,183825093088672e8,170
"cor.test(freqs$frequni, freqs$thre90)",evaluation,183825093088672e8,170
"t.test(freqs$frequni, freqs$thre90, paired = TRUE)",modeling,183825093088672e8,170
"datboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     dat %>% group_by(participant, freq) %>% sample_frac(1, replace = T) }) %>% group_by(participant, freq, n)",data cleaning,183825093088672e8,170
"datsim <- data_frame(freqsim = unique(dat$freq)) %>% group_by(freqsim) %>%      do({         dat     }) %>% filter(freqsim >= freq) %>% mutate(degFullSim = freqsim/freq *      degFull, radFullSim = degFullSim %>% degFullToRadFull()) %>%      semi_join(allfreqs) %>% group_by(participant, freq, freqsim)",exploratory,183825093088672e8,170
"uniformitysim <- datsim %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",exploratory,183825093088672e8,170
"trackingprob <- fit80$averages %>% select(participant, freq,      prob)",data cleaning,183825093088672e8,170
trackingprobminfreq <- trackingprob %>% semi_join(minfreq) %>%      ungroup() %>% rename(probfreqmin = prob) %>% select(-freq),evaluation,183825093088672e8,170
"trackingprob <- trackingprob %>% left_join(trackingprobminfreq) %>%      mutate(probnotrack = 2 * (probfreqmin - prob)) %>% mutate(probnotrack = ifelse(probnotrack >      1, 1, probnotrack), probnotrack = ifelse(probnotrack < 0,      0, probnotrack)) %>% rename(freqsim = freq)",evaluation,183825093088672e8,170
"datsimtrack <- datsim %>% select(participant, freqsim, freq,      radFullSim) %>% left_join(trackingprob) %>% do({     n <- length(.$radFullSim)     probnotrack <- unique(.$probnotrack)     nnotrack <- round(n * probnotrack)     track <- sample_n(., n - nnotrack)     notrack <- sample_n(., nnotrack)     notrack$radFullSim <- runif(nnotrack, 0, 2 * pi)     rbind(track, notrack) })",evaluation,183825093088672e8,170
"uniformitysimtrack <- datsimtrack %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",evaluation,183825093088672e8,170
"datsimboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     datsim %>% group_by(participant, freq, freqsim) %>% sample_frac(1,          replace = T) }) %>% group_by(participant, freq, freqsim, n)",evaluation,183825093088672e8,170
dispersion <- dat %>% summarise(rho = rho.circular(radFull)),evaluation,183825093088672e8,170
dispersionboot <- datboot %>% summarise(rho = rho.circular(radFull %>%      circular())),not sure,183825093088672e8,170
"dispersionbootci <- dispersionboot %>% summarise(inf = quantile(rho,      0.025), sup = quantile(rho, 0.975))",evaluation,183825093088672e8,170
dispersionuniformity <- dispersion %>% left_join(dispersionbootci) %>%      left_join(uniformity),evaluation,183825093088672e8,170
library(pwr),setup,325279601616785e8,407
dispersionsim <- datsim %>% summarise(rho = rho.circular(radFullSim)),evaluation,183825093088672e8,170
dispersionsimboot <- datsimboot %>% summarise(rho = rho.circular(radFullSim %>%      circular())),evaluation,183825093088672e8,170
"dispersionsimbootci <- dispersionsimboot %>% summarise(inf = quantile(rho,      0.025), sup = quantile(rho, 0.975))",evaluation,183825093088672e8,170
dispersionsimuniformity <- dispersionsim %>% left_join(dispersionsimbootci) %>%      left_join(uniformitysim),evaluation,183825093088672e8,170
dispersionsimuniformitylowfreq <- dispersionsimuniformity %>%      semi_join(minfreq) %>% semi_join(allfreqs),evaluation,183825093088672e8,170
dispersionsimtrack <- datsimtrack %>% summarise(rho = rho.circular(radFullSim)),evaluation,183825093088672e8,170
dispersionsimtrackuniformity <- dispersionsimtrack %>% left_join(uniformitysimtrack),evaluation,183825093088672e8,170
dispersionsimtrackuniformitylowfreq <- dispersionsimtrackuniformity %>%      semi_join(minfreq),evaluation,183825093088672e8,170
library(TOSTER),setup,325279601616785e8,407
"prho <- ggplot() + facet_wrap(~participant, scales = ""free_x"") +      geom_rect(data = fitthre, fill = ""black"", alpha = 0.1, aes(xmin = thre70,          xmax = thre90, ymin = 0, ymax = 1)) + geom_line(data = dispersionsimuniformitylowfreq,      show.legend = FALSE, size = sizeLine1, aes(x = freqsim, y = rho,          color = uniform)) + geom_line(data = dispersionsimtrackuniformity %>%      semi_join(minfreq), show.legend = FALSE, size = sizeLine1,      aes(x = freqsim, y = rho, color = uniform)) + geom_line(data = dispersionsimtrackuniformity %>%      semi_join(minfreq), show.legend = FALSE, size = sizeLine1,      lty = 3, aes(x = freqsim, y = rho)) + geom_point(data = dispersionuniformity,      size = 0.6, shape = 2, aes(x = freq, y = rho, color = uniform)) +      labs(x = ""Frequency (rps)"", y = ""Radial vector length"") +      scale_y_continuous(breaks = seq(0, 1, 0.5), limits = c(0,          1)) + scale_x_continuous(limits = c(0, 3.5), breaks = seq(0,      3.5, 1)) + theme(legend.key = element_blank(), legend.title = element_blank(),      legend.position = c(0.8, 0.13), axis.title.x = element_text(hjust = 0.25))",visualization,183825093088672e8,170
library(BEST),setup,325279601616785e8,407
prho,visualization,183825093088672e8,170
library(dplyr),setup,325279601616785e8,407
library(ggplot2),setup,325279601616785e8,407
"save_plot(""analysis/figures/prho.pdf"", prho, base_width = oneColumnWidth)",export,183825093088672e8,170
"geom_line(data = dispersionsimuniformityplot, size = sizeLine1,      aes(x = freqsim2, y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      geom_text(data = trackbinom %>% mutate(ast = if_else(chance,          """", ""*"")), aes(x = freq, label = ast), y = 0) + scale_color_discrete(guide = guide_legend(title = NULL),      breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,183825093088672e8,170
prho,visualization,183825093088672e8,170
"dispersionsimuniformityplot <- dispersionsimuniformity %>% mutate(freq2 = freq,      freqsim2 = freqsim)",visualization,183825093088672e8,170
"prho <- ggplot() + facet_grid(participant ~ freq2, scales = ""free"") +      geom_line(data = dispersionsimuniformityplot, size = sizeLine1,          aes(x = freqsim2, y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      geom_text(data = trackbinom %>% mutate(ast = if_else(chance,          """", ""*"")), aes(x = freq, label = ast), y = 0) + scale_color_discrete(guide = guide_legend(title = NULL),      breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      axis.title.x = element_text(hjust = 0.01))",visualization,183825093088672e8,170
prho,visualization,183825093088672e8,170
"save_plot(""analysis/figures/rho.pdf"", prho, base_width = 2 *      twoColumnWidth, base_height = twoColumnWidth)",export,183825093088672e8,170
"source(""../R-Scripts/BF10_tTest_Informed.R"")",exploratory,325279601616785e8,407
"oneminfreqsim <- dispersion %>% group_by(participant) %>% do(head(.,      1))",evaluation,183825093088672e8,170
"twominfreqsim <- dispersion %>% group_by(participant) %>% do(head(.,      2))",evaluation,183825093088672e8,170
"datsim2 <- datsim %>% semi_join(twominfreqsim) %>% group_by(participant,      freqsim)",evaluation,183825093088672e8,170
"uniformitysim2 <- datsim2 %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",evaluation,183825093088672e8,170
dispersionsim2 <- datsim2 %>% summarise(rho = rho.circular(radFullSim)) %>%      anti_join(oneminfreqsim) %>% left_join(uniformitysim2),evaluation,183825093088672e8,170
"prho2 <- ggplot() + facet_wrap(~participant, scales = ""free"") +      geom_line(data = dispersionsim2, size = sizeLine1, aes(x = freqsim,          y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      axis.title.x = element_text(hjust = 0.01))",visualization,183825093088672e8,170
prho2,visualization,183825093088672e8,170
"dispersionbootciunifotest <- datsim %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE)) %>% rename(freq2 = freq,      freqsim2 = freqsim)",evaluation,183825093088672e8,170
"prhouni <- ggplot() + facet_wrap(~freq) + geom_line(data = dispersionbootciunifotest %>%      filter(freq < 2.5), aes(x = freqsim, y = m)) + geom_line(data = dispersionuniformityplot,      size = sizeLine1, aes(x = freqsim, y = rho, color = uniform)) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          0.5)) + theme(legend.key = element_blank(), axis.title.x = element_text(hjust = 0.01)) +      geom_vline(xintercept = 2) + geom_hline(yintercept = 0.05)",visualization,183825093088672e8,170
prhouni,visualization,183825093088672e8,170
"dispersionsimbootciunifotest <- datsimboot %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE)) %>% group_by(participant,      freq, freqsim) %>% summarise(m = mean(uniform))",evaluation,183825093088672e8,170
d.sesoi <- 0.3,setup,325279601616785e8,407
dispersionuniformityplot <- dispersionuniformity %>% rename(freqsim = freq),evaluation,183825093088672e8,170
"prhounisim <- ggplot() + facet_wrap(~freq) + geom_line(data = dispersionsimbootciunifotest %>%      filter(freq < 2.5), aes(x = freqsim, y = m)) + geom_line(data = dispersionuniformityplot,      size = sizeLine1, aes(x = freqsim, y = rho, color = uniform)) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          0.5)) + theme(legend.key = element_blank(), axis.title.x = element_text(hjust = 0.01)) +      geom_vline(xintercept = 2) + geom_hline(yintercept = 0.05)",visualization,183825093088672e8,170
prhounisim,visualization,183825093088672e8,170
"fit_glm <- function(dat, tresh = 20) {     if (sum(dat[, ""total""] > 0) >= tresh) {         m <- tryCatch({             glm(total ~ year, offset = log(total_words), data = dat,                  family = quasipoisson(link = ""log""))         }, error = function(e) NA)     }     else {         m <- NA     }     if (!is.na(m[[1]])[[1]])          exp(coef(m)[[""year""]] * 10)     else NA }",modeling,602431616280228e7,233
"save_plot(""analysis/figures/rhounif.pdf"", prhouni, base_width = oneColumnWidth)",export,183825093088672e8,170
alpha.level <- 0.01,visualization,325279601616785e8,407
priori.power <- 0.9,modeling,325279601616785e8,407
"funWrap <- function(d) {     sta <- mle.wrappednormal(d$radFull)$sd     stams <- sta/(4 * pi * first(d$freq)) * 1000     data.frame(sta, stams) }",not sure,183825093088672e8,170
"process_slopes <- function(data, n = 8) {     sm <- plyr::ddply(data, c(""decade"", ""lemma""), function(xx) {         r1 <- fit_glm(filter(xx, year %in% 1930:1960))         r2 <- fit_glm(filter(xx, year %in% 1980:2010))         tibble(rate_early = r1, rate_late = r2)     }) %>% as_tibble()     b1_ <- sm %>% filter(decade == ""1940s"") %>% top_n(n, -rate_early)     b2_ <- sm %>% filter(decade == ""2000s"") %>% top_n(n, rate_late)     b <- bind_rows(b1_, b2_)     inner_join(b, data, by = c(""decade"", ""lemma"")) }",modeling,602431616280228e7,233
"pwr.t.test(d = d.sesoi, sig.level = alpha.level, power = priori.power)",modeling,325279601616785e8,407
"dispersionwrap <- dat %>% group_by(participant, freq) %>% do(funWrap(.))",not sure,183825093088672e8,170
"df <- read.csv(""../Example Data/Example_Data.csv"")",import,325279601616785e8,407
dispersiowrapnuniformity <- dispersionwrap %>% merge(uniformity),data cleaning,183825093088672e8,170
"plot(DV ~ Group, data = df)",visualization,325279601616785e8,407
"summarise(group_by(df, Group), mean = mean(DV), sd = sd(DV),      count = n(), min = min(DV), max = max(DV))",exploratory,325279601616785e8,407
"dispersionwrapboot <- datboot %>% group_by(participant, freq,      n) %>% do(funWrap(.))",evaluation,183825093088672e8,170
"dispersionwrapbootci <- dispersionwrapboot %>% group_by(participant,      freq) %>% summarise(inf = quantile(stams, 0.025), sup = quantile(stams,      0.975))",evaluation,183825093088672e8,170
dispersionwrapbootciuniformity <- dispersionwrapbootci %>% merge(uniformity),data cleaning,183825093088672e8,170
"dispersionwrapsim <- datsim %>% group_by(participant, freq, freqsim) %>%      do(funWrap(.))",evaluation,183825093088672e8,170
"t.test(DV ~ Group, data = df, alternative = ""two.sided"")",exploratory,325279601616785e8,407
"dispersionwrapsimboot <- datsimboot %>% filter(freq == 0.75) %>%      group_by(participant, freq, freqsim, n) %>% do(funWrap(.))",evaluation,183825093088672e8,170
"dispersionwrapsimbootci <- dispersionwrapsimboot %>% group_by(participant,      freq, freqsim) %>% summarise(inf = quantile(stams, 0.025),      sup = quantile(stams, 0.975))",evaluation,183825093088672e8,170
"pwra <- ggplot() + facet_wrap(~participant, scales = ""free_x"") +      geom_rect(data = fitthre, fill = ""black"", alpha = 0.1, aes(xmin = thre70,          xmax = thre90, ymin = 0, ymax = 160)) + geom_line(data = dispersionwrapsimbootci,      size = sizeLine1, aes(x = freqsim, y = inf), color = ""grey"") +      geom_line(data = dispersionwrapsimbootci, size = sizeLine1,          aes(x = freqsim, y = sup), color = ""grey"") + geom_line(data = dispersiowrapnuniformity,      size = sizeLine1, aes(x = freq, y = stams, color = uniform)) +      geom_point(data = dispersiowrapnuniformity, size = 0.8, aes(x = freq,          y = stams, color = uniform)) + geom_ribbon(data = dispersionwrapbootciuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Standard deviation (ms)"") + scale_x_continuous(limits = c(0,      3.5), breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,183825093088672e8,170
pwra,visualization,183825093088672e8,170
"save_plot(""analysis/figures/wrap.pdf"", pwra, base_width = oneColumnWidth)",export,183825093088672e8,170
"dif <- dispersionsim %>% filter(freq == 0.75) %>% ungroup() %>%      select(-freq) %>% rename(freq = freqsim, rhosim = rho) %>%      merge(dispersion) %>% group_by(participant, freq) %>% summarise(dif = rhosim -      rho)",evaluation,183825093088672e8,170
"ggplot() + facet_wrap(~participant) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_line(data = dif, aes(x = freq,      y = dif))",visualization,183825093088672e8,170
"geom_line(data = dispersionsim %>% filter(freq == 0.75), aes(x = freqsim,      rho)) + geom_line(data = dispersion, aes(x = freq, rho))",visualization,183825093088672e8,170
"TOSTtwo.raw(mean(df[df$Group == ""Meditation"", ]$DV), mean(df[df$Group ==      ""Waiting List"", ]$DV), sd(df[df$Group == ""Meditation"", ]$DV),      sd(df[df$Group == ""Waiting List"", ]$DV), length(df[df$Group ==          ""Meditation"", ]$DV), length(df[df$Group == ""Waiting List"",          ]$DV), low_eqbound = -9, high_eqbound = +9, alpha = 0.01,      var.equal = F, plot = T)",not sure,325279601616785e8,407
"best <- BESTmcmc(df[df$Group == ""Meditation"", ]$DV, df[df$Group ==      ""Waiting List"", ]$DV, rnd.seed = 20180309, verbose = FALSE,      numSavedSteps = 10000, parallel = TRUE)",exploratory,325279601616785e8,407
df.best <- data.frame(diff = (best$mu1 - best$mu2)),exploratory,325279601616785e8,407
summary(best),exploratory,325279601616785e8,407
"posterior.mode <- summary(best)[""muDiff"", ""mode""]",modeling,325279601616785e8,407
library(tidyverse),setup,183825093088672e8,170
"setwd(""/Users/angelD/Downloads/git_repo/SDE2"")",setup,183825093088672e8,170
"RF14.ctrl <- read_tsv(""analysis/03_ASprofile/data/whippetResult/RF14_vs_cntrl_output.diff"") %>%      mutate(absDeltaPsi = abs(DeltaPsi)) %>% mutate(Gene = str_replace_all(string = Gene,      pattern = ""\\..+$"", replacement = """")) %>% mutate(Group = ""RF14.ctrl"")",import,183825093088672e8,170
"hdi <- hdi(df.best$diff, credMass = 0.95)",modeling,325279601616785e8,407
"hdi[""lower""]",modeling,325279601616785e8,407
"hdi[""upper""]",modeling,325279601616785e8,407
"ggplot(data = df.best, aes(x = diff)) + geom_histogram(aes(y = ..density..),      fill = ""white"", color = ""darkgrey"", binwidth = 0.25) + geom_density(color = ""darkgrey"") +      geom_vline(xintercept = -9, linetype = ""dashed"") + geom_vline(xintercept = 9,      linetype = ""dashed"") + geom_vline(xintercept = 0, linetype = ""dashed"",      color = ""grey"") + geom_segment(x = hdi[""lower""], xend = hdi[""upper""],      y = 0, yend = 0, size = 1.1) + geom_point(x = posterior.mode,      y = 0, color = ""black"", shape = 15, size = 3) + scale_x_continuous(name = expression(paste(mu[1],      "" - "", mu[2]))) + scale_y_continuous(name = ""Density"")",visualization,325279601616785e8,407
"source(""../../bin/singleDrugAnalysis.R"")",import,668355487054214e8,408
"source(""../../bin/ctrpSingleAgentScreens.R"")",import,668355487054214e8,408
bf.alt.mu <- 0.62,not sure,325279601616785e8,407
aucMat = getCtrpScreensAsMatrix(),import,668355487054214e8,408
"fzMat = apply(aucMat, 1, function(x) apply(aucMat, 1, function(y) fzCor(x,      y)))",exploratory,668355487054214e8,408
rownames(fzMat) <- colnames(fzMat) <- rownames(aucMat),data cleaning,668355487054214e8,408
"cormat <- stats::cor(t(aucMat), use = ""pairwise.complete.obs"")",exploratory,668355487054214e8,408
"pars = c(1, 4, 5, 10, 100, 1000)",setup,668355487054214e8,408
"dsNorms <- lapply(pars, function(x) dSigTransform(fzMat, alpha = x))",exploratory,668355487054214e8,408
names(dsNorms) <- as.character(pars),data cleaning,668355487054214e8,408
do.test = FALSE,setup,668355487054214e8,408
library(ROCR),not sure,18636455363594e9,409
"pos <- scan(""data/analysis/P"")",visualization,18636455363594e9,409
library(sp),setup,479495592415333e8,1
library(maps),setup,479495592415333e8,1
library(maptools),setup,479495592415333e8,1
"ports_df <- read.csv(""/Users/efuller/Desktop/CNH/processedData/spatial/ports/all_ports.csv"",      stringsAsFactors = FALSE)",import,479495592415333e8,1
"if (do.test) {     lt = which(fzMat < 3, arr.ind = T)     ct = which(cormat > 0.9, arr.ind = T)     ctm = apply(ct, 1, function(x) intersect(which(lt[, 1] ==          x[[1]]), which(lt[, 2] == x[[2]])) > 0)     inds = ct[which(unlist(ctm)), ]     no = which(cormat[inds] < 0.9999)     inds = ct[no, ]     diffs = t(apply(inds, 1, function(x) {         print(paste(rownames(cormat)[x[1]], colnames(cormat)[x[2]]))         cval = cormat[x[1], x[2]]         fzval = fzMat[x[1], x[2]]         print(paste(""Cor:"", cval))         print(paste(""FZ:"", fzval))         na1 = which(!is.na(aucMat[x[1], ]))         na2 = which(!is.na(aucMat[x[2], ]))         print(paste(""Found"", length(intersect(na1, na2)), ""overlapping samples!""))         return(c(Cor = cval, FZ = fzval, Overlap = length(intersect(na1,              na2))))     })) }",exploratory,668355487054214e8,408
"latlon2county <- function(ports) {     counties <- map(""county"", fill = TRUE, col = ""transparent"",          plot = FALSE)     IDs <- sapply(strsplit(counties$names, "":""), function(x) x[1])     counties_sp <- map2SpatialPolygons(counties, IDs = IDs, proj4string = CRS(""+proj=longlat + datum=wgs84""))     pointsSP <- SpatialPoints(ports[-which(is.na(ports$lat)),          c(""lon"", ""lat"")], proj4string = CRS(""+proj=longlat + datum=wgs84""))     countyNames <- sapply(counties_sp@polygons, function(x) x@ID)     pr_counties <- spTransform(counties_sp, CRS(""+proj=aeqd +lat_0=41.30817205480597 +lon_0=-123.4149169921875""))     pr_points <- spTransform(pointsSP, CRS(""+proj=aeqd +lat_0=41.30817205480597 +lon_0=-123.4149169921875""))     library(rgeos)     county.df <- ports[-which(is.na(ports$lat)), ]     county.df$county <- NA     for (i in 1:nrow(county.df)) {         county.df$county[i] <- countyNames[which.min(gDistance(pr_points[i,              ], pr_counties, byid = TRUE))]     }     return(county.df) }",data cleaning,479495592415333e8,1
ports <- latlon2county(ports = ports_df),data cleaning,479495592415333e8,1
tp = length(which(pos >= 0)),not sure,18636455363594e9,409
fn = length(which(pos < 0)),not sure,18636455363594e9,409
rm(ports_df),data cleaning,479495592415333e8,1
"tickets_df <- readRDS(""/Users/efuller/Desktop/CNH/processedData/catch/1_cleaningData/tickets.RDS"")",import,479495592415333e8,1
library(dplyr),setup,479495592415333e8,1
"neg <- scan(""data/analysis/N"")",exploratory,18636455363594e9,409
fp = length(which(neg >= 0)),exploratory,18636455363594e9,409
tn = length(which(neg < 0)),exploratory,18636455363594e9,409
sen = tp/(tp + fn),evaluation,18636455363594e9,409
"all.inds = do.call(""rbind"", lapply(1:nrow(cormat), function(x) cbind(rep(x,      nrow(cormat)), 1:nrow(cormat))))",data cleaning,668355487054214e8,408
spec = tn/(tn + fp),evaluation,18636455363594e9,409
"all <- c(pos, neg)",evaluation,18636455363594e9,409
"lbl <- c(rep(1, length(pos)), rep(0, length(neg)))",evaluation,18636455363594e9,409
"pred <- prediction(all, lbl)",modeling,18636455363594e9,409
length(pos) + length(neg),modeling,18636455363594e9,409
length(pos),modeling,18636455363594e9,409
length(neg),modeling,18636455363594e9,409
tp,modeling,18636455363594e9,409
fn,modeling,18636455363594e9,409
fp,modeling,18636455363594e9,409
tn,modeling,18636455363594e9,409
"performance(pred, measure = ""auc"")@y.values[[1]]",modeling,18636455363594e9,409
sen,modeling,18636455363594e9,409
spec,modeling,18636455363594e9,409
"all.diffs = t(apply(all.inds, 1, function(x) {     cval = cormat[x[1], x[2]]     fzval = fzMat[x[1], x[2]]     na1 = which(!is.na(aucMat[x[1], ]))     na2 = which(!is.na(aucMat[x[2], ]))     if (!is.na(fzval) && x[1] != x[2] && fzval > 500)          print(paste(""Check:"", rownames(cormat)[x[1]], colnames(cormat)[x[2]]))     retvec = c(Cor = cval, FZ = fzval, Overlap = length(intersect(na1,          na2)), Ind1 = x[1], Ind2 = x[2])     ds = unlist(lapply(dsNorms, function(y) y[x[1], x[2]]))     names(ds) <- paste(""doubleSig"", pars, sep = ""_"")     return(c(retvec, ds)) }))",communication,668355487054214e8,408
"source(""~/selection/code/lib/readlib.R"")",import,18636455363594e9,409
df = data.frame(all.diffs),setup,668355487054214e8,408
version = NA,not sure,18636455363594e9,409
library(ggplot2),setup,668355487054214e8,408
"p <- ggplot(df, aes(x = Cor, y = FZ + 10)) + geom_point(aes(colour = Overlap)) +      scale_y_log10()",visualization,668355487054214e8,408
rm(list = ls()),data cleaning,275962801417336e8,410
"png(""spearmanVsFisherZ.png"")",export,668355487054214e8,408
seed <- 627,setup,275962801417336e8,410
set.seed(seed),setup,275962801417336e8,410
print(p),evaluation,668355487054214e8,408
"raw_path <- ""analysis/data/raw_data/""",import,275962801417336e8,410
dev.off(),setup,668355487054214e8,408
"derived_path <- ""analysis/data/derived_data/""",import,275962801417336e8,410
"source(""http://svn.research-infrastructures.eu/public/d4science/gcube/trunk/data-analysis/RConfiguration/RD4SFunctions/workspace_interaction.r"")",import,275962801417336e8,410
"p <- ggplot(df, aes(x = Cor, y = doubleSig_1)) + geom_point(aes(colour = Overlap)) +      scale_colour_gradientn(colours = rainbow(5))",visualization,668355487054214e8,408
"if (file.exists(paste0(raw_path, ""keys.csv""))) {     keys <- read.csv(""analysis/data/raw_data/keys.csv"", stringsAsFactors = FALSE)     username <<- keys$username     token <<- keys$token     rm(keys) }",data cleaning,275962801417336e8,410
"png(""spearmanVsDoubSigTransA1.png"")",export,668355487054214e8,408
print(p),evaluation,668355487054214e8,408
dev.off(),setup,668355487054214e8,408
"p <- ggplot(df, aes(x = Cor, y = doubleSig_4)) + geom_point(aes(colour = Overlap)) +      scale_colour_gradientn(colours = rainbow(5))",visualization,668355487054214e8,408
"png(""spearmanVsDoubSigTransA4.png"")",export,668355487054214e8,408
print(p),evaluation,668355487054214e8,408
dev.off(),setup,668355487054214e8,408
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,553972242632881e8,411
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,553972242632881e8,411
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,936488354578614e8,412
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,936488354578614e8,412
library(dplyr),setup,936488354578614e8,412
library(ggmcmc),setup,936488354578614e8,412
"fitfiles <- list.files(path = ""."", , pattern = ""^[0-9]*_[0-9]*.rds"",      full.names = FALSE)",import,936488354578614e8,412
numSites = 500,exploratory,12354402220808e9,413
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/""",exploratory,12354402220808e9,413
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/""",import,12354402220808e9,413
"case.name = c(""fullread.6ind.over"", ""2fullread.6ind.over"", ""4fullread.6ind.over"")",exploratory,12354402220808e9,413
"for (fit in fitfiles) {     outfile <- stringr::str_replace(fit, "".rds"", "".pdf"")     outfile <- paste0(""ggmcmc/"", outfile)     if (!file.exists(outfile)) {         fit1 <- readr::read_rds(fit)         S <- ggmcmc::ggs(fit1)         message(""Does not exist "", outfile)         ggmcmc(S, file = outfile)     } }",export,936488354578614e8,412
"incidfile <- ""data/processed/20122018_promed_loglinear_wide.csv""",setup,936488354578614e8,412
"metadatafile <- ""data/processed/all_african_centroids.csv""",setup,936488354578614e8,412
"places <- c(""LBR"", ""GIN"", ""SLE"")",data cleaning,936488354578614e8,412
"day0 <- readr::read_csv(incidfile, n_max = 1) %>% pull(date)",data cleaning,936488354578614e8,412
"twindows <- c(14, 28, 42)",data cleaning,936488354578614e8,412
n.dates.sim <- 28,data cleaning,936488354578614e8,412
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""^[0-9]*_[0-9]*.rds"",      )",import,936488354578614e8,412
"mtimes <- purrr::map(fitfiles, ~file.mtime(here::here(""data/stanfits"",      .x)) %>% as.Date)",data cleaning,936488354578614e8,412
"idx <- purrr::map(mtimes, ~.x >= as.Date(""2018-12-28""))",data cleaning,936488354578614e8,412
fitfiles <- fitfiles[unlist(idx)],data cleaning,936488354578614e8,412
"fitfiles <- stringr::str_replace(fitfiles, "".rds"", """")",data cleaning,936488354578614e8,412
"for (fit in fitfiles) {     message(""###############################"")     message(""Working on "", fit)     tproj <- strsplit(fit, split = ""_"")[[1]][1] %>% as.numeric()     twindow <- strsplit(fit, split = ""_"")[[1]][2] %>% as.numeric()     message(""working on "", tproj, ""_"", twindow)     rmarkdown::render(""analysis/projection_using_fitted.Rmd"",          params = list(tproj = tproj, twindow = twindow, n.dates.sim = n.dates.sim,              day0 = day0))     for (place in places) {         rmarkdown::render(""analysis/forecasts_assess.Rmd"", params = list(tproj = tproj,              twindow = twindow, incid = incidfile, n.dates.sim = n.dates.sim,              place = place))     } }",setup,936488354578614e8,412
"for (tw in twindows) {     tproj <- seq(from = tw + 7, to = 656 - tw, by = 7)     for (p in places) {         message(""working on "", tw, "" and "", p)         rmarkdown::render(""analysis/forecasts_metrics_consolidate.Rmd"",              params = list(twindow = tw, tproj = tproj, incid = incidfile,                  n.dates.sim = 28, place = p))     } }",setup,936488354578614e8,412
pars <- data.frame(),setup,936488354578614e8,412
"for (tw in twindows) {     for (i in 1:4) {         s1 <- seq(from = tw + (7 * i), to = 656 - tw, by = 28)         maxtproj <- 7 * floor((656 - tw)/7)         pars <- rbind(pars, expand.grid(maxtproj = maxtproj,              twindow = tw, tproj = list(s1)))     } }",data cleaning,936488354578614e8,412
"for (place in places) {     for (row in seq_len(nrow(pars))) {         rmarkdown::render(""analysis/projections_viz_fixed_country.Rmd"",              params = list(tproj = pars$tproj[[row]], twindow = pars$twindow[row],                  incid = incidfile, n.dates.sim = 28, place = place,                  maxtproj = pars$maxtproj[[row]]))     } }",communication,936488354578614e8,412
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""*_rquantiles_[0-9]*_[0-9]*.rds"",      )",import,936488354578614e8,412
"names(fitfiles) <- stringr::str_replace_all(fitfiles, "".rds"",      """")",data cleaning,936488354578614e8,412
"rquantiles <- purrr::map_dfr(fitfiles, function(x) {     x <- here::here(""data/stanfits"", x)     out <- readr::read_rds(x)     out <- slice(out, n())     out }, .id = ""params"")",data cleaning,936488354578614e8,412
"rquantiles <- tidyr::separate(rquantiles, params, into = c(""country"",      ""what"", ""tproj"", ""twindow""), sep = ""_"")",data cleaning,936488354578614e8,412
"rquantiles <- select(rquantiles, -what, -var)",data cleaning,936488354578614e8,412
"rquantiles <- mutate(rquantiles, ci = case_when(`2.5%` > 1 ~      ""ll_greater_than_1"", `97.5%` < 1 ~ ""ul_less_than_1"", TRUE ~      ""ci_includes_1""))",data cleaning,936488354578614e8,412
"readr::write_csv(x = rquantiles, path = ""data/processed/rquantiles_projection.csv"")",export,936488354578614e8,412
"fitfiles <- list.files(path = ""./data/stanfits/"", pattern = ""^[0-9]*_[0-9]*.rds"",      )",import,936488354578614e8,412
"fits <- purrr::map(fitfiles, ~readr::read_rds(here::here(""data/stanfits"",      .x)))",import,936488354578614e8,412
"fitfiles <- stringr::str_replace_all(fitfiles, "".rds"", """")",data cleaning,936488354578614e8,412
"outdir <- ""data/stanfits/flow_matrices/""",export,936488354578614e8,412
"for (i in 1:length(fits)) {     prefix <- fitfiles[[i]]     infile <- here::here(outdir, paste0(""flow_900_"", prefix,          "".rds""))     if (!file.exists(infile)) {         message(""running for "", i, "" and "", prefix)         res <- flow_mat_samples(i, fits = fits, nsim = 30)         message(""flow matrices for "", i)         message(""dumping them at "", prefix)         outfiles <- paste0(outdir, ""flow_"", seq_along(res), ""_"",              prefix, "".rds"")         purrr::walk2(res, outfiles, ~readr::write_rds(x = .x,              path = .y))     } }",export,936488354578614e8,412
"df <- readr::read_csv(""data/stanfits/still_running.csv"")",import,936488354578614e8,412
"prefix <- paste0(""*"", df$tproj, ""_"", df$twindow, ""*"")",data cleaning,936488354578614e8,412
"oldfiles <- purrr::map(prefix, ~list.files(path = ""./data/stanfits.25122018/"",      pattern = .x, ))",import,936488354578614e8,412
"file.copy(from = paste0(""data/stanfits.25122018/"", unlist(oldfiles)),      to = ""data/stanfits/"")",export,936488354578614e8,412
"oldflowmats <- purrr::map(prefix, ~list.files(path = ""./data/stanfits.25122018/flow_matrices/"",      pattern = .x, ))",export,936488354578614e8,412
"file.copy(from = paste0(""data/stanfits.25122018/flow_matrices/"",      unlist(oldflowmats)), to = ""data/stanfits/flow_matrices/"")",export,936488354578614e8,412
rm(list = ls()),setup,803807818097994e8,414
library(dplyr),import,803807818097994e8,414
"source(""Analysis/new_analysis/catch_shares/Analysis/01_create_vessel_df.R"")",data cleaning,803807818097994e8,414
vessel_landings <- create_vessel_landings(),exploratory,803807818097994e8,414
"source(""Analysis/new_analysis/catch_shares/Analysis/01_vessel_stats.R"")",not sure,803807818097994e8,414
library(ggplot2),setup,49273825623095e9,415
"source(""config.worldbank.R"", local = TRUE)",import,49273825623095e9,415
"datasets <- read.csv(paste0(metaPath, ""worldbank.metadata."",      refPeriod, "".csv""), header = T)",import,49273825623095e9,415
"cat(paste(""datasetX"", ""datasetY"", ""correlation"", ""pValue"", ""n"",      sep = "",""), file = paste0(summaryPath, ""correlation"", ""."",      refPeriod, "".csv""), sep = ""\n"")",export,49273825623095e9,415
"cat(paste(""dataset"", ""time"", sep = "",""), file = paste0(summaryPath,      ""metadata"", ""."", refPeriod, "".csv""), sep = ""\n"")",export,49273825623095e9,415
datasetLength <- nrow(datasets),exploratory,49273825623095e9,415
"for (i in 1:datasetLength) {     dtstart <- Sys.time()     for (j in 1:datasetLength) {         if (i <= j) {             datasetX <- datasets[i, ""identifier""]             datasetY <- datasets[j, ""identifier""]             plotPath <- paste0(dataPath, ""plots/"", datasetX,                  ""-"", datasetY, ""."", refPeriod, "".svg"")             dataX <- read.csv(paste0(observationPath, datasetX,                  ""."", refPeriod, "".csv""), na.strings = """", header = T)             dataY <- read.csv(paste0(observationPath, datasetY,                  ""."", refPeriod, "".csv""), na.strings = """", header = T)             data <- merge(dataX, dataY, by = ""refArea"")             n <- nrow(data)             if (n < 10 || sd(data$obsValue.x) == 0 || sd(data$obsValue.y) ==                  0) {                 NA             }             else {                 correlation <- cor(data$obsValue.x, data$obsValue.y,                    use = ""complete.obs"", method = correlationMethod)                 pValue <- cor.test(data$obsValue.x, data$obsValue.y,                    method = correlationMethod)$p.value                 analysisLine <- paste(datasetX, datasetY, correlation,                    pValue, n, sep = "","")                 print(analysisLine)                 cat(analysisLine, file = paste0(summaryPath,                    ""correlation"", ""."", refPeriod, "".csv""), sep = ""\n"",                    append = TRUE)             }         }     }     dtend <- Sys.time()     duration <- as.numeric(dtend - dtstart, units = ""secs"")     cat(paste(datasetX, duration, sep = "",""), file = paste0(summaryPath,          ""metadata"", ""."", refPeriod, "".csv""), sep = ""\n"", append = TRUE) }",exploratory,49273825623095e9,415
warnings(),communication,49273825623095e9,415
INTERACTIVE <- FALSE,setup,950369485653937e8,416
if (INTERACTIVE) {     analysis_dir <- dirname(file.choose())     setwd(analysis_dir) } else {     analysis_dir <- getwd() },setup,950369485653937e8,416
"data_dir <- file.path("".."", ""data"")",setup,950369485653937e8,416
"fig_dir <- file.path("".."", ""figures"")",setup,950369485653937e8,416
"diamonds1K_file <- ""diamonds1K.csv""",import,950369485653937e8,416
"diamonds1K <- read.csv(file = file.path(data_dir, diamonds1K_file),      stringsAsFactors = FALSE)",import,950369485653937e8,416
"R_files <- list.files(path = ""functions"", pattern = ""\\.R$"",      full.names = TRUE)",setup,950369485653937e8,416
"sapply(R_files, source)",setup,950369485653937e8,416
"diamonds1K$cut <- gsub(""Very Good"", ""Very Diamond"", diamonds1K$cut)",data cleaning,950369485653937e8,416
"diamonds1K$cut <- gsub(""Ideal"", ""WOW"", diamonds1K$cut)",data cleaning,950369485653937e8,416
"diamonds1K$cut <- ordered(diamonds1K$cut, levels = c(""Fair"",      ""Good"", ""Very Diamond"", ""Premium"", ""WOW""))",data cleaning,950369485653937e8,416
INTERACTIVE <- FALSE,setup,950369485653937e8,416
require(ggplot2),setup,950369485653937e8,416
require(lme4),setup,950369485653937e8,416
require(merTools),setup,950369485653937e8,416
require(lmerTest),setup,950369485653937e8,416
"source(system.file(""utils"", ""allFit.R"", package = ""lme4""))",setup,950369485653937e8,416
"source(""./functions/newbinplot.R"")",setup,950369485653937e8,416
require(arm),setup,950369485653937e8,416
"source(""./functions/ranNorm.R"")",setup,950369485653937e8,416
"source(""./functions/booter.R"")",setup,950369485653937e8,416
"survival_data <- read.table(""./analysis/nursery_experiment_inundation/data/nursery_experiment_data.txt"",      header = TRUE)",import,950369485653937e8,416
str(survival_data),exploratory,950369485653937e8,416
"ggplot(survival_data, aes(x = treat, y = surv)) + geom_point() +      stat_smooth()",visualization,950369485653937e8,416
"survival_model1 <- glmer(surv ~ treat + dia + (1 | sp/mother) +      (1 | block), data = survival_data, family = ""binomial"")",modeling,950369485653937e8,416
summary(survival_model1),modeling,950369485653937e8,416
"surv_model1_residuals <- resid(survival_model1, type = ""pearson"")",modeling,950369485653937e8,416
surv_model1_fitted <- fitted(survival_model1),evaluation,950369485653937e8,416
"newbinplot(surv_model1_residuals, surv_model1_fitted)",evaluation,950369485653937e8,416
"ranNorm(""mother:sp"", slope = 1, model = survival_model1)",evaluation,950369485653937e8,416
"ranNorm(""sp"", slope = 1, model = survival_model1)",evaluation,950369485653937e8,416
"ranNorm(""block"", slope = 1, model = surivival_model1)",evaluation,950369485653937e8,416
"surv_preds <- expand.grid(dia = mean(survival_data$dia), treat = seq(from = 0,      to = 21, length = 100), mother = 0, sp = 0, block = 0)",not sure,950369485653937e8,416
"surv_preds$p <- predict(survival_model1, newdata = surv_preds,      type = ""response"", re.form = NA)",evaluation,950369485653937e8,416
"predict(survival_model1, newdata = surv_preds, type = ""response"",      re.form = NA)",evaluation,950369485653937e8,416
summary(survival_model1),evaluation,950369485653937e8,416
"CI <- booter(survival_model1, surv_preds, survival_data, 1000)",modeling,950369485653937e8,416
"surv_preds$CI025 <- CI[1, ]",not sure,950369485653937e8,416
"surv_preds$CI025 <- CI[2, ]",evaluation,950369485653937e8,416
"write.table(surv_preds, file = ""./graphs/graph_data/surv_pred_dipter.csv"")",export,950369485653937e8,416
"ggplot(surv_preds, aes(x = treat, y = p)) + geom_line() + geom_ribbon(aes(ymin = CI[1,      ], ymax = CI[2, ]))",visualization,950369485653937e8,416
min(surv_preds$p),exploratory,950369485653937e8,416
max(surv_preds$p),exploratory,950369485653937e8,416
"surv_preds_dia <- expand.grid(dia = seq(from = min(survival_data$dia,      na.rm = TRUE), to = max(survival_data$dia, na.rm = TRUE),      length = 100), treat = 9)",not sure,950369485653937e8,416
"surv_preds_dia$p <- predict(survival_model1, newdata = surv_preds_dia,      type = ""response"", re.form = NA)",not sure,950369485653937e8,416
"ggplot(surv_preds_dia, aes(x = dia, y = p)) + geom_line()",visualization,950369485653937e8,416
"surv_model2 <- glmer(surv ~ sp + treat + dia + sp:treat + (1 |      mother) + (1 | block), data = survival_data, family = ""binomial"")",modeling,950369485653937e8,416
"surv_model3 <- glmer(surv ~ sp + treat + dia + sp:treat + (1 |      mother) + (1 | block), data = survival_data, family = ""binomial"",      control = glmerControl(optimizer = ""nlminbw""))",modeling,950369485653937e8,416
summary(surv_model3),modeling,950369485653937e8,416
"surv_model1_residuals <- resid(surv_model3, type = ""pearson"")",modeling,950369485653937e8,416
surv_model1_fitted <- fitted(surv_model3),modeling,950369485653937e8,416
"newbinplot(surv_model1_residuals, surv_model1_fitted)",evaluation,950369485653937e8,416
"ranNorm(""mother"", slope = 1, model = surv_model3)",evaluation,950369485653937e8,416
"ranNorm(""block"", slope = 1, model = surv_model3)",evaluation,950369485653937e8,416
"preds_sp_inter_surv <- expand.grid(sp = levels(survival_data$sp),      treat = seq(from = 0, to = 21, length = 100), dia = mean(survival_data$dia,          na.rm = TRUE))",evaluation,950369485653937e8,416
"preds_sp_inter_surv$p <- predict(surv_model3, newdata = preds_sp_inter_surv,      type = ""response"", re.form = NA)",evaluation,950369485653937e8,416
"CI <- booter(surv_model3, preds_sp_inter_surv, survival_data,      nsamples = 10)",evaluation,950369485653937e8,416
"CI025 <- CI[1, ]",evaluation,950369485653937e8,416
"CI975 <- CI[2, ]",evaluation,950369485653937e8,416
"ggplot(preds_sp_inter_surv, aes(x = treat, y = p, color = sp)) +      geom_line() + geom_ribbon(aes(ymin = CI025, ymax = CI975))",visualization,950369485653937e8,416
coef <- fixef(surv_model3),evaluation,950369485653937e8,416
"slope_coef <- data.frame(sp = levels(survival_data$sp), p = c(coef[11],      coef[11] + coef[13:length(coef)]))",modeling,950369485653937e8,416
rownames(slope_coef) <- c(),data cleaning,950369485653937e8,416
car::Anova(surv_model3),modeling,950369485653937e8,416
summary(surv_model3),modeling,950369485653937e8,416
"diff(AIC(surv_model3, survival_model1)[, 2])",evaluation,950369485653937e8,416
"write.table(slope_coef, file = ""./psSlopeCoef.txt"")",export,950369485653937e8,416
library(ncdf4),setup,950369485653937e8,416
library(here),setup,950369485653937e8,416
library(tidyverse),setup,950369485653937e8,416
library(stringr),setup,950369485653937e8,416
"txx = nc_open(here(""analysis"", ""data"", ""index-ts"", ""txx.nc""))",import,950369485653937e8,416
"gt37 = nc_open(here(""analysis"", ""data"", ""days-above-T"", ""Number_of_days_above_37degC.nc""),      write = TRUE)",import,950369485653937e8,416
"txx_timevals = ncvar_get(txx, varid = ""time"") %>% as.character()",data cleaning,950369485653937e8,416
"str_sub(txx_timevals, start = 7, end = 8) = ""15""",data cleaning,950369485653937e8,416
txx_timevals = txx_timevals %>% as.numeric(),data cleaning,950369485653937e8,416
"gt37_time = ncvar_def(""time"", ""day as %Y%m%d.%f"", gt37$dim$time,      missval = NA, longname = ""Time"")",data cleaning,950369485653937e8,416
"gt37 = ncvar_add(gt37, gt37_time)",data cleaning,950369485653937e8,416
"ncvar_put(gt37, varid = ""time"", txx_timevals, start = 1, count = -1)",data cleaning,950369485653937e8,416
"untagged_dbh <- read.csv(""analysis/data/alt_species_dbh.csv"")",exploratory,950369485653937e8,416
summary(untagged_dbh),exploratory,950369485653937e8,416
"untagged_dbh$date <- as.Date(untagged_dbh$Date, format = ""%m/%d/%Y"")",exploratory,950369485653937e8,416
library(dplyr),data cleaning,950369485653937e8,416
"filter(untagged_dbh, is.na(date))",setup,950369485653937e8,416
"filter(untagged_dbh, PlotID == ""SECRET02"")",exploratory,950369485653937e8,416
"untagged_dbh$date[is.na(untagged_dbh$date)] <- ""2012-05-22""",exploratory,950369485653937e8,416
untagged_dbh <- as.tbl(untagged_dbh),data cleaning,950369485653937e8,416
"untagged_dbh <- untagged_dbh %>% rename(visit_id = PlotVisit_PlotVisitID,      plot_id = PlotID) %>% select(-Date)",data cleaning,950369485653937e8,416
"veg_data <- read.csv(""analysis/data/veg_transects_qry.csv"")",data cleaning,950369485653937e8,416
str(veg_data),import,950369485653937e8,416
summary(veg_data),exploratory,950369485653937e8,416
summary(veg_data),exploratory,950369485653937e8,416
"untagged_dbh <- read.csv(""analysis/data/alt_species_dbh.csv"")",import,950369485653937e8,416
require(tidyverse),setup,950369485653937e8,416
require(singleCellSeq),setup,950369485653937e8,416
synapser::synLogin(),setup,950369485653937e8,416
"syn_file <- synapser::synTableQuery(""select id from syn11974770"")",setup,950369485653937e8,416
"analysis_dir <- ""syn12508617""",setup,950369485653937e8,416
"samp.tab <- read.table(synapser::synGet(syn_file)$path, header = T,      as.is = TRUE) %>% dplyr::select(-c(gene_id, gene_type)) %>%      dplyr::rename(Gene = ""gene_name"")",import,950369485653937e8,416
require(org.Hs.eg.db),setup,950369485653937e8,416
print(Sys.getpid()),setup,776964382501319e8,417
library(dplyr),setup,776964382501319e8,417
library(cmapQuery),setup,776964382501319e8,417
library(magrittr),setup,776964382501319e8,417
library(glue),setup,776964382501319e8,417
library(homologene),setup,776964382501319e8,417
"dir.create(""analysis/01.L1000Analysis/L1000Results/chemScores"",      showWarnings = FALSE)",export,776964382501319e8,417
"dir.create(""analysis/01.L1000Analysis/L1000Results/instanceScores"",      showWarnings = FALSE)",export,776964382501319e8,417
"print(""loading data"")",communication,776964382501319e8,417
"load(""data/genesEdgerNoOutlier.rda"")",import,776964382501319e8,417
"inst = readRDS(""analysis/00.cmapRanks/instances.rds"")",import,776964382501319e8,417
"rankMatrixL1000 = readRDS(""analysis/00.cmapRanks/rankMatrix.rds"")",import,776964382501319e8,417
"L1000geneAnnots = readRDS(""analysis/00.cmapRanks/L1000geneAnnots.rds"")",import,776964382501319e8,417
"L1000PreCalc = readRDS(""analysis/00.cmapRanks/L1000PreCalc.rds"")",import,776964382501319e8,417
rownames(rankMatrixL1000) = L1000geneAnnots$pr_gene_id,data cleaning,776964382501319e8,417
gc(),communication,776964382501319e8,417
"library(RItools, lib.loc = "".local"")",import,584649795200676e7,418
dataset = genesEdgerNoOutlier,not sure,776964382501319e8,417
"load(""data/twins.rda"")",import,584649795200676e7,418
"load(""analysis/balance.rda"")",import,584649795200676e7,418
"groups = c(""E12_1_week_IP_vs_naive_adult_3_IP"", ""E12_2_week_IP_vs_naive_adult_3_IP"",      ""E12_3_day_IP_vs_naive_adult_3_IP"", ""naive_1_week_IP_vs_naive_adult_3_IP"",      ""naive_2_weeks_IP_vs_naive_adult_3_IP"", ""naive_3_days_IP_vs_naive_adult_3_IP"")",data cleaning,776964382501319e8,417
set.seed(20110330),modeling,584649795200676e7,418
"groupShorthands = c(E12_1_week_IP_vs_naive_adult_3_IP = ""regen 1 week"",      E12_2_week_IP_vs_naive_adult_3_IP = ""regen 2 week"", E12_3_day_IP_vs_naive_adult_3_IP = ""regen 3 days"",      naive_1_week_IP_vs_naive_adult_3_IP = ""naive 1 week"", naive_2_weeks_IP_vs_naive_adult_3_IP = ""naive 2 weeks"",      naive_3_days_IP_vs_naive_adult_3_IP = ""naive 3 days"")",data cleaning,776964382501319e8,417
samples <- 1000,exploratory,584649795200676e7,418
FDRLimit = 0.05,modeling,776964382501319e8,417
"additive.model <- function(y, z, b, tau) {     y - as.numeric(z) * tau }",modeling,584649795200676e7,418
"print(""staring run"")",communication,776964382501319e8,417
"model1 <- min.max.model(additive.model, lower = 0, upper = 6)",modeling,584649795200676e7,418
twins$match <- propensity$matching[row.names(twins)],data cleaning,584649795200676e7,418
"twins.complete <- twins[twins$ideology.complete & !is.na(twins$match),      ]",data cleaning,584649795200676e7,418
"analysis.m1 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,      twins.complete$treated * 1, test.stat = mean.difference,      moe = model1, samples = samples, parameters = list(tau = seq(-0.9,          0.3, 0.05)))",modeling,584649795200676e7,418
"tmp <- function(y, z, b, beta) {     round(y/beta^(as.numeric(z))) }",evaluation,584649795200676e7,418
"model2 <- min.max.model(tmp, lower = 0, upper = 6)",not sure,584649795200676e7,418
"groups %>% lapply(function(group) {     print(group)     if (any(grepl(""FDR_pVal"", colnames(dataset)))) {         pVal = ""pVal_""     }     else {         pVal = """"     }     filter_criteriaUp = lazyeval::interp(~FC > 0 & Pval < FDRLimit,          FC = as.name(glue(""logFC_{group}"")), Pval = as.name(glue(""FDR_{pVal}{group}"")))     upGenes = dataset %>% dplyr::filter_(filter_criteriaUp) %>%          dplyr::arrange_(.dots = c(glue(""desc(logFC_{group})""))) %>%          dplyr::select(gene) %>% unlist %>% mouse2human %>% {         .$humanGene     } %>% unique     upTags = L1000geneAnnots %>% filter(pr_gene_symbol %in% upGenes) %$%          pr_gene_id     filter_criteriaDown = lazyeval::interp(~FC < 0 & Pval < FDRLimit,          FC = as.name(glue(""logFC_{group}"")), Pval = as.name(glue(""FDR_{pVal}{group}"")))     downGenes = dataset %>% dplyr::filter_(filter_criteriaDown) %>%          dplyr::arrange_(.dots = c(glue(""logFC_{group}""))) %>%          dplyr::select(gene) %>% unlist %>% mouse2human %>% {         .$humanGene     } %>% unique     downTags = L1000geneAnnots %>% filter(pr_gene_symbol %in%          downGenes) %$% pr_gene_id     print(""up-genes down-genes acquired"")     analysis = connectivityMapEnrichment(upTags, downTags, rankMatrixL10000,          inst0$pert_iname, preCalc = L1000PreCalc, vocal = TRUE)     print(""finished run. writing to file"")     write.table(analysis$chemScores, file = glue(""analysis/01.L1000Analysis/L1000Results/chemScores/{groupShorthands[group]}""))     write.table(analysis$instanceScores, file = glue(""analysis/01.L1000Analysis/L1000Results/instanceScores/{groupShorthands[group]}"")) })",not sure,776964382501319e8,417
"analysis.m2 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,      twins.complete$treated * 1, test.stat = mean.difference,      moe = model2, samples = samples, parameters = list(beta = c(8:18)/20))",evaluation,584649795200676e7,418
"save(file = ""analysis/randomization-inference.rda"", analysis.m1,      analysis.m2, twins.complete)",export,584649795200676e7,418
library(mailR),setup,641214593080804e8,419
"send = function(x) {     send.mail(from = ""brejafimano@gmail.com"", to = ""maurotcs@gmail.com"",          subject = ""First_try"", body = x, smtp = list(host.name = ""smtp.gmail.com"",              port = 465, user.name = ""brejafimano"", passwd = ""carnivora1"",              ssl = TRUE), authenticate = TRUE, send = TRUE) }",communication,641214593080804e8,419
start = Sys.time(),not sure,641214593080804e8,419
library(PBD),not sure,641214593080804e8,419
library(TreeSim),setup,641214593080804e8,419
library(parallel),setup,641214593080804e8,419
set.seed(666),setup,641214593080804e8,419
"constant = sim.bd.age(age = 10, numbsim = 50, lambda = 1.5, mu = 1,      complete = FALSE)",setup,641214593080804e8,419
"constant = constant[sapply(constant, class) == ""phylo""]",setup,641214593080804e8,419
"const.branch = lapply(constant, FUN = function(x) x$edge.length)",modeling,641214593080804e8,419
"init = c(2, 1, 1)",setup,641214593080804e8,419
"const.estimates = lapply(const.branch, FUN = pbd_ML, initparsopt = init)",modeling,641214593080804e8,419
"const.df = do.call(rbind, const.estimates)",data cleaning,641214593080804e8,419
head(const.df),exploratory,641214593080804e8,419
"save(constant, const.df, file = ""analysis/data/sim.bd.age_age10_lamb1.5_mu1.RData"")",export,641214593080804e8,419
loop1 = Sys.time(),not sure,641214593080804e8,419
"send(x = paste(""Simulation of phylogenies finished at"", loop1,      ""with"", length(constant), ""phylogenies.""))",communication,641214593080804e8,419
rep = 1e+05,setup,641214593080804e8,419
initial = list(),setup,641214593080804e8,419
set.seed(666),setup,641214593080804e8,419
"for (i in 1:nrow(const.df)) {     random = c(runif(2), runif(1, min = 0, max = 15), runif(1))     initial[[i]] = const.df[i, 1:4] + random }",not sure,641214593080804e8,419
"save(const.branch, initial, file = ""analysis/data/parameters_first_try.RData"")",export,641214593080804e8,419
library(msm),setup,641214593080804e8,419
first_try = list(),setup,641214593080804e8,419
"source(""analysis/R/pbd_Bayes.R"")",setup,641214593080804e8,419
"for (k in 1:length(const.branch)) {     prior_b = function(b) {         dtnorm(b, mean = as.numeric(initial[[k]][1]), sd = 15,              log = TRUE, lower = 0)     }     prior_mu1 = function(mu1) {         dtnorm(mu1, mean = as.numeric(initial[[k]][2]), sd = 15,              log = TRUE, lower = 0)     }     prior_la1 = function(la1) {         dtnorm(la1, mean = as.numeric(initial[[k]][3]), sd = 15,              log = TRUE, lower = 0)     }     prior_mu2 = function(mu1) {         dtnorm(mu1, mean = as.numeric(initial[[k]][4]), sd = 15,              log = TRUE, lower = 0)     }     first_try[[k]] = pbd_Bayes(brts = const.branch[[k]], initparsopt = initial[[k]],          prior_b = prior_b, prior_mu1 = prior_mu1, prior_la1 = prior_la1,          prior_mu2 = prior_mu2, step = 0.5, rep = rep)     save(first_try, file = ""analysis/data/results_first_try.RData"") }",export,641214593080804e8,419
loop2 = Sys.time(),not sure,641214593080804e8,419
"send(x = paste(""MCMC has finished at"", loop2, ""."", length(first_try),      ""phylogenies were analyzed.""))",communication,641214593080804e8,419
"sapply(first_try, FUN = function(x) sum(x$accepted)/rep)",modeling,641214593080804e8,419
"detach(""package:StockPriceSimulator"", unload = T)",setup,103835709625855e8,420
library(StockPriceSimulator),setup,103835709625855e8,420
library(pracma),setup,103835709625855e8,420
library(ggplot2),setup,103835709625855e8,420
library(dplyr),setup,916707236785442e8,421
library(purrr),setup,103835709625855e8,420
library(ggplot2),setup,916707236785442e8,421
"setwd(""c:/Users/ATE/thesisDoc/data"")",setup,103835709625855e8,420
library(scales),setup,916707236785442e8,421
library(stringr),setup,916707236785442e8,421
rm(list = ls()),setup,103835709625855e8,420
library(tidyr),setup,916707236785442e8,421
"load(file = ""u_heston.RData"")",import,103835709625855e8,420
"load(file = ""DOMAIN.RData"")",import,103835709625855e8,420
"dgg = read.table(file = ""data/google/5a_ar_correction_analysis-google-data.dat"",      header = T) %>% mutate(label = paste(""Google"", scP)) %>%      select(-scP)",import,916707236785442e8,421
"pi <- map(U_heston, function(u) {     purrr::map(u, function(x) {         purrr::map_dbl(x, ~dplyr::last(.x$delta) * dplyr::last(.x$s) +              dplyr::last(.x$p) - dplyr::last(.x$option))     }) })",evaluation,103835709625855e8,420
"dhp = read.table(file = ""data/hp/5a_ar_correction_analysis-hp-data.dat"",      header = T) %>% mutate(label = ""HP"")",import,916707236785442e8,421
"dfp = rbind(dgg, dhp)",data cleaning,916707236785442e8,421
"pi_bsm <- map(U_heston, function(u) {     purrr::map(u, function(x) {         purrr::map_dbl(x, ~dplyr::last(.x$delta.bsm) * dplyr::last(.x$s) +              dplyr::last(.x$p.bsm) - dplyr::last(.x$option))     }) })",communication,103835709625855e8,420
"factors = c(""HP"", ""Google 1:1"", ""Google 1:4"")",data cleaning,916707236785442e8,421
"dfp$label = factor(dfp$label, levels = factors)",data cleaning,916707236785442e8,421
"limits <- aes(ymax = s1, ymin = s2)",visualization,916707236785442e8,421
dodge <- position_dodge(width = 0.9),visualization,916707236785442e8,421
"dfp$class = factor(dfp$class, levels = c(""AR"", ""AR 25"", ""AR 50"",      ""AR 100""))",data cleaning,916707236785442e8,421
"dfp = dfp %>% mutate(metric_pt = ifelse(metric == ""Cost"", ""Custo"",      ""Violaes de SLO""))",data cleaning,916707236785442e8,421
"p = ggplot(dfp, aes(label, resp, fill = class)) + geom_bar(stat = ""identity"",      position = ""dodge"", alpha = 0.7) + geom_errorbar(limits,      position = dodge, width = 0.25, size = 1)",visualization,916707236785442e8,421
"p = p + scale_y_continuous(labels = percent) + facet_wrap(~metric_pt,      scales = ""free"")",visualization,916707236785442e8,421
"p = p + scale_fill_brewer(""Abordagem de predio:"", palette = ""Set1"")",visualization,916707236785442e8,421
"p = p + theme_bw(base_size = 32) + theme(legend.position = ""top"")",visualization,916707236785442e8,421
"p = p + xlab(""Dado de referncia"") + ylab(NULL)",visualization,916707236785442e8,421
"p = p + theme(legend.position = ""top"", legend.key.size = unit(1,      ""cm""))",visualization,916707236785442e8,421
"p = p + theme(axis.title.y = element_text(vjust = 1.5), axis.title.x = element_text(vjust = 3.1))",visualization,916707236785442e8,421
p,visualization,916707236785442e8,421
"png(filename = ""img/5a_ar_correction_analysis-all.png"", width = 1200,      height = 500)",export,916707236785442e8,421
"pl <- pmap(list(U_heston, pi), function(u, pi) {     pmap(list(u, pi), function(x, y) {         y/dplyr::first(x[[1]]$option)     }) })",communication,103835709625855e8,420
print(p),evaluation,916707236785442e8,421
"pl_bsm <- pmap(list(U_heston, pi_bsm), function(u, pi_bsm) {     pmap(list(u, pi_bsm), function(x, y) {         y/dplyr::first(x[[1]]$option)     }) })",communication,103835709625855e8,420
"l <- map(1:3, function(x) {     map(pl, function(y) {         map_dbl(y[seq(x, 15, by = 3)], mean) %>% round(3)     }) %>% pmap(c) %>% unlist })",communication,103835709625855e8,420
"l_bsm <- map(1:3, function(x) {     map(pl_bsm, function(y) {         map_dbl(y[seq(x, 15, by = 3)], mean) %>% round(3)     }) %>% pmap(c) %>% unlist })",communication,103835709625855e8,420
"xt <- pmap(list(l, l_bsm), list) %>% as.data.frame",communication,103835709625855e8,420
colnames(xt) <- 1:6,communication,103835709625855e8,420
"xt <- rbind(c(rep("""", 2), map_chr(c(91, 91, 182, 182, 399, 399),      paste, ""days before maturity"")), c(rep("""", 2), rep(c(""dddhst"",      ""dddbsm""), 3)), xt)",communication,103835709625855e8,420
"print(xtable::xtable(xt, align = ""lllllllll"", caption = ""Hedging with HSV: Relative P\\&L"",      label = ""t:analysis:heston:pl""), include.rownames = FALSE,      include.colnames = FALSE)",communication,103835709625855e8,420
x <- 1,communication,103835709625855e8,420
y <- 3,communication,103835709625855e8,420
dev.off(),visualization,916707236785442e8,421
"dfp %>% filter(class == ""AR"", metric_pt == ""Violaes de SLO"")",data cleaning,916707236785442e8,421
"dfp %>% filter(class != ""AR"", metric_pt == ""Custo"") %>% mutate(V = resp *      100)",data cleaning,916707236785442e8,421
"dfa = read.table(file = ""data/hp/5a_ar_correction_analysis-hp-data-raw.dat"",      header = T)",import,916707236785442e8,421
"dfb = read.table(file = ""data/google/5a_ar_correction_analysis-google-data-raw.dat"",      header = T)",import,916707236785442e8,421
"da = dfa %>% filter(class == ""AR"", metric == ""Cost"")",data cleaning,916707236785442e8,421
"db = dfb %>% filter(class == ""AR"", metric == ""Cost"")",data cleaning,916707236785442e8,421
"wilcox.test(da$value, alternative = ""less"")",exploratory,916707236785442e8,421
"ggplot(U_heston[[x]][[14]][[14]]) + geom_line(aes(x = time.period,      y = option), colour = ""blue"") + geom_point(aes(x = time.period,      y = delta * s + p), colour = "" red"") + geom_point(data = U_heston[[y]][[14]][[14]],      aes(x = time.period, y = delta * s + p), colour = ""black"")",communication,103835709625855e8,420
pl[[1]][[14]],communication,103835709625855e8,420
"S <- map(U_heston[[2]][[3]], ~data.frame(stock = .x$s, time = .x$time.period))[1:50]",communication,103835709625855e8,420
"setwd(""c:/Users/ATE/thesisDoc"")",communication,103835709625855e8,420
"wilcox.test(db$value, alternative = ""less"")",exploratory,916707236785442e8,421
"tikzDevice::tikz(file = ""figures/analysis.hsv.stocks.tex"", width = 4,      height = 2)",evaluation,103835709625855e8,420
"ggplot2::ggplot(dplyr::bind_rows(S, .id = ""uniqueID""), ggplot2::aes(x = time,      y = stock, group = uniqueID)) + ggplot2::geom_line(ggplot2::aes(alpha = 0.5)) +      theme(legend.position = ""none"") + ggplot2::labs(x = ""Time period"",      y = ""Stock price"")",evaluation,103835709625855e8,420
dev.off(),evaluation,103835709625855e8,420
"setwd(""c:/Users/ATE/thesisDoc/data"")",evaluation,103835709625855e8,420
domain,evaluation,103835709625855e8,420
"ppl1 <- map(1:nrow(domain), function(x) {     list(pl[[1]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[1]][[x]]))) }) %>% map(function(x) {     data.frame(ppl1 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",export,103835709625855e8,420
"da = dfa %>% filter(class != ""AR"", metric == ""Violation"")",data cleaning,916707236785442e8,421
"ppl2 <- map(1:nrow(domain), function(x) {     list(pl[[2]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[2]][[x]]))) }) %>% map(function(x) {     data.frame(ppl2 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",export,103835709625855e8,420
"ppl3 <- map(1:nrow(domain), function(x) {     list(pl[[3]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[3]][[x]]))) }) %>% map(function(x) {     data.frame(ppl3 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",export,103835709625855e8,420
"db = dfb %>% filter(class != ""AR"", metric == ""Violation"")",data cleaning,916707236785442e8,421
"setwd(""c:/Users/ATE/thesisDoc"")",modeling,103835709625855e8,420
"tikzDevice::tikz(file = ""figures/p.analysis.heston.pl.dist.big.tex"",      width = 6, height = 5)",modeling,103835709625855e8,420
"ggplot(ppl1) + stat_density(aes(ppl1), fill = ""seagreen4"", alpha = 0.7) +      stat_density(data = ppl2, aes(ppl2), fill = ""steelblue"",          alpha = 0.7) + stat_density(data = ppl3, aes(ppl3), fill = ""darkred"",      alpha = 0.7) + xlab(""Relative profit and loss"") + ylab(""Density"") +      xlim(-3, 3) + facet_wrap(~pivot, ncol = 3, scales = ""free_y"")",modeling,103835709625855e8,420
dev.off(),visualization,103835709625855e8,420
"setwd(""c:/Users/ATE/thesisDoc/data"")",visualization,103835709625855e8,420
domain,visualization,103835709625855e8,420
"ppl1 <- map(1:nrow(domain), function(x) {     list(pl[[3]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[3]][[x]]))) }) %>% map(function(x) {     data.frame(ppl1 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",visualization,103835709625855e8,420
"ppl2 <- map(1:nrow(domain), function(x) {     list(pl_bsm[[3]][[x]], rep(paste0(""K = "", domain$strike[x],          "" - dbm = "", domain$maturity[x]), length(pl_bsm[[3]][[x]]))) }) %>% map(function(x) {     data.frame(ppl2 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",visualization,103835709625855e8,420
"setwd(""c:/Users/ATE/thesisDoc"")",visualization,103835709625855e8,420
"tikzDevice::tikz(file = ""figures/p.analysis.heston.pl.dist.deltas.tex"",      width = 6, height = 5)",visualization,103835709625855e8,420
"ggplot(ppl1) + stat_bin(aes(ppl1), fill = ""seagreen4"", alpha = 0.7) +      stat_bin(data = ppl2, aes(ppl2), fill = ""darkred"", alpha = 0.7) +      xlab(""Relative profit and loss"") + ylab(""Density"") + xlim(-3,      3) + facet_wrap(~pivot, ncol = 3)",visualization,103835709625855e8,420
summary(da),modeling,916707236785442e8,421
dev.off(),data cleaning,103835709625855e8,420
"setwd(""c:/Users/ATE/thesisDoc/data"")",data cleaning,103835709625855e8,420
summary(db),modeling,916707236785442e8,421
domain,data cleaning,103835709625855e8,420
"ppl1 <- map(seq(2, 15, by = 3), function(x) {     U_heston[[1]][[x]][c(14, 2, 56, 22, 34)] }) %>% map(function(x) {     map(x, ~.x[seq(1, nrow(.x), by = 10), ]) })",data cleaning,103835709625855e8,420
"p1 <- ggplot(dplyr::bind_rows(ppl1[[1]], .id = ""uniqueID"")) +      geom_line(aes(x = time.period, y = option, group = uniqueID),          colour = ""black"") + geom_point(aes(x = time.period, y = delta.bsm *      s + p.bsm, group = uniqueID), color = ""darkred"", size = 0.75) +      geom_point(aes(x = time.period, y = delta * s + p, group = uniqueID),          colour = ""steelblue"", size = 0.5) + theme(legend.position = ""none"",      title = element_text(size = rel(0.8))) + labs(title = ""(K = 140, dbm = 182)"",      x = ""Time period"", y = ""Option value"")",data cleaning,103835709625855e8,420
"summary(c(da$value, db$value))",modeling,916707236785442e8,421
library(dplyr),setup,916707236785442e8,421
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,916707236785442e8,421
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"library(""countrycode"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,916707236785442e8,421
"capitals <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/country-capitals.csv"")",import,916707236785442e8,421
"capitals <- capitals[capitals$ContinentName == ""Africa"", ]",data cleaning,916707236785442e8,421
capitals$x <- as.numeric(paste(capitals$CapitalLongitude)),data cleaning,916707236785442e8,421
capitals$y <- as.numeric(paste(capitals$CapitalLatitude)),data cleaning,916707236785442e8,421
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,916707236785442e8,421
"opt_loc$wbcode <- countrycode(opt_loc$country, origin = ""country.name"",      destination = ""wb"")",data cleaning,916707236785442e8,421
"df <- opt_loc[!is.na(opt_loc$wbcode), ]",data cleaning,916707236785442e8,421
df$capital <- NA,data cleaning,916707236785442e8,421
"for (i in 1:nrow(capitals)) {     country <- countrycode(capitals$CountryCode[i], origin = ""iso2c"",          destination = ""wb"")     if (!is.na(country)) {         subset <- df[df$wbcode == country, ]         nearest_ID <- NA         min_dist <- 1e+09         if (nrow(subset) > 0) {             for (j in 1:nrow(subset)) {                 if (!is.na(subset[j, c(""x"")]) & !is.na(subset[j,                    c(""y"")])) {                   dist <- gdist(capitals[i, c(""x"")], capitals[i,                      c(""y"")], subset[j, c(""x"")], subset[j, c(""y"")])                   if (dist < min_dist) {                     min_dist <- dist                     nearest_ID <- subset[j, ""ID""]                   }                 }             }             df[df$ID == nearest_ID, ""capital""] <- 1         }     } }",data cleaning,916707236785442e8,421
"df[is.na(df$capital), ""capital""] <- 0",data cleaning,916707236785442e8,421
"df <- merge(opt_loc, df, by = ""ID"", all.x = T)",data cleaning,916707236785442e8,421
"df[is.na(df$capital), ""capital""] <- 0",data cleaning,916707236785442e8,421
"write.csv(df[, c(""ID"", ""capital"")], file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/ID_capitals.csv"",      row.names = FALSE)",export,916707236785442e8,421
"Treatment = ""Retinoic""",not sure,916707236785442e8,421
size = 1024,not sure,916707236785442e8,421
"for (chr in 1:22) {     path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/""     top5.sites = read.table(file = paste0(path, Treatment, "".05.txt""),          as.is = TRUE)     wh = which(top5.sites[, 1] == paste0(""chr"", chr))     sel.top5 = top5.sites[wh, ]     path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/""     chr.len = scan(file = paste0(path, ""chr.len.txt""))[chr]     len = dim(sel.top5)[1]     st = 1     center.posi = NULL     center.posi.ix = 1     while (st <= len) {         st.posi = sel.top5[st, 2]         max.posi = st.posi + size - 1         wh = which(sel.top5[, 3] <= max.posi)         en = wh[length(wh)]         en.posi = sel.top5[en, 3]         center.posi[center.posi.ix] = (en.posi + st.posi)/2         center.posi.ix = center.posi.ix + 1         st = en + 1     }     if (center.posi[1] - size/2 < 1) {         center.posi[1] = size/2 + 2     }     if (center.posi[length(center.posi)] + size/2 > chr.len) {         center.posi[length(center.posi)] = chr.len - size/2 -              2     }     path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/""     res = data.frame(chr = rep(paste0(""chr"", chr), length(center.posi)),          st.posi = center.posi - size/2 + 1, en.posi = center.posi +              size/2)     write.table(res, file = paste0(path, Treatment, ""."", size,          "".chr"", chr, "".locus""), col.names = TRUE, row.names = FALSE,          quote = FALSE) }",data cleaning,916707236785442e8,421
library(quickpsy),setup,916707236785442e8,421
library(tidyverse),setup,916707236785442e8,421
library(circular),setup,916707236785442e8,421
library(cowplot),setup,916707236785442e8,421
library(PropCIs),setup,916707236785442e8,421
library(R.utils),setup,916707236785442e8,421
"sourceDirectory(""R"")",import,916707236785442e8,421
"source(""graphical_parameters.R"")",import,916707236785442e8,421
"datpha <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = ""phase"",      session = as.character(1:4))",import,916707236785442e8,421
"datpha$participant <- datpha$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",modeling,916707236785442e8,421
"datpha <- datpha %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,916707236785442e8,421
"avpha <- datpha %>% group_by(participant, freq) %>% summarise(n = n(),      k = sum(response)) %>% group_by(participant, freq) %>% do({     m <- .$k/.$n     ci <- exactci(.$k, .$n, 0.05)$conf.int     data.frame(m = m, inf = ci[1], sup = ci[2]) })",data cleaning,916707236785442e8,421
"dattrack <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = c(""tracking""),      session = as.character(1:4))",data cleaning,916707236785442e8,421
"dattrack$participant <- dattrack$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,916707236785442e8,421
"dattrack <- dattrack %>% select(participant, freq, same, response) %>%      mutate(response = ifelse((same == ""True"" & response == ""right"") |          (same == ""False"" & response == ""left""), 1, 0))",data cleaning,916707236785442e8,421
"fit70 <- fit_psycho(dattrack, 0.7)",modeling,916707236785442e8,421
"fit80 <- fit_psycho(dattrack, 0.8)",modeling,916707236785442e8,421
"fit90 <- fit_psycho(dattrack, 0.9)",modeling,916707236785442e8,421
"thres <- fit70$thresholds %>% bind_rows(fit80$thresholds) %>%      bind_rows(fit90$thresholds) %>% spread(key = prob, value = thre,      sep = ""_"")",data cleaning,916707236785442e8,421
"setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"")",setup,514304180862382e8,422
"trackbinom <- fit70$averages %>% group_by(participant, freq) %>%      mutate(pvalue = binom.test(response, n)$p.value) %>% mutate(chance = ifelse(pvalue >      0.05, TRUE, FALSE))",data cleaning,916707236785442e8,421
"dat <- quickreadfiles(path = ""analysis/data"", participant = c(""pa"",      ""cc"", ""da"", ""al"", ""bj"", ""he"", ""lk"", ""ad""), task = c(""press""),      session = as.character(1:4))",import,916707236785442e8,421
"dat$participant <- dat$participant %>% recode(pa = ""Participant 1"",      cc = ""Participant 2"", da = ""Participant 3"", al = ""Participant 4"",      bj = ""Participant 5"", he = ""Participant 6"", lk = ""Participant 7"",      ad = ""Participant 8"")",data cleaning,916707236785442e8,421
"source(""RestrictionsApplied.R"")",import,514304180862382e8,422
"dat <- dat %>% select(participant, direction, angleLandmark,      freq, response) %>% filter(response != 9999) %>% mutate(totalerror = direction *      (response - angleLandmark), degSemi = totalerror %>% totalerrorToDegSemi(),      degFull = degSemi %>% degSemiToDegFull(), radFull = degFull %>%          degFullToRadFull()) %>% group_by(participant, freq)",data cleaning,916707236785442e8,421
"source(""grammars.R"")",import,514304180862382e8,422
minfreq <- dat %>% group_by(participant) %>% summarise(freq = min(freq)),exploratory,916707236785442e8,421
allfreqs <- dat %>% group_by(participant) %>% do({     tibble(freqsim = unique(.$freq)) }),exploratory,916707236785442e8,421
"uniformity <- dat %>% summarise(rayp = rayleigh.test(radFull)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE), uniform_lab = if_else(uniform,          ""Uniform"", ""Non-uniform""))",exploratory,916707236785442e8,421
"source(""makeDataVariables.R"")",import,514304180862382e8,422
datuniformity <- dat %>% left_join(uniformity),data cleaning,916707236785442e8,421
"setwd(""~/Documents/MPI/MonaghanAoA/Stats 2/analysis/"")",setup,514304180862382e8,422
"circmeans <- datuniformity %>% group_by(participant, freq) %>%      summarise(mrad = mean.circular(radFull), mdegSemi = mrad %>%          radFullToDegFull() %>% degFullToDegSemi()) %>% left_join(uniformity)",data cleaning,916707236785442e8,421
numConcepts = table(alldata$glotto),exploratory,514304180862382e8,422
praw <- plot_raw(),visualization,916707236785442e8,421
"save_plot(""analysis/figures/fig2.pdf"", praw, base_width = oneColumnWidth,      base_height = 0.8 * oneColumnWidth)",export,916707236785442e8,421
"alldata = alldata[numConcepts[alldata$glotto] > 500, ]",data cleaning,514304180862382e8,422
"datcir <- dat %>% left_join(circmeans) %>% mutate(radFullAli = radFull -      mrad, degSemiAli = degSemi - mdegSemi, degSemiAliFull = degSemiAli %>%      totalerrorToDegSemi()) %>% mutate(response = if_else(degSemiAliFull <      45 & degSemiAliFull > -45, 1, 0))",data cleaning,916707236785442e8,421
"ggplot(datcir) + facet_wrap(participant ~ freq) + geom_vline(xintercept = 0,      lty = 2) + geom_histogram(aes(x = degSemiAliFull), fill = ""blue"",      alpha = 0.5, bins = 20) + geom_vline(data = circmeans, aes(xintercept = mdegSemi),      color = ""red"")",visualization,916707236785442e8,421
"fitalig80 <- fit_psycho(datcir, 0.8)",modeling,916707236785442e8,421
"lengths = tapply(alldata$word.clean, alldata$glotto, function(d) {     lx = nchar(unlist(strsplit(d, "";"")))     lx[lx < 20] })",data cleaning,514304180862382e8,422
"ptrack <- ggplot() + facet_wrap(~participant) + geom_ribbon(data = fit70$curves %>%      merge(fitthre) %>% filter(x > thre90 & x < thre70), aes(x = x,      ymin = 0.4, ymax = y), fill = ""#4daf4a"", alpha = 0.3) + geom_point(data = fit70$averages,      size = 0.8, aes(x = freq, y = prob, color = ""Tracking"")) +      geom_point(data = fitalig80$averages, size = 0.8, aes(x = freq,          y = prob, color = ""Alig"")) + geom_line(data = fit70$curves,      size = sizeLine1, aes(x = x, y = y, color = ""Tracking"")) +      geom_line(data = fitalig80$curves, size = sizeLine1, aes(x = x,          y = y, color = ""Alig"")) + geom_point(data = avpha, size = 0.8,      aes(x = freq, y = m, ymin = inf, ymax = sup, color = ""Alignment"")) +      geom_line(data = avpha, size = sizeLine1, aes(x = freq, y = m,          ymin = inf, ymax = sup, color = ""Alignment"")) + geom_text(data = trackbinom %>%      mutate(ast = if_else(chance, """", ""*"")), aes(x = freq, label = ast),      y = 0.5) + scale_x_continuous(limits = c(0, 3.5), breaks = seq(0,      3.5, 1)) + scale_y_continuous(breaks = seq(0.5, 1, 0.25)) +      labs(x = ""Frequency (rps)"", y = ""Probability of correct responses"") +      theme(legend.position = c(0.8, 0.1))",visualization,916707236785442e8,421
ptrack,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/fig3.pdf"", ptrack, base_width = oneColumnWidth,      base_height = 0.8 * oneColumnWidth)",export,916707236785442e8,421
"plot(0, 0, ylim = c(0, 0.3), xlim = c(0, 34), type = ""n"", xlab = ""Word length"",      ylab = ""Density"")",visualization,514304180862382e8,422
"datboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     dat %>% group_by(participant, freq) %>% sample_frac(1, replace = T) }) %>% group_by(participant, freq, n)",not sure,916707236785442e8,421
"for (lang in unique(alldata$glotto)) {     dx = density(lengths[[lang]], bw = 1)     lines(dx) }",visualization,514304180862382e8,422
"datsim <- data_frame(freqsim = unique(dat$freq)) %>% group_by(freqsim) %>%      do({         dat     }) %>% filter(freqsim >= freq) %>% mutate(degFullSim = freqsim/freq *      degFull, radFullSim = degFullSim %>% degFullToRadFull()) %>%      semi_join(allfreqs) %>% group_by(participant, freq, freqsim)",modeling,916707236785442e8,421
"uniformitysim <- datsim %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",data cleaning,916707236785442e8,421
"trackingprob <- fit80$averages %>% select(participant, freq,      prob)",data cleaning,916707236785442e8,421
"dx.eng = density(lengths[[""stan1293""]], bw = 1)",not sure,514304180862382e8,422
trackingprobminfreq <- trackingprob %>% semi_join(minfreq) %>%      ungroup() %>% rename(probfreqmin = prob) %>% select(-freq),data cleaning,916707236785442e8,421
"lines(dx.eng, col = 2)",visualization,514304180862382e8,422
"trackingprob <- trackingprob %>% left_join(trackingprobminfreq) %>%      mutate(probnotrack = 2 * (probfreqmin - prob)) %>% mutate(probnotrack = ifelse(probnotrack >      1, 1, probnotrack), probnotrack = ifelse(probnotrack < 0,      0, probnotrack)) %>% rename(freqsim = freq)",data cleaning,916707236785442e8,421
"datsimtrack <- datsim %>% select(participant, freqsim, freq,      radFullSim) %>% left_join(trackingprob) %>% do({     n <- length(.$radFullSim)     probnotrack <- unique(.$probnotrack)     nnotrack <- round(n * probnotrack)     track <- sample_n(., n - nnotrack)     notrack <- sample_n(., nnotrack)     notrack$radFullSim <- runif(nnotrack, 0, 2 * pi)     rbind(track, notrack) })",data cleaning,916707236785442e8,421
"dx.dut = density(lengths[[""dutc1256""]], bw = 1)",not sure,514304180862382e8,422
"lines(dx.dut, col = 3)",visualization,514304180862382e8,422
"uniformitysimtrack <- datsimtrack %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",data cleaning,916707236785442e8,421
"datsimboot <- expand.grid(n = 1:1000) %>% group_by(n) %>% do({     datsim %>% group_by(participant, freq, freqsim) %>% sample_frac(1,          replace = T) }) %>% group_by(participant, freq, freqsim, n)",not sure,916707236785442e8,421
"meanLengths = sapply(lengths, mean, na.rm = T)",exploratory,514304180862382e8,422
dispersion <- dat %>% summarise(rho = rho.circular(radFull)),exploratory,916707236785442e8,421
hist(meanLengths),visualization,514304180862382e8,422
dispersionboot <- datboot %>% summarise(rho = rho.circular(radFull %>%      circular())),exploratory,916707236785442e8,421
"dispersionbootci <- dispersionboot %>% summarise(inf = quantile(rho,      0.025), sup = quantile(rho, 0.975))",exploratory,916707236785442e8,421
"abline(v = mean(lengths[[""stan1293""]]), col = 2)",visualization,514304180862382e8,422
dispersionuniformity <- dispersion %>% left_join(dispersionbootci) %>%      left_join(uniformity),data cleaning,916707236785442e8,421
"abline(v = mean(lengths[[""dutc1256""]]), col = 3)",visualization,514304180862382e8,422
"quantile(meanLengths, 0.05)",exploratory,514304180862382e8,422
dispersionsim <- datsim %>% summarise(rho = rho.circular(radFullSim)),data cleaning,916707236785442e8,421
dispersionsimboot <- datsimboot %>% summarise(rho = rho.circular(radFullSim %>%      circular())),data cleaning,916707236785442e8,421
"dispersionsimbootci <- dispersionsimboot %>% summarise(inf = quantile(rho,      0.025), sup = quantile(rho, 0.975))",data cleaning,916707236785442e8,421
"dataloan <- read.csv(""../data/loanword8.csv"", stringsAsFactors = F,      encoding = ""utf-8"", fileEncoding = ""utf-8"")",import,514304180862382e8,422
dispersionsimuniformity <- dispersionsim %>% left_join(dispersionsimbootci) %>%      left_join(uniformitysim),data cleaning,916707236785442e8,421
dispersionsimuniformitylowfreq <- dispersionsimuniformity %>%      semi_join(minfreq) %>% semi_join(allfreqs),data cleaning,916707236785442e8,421
"sources = read.csv(""../data/wold-dataset.cldf/loans.txt"", sep = ""|"",      stringsAsFactors = F, encoding = ""utf-8"", fileEncoding = ""utf-8"")",import,514304180862382e8,422
dispersionsimtrack <- datsimtrack %>% summarise(rho = rho.circular(radFullSim)),data cleaning,916707236785442e8,421
dispersionsimtrackuniformity <- dispersionsimtrack %>% left_join(uniformitysimtrack),data cleaning,916707236785442e8,421
dispersionsimtrackuniformitylowfreq <- dispersionsimtrackuniformity %>%      semi_join(minfreq),data cleaning,916707236785442e8,421
"prho <- ggplot() + facet_wrap(~participant, scales = ""free_x"") +      geom_rect(data = fitthre, fill = ""black"", alpha = 0.1, aes(xmin = thre70,          xmax = thre90, ymin = 0, ymax = 1)) + geom_line(data = dispersionsimuniformitylowfreq,      show.legend = FALSE, size = sizeLine1, aes(x = freqsim, y = rho,          color = uniform)) + geom_line(data = dispersionsimtrackuniformity %>%      semi_join(minfreq), show.legend = FALSE, size = sizeLine1,      aes(x = freqsim, y = rho, color = uniform)) + geom_line(data = dispersionsimtrackuniformity %>%      semi_join(minfreq), show.legend = FALSE, size = sizeLine1,      lty = 3, aes(x = freqsim, y = rho)) + geom_point(data = dispersionuniformity,      size = 0.6, shape = 2, aes(x = freq, y = rho, color = uniform)) +      labs(x = ""Frequency (rps)"", y = ""Radial vector length"") +      scale_y_continuous(breaks = seq(0, 1, 0.5), limits = c(0,          1)) + scale_x_continuous(limits = c(0, 3.5), breaks = seq(0,      3.5, 1)) + theme(legend.key = element_blank(), legend.title = element_blank(),      legend.position = c(0.8, 0.13), axis.title.x = element_text(hjust = 0.25))",visualization,916707236785442e8,421
"names(sources) = c(""original.word"", ""source.lang"", ""relation"",      ""certain"", ""dest.word"", ""dest.lang"")",data cleaning,514304180862382e8,422
prho,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/prho.pdf"", prho, base_width = oneColumnWidth)",export,916707236785442e8,421
"geom_line(data = dispersionsimuniformityplot, size = sizeLine1,      aes(x = freqsim2, y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      geom_text(data = trackbinom %>% mutate(ast = if_else(chance,          """", ""*"")), aes(x = freq, label = ast), y = 0) + scale_color_discrete(guide = guide_legend(title = NULL),      breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,916707236785442e8,421
prho,evaluation,916707236785442e8,421
"dispersionsimuniformityplot <- dispersionsimuniformity %>% mutate(freq2 = freq,      freqsim2 = freqsim)",data cleaning,916707236785442e8,421
"sources[sources$dest.word == ""tree trunk"", ]$dest.word = ""trunk""",data cleaning,514304180862382e8,422
"sources[sources$dest.word == ""pile up"", ]$dest.word = ""pile""",data cleaning,514304180862382e8,422
"prho <- ggplot() + facet_grid(participant ~ freq2, scales = ""free"") +      geom_line(data = dispersionsimuniformityplot, size = sizeLine1,          aes(x = freqsim2, y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      geom_text(data = trackbinom %>% mutate(ast = if_else(chance,          """", ""*"")), aes(x = freq, label = ast), y = 0) + scale_color_discrete(guide = guide_legend(title = NULL),      breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      axis.title.x = element_text(hjust = 0.01))",visualization,916707236785442e8,421
prho,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/rho.pdf"", prho, base_width = 2 *      twoColumnWidth, base_height = twoColumnWidth)",export,916707236785442e8,421
"sources.eng = sources[sources$dest.lang == ""English"", ]",data cleaning,514304180862382e8,422
"oneminfreqsim <- dispersion %>% group_by(participant) %>% do(head(.,      1))",data cleaning,916707236785442e8,421
"twominfreqsim <- dispersion %>% group_by(participant) %>% do(head(.,      2))",data cleaning,916707236785442e8,421
"datsim2 <- datsim %>% semi_join(twominfreqsim) %>% group_by(participant,      freqsim)",data cleaning,916707236785442e8,421
"uniformitysim2 <- datsim2 %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE))",data cleaning,916707236785442e8,421
dispersionsim2 <- datsim2 %>% summarise(rho = rho.circular(radFullSim)) %>%      anti_join(oneminfreqsim) %>% left_join(uniformitysim2),data cleaning,916707236785442e8,421
"sources.eng$dest.word = gsub(""\\(.+\\)"", """", sources.eng$dest.word)",data cleaning,514304180862382e8,422
"prho2 <- ggplot() + facet_wrap(~participant, scales = ""free"") +      geom_line(data = dispersionsim2, size = sizeLine1, aes(x = freqsim,          y = rho, color = uniform)) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_point(data = dispersionuniformity,      size = 0.8, aes(x = freq, y = rho, color = uniform)) + geom_ribbon(data = dispersionuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5),      limits = c(0, 1)) + scale_x_continuous(limits = c(0, 3.5),      breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      axis.title.x = element_text(hjust = 0.01))",visualization,916707236785442e8,421
"sources.eng$dest.word = gsub(""^ "", """", sources.eng$dest.word)",data cleaning,514304180862382e8,422
prho2,communication,916707236785442e8,421
"sources.eng$dest.word = gsub("" $"", """", sources.eng$dest.word)",data cleaning,514304180862382e8,422
"dispersionbootciunifotest <- datsim %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE)) %>% rename(freq2 = freq,      freqsim2 = freqsim)",data cleaning,916707236785442e8,421
"prhouni <- ggplot() + facet_wrap(~freq) + geom_line(data = dispersionbootciunifotest %>%      filter(freq < 2.5), aes(x = freqsim, y = m)) + geom_line(data = dispersionuniformityplot,      size = sizeLine1, aes(x = freqsim, y = rho, color = uniform)) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          0.5)) + theme(legend.key = element_blank(), axis.title.x = element_text(hjust = 0.01)) +      geom_vline(xintercept = 2) + geom_hline(yintercept = 0.05)",visualization,916707236785442e8,421
prhouni,evaluation,916707236785442e8,421
"sources.eng = sources.eng[order(sources.eng$relation, decreasing = T),      ]",exploratory,514304180862382e8,422
"dispersionsimbootciunifotest <- datsimboot %>% summarise(rayp = rayleigh.test(radFullSim)$p) %>%      mutate(uniform = ifelse(rayp > 0.05, TRUE, FALSE)) %>% group_by(participant,      freq, freqsim) %>% summarise(m = mean(uniform))",data cleaning,916707236785442e8,421
dispersionuniformityplot <- dispersionuniformity %>% rename(freqsim = freq),data cleaning,916707236785442e8,421
"prhounisim <- ggplot() + facet_wrap(~freq) + geom_line(data = dispersionsimbootciunifotest %>%      filter(freq < 2.5), aes(x = freqsim, y = m)) + geom_line(data = dispersionuniformityplot,      size = sizeLine1, aes(x = freqsim, y = rho, color = uniform)) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Rho"") + scale_y_continuous(breaks = seq(0, 1, 0.5)) +      scale_x_continuous(limits = c(0, 3.5), breaks = seq(0, 3.5,          0.5)) + theme(legend.key = element_blank(), axis.title.x = element_text(hjust = 0.01)) +      geom_vline(xintercept = 2) + geom_hline(yintercept = 0.05)",visualization,916707236785442e8,421
prhounisim,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/rhounif.pdf"", prhouni, base_width = oneColumnWidth)",export,916707236785442e8,421
"dataloan$source.language = sources.eng[match(dataloan$word, sources.eng$dest.word),      ]$source.lang",not sure,514304180862382e8,422
"funWrap <- function(d) {     sta <- mle.wrappednormal(d$radFull)$sd     stams <- sta/(4 * pi * first(d$freq)) * 1000     data.frame(sta, stams) }",data cleaning,916707236785442e8,421
"dispersionwrap <- dat %>% group_by(participant, freq) %>% do(funWrap(.))",data cleaning,916707236785442e8,421
"dataloan$source.word = sources.eng[match(dataloan$word, sources.eng$dest.word),      ]$original.word",not sure,514304180862382e8,422
dispersiowrapnuniformity <- dispersionwrap %>% merge(uniformity),data cleaning,916707236785442e8,421
"dispersionwrapboot <- datboot %>% group_by(participant, freq,      n) %>% do(funWrap(.))",data cleaning,916707236785442e8,421
"write.csv(dataloan, ""../data/loanword8.csv"")",export,514304180862382e8,422
"dispersionwrapbootci <- dispersionwrapboot %>% group_by(participant,      freq) %>% summarise(inf = quantile(stams, 0.025), sup = quantile(stams,      0.975))",data cleaning,916707236785442e8,421
dispersionwrapbootciuniformity <- dispersionwrapbootci %>% merge(uniformity),data cleaning,916707236785442e8,421
"dispersionwrapsim <- datsim %>% group_by(participant, freq, freqsim) %>%      do(funWrap(.))",data cleaning,916707236785442e8,421
"dispersionwrapsimboot <- datsimboot %>% filter(freq == 0.75) %>%      group_by(participant, freq, freqsim, n) %>% do(funWrap(.))",data cleaning,916707236785442e8,421
"dispersionwrapsimbootci <- dispersionwrapsimboot %>% group_by(participant,      freq, freqsim) %>% summarise(inf = quantile(stams, 0.025),      sup = quantile(stams, 0.975))",data cleaning,916707236785442e8,421
"pwra <- ggplot() + facet_wrap(~participant, scales = ""free_x"") +      geom_rect(data = fitthre, fill = ""black"", alpha = 0.1, aes(xmin = thre70,          xmax = thre90, ymin = 0, ymax = 160)) + geom_line(data = dispersionwrapsimbootci,      size = sizeLine1, aes(x = freqsim, y = inf), color = ""grey"") +      geom_line(data = dispersionwrapsimbootci, size = sizeLine1,          aes(x = freqsim, y = sup), color = ""grey"") + geom_line(data = dispersiowrapnuniformity,      size = sizeLine1, aes(x = freq, y = stams, color = uniform)) +      geom_point(data = dispersiowrapnuniformity, size = 0.8, aes(x = freq,          y = stams, color = uniform)) + geom_ribbon(data = dispersionwrapbootciuniformity,      alpha = 0.2, aes(x = freq, ymin = inf, ymax = sup, fill = uniform)) +      scale_color_discrete(guide = guide_legend(title = NULL),          breaks = c(T, F), labels = c(""Uniform"", ""Non-uniform"")) +      scale_fill_discrete(guide = guide_legend(title = NULL), breaks = c(T,          F), labels = c(""Uniform"", ""Non-uniform"")) + labs(x = ""Frequency (rps)"",      y = ""Standard deviation (ms)"") + scale_x_continuous(limits = c(0,      3.5), breaks = seq(0, 3.5, 1)) + theme(legend.key = element_blank(),      legend.position = c(0.7, 0.16), axis.title.x = element_text(hjust = 0.01))",visualization,916707236785442e8,421
pwra,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/wrap.pdf"", pwra, base_width = oneColumnWidth)",export,916707236785442e8,421
"dif <- dispersionsim %>% filter(freq == 0.75) %>% ungroup() %>%      select(-freq) %>% rename(freq = freqsim, rhosim = rho) %>%      merge(dispersion) %>% group_by(participant, freq) %>% summarise(dif = rhosim -      rho)",data cleaning,916707236785442e8,421
"ggplot() + facet_wrap(~participant) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.1, aes(xmin = thre70, xmax = thre90,          ymin = 0, ymax = 1)) + geom_line(data = dif, aes(x = freq,      y = dif))",visualization,916707236785442e8,421
"geom_line(data = dispersionsim %>% filter(freq == 0.75), aes(x = freqsim,      rho)) + geom_line(data = dispersion, aes(x = freq, rho))",visualization,916707236785442e8,421
library(dplyr),import,514304180862382e8,422
library(quantreg),import,514304180862382e8,422
"anglestoplot <- tibble(n = 1:4, x = rep(3.6, 4), y = c(0, 45,      90, -45), angle = c(""0"", ""45"", "" 90\n-90"", ""-45""), participant = ""Participant 5"")",visualization,916707236785442e8,421
"zeroline <- tibble(participant = datuniformity$participant %>%      unique(), x = 0, xend = c(3.8, 3.8, 3.8, 3.2, 3.2, 3.2, 3.2,      3.2), y = 0, yend = 0)",visualization,916707236785442e8,421
"praw <- ggplot() + facet_wrap(~participant, ncol = 3) + geom_rect(data = fitthre,      fill = ""black"", alpha = 0.2, aes(xmin = thre70, xmax = thre90,          ymin = -90, ymax = 90)) + geom_point(data = datuniformity,      aes(x = freq, y = degSemi, color = uniform), size = 0.35,      alpha = 0.5, shape = 16) + geom_text(data = anglestoplot,      aes(x = x, y = y, label = angle, group = n), size = sizeText) +      geom_segment(data = zeroline, aes(y = y, yend = yend, x = x,          xend = xend), size = sizeLine1) + scale_color_manual(name = ""p"",      values = c(""#08519c"", ""#3182bd"", ""#6baed6"", ""#b30000"")) +      scale_x_continuous(breaks = seq(0, 3, 1), labels = as.character(0:3)) +      scale_y_continuous(breaks = seq(-45, 90, 45), limits = c(-90,          90), labels = c(""-45"", ""0"", ""45"", ""90"")) + xlab(""Frequency (rps)"") +      ylab(""Error (deg)"") + coord_polar(theta = ""y"", start = pi/2,      direction = -1) + theme(axis.text.x = element_blank(), axis.title.x = element_blank(),      axis.line.x = element_blank(), axis.line.y = element_line(size = sizeLine1),      panel.spacing = unit(-0.32, ""lines""), legend.key = element_blank(),      legend.key.height = unit(0.7, ""lines""), legend.position = c(0.85,          0.16)) + guides(colour = guide_legend(override.aes = list(size = 2)))",visualization,916707236785442e8,421
library(ggplot2),setup,514304180862382e8,422
praw,evaluation,916707236785442e8,421
"save_plot(""analysis/figures/raw.pdf"", praw, base_width = oneColumnWidth)",export,916707236785442e8,421
nonuniformspeed <- uniformity %>% filter(!uniform) %>% summarise(freq = max(freq)) %>%      rename(frequni = freq),data cleaning,916707236785442e8,421
args <- commandArgs(trailingOnly = TRUE),setup,514304180862382e8,422
nontrackspeed <- trackbinom %>% group_by(participant) %>% filter(!chance) %>%      summarise(freq = max(freq)) %>% rename(freqtrack = freq),data cleaning,916707236785442e8,421
freqs <- nonuniformspeed %>% left_join(nontrackspeed) %>% left_join(fitthre80),data cleaning,916707236785442e8,421
"ggplot(freqs, aes(frequni, thre90)) + geom_point() + geom_abline() +      coord_equal(xlim = c(0, 2.5), ylim = c(0, 2.5))",data cleaning,916707236785442e8,421
"data_dir <- ""../../data/ideology_analysis/""",setup,514304180862382e8,422
"cor.test(freqs$frequni, freqs$thre90)",exploratory,916707236785442e8,421
"t.test(freqs$frequni, freqs$thre90, paired = TRUE)",exploratory,916707236785442e8,421
"res_dir <- paste0(data_dir, ""bootstrap_results/"")",setup,514304180862382e8,422
"setwd(""Your_working_directory/"")",setup,636683781864122e8,1
"quantiles <- c(seq(0.5, 0.9, by = 0.1), seq(0.91, 0.97, by = 0.01))",not sure,514304180862382e8,422
numSites = 578,setup,929016689537093e8,423
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/""",import,929016689537093e8,423
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/""",import,929016689537093e8,423
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",exploratory,929016689537093e8,423
"done_list_alt = vector(""list"", length(case.name))",exploratory,929016689537093e8,423
"done_list_null = vector(""list"", length(case.name))",exploratory,929016689537093e8,423
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.alt, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.logLR.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[1, 2])) {                   logLR_list[IX] = as.numeric(dat[1, 2])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_alt[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.alt, ""sum/logLR."",          case.name[cc], "".Robj"")) }",import,929016689537093e8,423
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.null, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.logLR.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[1, 2])) {                   logLR_list[IX] = as.numeric(dat[1, 2])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.null, ""sum/logLR."",          case.name[cc], "".Robj"")) }",import,929016689537093e8,423
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.null, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.logLR.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[1, 2])) {                   logLR_list[IX] = as.numeric(dat[1, 2])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.null, ""sum/logLR."",          case.name[cc], "".Robj"")) }",import,929016689537093e8,423
numSites = 578,setup,929016689537093e8,423
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/""",setup,929016689537093e8,423
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/""",setup,929016689537093e8,423
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",import,929016689537093e8,423
"done_list_alt = vector(""list"", length(case.name))",import,929016689537093e8,423
"done_list_null = vector(""list"", length(case.name))",import,929016689537093e8,423
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.alt, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.logLR.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[1, 2])) {                   logLR_list[IX] = as.numeric(dat[1, 2])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_alt[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.alt, ""sum/logLR."",          case.name[cc], "".Robj"")) }",import,929016689537093e8,423
"for (cc in 1:length(case.name)) {     logLR_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     num_dir_path = paste0(path.null, ""output/"", case.name[cc],          ""."")     for (i in 1:numSites) {         num_path = paste0(num_dir_path, i, "".fph.logLR.txt"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = read.table(num_path, as.is = TRUE)                 if (!is.na(dat[1, 2])) {                   logLR_list[IX] = as.numeric(dat[1, 2])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""logLR_list"", ""done_res"", file = paste0(path.null, ""sum/logLR."",          case.name[cc], "".Robj"")) }",import,929016689537093e8,423
library(dplyr),setup,929016689537093e8,423
library(MASS),setup,929016689537093e8,423
library(ggplot2),setup,929016689537093e8,423
"source(""./source/data_processing.R"")",import,929016689537093e8,423
"cor_matrix <- cor(analysis_df %>% mutate(Attrition = as.numeric(Attrition ==      ""Yes"")) %>% select_if(is.numeric))",data cleaning,929016689537093e8,423
max(cor_matrix[cor_matrix < 1 & cor_matrix > -1]),data cleaning,929016689537093e8,423
corrplot::corrplot(cor_matrix),modeling,929016689537093e8,423
"x <- lapply(analysis_df %>% select_if(is.factor), function(x) min(prop.table(table(x))))",exploratory,929016689537093e8,423
x[x < 0.05],exploratory,929016689537093e8,423
"uni_models_list <- lapply(names(analysis_df[, -1]), function(curVar) {     model_df <- data.frame(y = analysis_df$Attrition == ""Yes"")     model_df[curVar] <- analysis_df[[curVar]]     summary(glm(formula(paste(""y ~ "", curVar)), model_df, family = binomial(link = ""logit""))) })",exploratory,929016689537093e8,423
"names(uni_models_list) <- names(analysis_df[, -1])",data cleaning,929016689537093e8,423
uni_models_list,exploratory,929016689537093e8,423
"top_logit <- sort(sapply(uni_models_list, function(x) x$aic))",exploratory,929016689537093e8,423
"top_logit <- names(head(top_logit, 5))",data cleaning,929016689537093e8,423
"chi_sq_list <- lapply(names(analysis_df[, -1] %>% select_if(is.factor)),      function(curVar) {         tbl <- table(analysis_df[[curVar]], analysis_df$Attrition)         print(curVar)         print(tbl)         chisq.test(tbl)     })",modeling,929016689537093e8,423
"names(chi_sq_list) <- names(analysis_df[, -1] %>% select_if(is.factor))",data cleaning,929016689537093e8,423
chi_sq_list,evaluation,929016689537093e8,423
"top_chi <- sort(sapply(chi_sq_list, function(x) x$p.value))",evaluation,929016689537093e8,423
"top_chi <- names(head(top_chi, 5))",evaluation,929016689537093e8,423
"multi_logit <- glm(paste(""Attrition ~"", paste(unique(top_chi,      top_logit), collapse = "" + "")), data = analysis_df %>% mutate(Attrition = Attrition ==      ""Yes""), family = binomial(link = ""logit""))",modeling,929016689537093e8,423
summary(multi_logit),evaluation,929016689537093e8,423
"stepAIC(multi_logit, direction = ""both"")",modeling,929016689537093e8,423
library(gbm),setup,929016689537093e8,423
"gbm_model <- gbm.fit(as.data.frame(analysis_df[, -1]), analysis_df$Attrition ==      ""Yes"")",modeling,929016689537093e8,423
"gbm_plot_data <- data.frame(Var = summary(gbm_model)$var, Influence = summary(gbm_model)$rel.inf)",communication,929016689537093e8,423
"gbm_plot_data$Var <- factor(gbm_plot_data$Var, gbm_plot_data$Var[order(gbm_plot_data$Influence)])",visualization,929016689537093e8,423
"ggplot(gbm_plot_data) + geom_bar(aes(Var, Influence), stat = ""identity"") +      xlab("""") + ylab(""Rel Influence"") + coord_flip()",visualization,929016689537093e8,423
"top_gbm <- as.character(head(summary(gbm_model)$var, 6))",evaluation,929016689537093e8,423
library(randomForest),setup,929016689537093e8,423
"rf_model <- randomForest(x = as.data.frame(analysis_df[, -1]),      y = analysis_df$Attrition == ""Yes"", importance = TRUE)",modeling,929016689537093e8,423
rf_model,evaluation,929016689537093e8,423
varImpPlot(rf_model),visualization,929016689537093e8,423
importance(rf_model),evaluation,929016689537093e8,423
"top_rf <- tail(rownames(importance(rf_model, type = 1))[order(importance(rf_model,      type = 1))], 5)",communication,929016689537093e8,423
"all_top <- unique(c(top_logit, top_chi, top_gbm, top_rf))",communication,929016689537093e8,423
"all_model <- glm(""Attrition ~ ."", data = analysis_df[c(""Attrition"",      all_top)] %>% mutate(Attrition = Attrition == ""Yes""), family = binomial(link = ""logit""))",modeling,929016689537093e8,423
summary(all_model),evaluation,929016689537093e8,423
"step_reduce_model <- stepAIC(all_model, direction = ""back"")",modeling,929016689537093e8,423
step_reduce_model$coefficients,evaluation,929016689537093e8,423
summary(step_reduce_model),evaluation,929016689537093e8,423
"or_table <- exp(cbind(OR = coef(step_reduce_model), confint(step_reduce_model)))",communication,929016689537093e8,423
or_table,communication,929016689537093e8,423
"with(step_reduce_model, pchisq(null.deviance - deviance, df.null -      df.residual, lower.tail = FALSE))",evaluation,929016689537093e8,423
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/cleaning"")",setup,929016689537093e8,423
"source(""standardize_feature.R"")",import,929016689537093e8,423
"source(""subsets_list.R"")",import,929016689537093e8,423
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/ch1 discrimination/plots"")",setup,929016689537093e8,423
"source(""correlation.R"")",setup,929016689537093e8,423
subsets_novictims <- subsets_list[5:length(subsets_list)],setup,929016689537093e8,423
subset_names <- names(subsets_list)[5:length(subsets_list)],setup,929016689537093e8,423
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,      2)))",setup,929016689537093e8,423
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,      2)))",setup,929016689537093e8,423
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/cleaning"")",setup,929016689537093e8,423
"source(""standardize_feature.R"")",setup,929016689537093e8,423
"source(""subsets_list.R"")",import,929016689537093e8,423
"setwd(""~/Dropbox/Projects/Mugshots Project/Code/analysis/ch1 discrimination/plots"")",setup,929016689537093e8,423
"source(""correlation.R"")",import,929016689537093e8,423
subsets_novictims <- subsets_list[5:length(subsets_list)],data cleaning,929016689537093e8,423
subset_names <- names(subsets_list)[5:length(subsets_list)],data cleaning,929016689537093e8,423
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,43282438092865e9,424
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,      2)))",modeling,929016689537093e8,423
"lib = file.path(getwd(), ""pkgs"")",setup,43282438092865e9,424
rm(list = ls(all = TRUE)),setup,980009025195613e8,425
"wd <- ""Wetland_Hydrologic_Capacitance_Model""",setup,980009025195613e8,425
"dir <- ""//nfs/WHC-data/Validation_Modeling/WHC_BaltimoreCorner""",setup,980009025195613e8,425
library(raster),setup,980009025195613e8,425
library(rgdal),setup,980009025195613e8,425
library(rgeos),setup,980009025195613e8,425
library(maptools),setup,980009025195613e8,425
library(plyr),setup,980009025195613e8,425
library(dplyr),setup,980009025195613e8,425
library(Evapotranspiration),setup,980009025195613e8,425
"proj <- CRS(""+proj=utm +zone=17 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"")",setup,980009025195613e8,425
"dem <- raster(readGDAL(paste0(dir, ""/Model Inputs/DEM/dem"")))",setup,980009025195613e8,425
"soils.shp <- readOGR(dsn = paste0(dir, ""/Model Inputs/Soils""),      layer = ""SSURGO"")",import,980009025195613e8,425
"climate <- read.csv(paste0(dir, ""/Model Inputs/Climate/ncdc.csv""))",import,980009025195613e8,425
"dem <- projectRaster(dem, crs = proj)",not sure,980009025195613e8,425
"soils.shp <- spTransform(soils.shp, proj)",not sure,980009025195613e8,425
"pp <- data.frame(x = 947025.897981, y = 4335592.83542)",not sure,980009025195613e8,425
coordinates(pp) <- ~x + y,modeling,980009025195613e8,425
projection(pp) <- proj,modeling,980009025195613e8,425
pp.shp <- SpatialPoints(pp),modeling,980009025195613e8,425
"pp.shp <- SpatialPointsDataFrame(pp, data.frame(x = 947025.897981,      y = 4335592.83542))",exploratory,980009025195613e8,425
"wetland <- data.frame(x = 947057.170661, y = 4335552.88131)",exploratory,980009025195613e8,425
coordinates(wetland) <- ~x + y,modeling,980009025195613e8,425
projection(wetland) <- proj,modeling,980009025195613e8,425
wetland.shp <- SpatialPoints(wetland),modeling,980009025195613e8,425
"wetland.shp <- SpatialPointsDataFrame(wetland, data.frame(x = 947025.897981,      y = 4335592.83542))",modeling,980009025195613e8,425
plot(dem),visualization,980009025195613e8,425
"plot(soils.shp, border = ""grey60"", cex = 0.25, add = T)",visualization,980009025195613e8,425
"plot(pp.shp, pch = 19, col = ""red"", cex = 1, add = T)",visualization,980009025195613e8,425
"plot(wetland.shp, pch = 19, col = ""green"", cex = 1, add = T)",visualization,980009025195613e8,425
"save.image(paste0(dir, ""/Backup/input_data.RData""))",export,980009025195613e8,425
rm(list = ls(all = TRUE)),setup,980009025195613e8,425
"wd3 <- ""~/Wetland_Hydrologic_Capacitance_Model""",import,980009025195613e8,425
"dir3 <- ""//nfs/WHC-data/Validation_Modeling/WHC_BaltimoreCorner""",setup,980009025195613e8,425
"soil.data <- read.csv(paste0(dir3, ""/Model Inputs/Soils/WHC_Soils_Input.csv""))",import,980009025195613e8,425
"load(paste0(dir3, ""/Backup/DEM_Processing.RData""))",import,980009025195613e8,425
"soils.shp <- spTransform(soils.shp, dem@crs)",data cleaning,980009025195613e8,425
"soils.shp <- raster::intersect(soils.shp, watershed.shp)",data cleaning,980009025195613e8,425
"soils.shp@data$area_m2 <- gArea(soils.shp, byid = T)",data cleaning,980009025195613e8,425
soils <- soils.shp@data,data cleaning,980009025195613e8,425
"soils <- soils[, c(""MUKEY"", ""area_m2"")]",data cleaning,980009025195613e8,425
soil.data$MUKEY <- paste(soil.data$MUID),data cleaning,980009025195613e8,425
"soils <- left_join(soils, soil.data)",data cleaning,980009025195613e8,425
remove(soil.data),not sure,980009025195613e8,425
"fun <- function(x) {     sum(soils[, x] * soils[, ""area_m2""])/sum(soils[, ""area_m2""]) }",evaluation,980009025195613e8,425
soils <- na.omit(soils),data cleaning,980009025195613e8,425
"soils <- c(fun(""y_cl""), fun(""y_rd""), fun(""s_fc""), fun(""s_w""),      fun(""n""), fun(""clay""), fun(""ksat""))",not sure,980009025195613e8,425
soils <- data.frame(soils),not sure,980009025195613e8,425
"rownames(soils) <- c(""y_cl"", ""y_rd"", ""s_fc"", ""s_w"", ""n"", ""clay"",      ""ksat"")",data cleaning,980009025195613e8,425
soils <- data.frame(t(soils)),data cleaning,980009025195613e8,425
soils$Sy_soil <- soils$n * (1 - soils$s_fc/100),data cleaning,980009025195613e8,425
"climate$year <- as.numeric(substr(climate$DATE, 1, 4))",data cleaning,980009025195613e8,425
"climate <- climate[climate$year > 2007, ]",data cleaning,980009025195613e8,425
precip.VAR <- climate$PRCP,exploratory,980009025195613e8,425
precip.VAR[precip.VAR < 0] <- 0,exploratory,980009025195613e8,425
"climatedata <- data.frame(substr(climate$DATE, 1, 4))",exploratory,980009025195613e8,425
"colnames(climatedata) <- ""Year""",exploratory,980009025195613e8,425
"climatedata$Month <- as.numeric(substr(climate$DATE, 5, 6))",exploratory,980009025195613e8,425
"climatedata$Day <- as.numeric(substr(climate$DATE, 7, 8))",exploratory,980009025195613e8,425
climatedata$Tmax <- (climate$TMAX),exploratory,980009025195613e8,425
climatedata$Tmin <- (climate$TMIN),exploratory,980009025195613e8,425
climatedata$RHmax <- 0,data cleaning,980009025195613e8,425
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,670532359508797e8,426
climatedata$RHmin <- 0,data cleaning,980009025195613e8,425
climatedata$Rs <- 0,data cleaning,980009025195613e8,425
"input <- ReadInputs(varnames = colnames(climatedata), climatedata = climatedata,      stopmissing = c(10, 10, 3), timestep = ""daily"", interp_missing_days = F,      interp_missing_entries = F, interp_abnormal = F, missing_method = ""DoY average"",      abnormal_method = ""DoY average"")",import,980009025195613e8,425
"data(""constants"")",import,980009025195613e8,425
"setwd(""C:/Users/Amir/Documents/GitHub/structural_prediction_of_ER/"")",setup,670532359508797e8,426
constants$Elev <- 10,import,980009025195613e8,425
"data_1RD8_AB = read.csv(""correlation_analysis/combined_data/data_1RD8_AB.csv"")",setup,670532359508797e8,426
"data_2FP7_B = read.csv(""correlation_analysis/combined_data/data_2FP7_B.csv"")",setup,670532359508797e8,426
constants$lat_rad <- 38.8846 * pi/180,exploratory,980009025195613e8,425
"data_2Z83_A = read.csv(""correlation_analysis/combined_data/data_2Z83_A.csv"")",setup,670532359508797e8,426
"data_2JLY_A = read.csv(""correlation_analysis/combined_data/data_2JLY_A.csv"")",setup,670532359508797e8,426
"df <- ET.HargreavesSamani(data = input, constants = constants,      ts = ""daily"")",data cleaning,980009025195613e8,425
"data_3GOL_A = read.csv(""correlation_analysis/combined_data/data_3GOL_A.csv"")",setup,670532359508797e8,426
"data_3LYF_A = read.csv(""correlation_analysis/combined_data/data_3LYF_A.csv"")",setup,670532359508797e8,426
pet.VAR <- df$ET.Daily,data cleaning,980009025195613e8,425
"data_4AQF_B = read.csv(""correlation_analysis/combined_data/data_4AQF_B.csv"")",import,670532359508797e8,426
"data_4GHA_A = read.csv(""correlation_analysis/combined_data/data_4GHA_A.csv"")",import,670532359508797e8,426
"data_4IRY_A = read.csv(""correlation_analysis/combined_data/data_4IRY_A.csv"")",import,670532359508797e8,426
"setwd(""/Users/t-rex-Box/Desktop/work/nba-predictor/"")",setup,152632966637611e8,427
"source(""analysis/util.R"")",import,152632966637611e8,427
"source(""analysis/prepare_features.R"")",import,152632966637611e8,427
"train.glm <- glm(ScoreDiff ~ Team1_win_last_6 + Team2_win_last_6 +      Team1_away_win_percentage_10 + Team2_away_win_percentage_10 +      Team1_avg_pnt_top_3_players_6 + Team2_avg_pnt_top_3_players_6,      data = train)",modeling,152632966637611e8,427
summary(train.glm),modeling,152632966637611e8,427
"p.hats <- predict.glm(train.glm, newdata = test, type = ""response"")",evaluation,152632966637611e8,427
as.numeric(p.hats > 0),evaluation,152632966637611e8,427
"mean((p.hats > 0) == test$Result, na.rm = TRUE)",evaluation,152632966637611e8,427
"setwd(""/Users/t-rex-Box/Desktop/work/nba-predictor/"")",setup,152632966637611e8,427
library(grid),import,152632966637611e8,427
library(gridExtra),import,152632966637611e8,427
library(plyr),import,152632966637611e8,427
library(GenomicRanges),setup,152632966637611e8,427
library(qgraph),import,152632966637611e8,427
"key <- subset(sig, !duplicated(probename), select = c(probename,      probegene))",data cleaning,152632966637611e8,427
"nom <- subset(key, duplicated(probegene))$probename",data cleaning,152632966637611e8,427
"sig2 <- subset(sig, !probename %in% nom)",data cleaning,152632966637611e8,427
"a <- subset(sig2, select = c(snp1, snp2))",data cleaning,152632966637611e8,427
wd = getwd(),setup,304049919359386e8,428
"names(a) <- c(""from"", ""to"")",data cleaning,152632966637611e8,427
a$thickness <- 1,exploratory,152632966637611e8,427
a$col <- as.character(sig2$rep),data cleaning,152632966637611e8,427
"a$col[a$col == 0] <- ""white""",data cleaning,152632966637611e8,427
library(tidyverse),setup,879442358622327e8,429
library(tidync),setup,879442358622327e8,429
library(lubridate),setup,879442358622327e8,429
library(here),setup,879442358622327e8,429
"a$col[a$col == 1] <- ""black""",data cleaning,152632966637611e8,427
"a$col[a$col == 2] <- ""black""",data cleaning,152632966637611e8,427
a$col2 <- a$col,data cleaning,152632966637611e8,427
"a$col2[sig2$rep == 1] <- ""white""",data cleaning,152632966637611e8,427
a$col3 <- as.character(sig2$rep),data cleaning,152632966637611e8,427
"a$col3[a$col3 == 0] <- """"",data cleaning,152632966637611e8,427
"a$col3[a$col3 == 1] <- ""black""",exploratory,152632966637611e8,427
"a$col3[a$col3 == 2] <- ""red""",data cleaning,152632966637611e8,427
a$thickness2 <- a$thickness,data cleaning,152632966637611e8,427
"a$thickness2[a$col3 == ""red""] <- 1.5",data cleaning,152632966637611e8,427
"a$cistrans <- ""blue""",data cleaning,152632966637611e8,427
a$cistrans[sig2$c],data cleaning,152632966637611e8,427
"setwd(""/Users/emrys/Documents/Projects/MobaAnalysis/analysis"")",setup,510335135739297e8,430
"library(""rjson"")",import,510335135739297e8,430
"result <- fromJSON(file = ""battle_hours.json"")",import,510335135739297e8,430
json_data = as.data.frame(result),data cleaning,510335135739297e8,430
print(json_data),exploratory,510335135739297e8,430
print(typeof(json_data)),exploratory,510335135739297e8,430
"b <- c(result[""00""][1], result[""01""][1], result[""02""][1], result[""03""][1],      result[""04""][1], result[""05""][1], result[""06""][1], result[""07""][1],      result[""08""][1], result[""09""][1], result[""10""][1], result[""11""][1],      result[""12""][1], result[""13""][1], result[""14""][1], result[""15""][1],      result[""16""][1], result[""17""][1], result[""18""][1], result[""19""][1],      result[""20""][1], result[""21""][1], result[""22""][1], result[""23""][1])",data cleaning,510335135739297e8,430
"v <- c(1, 2, 4)",data cleaning,510335135739297e8,430
print(typeof(v)),exploratory,510335135739297e8,430
"png(file = ""test.png"")",visualization,510335135739297e8,430
"plot(json_data[0], type = ""o"", main = ""Test"")",visualization,510335135739297e8,430
dev.off(),visualization,510335135739297e8,430
"setwd(""/Users/emrys/Documents/Projects/MobaAnalysis/analysis"")",setup,510335135739297e8,430
"analysisDir = normalizePath(""."")",setup,510335135739297e8,430
"setwd(""/Users/ereznik/pancanmet_analysis/analysis/"")",setup,510335135739297e8,430
"source(""functions/readBigMet.R"")",import,510335135739297e8,430
"source(""functions/multiplot_mod.R"")",import,510335135739297e8,430
"source(""plottingconventions.R"")",import,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
library(xlsx),import,510335135739297e8,430
library(combinat),import,510335135739297e8,430
study2drop = c(),data cleaning,510335135739297e8,430
pthresh = 0.1,data cleaning,510335135739297e8,430
metdata = readBigMet(study2drop),import,510335135739297e8,430
met = metdata$met,exploratory,510335135739297e8,430
tissuetype = metdata$tissuetype,exploratory,510335135739297e8,430
studytype = metdata$studytype,data cleaning,510335135739297e8,430
uqstudy = unique(studytype),exploratory,510335135739297e8,430
"tmap = read.csv(""../data/merged_metabolomics/merged_tissuetypes.csv"",      row.names = 1, header = T)",import,510335135739297e8,430
mult = names(which(table(tmap) > 1)),exploratory,510335135739297e8,430
pnames = list(),data cleaning,510335135739297e8,430
pctr = 1,data cleaning,510335135739297e8,430
library(foreign),setup,177274869056419e8,431
library(dplyr),setup,177274869056419e8,431
"EUmanifesto <- read.dta(""./Analysis/Data/Euromanifesto/ZA5102_v1-0-0.dta"",      convert.factors = F)",import,177274869056419e8,431
"EUmanifesto <- filter(EUmanifesto, country != 10)",exploratory,177274869056419e8,431
"EUmanifesto <- filter(EUmanifesto, vote >= -777)",exploratory,177274869056419e8,431
"write.csv(EUmanifesto, ""Analysis/Data/Euromanifesto/EMP.csv"")",export,177274869056419e8,431
library(tidyverse),setup,177274869056419e8,431
library(tidync),setup,177274869056419e8,431
library(lubridate),setup,177274869056419e8,431
library(here),setup,177274869056419e8,431
"for (ttype in mult) {     print(ttype)     s2use = rownames(tmap)[which(tmap[, 1] == ttype)]     idx = which(studytype %in% s2use)     d = met[, idx]     d = d[complete.cases(d), ]     d = as.matrix(d)     d_study = unlist(lapply(strsplit(colnames(d), "":""), `[[`,          1))     d_tissue = unlist(lapply(strsplit(colnames(d), "":""), `[[`,          3))     fc = data.frame(matrix(0, dim(d)[1], length(s2use)), row.names = rownames(d))     colnames(fc) = s2use     p = fc     padj = fc     for (s in unique(s2use)) {         normidx = which(d_study == s & d_tissue == ""Normal"")         tumidx = which(d_study == s & (d_tissue == ""Tumor""))         for (metabolite in rownames(d)) {             fc[metabolite, s] = log2(mean(d[metabolite, tumidx])/mean(d[metabolite,                  normidx]))             p[metabolite, s] = wilcox.test(d[metabolite, tumidx],                  d[metabolite, normidx])$p.value         }         padj[, s] = p.adjust(p[, s], method = ""BH"")     }     write.xlsx2(fc, paste(""../results/sametissue/"", ttype, "".xlsx"",          sep = """"), sheetName = ""FC"", col.names = TRUE, row.names = TRUE,          append = FALSE)     write.xlsx2(p, paste(""../results/sametissue/"", ttype, "".xlsx"",          sep = """"), sheetName = ""P"", col.names = TRUE, row.names = TRUE,          append = TRUE)     write.xlsx2(padj, paste(""../results/sametissue/"", ttype,          "".xlsx"", sep = """"), sheetName = ""PAdj"", col.names = TRUE,          row.names = TRUE, append = TRUE)     fcadj = fc     fcadj[p > pthresh] = 0     scombs = combn(s2use, 2)     if (length(scombs) == 2) {         scombs = matrix(t(scombs))     }     for (i in 1:dim(scombs)[2]) {         study1 = scombs[1, i]         study2 = scombs[2, i]         s2plot = scombs[, i]         plotdata = fc[, s2plot]         colnames(plotdata) = c(""X"", ""Y"")         sigmets = rownames(padj)[which(p[, study1] < pthresh &              p[, study2] < pthresh)]         plotdata$Significance = ""NS""         plotdata[sigmets, ""Significance""] = ""Significant""         tempfc = fcadj[, s2plot]         tempfc = tempfc[-which(tempfc == 0, arr.ind = TRUE)[,              1], ]         tempfc = sign(tempfc)         pvalue = fisher.test(table(tempfc))$p.value         pvalue = round(pvalue, 3)         tissuecor = cor.test(plotdata$X, plotdata$Y, method = ""spearman"")         tissuecorval = round(tissuecor$estimate, 3)         tissuecorp = round(tissuecor$p.value, 3)         titlestr = paste(ttype, "", Fisher Test P-Value ="", pvalue,              ""\n"", ""Spearman rho"", tissuecorval, ""P-Value ="",              tissuecorp, sep = "" "")         fignum = ggplot(plotdata, aes(X, Y, color = Significance)) +              geom_point() + theme_classic() + xlab(names2plot[s2plot[1]]) +              ylab(names2plot[s2plot[2]]) + geom_vline(xintercept = 0) +              geom_hline(yintercept = 0) + ggtitle(titlestr) +              scale_color_manual(values = c(NS = ""gray"", Significant = ""red""))         pname = paste(""fignum"", pctr, sep = """")         pctr = pctr + 1         pnames = c(pnames, pname)         assign(pname, fignum)         print(fignum)     } }",visualization,510335135739297e8,430
pnames = unlist(pnames),data cleaning,510335135739297e8,430
"ann = tidync(here(""analysis"", ""data"", ""days-above-compliant"",      ""tn_gt20_annual_mean.nc"")) %>% hyper_tibble() %>% rename(count = tmin) %>%      mutate(dt = as.Date(""1911-12-31"") + days(time), year = year(dt)) %>%      select(year, count)",data cleaning,177274869056419e8,431
"mth = tidync(here(""analysis"", ""data"", ""days-above-compliant"",      ""tn_gt20_monthly_mean.nc"")) %>% hyper_tibble() %>% rename(count = tmin) %>%      mutate(dt = as.Date(""1911-01-31"") + days(time), year = year(dt)) %>%      select(year, count)",data cleaning,177274869056419e8,431
"pdf(""../results/sametissue/sametissue.pdf"", height = 10, width = 10)",visualization,510335135739297e8,430
mth_sum = mth %>% group_by(year) %>% summarise(count = sum(count)),exploratory,177274869056419e8,431
"multiplot_mod(pnames, cols = 2)",visualization,510335135739297e8,430
dev.off(),visualization,510335135739297e8,430
"joined = ann %>% left_join(mth_sum, by = ""year"") %>% mutate(diff = count.x -      count.y)",data cleaning,177274869056419e8,431
hist(joined$diff),visualization,177274869056419e8,431
"source(""analysis/utils.R"")",import,510335135739297e8,430
"source(""analysis/analysis.R"")",import,510335135739297e8,430
suppressPackageStartupMessages(library(dplyr)),import,510335135739297e8,430
"humanize_classification <- function(vector) ifelse(vector ==      1, ""multiforce"", ifelse(vector == 2, ""force and reuse"", ifelse(vector ==      3, ""just force"", ifelse(vector == 4, ""unforced"", ""?""))))",data cleaning,510335135739297e8,430
"to_bits <- function(x) lapply(x, to_bits_single)",data cleaning,510335135739297e8,430
"humanize_metaprogramming <- function(vector) sapply(vector, function(x) {     e <- as.numeric(intToBits(x))     paste(Filter(function(x) x != """", ifelse(sum(e[1:6]), c(ifelse(sum(e[1:3]),          ""lookup"", """"), ifelse(e[1], ""expr"", """"), ifelse(e[2],          ""env"", """"), ifelse(e[3], ""val"", """"), ifelse(sum(e[4:6]),          ""set"", """"), ifelse(e[4], ""expr"", """"), ifelse(e[5], ""env"",          """"), ifelse(e[6], ""val"", """")), c(""clean""))), collapse = "" "") })",data cleaning,510335135739297e8,430
"analyze_database <- function(database_file_path) {     components <- stringr::str_split(basename(tools::file_path_sans_ext(database_file_path)),          ""-"", 2)[[1]]     db <- src_sqlite(database_file_path)     data <- db %>% tbl(""promise_lifecycle"") %>% select(promise_id,          event_type, inside_force) %>% group_by(promise_id) %>%          summarise(forces = sum(event_type == 1, na.rm = TRUE),              lookups = sum(event_type == 5, na.rm = TRUE) & (inside_force ==                  1), metaprogramming_any = sum(event_type >= 3,                  na.rm = TRUE) & sum(event_type <= 8, na.rm = TRUE) &                  (inside_force != 1), lookup_expr = sum(event_type ==                  3, na.rm = TRUE) & (inside_force != 1), lookup_env = sum(event_type ==                  4, na.rm = TRUE) & (inside_force != 1), lookup_val = sum(event_type ==                  5, na.rm = TRUE) & (inside_force != 1), set_expr = sum(event_type ==                  6, na.rm = TRUE) & (inside_force != 1), set_env = sum(event_type ==                  7, na.rm = TRUE) & (inside_force != 1), set_val = sum(event_type ==                  8, na.rm = TRUE) & (inside_force != 1)) %>% mutate(classification = ifelse(forces >          0, ifelse(forces > 1, 1, ifelse(lookups > 0, 2, 3)),          4), metaprogramming = ifelse(lookup_expr > 0, 1, 0) +          ifelse(lookup_env > 0, 2, 0) + ifelse(lookup_val > 0,          4, 0) + ifelse(set_expr > 0, 8, 0) + ifelse(set_env >          0, 16, 0) + ifelse(set_val > 0, 32, 0)) %>% group_by(classification,          metaprogramming) %>% count %>% as.data.frame     list(accesses = data) }",data cleaning,510335135739297e8,430
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,232964377151802e8,432
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,232964377151802e8,432
"summarize_analyses <- function(analyses) {     list(accesses = analyses$accesses %>% group_by(classification) %>%          summarise(number = sum(n)) %>% mutate(percent = (100 *          number/sum(number))) %>% mutate(classification = humanize_classification(classification)),          metaprogramming = analyses$accesses %>% group_by(metaprogramming) %>%              summarise(number = sum(n)) %>% mutate(percent = (100 *              number/sum(number))) %>% ungroup %>% mutate(metaprogramming = humanize_metaprogramming(metaprogramming)),          accesses_and_metaprogramming = analyses$accesses %>%              group_by(classification, metaprogramming) %>% summarise(number = sum(n)) %>%              mutate(percent = (100 * number/sum(number))) %>%              ungroup %>% mutate(label = paste0(classification = humanize_classification(classification),              "" "", metaprogramming = humanize_metaprogramming(metaprogramming))) %>%              select(label, number, percent)) }",data cleaning,510335135739297e8,430
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,232964377151802e8,432
"visualize_analyses <- function(analyses) {     list(accesses = ggplot(analyses$accesses, aes(x = classification,          y = number)) + geom_col() + scale_y_continuous(labels = count_labels) +          theme(legend.position = ""none"", axis.title.x = element_blank()),          metaprogramming = ggplot(analyses$metaprogramming, aes(x = metaprogramming,              y = number)) + geom_col() + scale_y_continuous(labels = count_labels) +              theme(legend.position = ""none"", axis.title.x = element_blank()),          accesses_and_metaprogramming = ggplot(analyses$accesses_and_metaprogramming,              aes(x = label, y = number)) + geom_col() + scale_y_continuous(labels = count_labels) +              theme(legend.position = ""none"", axis.title.x = element_blank())) }",visualization,510335135739297e8,430
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,232964377151802e8,432
latex_analyses <- function(analyses) {     list() },communication,510335135739297e8,430
"main <- function() {     analyzer <- create_analyzer(""Promise Metaprogramming and Accesses"",          analyze_database, combine_analyses, summarize_analyses,          visualize_analyses, latex_analyses)     drive_analysis(analyzer) }",communication,510335135739297e8,430
library(dygraphs),import,232964377151802e8,432
main(),setup,510335135739297e8,430
"dygraph(gpg_pauses, xlab = ""Keypress index"", ylab = ""Pause length"",      main = paste0(ID, "" "", file_index, "" "", txt_files[file_index],          "" "", n)) %>% dySeries(""V1"", label = ""Seconds"") %>% dyLegend(show = ""always"",      hideOnMouseOut = FALSE) %>% dyRangeSelector()",import,232964377151802e8,432
p_threshold <- 8,import,232964377151802e8,432
warnings(),evaluation,510335135739297e8,430
which(pause > p_threshold),import,232964377151802e8,432
which(pause > p_threshold),import,232964377151802e8,432
library(dygraphs),visualization,232964377151802e8,432
require(tidyverse),import,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
"dygraph(gpg_pauses, xlab = ""Keypress index"", ylab = ""Pause length"",      main = paste0(ID, "" "", file_index, "" "", txt_files[file_index],          "" "", n)) %>% dySeries(""V1"", label = ""Seconds"") %>% dyLegend(show = ""always"",      hideOnMouseOut = FALSE) %>% dyRangeSelector()",visualization,232964377151802e8,432
p_threshold <- 8,visualization,232964377151802e8,432
library(plotly),import,510335135739297e8,430
which(pause > p_threshold),import,232964377151802e8,432
"setwd(""~/proyectos/exploratory-data-analysis/turistificacion/"")",setup,510335135739297e8,430
"f1 <- ""~/proyectos/exploratory-data-analysis/turistificacion/data/raw/actividades-comerciales/20150201.csv""",setup,510335135739297e8,430
"f2 <- ""~/proyectos/exploratory-data-analysis/turistificacion/data/raw/actividades-comerciales/20180301.csv""",setup,510335135739297e8,430
library(dygraphs),visualization,232964377151802e8,432
"distritos <- c(""ARGANZUELA"", ""USERA"", ""CENTRO"")",setup,510335135739297e8,430
"MCMaster = read.csv(""~/NoiseHedonicProject/Noise-Hedonic/analysis/04MonteCarloSim/Revision/Model3/LWRMonteCarloStats2014-07-02.csv"")",visualization,232964377151802e8,432
"MCMaster = MCMaster[1:94, ]",visualization,232964377151802e8,432
"MCplotter = function(outputcoefficient, statcoefficient, meanORsd = ""mean"") {     if (meanORsd == ""mean"")          actual = mean(output[[outputcoefficient]][, ""k2000""],              na.rm = T)     if (meanORsd == ""sd"")          actual = sd(output[[outputcoefficient]][, ""k2000""], na.rm = T)     temp = density(MCMaster[, statcoefficient])     plot(temp, xlim = c(min(c(range(temp$x), actual), na.rm = T),          max(c(range(temp$x), actual), na.rm = T)), main = paste(meanORsd,          sub(""beta."", """", outputcoefficient)), axes = F, ylab = """",          xlab = """")     axis(1)     mtext(""relative frequency"", 2, 1, cex = 0.7)     abline(v = actual, col = ""red"") }",visualization,232964377151802e8,432
"df1 <- read_delim(f1, "";"") %>% select(desc_situacion_local, id_local,      desc_distrito_local, desc_barrio_local, clase_vial_acceso,      desc_vial_acceso, rotulo, desc_seccion, desc_division, desc_epigrafe) %>%      filter(!is.na(desc_seccion) & desc_situacion_local == ""Abierto"") %>%      mutate(desc_distrito_local = trim(desc_distrito_local)) %>%      filter(desc_distrito_local %in% distritos)",data cleaning,510335135739297e8,430
"outputCOEFS = rep(names(output)[c(1:5, 16, 19, 20, 21, 22, 23,      24, 17, 18)], 2)",visualization,232964377151802e8,432
statCOEFS = names(MCMaster)[3:30],visualization,232964377151802e8,432
"df2 <- read_delim(f2, "";"") %>% select(desc_situacion_local, id_local,      desc_distrito_local, desc_barrio_local, clase_vial_acceso,      desc_vial_acceso, rotulo, desc_seccion, desc_division, desc_epigrafe) %>%      filter(!is.na(desc_seccion) & desc_situacion_local == ""Abierto"") %>%      mutate(desc_distrito_local = trim(desc_distrito_local)) %>%      filter(desc_distrito_local %in% distritos)",data cleaning,510335135739297e8,430
"meanORsds = rep(c(""mean"", ""sd""), c(14, 14))",visualization,232964377151802e8,432
"pdf(""analysis/04MonteCarloSim/Revision/MCsimResultsk2000.pdf"",      height = 6, width = 24)",visualization,232964377151802e8,432
"par(mfrow = c(2, 14))",visualization,232964377151802e8,432
"df1_aggr <- df1 %>% group_by(desc_distrito_local, desc_epigrafe) %>%      summarize(count_2015 = n())",data cleaning,510335135739297e8,430
"for (i in 1:length(outputCOEFS)) {     MCplotter(outputCOEFS[i], statCOEFS[i], meanORsds[i])     title(MYMODEL, line = 1, outer = T) }",visualization,232964377151802e8,432
dev.off(),visualization,232964377151802e8,432
"pdf(""analysis/04MonteCarloSim/Revision/MCsimResultsSDsk2000.pdf"",      height = 6, width = 8)",visualization,232964377151802e8,432
"df2_aggr <- df2 %>% group_by(desc_distrito_local, desc_epigrafe) %>%      summarize(count_2018 = n())",data cleaning,510335135739297e8,430
"df_diff <- df1_aggr %>% inner_join(df2_aggr, by = c(desc_distrito_local = ""desc_distrito_local"",      desc_epigrafe = ""desc_epigrafe"")) %>% mutate(diff_perc = ((count_2018 -      count_2015)/count_2015) * 100) %>% mutate(diff = (count_2018 -      count_2015))",data cleaning,510335135739297e8,430
"write_csv(df_diff, ""diff.csv"")",export,510335135739297e8,430
df <- data.frame(),setup,510335135739297e8,430
"for (x in files) {     print(x)     y <- strsplit(x, ""/"")     file_name <- y[[1]][[length(y[[1]])]]     date <- as.Date(file_name, ""%Y%m%d"")     df_sum <- read_delim(x, "","") %>% group_by(desc_distrito_local,          desc_barrio_local, categoria) %>% summarize(count = n()) %>%          mutate(date = date)     if (nrow(df) == 0) {         df <- df_sum     }     else {         df <- rbind(df, df_sum)     } }",data cleaning,510335135739297e8,430
View(df),visualization,510335135739297e8,430
require(tidyverse),import,510335135739297e8,430
"for (pack in 1:length(packages)) {     if (packages[pack] %in% rownames(installed.packages()) ==          FALSE) {         stop(paste(""You need to install the"", packages[pack]),              "" package from CRAN."")     } }",setup,510335135739297e8,430
"if (packageVersion(""Rcpp"") != ""0.11.5"") install.packages(""Rcpp"")",setup,510335135739297e8,430
"dir.create(""../results/"", showWarnings = FALSE)",setup,510335135739297e8,430
"source(""get_allometric_data.R"")",import,510335135739297e8,430
"source(""allometry_linear_model.R"")",import,510335135739297e8,430
"source(""control_fh_ANOVA.R"")",import,510335135739297e8,430
"source(""treatment_ANOVA.R"")",import,510335135739297e8,430
"source(""height_analysis.R"")",import,510335135739297e8,430
"source(""wet_dry_ratio_test.R"")",import,510335135739297e8,430
"print(""All analysis for Tredennick et al. 2015 complete. Check your results folder."")",export,510335135739297e8,430
"filepath2 <- ""/Data/spotprices.csv""",import,327710893005133e8,433
"path <- c(getwd(), filepath2)",import,327710893005133e8,433
"path <- paste(path, collapse = """")",import,327710893005133e8,433
"print(""If errors occur or you have questions, email Andrew Tredennick at atredenn@gmail.com."")",export,510335135739297e8,430
"spotprices <- read.csv(path, header = TRUE, sep = "","", stringsAsFactors = FALSE)",import,327710893005133e8,433
"spotprices <- spotprices[, -1]",data cleaning,327710893005133e8,433
rm(list = ls()),setup,510335135739297e8,430
"setwd(""C:/Users/Xuebert/Dropbox/Albert Xue/Research/Deployment/SHAPE-Seq_event_detector/"")",setup,510335135739297e8,430
"colnames(spotprices) <- c(""Date"", ""WTISpotPriceBBL"", ""BrentSpotPriceBBL"")",data cleaning,327710893005133e8,433
"source(""support_functions/plotting/make_visual.R"")",import,510335135739297e8,430
"source(""support_functions/utility_functions.R"")",import,510335135739297e8,430
oldwd <- getwd(),setup,327710893005133e8,433
"source(""support_functions/color_to_hex.R"")",import,510335135739297e8,430
"source(""support_functions/find_ND.R"")",import,510335135739297e8,430
"filepath2 <- ""/Data/""",setup,327710893005133e8,433
"path <- c(getwd(), filepath2)",setup,327710893005133e8,433
"path <- paste(path, collapse = """")",setup,327710893005133e8,433
setwd(path),setup,327710893005133e8,433
"write.csv(spotprices, file = ""CleanSpotPrices.csv"")",export,327710893005133e8,433
setwd(oldwd),setup,327710893005133e8,433
"com.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC2/run/gen.data/com/""",communication,327710893005133e8,433
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC2/run/""",setup,327710893005133e8,433
siteSize = 1024,setup,327710893005133e8,433
"treatment = ""Copper""",setup,327710893005133e8,433
"compare_optimized <- function(optimized_file, original_file,      outfile_name = ""outfile"") {     load(optimized_file)     data_mat = Reduce(""+"", data_mat)     original_events = read.csv(original_file)     original_events[original_events == -3] = -1     original_events[original_events == -1.5] = 1     original_events[original_events == 3] = 1     original_events[original_events == 1.5] = 1     original_events[original_events == 2] = 0     original_events[original_events == -2] = 0     concurrent_events = matrix(NA, nrow = 0, ncol = 4)     event_locations = expand_runs(event_scan[winner][[1]], data_mat)     event_locations[is.na(event_locations)] = 0     agreement = which((event_locations == original_events) &          (event_locations != 0) & (original_events != 0), arr.ind = T)     disagreement_FP = which((event_locations != original_events) &          (original_events == 0), arr.ind = T)     disagreement_FN = which((event_locations != original_events) &          (event_locations == 0), arr.ind = T)     disagreement_TN = which((original_events == 0) & (event_locations ==          0), arr.ind = T)     pdf(paste(outfile_name, "".pdf"", sep = """"), width = 14, height = 14,          useDingbats = F)     temp = data_mat * 0     temp[agreement] = event_locations[agreement]     make_visual(data_mat, temp, concurrent_events)     par(new = T)     event_colors = list(upswing = color_to_hex(""purple"", 0.1),          downswing = color_to_hex(""purple"", 0.1))     temp = data_mat * 0     temp[disagreement_FP] = event_locations[disagreement_FP]     make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3,          3), ramp_draw = c(-1, 1), event_colors = event_colors,          box_resize = 1, lwd = 2)     par(new = T)     event_colors = list(upswing = color_to_hex(""forestgreen"",          0.1), downswing = color_to_hex(""forestgreen"", 0.1))     temp = data_mat * 0     temp[disagreement_FN] = original_events[disagreement_FN]     make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3,          3), ramp_draw = c(-1, 1), event_colors = event_colors,          box_resize = 1, lwd = 2)     par(new = F)     make_visual(data_mat, original_events, concurrent_events)     title(""Original"")     make_visual(data_mat, event_locations, concurrent_events)     title(""Optimized"")     temp = cbind(matrix(threshold_distance/max(threshold_distance),          ncol = 1), matrix(event_distance, ncol = 1))     ND = find_ND(temp)     par(mar = c(8, 8, 8, 8))     plot(x = temp[ND, 1], y = temp[ND, 2], xlab = ""Normalized threshold sum"",          ylab = ""Normalized event number"", xlim = c(0, 1), ylim = c(0,              1), col = ""grey50"", pch = 20, cex = 2)     par(new = T)     plot(x = threshold_distance[winner]/max(threshold_distance),          y = event_distance[winner], xaxt = ""n"", yaxt = ""n"", xlim = c(0,              1), ylim = c(0, 1), xlab = """", ylab = """", bty = ""n"",          pch = 20, col = ""red"", cex = 3)     lines(x = c(0, threshold_distance[winner]/max(threshold_distance)),          y = c(0, event_distance[winner]), lty = 2)     dev.off()     TP = nrow(agreement)     FP = nrow(disagreement_FP)     FN = nrow(disagreement_FN)     TN = nrow(disagreement_TN)     TPR = TP/(TP + FN)     FPR = FP/(FP + TN)     precision = TP/(TP + FP)     return(list(TPR = TPR, FPR = FPR, precision = precision)) }",visualization,510335135739297e8,430
null = FALSE,data cleaning,327710893005133e8,433
"strand = ""both""",setup,327710893005133e8,433
meanR.thresh = 2,not sure,327710893005133e8,433
"window.size.list = c(100, 300, 1024)",visualization,327710893005133e8,433
wavelet.preprocess.QT = TRUE,not sure,327710893005133e8,433
wavelet.preprocess.NoQT = TRUE,not sure,327710893005133e8,433
"compare_optimized(""optimized_thresholds_SRP_2.RData"", ""analysis/SRP/replicates/SRP.csv"",      ""optimized_comparison_SRP_2"")",import,510335135739297e8,430
deseq.preprocess = TRUE,not sure,327710893005133e8,433
"compare_optimized(""optimized_thresholds_F_0mM_2.RData"", ""analysis/F/replicates/F_0mM.csv"",      ""optimized_comparison_F_0mM_2"")",import,510335135739297e8,430
"get.com.preprocess.run.multiseq.ATACseq(com.path, wd.path, siteSize,      treatment, null, strand, meanR.thresh, window.size.list,      wavelet.preprocess.QT, wavelet.preprocess.NoQT, deseq.preprocess)",visualization,327710893005133e8,433
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",import,510335135739297e8,430
load(latestPrepName),import,510335135739297e8,430
set.seed(1234),setup,510335135739297e8,430
"message(""=== SENSITIVITY ANALYSIS ==="")",exploratory,510335135739297e8,430
"library(""sensitivity"")",import,510335135739297e8,430
"library(""ggplot2"")",import,510335135739297e8,430
"library(""pse"")",import,510335135739297e8,430
"library(""reshape2"")",import,510335135739297e8,430
"library(""parallel"")",import,510335135739297e8,430
selDatasets <- datasetsByType$absolute,import,510335135739297e8,430
selRegions <- regionNames,data cleaning,510335135739297e8,430
"selSamples <- setdiff(sampleNames, sampleNames[grep(""Titration"",      sampleNames)])",exploratory,510335135739297e8,430
"originalLsaData <- lsaData[lsaData$datasetName %in% selDatasets &      lsaData$regionName %in% selRegions & lsaData$sampleName %in%      selSamples, ]",data cleaning,510335135739297e8,430
"referenceValues <- aggregate(abs(deviationCorridor) ~ datasetName,      originalLsaData, mean, na.rm = TRUE)",data cleaning,510335135739297e8,430
"referenceValues <- structure(referenceValues[, 2], names = referenceValues[,      1])",data cleaning,510335135739297e8,430
"parRanges <- list(minAssayTypeNumValues = 2:length(unique(datasetTable[datasetsByType$absolute,      ""assayGroup""])), corridorExtValues = seq(0, 50, by = 5))",data cleaning,510335135739297e8,430
"prepData <- function(corridorMinAssayTypes = CORRIDOR_MIN_NUM_ASSAY_TYPES,      corridorExtension = CORRIDOR_EXTENSION) {     lsaData <- originalLsaData     rNames <- unique(lsaData$regionName)     sNames <- unique(lsaData$sampleName)     consensusMeths <- list(lower = function(x) {         max(0, min(x, na.rm = T) - corridorExtension/2)     }, upper = function(x) {         min(100, max(x, na.rm = T) + corridorExtension/2)     }, median = function(x) {         median(x, na.rm = T)     })     for (curRegion in rNames) {         curRegionData <- lsaData[lsaData$regionName == curRegion &              lsaData$datasetName %in% datasetsByType$absolute,              ]         curRegionData$assayGroup <- datasetTable[curRegionData$datasetName,              ""assayGroup""]         for (curSample in sNames) {             curRegionSampleData <- curRegionData[curRegionData$sampleName ==                  curSample, ]             cutoffs <- sort(unique(c(-0.001, 100, curRegionSampleData$methValue)))             intervals <- data.frame(t(combn(cutoffs, 2)))             names(intervals) <- c(""lower"", ""upper"")             intervals$width <- intervals$upper - intervals$lower             intervals <- intervals[intervals$width > 0, ]             intervals <- intervals[order(intervals$width), ]             for (i in 1:nrow(intervals)) {                 selData <- curRegionSampleData[curRegionSampleData$methValue >=                    intervals[i, ""lower""] & curRegionSampleData$methValue <=                    intervals[i, ""upper""], ]                 if (length(unique(selData$assayGroup)) >= corridorMinAssayTypes)                    break             }             if (length(unique(selData$assayGroup)) >= corridorMinAssayTypes) {                 for (val in names(consensusMeths)) {                   lsaData[lsaData$regionName == curRegion & lsaData$sampleName ==                      curSample, val] <- consensusMeths[[val]](selData$methValue)                 }             }         }     }     lsaData$deviationMedian <- lsaData$methValue - lsaData$median     lsaData$deviationCorridor <- ifelse(lsaData$methValue >=          lsaData$lower & lsaData$methValue <= lsaData$upper, 0,          ifelse(lsaData$methValue < lsaData$lower, lsaData$methValue -              lsaData$lower, lsaData$methValue - lsaData$upper))     return(lsaData) }",data cleaning,510335135739297e8,430
"evalRes <- function(x) {     tmp <- aggregate(abs(deviationCorridor) ~ datasetName, x,          mean, na.rm = TRUE)     tmp <- sort(structure(tmp[, 2], names = tmp[, 1]))     x <- as.numeric(tmp)     y <- as.numeric(referenceValues[names(tmp)])     res <- list(mean = mean(x, na.rm = TRUE), pearson = cor(x,          y, method = ""pearson"", use = ""pairwise""), spearman = cor(x,          y, method = ""spearman"", use = ""pairwise""), best = names(tmp)[1],          worst = names(tmp)[length(tmp)])     for (deltaN in 1:floor(length(x)/2)) {         top <- x[1:deltaN]         bot <- x[(length(x) - deltaN + 1):length(x)]         res[[paste0(""delta"", deltaN)]] <- mean(top) - mean(bot)     }     append(res, tmp) }",data cleaning,510335135739297e8,430
"runAnalysisTrial <- function(corridorMinAssayTypes, corridorExtension) {     message(""corridorMinAssayTypes = "", corridorMinAssayTypes,          "", corridorExtension = "", corridorExtension)     curData <- prepData(corridorMinAssayTypes = corridorMinAssayTypes,          corridorExtension = corridorExtension)     curData <- curData[, c(""datasetName"", ""deviationCorridor"")]     evalRes(curData) }",data cleaning,510335135739297e8,430
library(gdata),setup,944559750379994e8,434
pseResults <- list(),data cleaning,510335135739297e8,430
library(tidyverse),evaluation,944559750379994e8,434
"for (minAssayTypeNum in parRanges$minAssayTypeNumValues) {     pseResults[[as.character(minAssayTypeNum)]] <- list()     for (corridorExt in parRanges$corridorExtValues) {         message(""corridorMinAssayTypes = "", minAssayTypeNum,              "", corridorExtension = "", corridorExt)         curData <- prepData(corridorMinAssayTypes = minAssayTypeNum,              corridorExtension = corridorExt)         e <- evalRes(curData[, c(""datasetName"", ""deviationCorridor"")])         pseResults[[as.character(minAssayTypeNum)]][[as.character(corridorExt)]] <- e     } }",exploratory,510335135739297e8,430
ggData <- melt(pseResults),data cleaning,510335135739297e8,430
"colnames(ggData) <- c(""value"", ""metric"", ""corridorExtValues"",      ""minAssayTypeNumValues"")",data cleaning,510335135739297e8,430
"ggData$corridorExtValues <- factor(as.numeric(ggData$corridorExtValues)/2,      levels = parRanges$corridorExtValues/2)",data cleaning,510335135739297e8,430
"ggData$minAssayTypeNumValues <- factor(ggData$minAssayTypeNumValues,      levels = parRanges$minAssayTypeNumValues)",data cleaning,510335135739297e8,430
"ggData2 <- ggData[ggData$metric %in% datasetNames, ]",data cleaning,510335135739297e8,430
ggData2$value <- as.numeric(ggData2$value),data cleaning,510335135739297e8,430
ggData2$corridorExtValues <- as.numeric(as.character(ggData2$corridorExtValues)),data cleaning,510335135739297e8,430
library(gdata),setup,324950942071155e8,434
"ggData2$minAssayTypeNumValues <- paste(""Min. assay types: "",      ggData2$minAssayTypeNumValues)",data cleaning,510335135739297e8,430
library(tidyverse),setup,324950942071155e8,434
"ggData2$datasetName <- factor(ggData2$metric, levels = names(sort(referenceValues)),      labels = datasetTable[names(sort(referenceValues)), ""prettyLabel""])",data cleaning,510335135739297e8,430
"trm_mixed_100d <- data.frame(chromosome = dir(), size = humanReadable(file.size(dir())),      stringsAsFactors = FALSE)",import,324950942071155e8,434
"trm_mixed_100d <- trm_mixed_100d %>% mutate(chromosome = str_replace(chromosome,      "".res"", """")) %>% separate(chromosome, c(""chr"", ""genome"",      ""disease"", ""outcome""), sep = ""_"") %>% arrange(genome, chr) %>%      mutate(chr = as.double(chr), size = trimws(size)) %>% separate(size,      c(""size"", ""size_unit""), sep = "" "") %>% mutate(size = as.double(size)) %>%      as_tibble()",data cleaning,324950942071155e8,434
"refDispData <- data.frame(corridorExtValues = CORRIDOR_EXTENSION,      minAssayTypeNumValues = paste(""Min. assay types: "", CORRIDOR_MIN_NUM_ASSAY_TYPES),      datasetName = datasetTable[names(referenceValues), ""prettyLabel""],      value = referenceValues)",data cleaning,510335135739297e8,430
"log_files <- dir(path = ""/projects/rpci/lsuchest/abbasriz/DBMT_100d/analyses/mixed/log"",      pattern = "".err"", full.names = TRUE)",import,324950942071155e8,434
"d <- ggplot(ggData2, aes(datasetName, value, group = corridorExtValues,      color = corridorExtValues)) + facet_grid(~minAssayTypeNumValues) +      geom_line() + defaultPlotTheme(flipX = TRUE, fontSize = 8) +      annotate(""segment"", x = -Inf, xend = Inf, y = -Inf, yend = -Inf) +      annotate(""segment"", x = -Inf, xend = -Inf, y = -Inf, yend = Inf) +      xlab(""Dataset (ordered by average absolute deviation with default corridor parameters)"") +      ylab(""Average abs. deviation from corridor"") + scale_color_gradient2(low = ""#ffeda0"",      mid = ""#31a354"", high = ""#002200"", midpoint = 12.5) + geom_line(data = refDispData,      color = ""red"")",visualization,510335135739297e8,430
"pull_times <- function(log_files) {     pulled_times <- system(sprintf(""awk '$1 == \""Analysis\"" {print $0}' %s"",          log_files), intern = TRUE)     dates <- pulled_times %>% str_extract(""[0-9]+-[0-9]+-[0-9]+"")     times <- pulled_times %>% str_extract(""[0-9]+:[0-9]+:[0-9]+"")     start_finish <- as.POSIXct(paste(dates, times), format = ""%Y-%m-%d %H:%M:%S"")     as.double(difftime(start_finish[2], start_finish[1], units = ""min"")) }",data cleaning,324950942071155e8,434
"svgPlotGG(d, ""sensitivity_2b_lines"", 22, 8, units = ""cm"")",export,510335135739297e8,430
"run_times <- sapply(log_files, pull_times)",data cleaning,324950942071155e8,434
"res <- data.frame(files = names(run_times), mins = as.double(run_times),      stringsAsFactors = FALSE) %>% mutate(time_units = ""min"")",data cleaning,324950942071155e8,434
"res$files <- res$files %>% str_split(pattern = ""/"") %>% map_chr(c(10,      1)) %>% str_replace("".err"", """")",data cleaning,324950942071155e8,434
"res <- res %>% separate(files, c(""jobid"", ""analysis""), sep = ""_"",      extra = ""merge"") %>% group_by(analysis, time_units) %>% summarize(time = sum(mins,      na.rm = TRUE)) %>% ungroup() %>% separate(analysis, c(""chr"",      ""genome"", ""disease"", ""outcome""), sep = ""_"") %>% mutate(chr = as.double(chr))",data cleaning,324950942071155e8,434
"ggData2 <- ggData[ggData$metric %in% c(""best"", ""worst""), ]",data cleaning,510335135739297e8,430
"times_collected <- res %>% right_join(trm_mixed_100d) %>% select(chr,      genome, disease, outcome, time, time_units, size, size_unit) %>%      arrange(genome, chr)",data cleaning,324950942071155e8,434
"ggData2$assayGroup <- datasetTable[as.character(ggData2$value),      ""assayGroup""]",data cleaning,510335135739297e8,430
"ggData2$prettyLabel <- datasetTable[as.character(ggData2$value),      ""prettyLabel""]",data cleaning,510335135739297e8,430
"ggData2$metric <- factor(ggData2$metric, levels = c(""best"", ""worst""),      labels = c(""Best (lowest average abs. deviation)"", ""Worst (highest average abs. deviation)""))",data cleaning,510335135739297e8,430
"d <- ggplot(ggData2, aes(corridorExtValues, minAssayTypeNumValues)) +      geom_tile(aes(fill = assayGroup), colour = ""white"") + scale_fill_manual(values = plotColLookup$assayGroup,      guide = FALSE) + geom_text(aes(label = prettyLabel), family = ""Arial"",      colour = ""black"", size = 2.6) + ylab(""Min. number of assay types in corridor"") +      xlab(""Corridor extension (+/- X%)"") + coord_flip() + facet_grid(metric ~      ., scales = ""free"", margins = F) + theme_bw() + theme(panel.grid.major = element_blank(),      panel.grid.minor = element_blank(), panel.border = element_blank(),      panel.margin = unit(0, ""lines""), axis.title = element_text(size = 8,          face = ""bold""), axis.text.y = element_text(hjust = 1,          vjust = 0.5, size = 8), axis.text.x = element_text(hjust = 1,          vjust = 0.5, size = 8), axis.ticks = element_blank(),      strip.background = element_blank(), strip.text = element_text(size = 8,          face = ""bold""))",visualization,510335135739297e8,430
"svgPlotGG(d, ""sensitivity_2b_bestworst"", 11, 14, units = ""cm"")",export,510335135739297e8,430
library(lattice),setup,324950942071155e8,434
library(latticeExtra),setup,324950942071155e8,434
library(gridExtra),setup,324950942071155e8,434
library(ggplot2),setup,324950942071155e8,434
library(reshape2),setup,324950942071155e8,434
"myLHS <- LHS(model = function(X) {     print(X)     return(mcmapply(function(a, b) {         runAnalysisTrial(a, b)     }, round(X[, 1]), X[, 2], mc.cores = 16)) }, factors = names(parRanges), N = 1000, q = c(""qunif"", ""qunif""),      q.arg = lapply(parRanges, function(x) list(min = min(x),          max = max(x))), nboot = 50)",data cleaning,510335135739297e8,430
library(plyr),setup,324950942071155e8,434
"defRun <- runAnalysisTrial(CORRIDOR_MIN_NUM_ASSAY_TYPES, CORRIDOR_EXTENSION)",modeling,510335135739297e8,430
"multiplot <- function(..., plotlist = NULL, file, cols = 1, layout = NULL) {     require(grid)     plots <- c(list(...), plotlist)     numPlots = length(plots)     if (is.null(layout)) {         layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),              ncol = cols, nrow = ceiling(numPlots/cols))     }     if (numPlots == 1) {         print(plots[[1]])     }     else {         grid.newpage()         pushViewport(viewport(layout = grid.layout(nrow(layout),              ncol(layout))))         for (i in 1:numPlots) {             matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))             print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,                  layout.pos.col = matchidx$col))         }     } }",exploratory,324950942071155e8,434
resNames <- names(defRun),data cleaning,510335135739297e8,430
"ggData <- data.frame(get.data(myLHS), as.data.frame(get.results(myLHS,      get.mean = FALSE)))",data cleaning,510335135739297e8,430
"colnames(ggData) <- c(""Min. number of assay types in corridor"",      ""Corridor extension (+/- X%)"", resNames)",data cleaning,510335135739297e8,430
"ggData[, 1] <- round(ggData[, 1])",data cleaning,510335135739297e8,430
"ggData[, 2] <- ggData[, 2]/2",data cleaning,510335135739297e8,430
"ggData[, -(1:2)] <- apply(ggData[, -(1:2)], 2, unlist)",data cleaning,510335135739297e8,430
"plot3d <- function(res, geno, phen, z = -45) {     a <- tapply(phen[, res$probeid], list(geno[, res$pos1], geno[,          res$pos2]), function(x) mean(x, na.rm = T))     a <- a - min(a, na.rm = T)     b <- table(geno[, res$pos1], geno[, res$pos2])     print(b)     p <- cloud(a, panel.3d.cloud = panel.3dbars, col = ""black"",          col.facet = c(""#e5f5e0"", ""#A1D99B"", ""#31A354""), xbase = 0.6,          ybase = 0.6, xlab = ""SNP1"", ylab = ""SNP2"", zlab = ""y"",          default.scales = list(arrows = F), screen = list(z = z,              x = -60, y = 3), main = paste(res$chr1, res$chr2))     return(list(a, b, p)) }",visualization,324950942071155e8,434
"ggData <- melt(ggData, id.vars = c(""Min. number of assay types in corridor"",      ""Corridor extension (+/- X%)""))",data cleaning,510335135739297e8,430
"ggData2 <- ggData[ggData$variable %in% c(""mean"", ""pearson"", ""spearman""),      ]",data cleaning,510335135739297e8,430
ggData2$value <- as.numeric(ggData2$value),data cleaning,510335135739297e8,430
"plot3dGp <- function(gp, title = """", snp1 = ""SNP1"", snp2 = ""SNP2"",      z = -45) {     p <- cloud(gp, panel.3d.cloud = panel.3dbars, col = ""black"",          col.facet = c(""#e5f5e0"", ""#A1D99B"", ""#31A354""), xbase = 0.6,          ybase = 0.6, xlab = snp1, ylab = snp2, zlab = ""y"", default.scales = list(arrows = F),          screen = list(z = z, x = -60, y = 3), main = title) }",visualization,324950942071155e8,434
"ggData2$variable <- factor(ggData2$variable, levels = c(""mean"",      ""pearson"", ""spearman""), labels = c(""Average abs. deviation"",      ""Pearson correlation vs. default"", ""Spearman correlation vs. default""))",data cleaning,510335135739297e8,430
"plot3dProbe <- function(res, pg, geno, phen, z = 45) {     a <- subset(res, probegene == pg)     l <- list()     for (i in 1:nrow(a)) {         l[[i]] <- plot3d(a[i, ], xmat, resphen, z)[[3]]     }     do.call(grid.arrange, l) }",visualization,324950942071155e8,434
"ylims <- c(10, 1, 1)",data cleaning,510335135739297e8,430
"subSigPg <- function(pg, s = sig) {     return(subset(s, probegene == pg)) }",data cleaning,324950942071155e8,434
"for (i in 1:length(levels(ggData2$variable))) {     d <- ggplot(ggData2[ggData2$variable == levels(ggData2$variable)[i],          ], aes(`Min. number of assay types in corridor`, value,          color = `Corridor extension (+/- X%)`)) + geom_point(size = 0.8) +          ylab(levels(ggData2$variable)[i]) + defaultPlotTheme() +          scale_color_gradient2(low = ""#ffeda0"", mid = ""#31a354"",              high = ""#002200"", midpoint = mean(ggData$`Corridor extension (+/- X%)`),              guide = guide_colorbar(title = ""Colors:"", direction = ""horizontal"")) +          ylim(0, ylims[i]) + theme(panel.grid.major = element_line(color = ""lightgray"",          linetype = 2), panel.grid.major.x = element_blank()) +          geom_point(x = CORRIDOR_MIN_NUM_ASSAY_TYPES, y = as.numeric(defRun[i]),              color = ""red"", size = 4, pch = 4)     svgPlotGG(d, paste0(""sensitivity_lhs_byminassay_"", i), 10,          7, units = ""cm"")     d <- ggplot(ggData2[ggData2$variable == levels(ggData2$variable)[i],          ], aes(`Corridor extension (+/- X%)`, value, color = as.factor(`Min. number of assay types in corridor`))) +          geom_point(size = 0.8) + ylim(0, ylims[i]) + ylab(levels(ggData2$variable)[i]) +          defaultPlotTheme() + scale_color_manual(values = c(""#018571"",          ""#AAD6CF"", ""#EFB3D8"", ""#D01C8B""), guide = guide_legend(title = ""Colors:"",          direction = ""horizontal"")) + theme(panel.grid.major = element_line(color = ""lightgray"",          linetype = 2), panel.grid.major.x = element_blank()) +          geom_point(x = CORRIDOR_EXTENSION/2, y = as.numeric(defRun[i]),              color = ""red"", size = 4, pch = 4)     svgPlotGG(d, paste0(""sensitivity_lhs_bycorridorext_"", i),          12, 7, units = ""cm"") }",visualization,510335135739297e8,430
"plot3dHairballs <- function(sig, pg, cissnp, resphen, xmat, bim,      z = 45) {     s <- subset(sig, probegene == pg)     pn <- s$probename[1]     snps <- unique(c(s$snp1, s$snp2))     stopifnot(cissnp %in% snps)     tsnps <- snps[!snps %in% cissnp]     x1 <- xmat[, match(cissnp, bim$V2)]     x <- xmat[, match(tsnps, bim$V2)]     y <- resphen[, match(pn, colnames(resphen))]     temp1 <- subset(s, select = c(snp1, chr1))     temp2 <- subset(s, select = c(snp2, chr2))     names(temp1) <- names(temp2) <- c(""snp"", ""chr"")     chrkey <- rbind(temp1, temp2)     chrkey <- subset(chrkey, !duplicated(snp))     l <- list()     for (i in 1:ncol(x)) {         print(table(x1, x[, i]))         gp <- tapply(y, list(x1, x[, i]), function(x) mean(x,              na.rm = T))         gp <- gp - min(gp, na.rm = T)         print(gp)         title <- paste(""Chromosome"", subset(chrkey, snp == cissnp)$chr,              ""x"", subset(chrkey, snp == tsnps[i])$chr)         l[[i]] <- plot3dGp(gp, title, cissnp, tsnps[i], z)     }     do.call(grid.arrange, l) }",visualization,324950942071155e8,434
"load(""~/repo/eQTL-2D/analysis/interaction_list_replication_summary.RData"")",import,324950942071155e8,434
"load(""~/repo/eQTL-2D/data/residuals_all.RData"")",import,324950942071155e8,434
"load(""~/repo/eQTL-2D/data/clean_geno_final.RData"")",import,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/TMEM149.pdf"", width = 20,      height = 20)",export,324950942071155e8,434
"plot3dHairballs(sig, ""TMEM149"", ""rs8106959"", resphen, xmat, bim,      z = -45)",visualization,324950942071155e8,434
"PPTA.design <- function(A, X, M = 1000) {     library(MCMCpack)     n = length(A)     k = ncol(as.matrix(X))     ps.mcmc = MCMClogit(A ~ X, burnin = 1000, mcmc = M)     ps = matrix(NA, n, M)     ppta = matrix(NA, n, M)     S = S.grid = matrix(NA, n, M)     for (i in 1:M) {         ps[, i] = plogis(model.matrix(A ~ X) %*% ps.mcmc[i, ])         ppta[, i] = rbinom(n, 1, ps[, i])         S[, i] = ppta[, i] != A     }     out = list(ps.mcmc = ps.mcmc, ps = ps, ppta = ppta, S = S,          A = A, M = M)     class(out) = ""PPTA.design""     return(out) }",modeling,510335135739297e8,430
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/MBNL1.pdf"", width = 20, height = 20)",export,324950942071155e8,434
"PPTA.analysis <- function(Y, out, Qburn = 10, Q = 10, outcome.dist = ""guassian"") {     library(MCMCpack)     if (class(out) != ""PPTA.design"") {         stop(""out is not a PPTA.design object"")     }     n = length(Y)     M = out$M     A = out$A     S = out$S     seeds = abs(round(rnorm(M) * 1e+05) + 1)     if (outcome.dist == ""gaussian"") {         out.mcmc = array(NA, c(Q, 3, M))         out.freq = matrix(NA, M, 2)         for (i in 1:M) {             out.mcmc[, , i] = MCMCregress(Y[S[, i]] ~ A[S[, i]],                  burnin = Qburn, mcmc = Q, seed = seeds[i])             freqmod = lm(Y[S[, i]] ~ A[S[, i]])             out.freq[i, 1] = freqmod$coefficients[2]             out.freq[i, 2] = vcov(freqmod)[2, 2]         }     }     if (outcome.dist == ""binomial"") {         out.mcmc = array(NA, c(Q, 2, M))         out.freq = matrix(NA, M, 2)         for (i in 1:M) {             out.mcmc[, , i] = MCMClogit(Y[S[, i]] ~ A[S[, i]],                  burnin = Qburn, mcmc = Q, seed = seeds[i])             freqmod = glm(Y[S[, i]] ~ A[S[, i]], family = ""binomial"")             out.freq[i, 1] = freqmod$coefficients[2]             out.freq[i, 2] = vcov(freqmod)[2, 2]         }     }     if (outcome.dist == ""poisson"") {         out.mcmc = out.mcmc.grid = array(NA, c(Q, 2, M))         out.freq = matrix(NA, M, 2)         for (i in 1:M) {             out.mcmc[, , i] = MCMCpoisson(Y[S[, i]] ~ A[S[, i]],                  burnin = Qburn, mcmc = Q, seed = seeds[i])             freqmod = glm(Y[S[, i]] ~ A[S[, i]], family = ""poisson"")             out.freq[i, 1] = freqmod$coefficients[2]             out.freq[i, 2] = vcov(freqmod)[2, 2]         }     }     out = list(mcmc = out.mcmc, MLE = out.freq)     class(out) = ""PPTA.analysis""     return(out) }",modeling,510335135739297e8,430
"plot3dHairballs(sig, ""MBNL1"", ""rs13069559"", resphen, xmat, bim,      z = -45)",visualization,324950942071155e8,434
"plot.PPTA.design <- function(x, y, type = ""balance"") {     library(ggplot2)     if (type == ""balance"") {         m = nrow(x$ps.mcmc)         bal.ppta = numeric(m)         bal.grid = numeric(m)         for (i in 1:m) {             index = x$S[, i] == 1             bal.ppta[i] = diff(tapply(y[index], x$A[index], mean))         }         d = data.frame(Iteration = 1:m, balance = bal.ppta, estimator = ""PPTA"")         ggplot(data = d, aes(Iteration, balance)) + geom_line() +              facet_grid(estimator ~ .)     } }",visualization,510335135739297e8,430
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/CAST.pdf"", width = 20, height = 20)",export,324950942071155e8,434
"home <- Sys.getenv(""HOME"")",setup,510335135739297e8,430
"plot3dHairballs(sig, ""CAST"", ""rs7733671"", resphen, xmat, bim,      z = 45)",visualization,324950942071155e8,434
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/TRAPPC5.pdf"", width = 20,      height = 20)",export,324950942071155e8,434
"plot3dHairballs(sig, ""TRAPPC5"", ""rs17159840"", resphen, xmat,      bim, z = 45)",visualization,324950942071155e8,434
"projectDir <- paste(home, ""/work/research/researchProjects/encode/encode-manager"",      sep = """")",setup,510335135739297e8,430
setwd(projectDir),setup,510335135739297e8,430
getwd(),setup,510335135739297e8,430
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/HMBOX1.pdf"", width = 15,      height = 15)",export,324950942071155e8,434
"getFullPath <- function(projectPath) {     paste(projectDir, projectPath, sep = ""/"") }",setup,510335135739297e8,430
"exportAsTable <- function(df, file) {     write.table(df, file = file, quote = FALSE, row.names = FALSE,          sep = ""\t"") }",export,510335135739297e8,430
"plot3dProbe(sig, ""HMBOX1"", xmat, resphen)",visualization,324950942071155e8,434
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/NAPRT1.pdf"", width = 15,      height = 15)",export,324950942071155e8,434
"clear <- function(save.vec = c()) {     ls.vec <- ls(globalenv())     del.vec <- setdiff(ls.vec, c(save.vec, ""clear""))     rm(list = del.vec, pos = globalenv()) }",data cleaning,510335135739297e8,430
"plot3dHairballs(sig, ""NAPRT1"", ""rs2123758"", resphen, xmat, bim,      z = -45)",visualization,324950942071155e8,434
dev.off(),evaluation,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/ADK.pdf"", width = 15, height = 15)",export,324950942071155e8,434
"readInTable <- function(file) read.table(file = file, stringsAsFactors = FALSE,      header = TRUE)",import,510335135739297e8,430
"plot3dProbe(sig, ""ADK"", xmat, resphen)",evaluation,324950942071155e8,434
dev.off(),evaluation,324950942071155e8,434
"source(paste(home, ""/work/research/researchProjects/encode/encode-manager/analysis/rnaSeq/exprLib.R"",      sep = """"))",import,510335135739297e8,430
"source(paste(home, ""/work/research/researchProjects/encode/encode-manager/analysis/getENSGfromBiomartByRefseq.R"",      sep = """"))",import,510335135739297e8,430
"source(paste(home, ""/work/research/researchProjects/encode/encode-manager/analysis/rnaSeq/pcaAnalysisWOoutlier.R"",      sep = """"))",import,510335135739297e8,430
"makeHrSnpList <- function(sig, filename) {     hr <- unique(c(sig$snp1, sig$snp2))     write.table(hr, file = filename, row = F, col = F, qu = F) }",export,324950942071155e8,434
"getTrainFromY <- function(y, ratio) {     totalCount <- length(y)     first.second <- c(which(y == 1)[1], which(y == 1)[2])     train = sample((1:totalCount)[-first.second], (totalCount -          2) * ratio)     c(first.second[1], train) }",data cleaning,510335135739297e8,430
"readHrResults <- function(filename) {     hr2 <- scan(filename, what = character(), na.strings = ""."")     h <- hr2[1:31]     hr2 <- hr2[-c(1:31)]     hr2 <- as.data.frame(matrix(hr2, ncol = 31, byrow = T), stringsAsFactors = FALSE)     names(hr2) <- h     hr2$r2 <- as.numeric(hr2$r2)     hr2$chr <- as.numeric(hr2$chr)     hr2$pos <- as.numeric(hr2$pos)     hr2$is_query_snp <- as.numeric(hr2$is_query_snp) * -1     hr2 <- hr2[order(hr2$chr, hr2$pos), ]     return(hr2) }",import,324950942071155e8,434
getLevels <- function(x) {     length(levels(factor(x))) },exploratory,510335135739297e8,430
"calcAUC <- function(prob, label) {     AUC <- NA     if (!identical(getLevels(label), 2)) {         return(NA)     }     AUC <- try({         (performance(prediction(predictions = prob, labels = label),              ""auc""))@y.values[[1]]     })     if (""try-error"" %in% class(AUC)) {         NA     }     else {         AUC     } }",modeling,510335135739297e8,430
"getRsGene <- function(hr, sig) {     a <- subset(hr2, is_query_snp == 1)     a$GENCODE_name     a <- subset(a, select = c(rsID, GENCODE_name))     head(sig)     sig <- merge(sig, a, by.x = ""snp1"", by.y = ""rsID"", all.x = T)     sig <- merge(sig, a, by.x = ""snp2"", by.y = ""rsID"", all.x = T,          suff = c(1, 2))     return(sig) }",data cleaning,324950942071155e8,434
"getProbeGeneList <- function(sig, pg) {     a <- subset(sig, probegene == pg)     print(with(a, table(c(probegene, GENCODE_name1, GENCODE_name2))))     genelist <- with(a, unique(c(probegene, GENCODE_name1, GENCODE_name2)))     for (i in 1:length(genelist)) {         cat(genelist[i], ""\n"")     } }",data cleaning,324950942071155e8,434
"getPcaData = function(exprCols = 2:33) {     combined.in.file = getFullPath(""data/combinedExprWithStats_transEachSample.tab"")     combined.in.file = getFullPath(""data/combinedExprWithStats_transEachSample.tab"")     lnc.in.file = getFullPath(""data/lncExprWithStats_transEachSample.tab"")     lnc.colIndex = exprCols     lnc.expr = readInTable(lnc.in.file)     lnc.expr$gene_id_short <- sapply(lnc.expr$gene_id, function(x) {         as.vector(strsplit(x, ""\\."")[[1]])[1]     })     func.df <- getEnslist()     normalizePcaFactorsFromLoadingForRatioTestLocal <- function(pca,          lncDataFrame, exprCols) {         lncDataFrame[exprCols] = transformDataByPCA(df = lncDataFrame[,              exprCols], pca = pca)         colnames(lncDataFrame)[exprCols] = paste0(""Comp."", seq_along(exprCols))         lncDataFrame     }     func.df <- within(func.df, {         gene_id_short = ensembl_gene_id         gene_id = gene_id_short         lncRnaName = external_gene_id     })     f.df <- getAnnotLncDf(lncDf = lnc.expr, annotDf = func.df,          exprCol = 2:33, annotColName = ""lncRnaName"")     f.df[[""lncRnaName""]] = ifelse(f.df$lncRnaName == ""notFound"",          f.df$gene_id_short, f.df$lncRnaName)     r1.vec = c(""MALAT1"", ""H19"", ""RP11-255B23.3"")     r2.vec = c(""ENSG00000235162"", ""ENSG00000228474"", ""ENSG00000175061"",          ""DANCR"", ""SNGG1"", ""ZFAS1"", ""ENSG00000249790"", ""ENSG00000256329"",          ""ENSG00000235162"", ""ENSG00000228474"", ""ENSG00000249532"",          ""ENSG00000249502"", ""MALAT1"", ""H19"", ""RP11-255B23.3"")     comb.df <- getAnnotLncDf(lncDf = lnc.expr, annotDf = f.df,          exprCol = 2:33, annotColName = ""lncRnaName"")     lncDf.reduced.2 <- f.df[which(!f.df$lncRnaName %in% r2.vec),          ]     lnc.pca <- princomp(lncDf.reduced.2[exprCols], cor = FALSE)     exprCols = 2:33     lnc.pca.factors.r2.full <- normalizePcaFactorsFromLoadingForRatioTestLocal(pca = lnc.pca,          lncDataFrame = comb.df, exprCols = exprCols)     pca.df <- lnc.pca.factors.r2.full[exprCols]     pca.df[[""label""]] = ifelse(f.df[[""withinSubset""]] == ""false"",          0, 1)     pca.df }",modeling,510335135739297e8,430
"hr2 <- readHrResults(""HaploReg_results.txt"")",import,324950942071155e8,434
sigmoid <- function(x) {     1/(1 + exp(-1 * x)) },modeling,510335135739297e8,430
"mbnl1 <- subset(sig, probegene == ""MBNL1"")",data cleaning,324950942071155e8,434
"costFunction <- function(X, y, thetaVec, k) {     theta = matrix(thetaVec, k, k)     xTx = apply(X, 1, function(row) t(row) %*% theta %*% row)     sig = sigmoid(xTx)     z1 = ifelse(y == 1, -log(sig), -log(1 - sig))     z2 = ifelse(z1 == Inf, 0, z1)     sum(z2) }",modeling,510335135739297e8,430
"ms <- unique(c(mbnl1$snp1, mbnl1$snp2))",data cleaning,324950942071155e8,434
"a <- subset(hr2, rsID %in% ms)",data cleaning,324950942071155e8,434
plot(log(diff(hr2$pos)[diff(hr2$pos) > 0])),visualization,324950942071155e8,434
"cfLambda_old <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) {             t(row) %*% theta %*% row         })         sig = abs(sigmoid(xTx))         z1 = ifelse(y == 1, -log(sig), -log(1 - sig))         -1/length(y) * sum(ifelse(z1 == Inf, 0, z1))     } }",data cleaning,510335135739297e8,430
"getProbeGeneList(sig, ""TMEM149"")",import,324950942071155e8,434
"cfLambdaT <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) {             t(row) %*% theta %*% row         })         sig = sigmoid(xTx)         z1 = ifelse(y == 1, log(sig), -log(exp(xTx) + 1))         -1/length(y) * sum(ifelse(z1 == -Inf, 0, z1))     } }",data cleaning,510335135739297e8,430
"getProbeGeneList(sig, ""MBNL1"")",exploratory,324950942071155e8,434
"cfLambda <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) {             t(row) %*% theta %*% row         })         sig = sigmoid(xTx)         z1 = ifelse(y == 1, log(sig), log(1 - sig))         -1/length(y) * sum(ifelse(z1 == -Inf, 0, z1))     } }",data cleaning,510335135739297e8,430
"getProbeGeneList(sig, ""CAST"")",exploratory,324950942071155e8,434
"getProbeGeneList(sig, ""TRAPPC5"")",exploratory,324950942071155e8,434
"getProbeGeneList(sig, ""NAPRT1"")",exploratory,324950942071155e8,434
"cfLambdaReg <- function(X, y, k, lambda) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) {             t(row) %*% theta %*% row         })         sig = sigmoid(xTx)         z1 = ifelse(y == 1, log(sig), -log(exp(xTx) + 1))         -1/length(y) * sum(ifelse(z1 == -Inf, 0, z1)) + (lambda/(2 *              length(y))) * sum(thetaVec^2)         -1/length(y) * sum(ifelse(z1 == -Inf, 0, z1)) + (lambda/(2 *              length(y))) * sum(c(0, thetaVec[-1])^2)     } }",data cleaning,510335135739297e8,430
"cfLambdaIterate <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) t(row) %*% theta %*%              row)         sig = sigmoid(xTx)         cost = 0         for (row in 1:length(y)) {             tmp = y[row] * log(sig[row]) + (1 - y[row]) * log(1 -                  sig[row])             cost = cost + tmp         }         cost * (-1/length(y))     } }",data cleaning,510335135739297e8,430
"gradFunction <- function(X, y, thetaVec) {     theta = matrix(thetaVec, k)     xTx = apply(X, 1, function(row) t(row) %*% theta %*% row)     sig = sigmoid(xTx)     s1 = sum(y - sig)     (1 * length(y)) * as.vector(unlist(numcolwise(mean)(as.data.frame(t(apply(X,          1, function(x) {             x %*% t(x)         })))) * dim(X)[1])) + s1 }",modeling,510335135739297e8,430
"cumTransAlleles <- function(sig, pg, cissnp, resphen, xmat, bim) {     s <- subset(sig, probegene == pg)     pn <- s$probename[1]     snps <- unique(c(s$snp1, s$snp2))     stopifnot(cissnp %in% snps)     tsnps <- snps[!snps %in% cissnp]     x1 <- xmat[, match(cissnp, bim$V2)]     x <- xmat[, match(tsnps, bim$V2)]     y <- resphen[, match(pn, colnames(resphen))]     x_code <- x     info <- data.frame(tsnps, ref = 2)     for (i in 1:ncol(x)) {         print(table(x1, x[, i]))         gp <- tapply(y, list(x1, x[, i]), function(x) mean(x,              na.rm = T))         print(gp)         print(info$ref[i] <- ifelse(gp[1, 3] > gp[3, 3], 0, 2))         if (info$ref[i] == 0) {             x_code[, i] <- -1 * (x_code[, 1] - 1) + 1         }     }     x_code <- apply(x_code, 1, sum)     l <- list()     l$gp <- tapply(y, list(x1, x_code), function(x) mean(x, na.rm = T))     l$count <- table(list(x1, x_code))     l$se <- tapply(y, list(x1, x_code), function(x) sd(x, na.rm = T))/sqrt(l$count)     return(l) }",modeling,324950942071155e8,434
"gfLambda <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) t(row) %*% theta %*%              row)         sig = sigmoid(xTx)         s1 = sum(sig - y)         (1/length(y)) * (as.vector(unlist(numcolwise(mean)(as.data.frame(t(apply(X,              1, function(x) {                 x %*% t(x)             })))) * dim(X)[1])) * s1)     } }",modeling,510335135739297e8,430
"gfLambdaT <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) t(row) %*% theta %*%              row)         sig = sigmoid(xTx)         s1 = sum(sig - y)         (1/length(y)) * matrix(apply(X, 1, function(x) {             as.vector(tcrossprod(x))         }) %*% (sig - y), k)     } }",modeling,510335135739297e8,430
"gfLambdaReg <- function(X, y, k, lambda) {     function(thetaVec) {         theta = matrix(thetaVec, k)         regTheta = theta * (lambda/length(y))         regTheta[1, 1] = 0         xTx = apply(X, 1, function(row) t(row) %*% theta %*%              row)         sig = sigmoid(xTx)         s1 = sum(sig - y)         (1/length(y)) * matrix(apply(X, 1, function(x) {             as.vector(tcrossprod(x))         }) %*% (sig - y), k) + regTheta     } }",modeling,510335135739297e8,430
"cta <- cumTransAlleles(sig, ""TMEM149"", ""rs8106959"", resphen,      xmat, bim)",modeling,324950942071155e8,434
a <- melt(cta$gp),data cleaning,324950942071155e8,434
"gfLambdaIterate <- function(X, y, k) {     function(thetaVec) {         theta = matrix(thetaVec, k)         xTx = apply(X, 1, function(row) t(row) %*% theta %*%              row)         sig = sigmoid(xTx)         outMat = matrix(rep(0, k * k), k)         for (j in 1:k) {             for (i in 1:k) {                 tmp <- 0                 for (row in 1:length(y)) {                   xxTLocal <- X[row, i] * X[row, j]                   tmp <- tmp + (sig[row] - y[row]) * xxTLocal                 }                 outMat[i, j] <- tmp             }         }         outMat * (1/length(y))     } }",modeling,510335135739297e8,430
b <- melt(cta$se),data cleaning,324950942071155e8,434
a$se <- b$value,evaluation,324950942071155e8,434
"filterXbyOptimTheta <- function(X, thetaVec, k) {     theta = matrix(thetaVec, k)     guess = apply(X, 1, function(row) t(row) %*% matrix(thetaVec,          k) %*% row)     o <- optim(fn = cfLamda(X, y, k), par = runif(k * k), method = ""CG"")     X = as.matrix(lnc.pca.df[1:n, 1:k - 1])     X = cbind(rep(1, dim(X)[1]), X)     y = as.matrix(lnc.pca.df[1:n, 33])     guess = apply(X, 1, function(row) t(row) %*% matrix(o$par,          k) %*% row)     df <- data.frame(x = guess, ellipse = guess, y = y, label = y)     ggplot(df, aes(x = log(x), fill = factor(y))) + geom_density(alpha = I(0.6))     df.plot <- plotDistanceAwayRatio(df, label = y)     ggplot(df.plot, aes(y = prec, x = sens)) + geom_point() +          xlim(0, 1) + ylim(0, 1) + theme_bw() + geom_smooth() }",modeling,510335135739297e8,430
"ggplot(a, aes(x = Var2, y = value)) + geom_line() + facet_grid(Var1 ~      .) + geom_errorbar(aes(ymax = value + se, ymin = value -      se))",visualization,324950942071155e8,434
"filterXbyOptimTheta_getGuess <- function(X, thetaVec, k) {     theta = matrix(thetaVec, k)     guess = apply(X, 1, function(row) t(row) %*% matrix(thetaVec,          k) %*% row) }",modeling,510335135739297e8,430
"sigb <- subset(sig, pnest_egcut > -log10(0.05/380) | pnest_fehr >      -log10(0.05/380))",data cleaning,324950942071155e8,434
"pdf(""~/repo/eQTL-2D/analysis/images/ADK.pdf"", width = 15, height = 15)",export,324950942071155e8,434
"plotDistanceAwayRatio <- function(df, label, exprCols, df.center = suppressMessages(melt(ddply(df[exprCols],      .(), numcolwise(mean)))[[""value""]]), rand = FALSE, ellipse = TRUE) {     df[[""withinSubset""]] = label     if (rand == TRUE) {         df[[""rand""]] = runif(length(df[[""withinSubset""]]))         df[[""withinSubset""]] = df[order(df[[""rand""]]), ""withinSubset""]     }     if (ellipse == TRUE) {         df[[""dist""]] = df[[""ellipse""]]     }     else {         df[[""dist""]] = apply(df[exprCols], 1, function(x) sqrt(sum((x -              df.center)^2)))     }     dfo = df[order(max(df$dist) - df$dist), ]     dfo[[""TP""]] = cumsum(dfo$withinSubset)     dfo[[""predict""]] = seq_along(dfo$withinSubset)     dfo[[""P""]] = sum(dfo$withinSubset)     dfo[[""totalMembers""]] = length(dfo$withinSubset)     dfo[[""N""]] = dfo[[""totalMembers""]] - dfo[[""P""]]     dfo.stats = within(dfo, {         FP = predict - TP         TN = (totalMembers - predict) - (P - TP)         FN = P - TP         sens = TP/(TP + FN)         prec = TP/(TP + FP)         TPR = TP/P         FPR = FP/N         FNR = FN/P         TNR = TN/N         Fscore = (2 * prec * sens)/(prec + sens)         accuracy = (TP + TN)/(P + N)         errorRate = (FP + FN)/(P + N)         label = withinSubset     })     dfo.stats[c(""predict"", ""totalMembers"", ""P"", ""N"", ""TP"", ""FP"",          ""TN"", ""FN"", ""sens"", ""prec"", ""TPR"", ""FPR"", ""FNR"", ""TNR"",          ""Fscore"", ""accuracy"", ""errorRate"", ""dist"", ""label"")] }",visualization,510335135739297e8,430
"plot3dProbe(sig, ""ADK"", xmat, resphen, z = 45)",visualization,324950942071155e8,434
"main <- function() {     lnc.pca.df <- getPcaData()     lnc.pca.df <- lnc.pca.df[order(lnc.pca.df$label, decreasing = TRUE),          ]     k = 8     n = 1500     yCount = length(which(lnc.pca.df$label == 1))     dataSample = c(1:94, sample(94:length(lnc.pca.df$label),          (n - yCount)))     dataSample = 1:n     X = as.matrix(lnc.pca.df[dataSample, 1:k - 1])     X = cbind(rep(1, dim(X)[1]), X)     y = as.matrix(lnc.pca.df[dataSample, 33])     X.full = as.matrix(lnc.pca.df[, 1:k - 1])     X.full = cbind(rep(1, dim(X.full)[1]), X.full)     y.full = as.matrix(lnc.pca.df[, 33])     thetaGuess = runif(k * k)     zeroGuess = rep(0, k * k)     o <- optim(fn = cfLambda(X, y, k), gr = gfLambda(X, y, k),          par = matrix(runif(k * k), k), method = ""CG"")     results.df <- data.frame(trial = 1:100, cost = rep(0, 100))     best.cost = 1e+06     best.theta = matrix(runif(k * k), k)     for (i in 1:20) {         print(i)         local = optim(fn = cfLambda(X, y, k), par = matrix(runif(k *              k), k), method = ""BFGS"")         results.df$trial[i] = i         results.df$cost[i] = local$value         if (local$value < best.cost) {             best.cost = local$value             best.theta = local$par         }     }     dfo = plotDistanceAwayRatio(df = as.data.frame(X.full), label = y.full,          exprCols = 1:k, ellipse = FALSE)     dfo$type = ""circle""     guess = apply(X.full, 1, function(row) t(row) %*% matrix(best.theta,          k) %*% row)     df = data.frame(x = guess, ellipse = guess, y = y.full, label = y.full)     df.plot = plotDistanceAwayRatio(df, label = y.full)     df.plot$type = ""ellipse""     df.random = plotDistanceAwayRatio(df, label = sample(y.full,          length(y.full)))     df.random$type = ""randomLabel""     df.comb = rbind(dfo, df.plot)     ggplot(df.comb, aes(y = prec, x = sens)) + geom_point() +          xlim(0, 1) + ylim(0, 1) + theme_bw() + geom_smooth() +          facet_wrap(~type) + ggtitle(paste(""Log Reg: rows ="",          n, ""cols="", k, ""\nPCA data used""))     ggsave(""~/Desktop/ellipse2.pdf"", height = 4, width = 6)     df.comb.roc = rbind(dfo, df.plot, df.random)     ggplot(df.comb.roc, aes(x = FPR, y = TPR, color = type)) +          geom_line() + geom_point() + theme_bw() + geom_abline(slope = 1) +          ggtitle(""ROC Curve of radius based prediction on pca\n"") +          xlab(""False Positive Rate"") + ylab(""True Positive Rate"")     ggsave(file = ""~/Desktop/ellipse-roc1.pdf"", height = 4, width = 5) }",data cleaning,510335135739297e8,430
dev.off(),evaluation,324950942071155e8,434
"load(""~/repo/eQTL-2D/data/probeinfo_all.RData"")",import,324950942071155e8,434
"load(""~/repo/eQTL-2D/filtering/marginal_lists/marginal_list.RData"")",import,324950942071155e8,434
"runLogReg = function(lncDf, outdir = ""~/Desktop/testPCA"", cols,      iter = 10, debug = FALSE, titleMsg = """", filebase = """") {     k <- length(cols) + 1     n <- dim(lncDf)[1]     if (!file.exists(outdir)) {         dir.create(outdir, recursive = TRUE)     }     makeOutFile <- function(x) {         outfile <- paste(paste(outdir, filebase, sep = ""/""),              x, sep = """")         print(paste(""making"", outfile))         gsub("" "", """", outfile)     }     titleWithBanner <<- function(x) paste(titleMsg, x, sep = ""\n"")     yCount <- length(which(lncDf$label == 1))     X <- as.matrix(lncDf[, cols])     X <- cbind(rep(1, dim(X)[1]), X)     y <- as.matrix(lncDf[, ""label""])     X[, 1] <- 1     thetaGuess <- runif(k * k)     zeroGuess <- rep(0, k * k)     o <- optim(fn = cfLambda(X, y, k), gr = gfLambdaIterate(X,          y, k), par = matrix(runif(k * k), k), method = ""BFGS"")     o$value     o <- optim(fn = cfLambda(X, y, k), gr = gfLambda(X, y, k),          par = matrix(thetaGuess, k), method = ""BFGS"")     results.df <- data.frame(trial = 1:100, cost = rep(0, 100))     best.cost = 1e+06     best.theta = matrix(runif(k * k), k)     for (i in 1:iter) {         print(i)         local = optim(fn = cfLambda(X, y, k), par = matrix(-runif(k *              k), k), method = ""BFGS"")         results.df$trial[i] = i         results.df$cost[i] = local$value         if (local$value < best.cost) {             best.cost = local$value             best.theta = local$par         }     }     if (""o"" %in% ls() && debug == TRUE) {         best.cost = o$value         best.theta = o$par     }     dfo.circle = plotDistanceAwayRatio(df = as.data.frame(X),          label = y, exprCols = 1:k, ellipse = FALSE)     dfo.circle$type = ""circle""     guess = filterXbyOptimTheta_getGuess(X, best.theta, k)     df.ellipse.tmp = data.frame(x = guess, ellipse = guess, y = y,          label = y)     df.ellipse = plotDistanceAwayRatio(df.ellipse.tmp, label = y,          exprCols = 1:k, ellipse = TRUE)     df.ellipse$type = ""ellipse""     df.random.tmp = data.frame(x = guess, ellipse = guess, y = y,          label = y)     df.random = plotDistanceAwayRatio(df.random.tmp, label = sample(y,          length(y)))     df.random$type = ""randomLabel""     df.comb = rbind(dfo.circle, df.ellipse)     ggplot(df.comb, aes(y = prec, x = sens)) + geom_point() +          xlim(0, 1) + ylim(0, 1) + theme_bw() + geom_smooth() +          facet_wrap(~type) + ggtitle(paste(titleMsg, ""Precision/Sensitivity Curve for logistic regression"",          sep = ""\n""))     ggsave(makeOutFile(""elipse.pdf""), height = 4, width = 6)     df.comb.roc = rbind(df.comb, df.random)     ggplot(df.comb.roc, aes(x = FPR, y = TPR, color = type)) +          geom_line() + geom_point() + theme_bw() + geom_abline(slope = 1) +          ggtitle(paste(titleMsg, ""ROC Curve of radius based prediction on pca\n"",              sep = ""\n"")) + xlab(""False Positive Rate"") + ylab(""True Positive Rate"")     ggsave(makeOutFile(""elipse-ROC.pdf""), height = 4, width = 5) }",modeling,510335135739297e8,430
"temp <- subset(probeinfo_all, select = c(PROBE_ID, ILMN_GENE))",data cleaning,324950942071155e8,434
"runLogRegTheta = function(X, k, y, cols, iter = 10, reg = FALSE,      lambda = 1) {     if (TRUE == reg) {         costFunction <- cfLambdaReg(X, y, k, lambda)     }     else {         costFunction <- cfLambda(X, y, k)     }     thetaGuess <- runif(k * k)     zeroGuess <- rep(0, k * k)     results.df <- data.frame(trial = 1:100, cost = rep(0, 100))     best.cost = 1e+06     best.theta = matrix(runif(k * k), k)     for (i in 1:iter) {         print(i)         local = optim(fn = costFunction, par = matrix(-runif(k *              k), k), method = ""BFGS"")         results.df$trial[i] = i         results.df$cost[i] = local$value         if (local$value < best.cost) {             best.cost = local$value             best.theta = local$par         }     }     best.theta }",modeling,510335135739297e8,430
"marginal_list <- merge(marginal_list, temp, by.x = ""probename"",      by.y = ""PROBE_ID"", all.x = T)",data cleaning,324950942071155e8,434
"testTheta <- function(X, k, y, cols, theta) {     predictLabel <- ifelse(apply(X, 1, function(x) {         t(x) %*% theta %*% x     }) < 0, 0, 1)     predictY <- ifelse(predictLabel == y, 1, 0)     sum(predictY)/length(predictY) }",evaluation,510335135739297e8,430
"subset(marginal_list, snp %in% c(""rs2395095"", ""rs10824092""))",data cleaning,324950942071155e8,434
"testThetaTPR <- function(X, k, y, cols, theta) {     predictLabel <- ifelse(apply(X, 1, function(x) {         t(x) %*% theta %*% x     }) < 0, 0, 1)     predictY <- ifelse(predictLabel == y, 1, 0)     sum(predictY[which(y == 1)])/length(predictY[which(y == 1)]) }",evaluation,510335135739297e8,430
"plot3dProbe(sig, ""CTSC"", xmat, resphen, z = 135)",evaluation,324950942071155e8,434
"testThetaStats <- function(X, k, y, cols, theta) {     probs <- sigmoid(apply(X, 1, function(x) {         t(x) %*% theta %*% x     }))     AUC <- calcAUC(probs, y)     predictLabel <- ifelse(apply(X, 1, function(x) {         t(x) %*% theta %*% x     }) < 0, 0, 1)     predictY <- ifelse(predictLabel == y, 1, 0)     TP <- length(which(predictY == 1 & y == 1))     TN <- length(which(predictY == 1 & y == 0))     FN <- length(which(predictY == 0 & y == 1))     FP <- length(which(predictY == 0 & y == 0))     list(TP = TP, TN = TN, FN = FN, FP = FP, AUC = AUC) }",evaluation,510335135739297e8,430
"a <- as.data.frame(do.call(rbind, sig$vc))",data cleaning,324950942071155e8,434
sig$varA <- a$.a + a$a.,evaluation,324950942071155e8,434
"trainAndTestLogReg <- function(lncDf, ratio, cols, mainEffects = TRUE,      reg = FALSE, lambda = 1, iter = 1, glmTypeOutput = FALSE) {     if (ratio >= 1) {         stop(""trainAndTestLogReg must have a ratio < 1"")     }     if (sum(y) < 2) {         stop(""trainAndTestLogReg must have sum(y == 1) >= 2"")     }     totalCount = dim(lncDf)[1]     k <- length(cols) + 1     n <- dim(lncDf)[1]     yCount <- length(which(lncDf$label == 1))     X <- as.matrix(lncDf[, cols])     X <- cbind(rep(1, dim(X)[1]), X)     y <- as.matrix(lncDf[, ""label""])     if (TRUE == mainEffects) {         X[, 1] <- 1     }     else {         X <- X[, -1]         k <- k - 1     }     X <- X/max(X)     train <- getTrainFromY(y, ratio)     theta <- matrix(runNLM(X[train, ], y[train], k, reg, lambda)$estimate,          k)     probs <- sigmoid(apply(X[-train, ], 1, function(x) {         t(x) %*% theta %*% x     }))     if (glmTypeOutput) {         getStatsFromGlmModel(probs, y[-train], knn = FALSE)     }     else {         AUC <- try(getStatsFromGlmModel(probs, y[-train], knn = FALSE)$AUC)         if (""try-error"" %in% class(AUC)) {             warning(""problem in trainAndTestLogReg see line 579 "")             return(list(R = NA, TPR = NA, TP = NA, TN = NA, FP = NA,                  FN = NA, AUC = NA))         }         four <- testThetaStats(X, k, y, cols, theta)         list(R = testTheta(X[-train, ], k, y[-train], cols, theta),              TPR = testThetaTPR(X[-train, ], k, y[-train], cols,                  theta), TP = four$TP, TN = four$TN, FP = four$FP,              FN = four$FN, AUC = AUC)     } }",modeling,510335135739297e8,430
sig$varD <- a$.d + a$d.,evaluation,324950942071155e8,434
"mainTest <- function() {     k = 3     n = 100     n0 = 1     X = cbind(rep(1, dim(X)[1]), X)     X = as.matrix(lnc.pca.df[n0:n, 1:k])     y = as.matrix(lnc.pca.df[n0:n, 33])     thetaGuess = runif(k * k)     zeroGuess = rep(0, k * k) }",modeling,510335135739297e8,430
"test1 = function(outdir = ""/home/wespisea/work/research/researchProjects/encode/encode-manager/plots/fullAnalysisExperiment/test/logReg/sampleData/"") {     if (!file.exists(outdir)) {         dir.create(outdir)     }     nn = 1000     lower.df = data.frame(x0 = rep(1, nn), x1 = runif(nn) * 2 -          1, x2 = runif(nn) * 2 - 1, y = rep(0, nn))     lower.df$dist <- apply(lower.df, 1, function(x) sqrt(x[[""x2""]]^2 +          x[[""x1""]]^2))     lower.df <- lower.df[which(lower.df$dist < 1), ]     lowerMax = ifelse(dim(lower.df)[1] > 100, 100, dim(lower.df)[1])     upper.df = data.frame(x0 = rep(1, nn), x1 = runif(nn) * 3 -          1.5, x2 = runif(nn) * 3 - 1.5, y = rep(1, nn))     upper.df$dist <- apply(upper.df, 1, function(x) sqrt(x[[""x2""]]^2 +          x[[""x1""]]^2))     upper.df <- upper.df[which(upper.df$dist < 1.5 & upper.df$dist >          1), ]     upperMax = ifelse(dim(upper.df)[1] > 100, 100, dim(upper.df)[1])     X.df = rbind(lower.df[1:lowerMax, ], upper.df[1:upperMax,          ])     X.test = as.matrix(X.df[, 1:3])     y.test = X.df$y     k.test = 3     train = sample(seq_along(X.df$y), 0.7 * length(X.df$y))     ggplot(X.df, aes(x1, x2, color = factor(y))) + geom_point() +          theme_bw() + ggtitle(""data"")     ggsave(paste(outdir, ""dataPlot.pdf""))     ggplot(X.df[train, ], aes(x1, x2, color = factor(y))) + geom_point() +          theme_bw() + ggtitle(""Training data"")     ggsave(paste(outdir, ""dataPlot-train.pdf""))     ggplot(X.df[-train, ], aes(x1, x2, color = factor(y))) +          geom_point() + theme_bw() + ggtitle(""Testing data"")     ggsave(paste(outdir, ""dataPlot-test.pdf""))     theta = matrix(runNLM(X[train, ], y.test[train], k = 3, reg = TRUE,          0)$estimate, 3)     X.df$predict <- ifelse(apply(X, 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     X.df$correct <- ifelse(X.df$predict == X.df$y, 1, 0)     trainR = sum(X.df[train, ""correct""])/dim(X.df[train, ])[1]     ggplot(X.df[train, ], aes(x1, x2, color = factor(y), size = 1 -          correct)) + geom_point() + theme_bw() + ggtitle(paste(""test performance -- wrong points are large\nR="",          trainR, sep = """"))     ggsave(paste(outdir, ""dataPlot-test-Incorrect.pdf""))     testR = sum(X.df[-train, ""correct""])/dim(X.df[-train, ])[1]     ggplot(X.df[-train, ], aes(x1, x2, color = factor(y), size = 1 -          correct)) + geom_point() + theme_bw() + ggtitle(paste(""test performance -- wrong points are large\nR="",          testR, sep = """"))     ggsave(paste(outdir, ""dataPlot-test-Incorrect.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-2, 2, by = 0.1),          x2 = seq(-2, 2, by = 0.1)))     analysis.df$x0 <- 1     theta <- matrix(runNLM(X[train, ], y.test[train], k = 3,          reg = TRUE, 0)$estimate, 3)     analysis.df$predict <- ifelse(apply(as.matrix(analysis.df[c(""x0"",          ""x1"", ""x2"")], ), 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 0"")     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=0.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-2, 2, by = 0.1),          x2 = seq(-2, 2, by = 0.1)))     analysis.df$x0 <- 1     theta <- matrix(runNLM(X[train, ], y.test[train], k = 3,          reg = TRUE, 10)$estimate, 3)     analysis.df$predict <- ifelse(apply(as.matrix(analysis.df[c(""x0"",          ""x1"", ""x2"")], ), 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 10"")     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=10.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-2, 2, by = 0.1),          x2 = seq(-2, 2, by = 0.1)))     analysis.df$x0 <- 1     theta <- matrix(runNLM(X[train, ], y.test[train], k = 3,          reg = TRUE, 50)$estimate, 3)     analysis.df$predict <- ifelse(apply(as.matrix(analysis.df[c(""x0"",          ""x1"", ""x2"")], ), 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 50"")     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=50.pdf"")) }",visualization,510335135739297e8,430
"test2 = function(outdir = ""/home/wespisea/work/research/researchProjects/encode/encode-manager/plots/fullAnalysisExperiment/test/logReg/sampleData2/"") {     if (!file.exists(outdir)) {         dir.create(outdir)     }     xval = 1     nn = 1000     lower.df = data.frame(x0 = rep(xval, nn), x1 = runif(nn) *          0.5 - 0.25, x2 = runif(nn) * 0.5 - 0.25, y = rep(0, nn))     lower.df$dist <- apply(lower.df, 1, function(x) sqrt(x[[""x2""]]^2 +          x[[""x1""]]^2))     lower.df <- lower.df[which(lower.df$dist < 1), ]     lowerMax = ifelse(dim(lower.df)[1] > 200, 200, dim(lower.df)[1])     ones = 200     upper.df = data.frame(x0 = rep(xval, ones), x1 = runif(ones) *          0.5, x2 = runif(ones) * 0.5, y = rep(1, ones))     upper.df[1:50, ""x2""] <- upper.df[1:50, ""x2""] + 1     upper.df[1:50, ""x1""] <- upper.df[1:50, ""x1""] - 0.25     upper.df[51:100, ""x2""] <- upper.df[51:100, ""x2""] - 1.5     upper.df[51:100, ""x1""] <- upper.df[51:100, ""x1""] - 0.25     upper.df[101:150, ""x1""] <- upper.df[101:150, ""x1""] + 1     upper.df[101:150, ""x2""] <- upper.df[101:150, ""x2""] - 0.25     upper.df[151:200, ""x1""] <- upper.df[151:200, ""x1""] - 1.5     upper.df[151:200, ""x2""] <- upper.df[151:200, ""x2""] - 0.25     upper.df$dist = 0     X.df = rbind(lower.df[1:200, ], upper.df)     X.test = as.matrix(X.df[, c(""x0"", ""x1"", ""x2"")])     y.test = X.df$y     k.test = 3     train = 1:300     ggplot(X.df, aes(x1, x2, color = factor(y))) + geom_point() +          theme_bw() + ggtitle(""data"") + xlim(-2, 2) + ylim(-2,          2)     ggsave(paste(outdir, ""dataPlot.pdf""))     ggplot(X.df[train, ], aes(x1, x2, color = factor(y))) + geom_point() +          theme_bw() + ggtitle(""Training data"") + xlim(-2, 2) +          ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-train.pdf""))     ggplot(X.df[-train, ], aes(x1, x2, color = factor(y))) +          geom_point() + theme_bw() + ggtitle(""Testing data"") +          xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-test.pdf""))     theta = matrix(runNLM(X.test[train, ], y.test[train], k = 3,          reg = TRUE, 0)$estimate, 3)     X.df$predict <- ifelse(apply(X.test, 1, function(x) t(x) %*%          matrix(theta, 3) %*% x) < 0, 0, 1)     X.df$correct <- ifelse(X.df$predict == X.df$y, 1, 0)     trainR = sum(X.df[train, ""correct""])/dim(X.df[train, ])[1]     ggplot(X.df[train, ], aes(x1, x2, color = factor(y), size = 1 -          correct)) + geom_point() + theme_bw() + ggtitle(paste(""test performance -- wrong points are large\nR="",          trainR, sep = """")) + xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-train-Incorrect.pdf""))     testR = sum(X.df[-train, ""correct""])/dim(X.df[-train, ])[1]     ggplot(X.df[-train, ], aes(x1, x2, color = factor(y), size = 1 -          correct)) + geom_point() + theme_bw() + ggtitle(paste(""test performance -- wrong points are large\nR="",          testR, sep = """")) + xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-test-Incorrect.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-2, 2, by = 0.1),          x2 = seq(-2, 2, by = 0.05)))     analysis.df$x0 <- xval     theta <- matrix(runNLM(X.test[train, ], y.test[train], k = 3,          reg = TRUE, 0)$estimate, 3)     analysis.df$predict <- ifelse(apply(as.matrix(analysis.df[c(""x0"",          ""x1"", ""x2"")], ), 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 0"") +          xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=0.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-2, 2, by = 0.1),          x2 = seq(-2, 2, by = 0.05)))     analysis.df$x0 <- xval     analysis.df$dist <- apply(analysis.df, 1, function(x) sqrt(x[[""x2""]]^2 +          x[[""x1""]]^2))     theta <- matrix(runNLM(X.test[train, ], y.test[train], k = 3,          reg = TRUE, 10)$estimate, 3)     analysis.df$predict <- ifelse(apply(as.matrix(analysis.df[c(""x0"",          ""x1"", ""x2"")], ), 1, function(x) t(x) %*% matrix(theta,          3) %*% x) < 0, 0, 1)     analysis.df$val <- apply(as.matrix(analysis.df[c(""x0"", ""x1"",          ""x2"")], ), 1, function(x) t(x) %*% matrix(theta, 3) %*%          x)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 10"") +          xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=10.pdf""))     analysis.df <- data.frame(expand.grid(x1 = seq(-10, 10, by = 0.1),          x2 = seq(-10, 10, by = 0.05)))     analysis.df$x0 <- xval     theta <- matrix(runNLM(X.test[train, ], y.test[train], k = 3,          reg = TRUE, 50)$estimate, 3)     analysis.df$predict <- ifelse(apply(analysis.df[c(""x0"", ""x1"",          ""x2"")], 1, function(x) t(x) %*% matrix(theta, 3) %*%          x) < 0, 0, 1)     ggplot(analysis.df, aes(x1, x2, fill = factor(predict))) +          geom_tile() + theme_bw() + ggtitle(""Decision boundary for training\nLambda = 50"") +          xlim(-2, 2) + ylim(-2, 2)     ggsave(paste(outdir, ""dataPlot-decisionBoundary-lambda=50.pdf"")) }",visualization,510335135739297e8,430
"runNLM <- function(X, y, k, reg, lambda, useGradient = TRUE) {     if (TRUE == reg) {         dim(X)         a <- cfLambdaReg(X, y, k, lambda)         b <- gfLambdaReg(X, y, k, lambda)     }     else {         a <- cfLambdaT(X, y, k)         b <- gfLambdaT(X, y, k)     }     if (useGradient) {         fgh <- function(x) {             res <- a(x)             attr(res, ""gradient"") <- b(x)             return(res)         }     }     else {         fgh <- function(x) {             res <- a(x)             return(res)         }     }     nlm(f = fgh, p = runif(k * k), check.analyticals = TRUE) }",modeling,510335135739297e8,430
"nlmTest <- function() {     a <- cfLambdaT(X, y, k)     yy <- ifelse(y == 1, 0, 1)     b <- gfLambdaT(X, y, k)     fgh <- function(x) {         res <- a(x)         attr(res, ""gradient"") <- b(x)         return(res)     }     nlm(f = fgh, p = runif(k * k), check.analyticals = TRUE) }",modeling,510335135739297e8,430
"nlmTestReg <- function() {     a <- cfLambdaReg(X, y, k, lambda = 1000)     b <- gfLambdaReg(X, ifelse(y == 1, 1, 1), k, lambda = 1000)     fgh <- function(x) {         res <- a(x)         attr(res, ""gradient"") <- b(x)         return(res)     }     nlm(f = fgh, p = runif(k * k), check.analyticals = TRUE) }",modeling,510335135739297e8,430
rm(list = ls()),setup,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
library(reshape2),import,510335135739297e8,430
library(plyr),import,510335135739297e8,430
"setwd(""/Users/pascaltimshel/git/snpsnap/analysis/validation_summary_stats_inputEQmatched"")",setup,510335135739297e8,430
"path.base = ""/Users/pascaltimshel/snpsnap/validation_07-08-2014""",setup,510335135739297e8,430
"analysis_name = ""SNPsnap_rand100_defaultMatchCrit_n100_excludeInputHLA""",setup,510335135739297e8,430
"path.analysis = file.path(path.base, analysis_name)",setup,510335135739297e8,430
"file.annotation.input = file.path(path.analysis, ""input_snps_annotated.tab"")",setup,510335135739297e8,430
"file.annotation.matched = file.path(path.analysis, ""matched_snps_annotated.tab"")",setup,510335135739297e8,430
df.input = read.delim(file.annotation.input),import,510335135739297e8,430
df.matched = read.delim(file.annotation.matched),import,510335135739297e8,430
"df.matched[, ""set""] <- as.factor(df.matched[, ""set""])",data cleaning,510335135739297e8,430
str(df.matched),exploratory,510335135739297e8,430
sig$varI <- a$aa + a$ad + a$da + a$dd,modeling,324950942071155e8,434
"prop <- subset(sig, select = c(varA, varI, varD))",evaluation,324950942071155e8,434
"prop <- prop[order(prop$varA + prop$varI + prop$varD, decreasing = T),      ]",evaluation,324950942071155e8,434
prop$index <- 1:nrow(prop),evaluation,324950942071155e8,434
"prop <- melt(prop, id = c(""index""))",data cleaning,324950942071155e8,434
"prop <- prop[nrow(prop):1, ]",evaluation,324950942071155e8,434
"prop$variable <- factor(prop$variable, levels = c(""varI"", ""varD"",      ""varA""))",evaluation,324950942071155e8,434
"levels(prop$variable) <- c(""Interaction"", ""Dominance"", ""Additive"")",evaluation,324950942071155e8,434
"df.stat.input <- summarise(df.input, set = as.factor(""input""),      origin = as.factor(""input""), N = nrow(df.input), mean_freq_bin = mean(freq_bin),      mean_gene_count = mean(gene_count), mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",exploratory,510335135739297e8,430
"p1 <- ggplot(prop, aes(y = value, x = index)) + geom_bar(stat = ""identity"",      aes(fill = variable, colour = variable), position = position_stack(width = 0)) +      scale_fill_brewer(""Variance component"") + scale_colour_brewer(""Variance component"") +      ylab(""Phenotypic variance"") + xlab("""") + coord_flip() + theme(legend.position = ""none"") +      theme(axis.text.y = element_text(size = 0), axis.ticks.y = element_line(size = 0))",visualization,324950942071155e8,434
"ggsave(""~/repo/eQTL-2D/analysis/images/proportion_additive.pdf"",      width = 10, height = 10)",export,324950942071155e8,434
ptm <- proc.time(),exploratory,510335135739297e8,430
"a <- as.data.frame(do.call(rbind, sig$vc))",data cleaning,324950942071155e8,434
sig$varA <- a$.a + a$a.,evaluation,324950942071155e8,434
sig$varD <- a$.d + a$d.,modeling,324950942071155e8,434
"df.stat.matched <- ddply(df.matched, c(""set""), summarise, origin = as.factor(""matched""),      N = length(set), mean_freq_bin = mean(freq_bin), mean_gene_count = mean(gene_count),      mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",data cleaning,510335135739297e8,430
sig$varI <- a$aa + a$ad + a$da + a$dd,data cleaning,324950942071155e8,434
proc.time() - ptm,data cleaning,510335135739297e8,430
"sig$varG <- with(sig, varA + varD + varI)",data cleaning,324950942071155e8,434
sig$varA <- sig$varA/sig$varG,data cleaning,324950942071155e8,434
"df.stat <- rbind(df.stat.input, df.stat.matched)",data cleaning,510335135739297e8,430
sig$varD <- sig$varD/sig$varG,data cleaning,324950942071155e8,434
sig$varI <- sig$varI/sig$varG,evaluation,324950942071155e8,434
"csv.filename <- paste(analysis_name, ""_stat.csv"", sep = """")",setup,510335135739297e8,430
"prop <- subset(sig, select = c(varA, varI, varD))",data cleaning,324950942071155e8,434
"write.csv(df.stat, file = csv.filename, row.names = FALSE)",export,510335135739297e8,430
"prop <- prop[order(prop$varA, decreasing = T), ]",data cleaning,324950942071155e8,434
"df.compare <- ddply(df.stat, .(origin), summarise, mean_freq_bin = mean(mean_freq_bin),      mean_gene_count = mean(mean_gene_count), mean_dist_nearest_gene_snpsnap = mean(mean_dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(mean_friends_ld05))",data cleaning,510335135739297e8,430
prop$index <- 1:nrow(prop),modeling,324950942071155e8,434
"prop <- melt(prop, id = c(""index""))",data cleaning,324950942071155e8,434
"prop <- prop[nrow(prop):1, ]",modeling,324950942071155e8,434
"prop$variable <- factor(prop$variable, levels = c(""varI"", ""varD"",      ""varA""))",evaluation,324950942071155e8,434
"df.ratio <- df.compare[1, -1]/df.compare[2, -1] * 100",data cleaning,510335135739297e8,430
"df.compare <- rbind.fill(df.compare, df.ratio)",data cleaning,510335135739297e8,430
"levels(prop$variable) <- c(""Interaction"", ""Dominance"", ""Additive"")",evaluation,324950942071155e8,434
"csv.filename <- paste(analysis_name, ""_compare.csv"", sep = """")",setup,510335135739297e8,430
"p2 <- ggplot(prop, aes(y = value, x = index)) + geom_bar(stat = ""identity"",      aes(fill = variable, colour = variable), position = position_stack(width = 0)) +      scale_fill_brewer(""Variance component"") + scale_colour_brewer(""Variance component"") +      ylab(""Proportion of genetic variance"") + xlab("""") + coord_flip() +      theme(legend.justification = c(1, 0), legend.position = c(1,          0)) + theme(axis.text.y = element_text(size = 0), axis.ticks.y = element_line(size = 0))",visualization,324950942071155e8,434
"write.csv(df.compare, file = csv.filename, row.names = FALSE)",export,510335135739297e8,430
"ggsave(""~/repo/eQTL-2D/analysis/images/proportion_genetic.pdf"",      width = 10, height = 10)",export,324950942071155e8,434
"work_dir = ""/home/max/Desktop/Identification of the class of English text among several classes/analysis/scripts""",setup,510335135739297e8,430
"pdf(file = ""~/repo/eQTL-2D/analysis/images/variance_components.pdf"",      width = 10, height = 10)",export,324950942071155e8,434
"install.packages(""textreadr"")",setup,510335135739297e8,430
library(textreadr),import,510335135739297e8,430
"multiplot(p1, p2, cols = 2)",visualization,324950942071155e8,434
setwd(work_dir),setup,510335135739297e8,430
getwd(),setup,510335135739297e8,430
dev.off(),evaluation,324950942071155e8,434
"business <- read_dir(""../../dataset/business"", pattern = "".txt"")",import,510335135739297e8,430
"entertainment <- read_dir(path = ""../../dataset/entertainment"")",import,510335135739297e8,430
"politics <- read_dir(""../../dataset/politics"")",import,510335135739297e8,430
"sport <- read_dir(""../../dataset/sport"")",import,510335135739297e8,430
"tech <- read_dir(""../../dataset/tech"")",import,510335135739297e8,430
"read.dir <- function(dir, pattern) {     file.names <- dir(dir, pattern = pattern)     file.names = as.data.frame(x = file.names)     file.names$content = NA     colnames(file.names) = c(""filename"", ""content"")     for (i in 1:length(file.names[, 1])) {         path <- paste0(dir, ""/"", file.names[i, 1])         line <- readLines(path)         file.names[i, 2] <- paste(line, sep = """", collapse = """")     }     return(file.names) }",import,510335135739297e8,430
"business <- read.dir(""../../dataset/business"", "".txt"")",import,510335135739297e8,430
"entertainment <- read.dir(""../../dataset/entertainment"", "".txt"")",import,510335135739297e8,430
"politics <- read.dir(""../../dataset/politics"", "".txt"")",import,510335135739297e8,430
"sport <- read.dir(""../../dataset/sport"", "".txt"")",import,510335135739297e8,430
"tech <- read.dir(""../../dataset/tech"", "".txt"")",import,510335135739297e8,430
"write.csv(x = business, file = ""../../analysis/data/business.csv"")",export,510335135739297e8,430
"ciOverlap <- function(ci, sig, win) {     ci$index <- 1:nrow(ci)     sig$int1 <- NA     sig$int2 <- NA     for (i in 1:nrow(sig)) {         cat(i, ""of"", nrow(sig), ""\n"")         chr1 <- sig$chr1[i]         chr2 <- sig$chr2[i]         pos1 <- sig$position1[i]         pos2 <- sig$position2[i]         sa <- subset(ci, loci1_chromosome == chr1 & loci2_chromosome ==              chr2)         sb <- subset(ci, loci1_chromosome == chr2 & loci2_chromosome ==              chr1)         sa$diff1 <- with(sa, abs(loci1_position - pos1))         sa$diff2 <- with(sa, abs(loci2_position - pos2))         sb$diff1 <- with(sb, abs(loci1_position - pos2))         sb$diff2 <- with(sb, abs(loci2_position - pos1))         sa <- subset(sa, diff1 < win & diff2 < win)         sb <- subset(sb, diff1 < win & diff2 < win)         if (nrow(sa) > 0) {             sig$int1[i] <- list(sa)             print(""Found!"")         }         if (nrow(sb) > 0) {             sig$int2[i] <- list(sb)             print(""Found!"")         }     }     print(sum(!is.na(sig$int1) | !is.na(sig$int2)))     return(sig) }",evaluation,324950942071155e8,434
"write.csv(x = entertainment, file = ""../../analysis/data/entertainment.csv"")",export,510335135739297e8,430
"write.csv(x = politics, file = ""../../analysis/data/politics.csv"")",export,510335135739297e8,430
"write.csv(x = sport, file = ""../../analysis/data/sport.csv"")",export,510335135739297e8,430
"write.csv(x = tech, file = ""../../analysis/data/tech.csv"")",export,510335135739297e8,430
"load(""~/repo/eQTL-2D/analysis/interaction_list_meta_analysis.RData"")",import,324950942071155e8,434
"business$class <- c(""business"")",exploratory,510335135739297e8,430
"ci <- read.csv(""~/repo/eQTL-2D/data/supFile3_K562_interactingLoci_clusters.csv"",      header = T)",import,324950942071155e8,434
"entertainment$class <- c(""entertainment"")",data cleaning,510335135739297e8,430
dim(ci),evaluation,324950942071155e8,434
"politics$class <- c(""politics"")",setup,510335135739297e8,430
"sport$class <- c(""sport"")",setup,510335135739297e8,430
"tech$class <- c(""tech"")",setup,510335135739297e8,430
head(ci),evaluation,324950942071155e8,434
table(ci$cluster),exploratory,324950942071155e8,434
"sig2 <- subset(meta, filter != 3)",exploratory,324950942071155e8,434
"bbc.data.matrix <- rbind(business, entertainment, politics, sport,      tech)",data cleaning,510335135739297e8,430
"counts <- rep(0, 4)",evaluation,324950942071155e8,434
"write.csv(x = bbc.data.matrix, file = ""../../analysis/data/bbc.csv"")",export,510335135739297e8,430
"save(bbc.data.matrix, file = ""../../analysis/data/bbc_DataMatrix.RData"")",export,510335135739297e8,430
"a1 <- ciOverlap(ci, sig2, 10000)",evaluation,324950942071155e8,434
library(dplyr),import,510335135739297e8,430
counts[1] <- sum((!is.na(a1$int1) | !is.na(a1$int2))),modeling,324950942071155e8,434
"a2 <- ciOverlap(ci, sig2, 250000)",modeling,324950942071155e8,434
library(tidyr),import,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
library(scatterplot3d),import,510335135739297e8,430
library(lme4),import,510335135739297e8,430
library(psych),import,510335135739297e8,430
library(stats),import,510335135739297e8,430
counts[2] <- sum((!is.na(a2$int1) | !is.na(a2$int2))),modeling,324950942071155e8,434
library(scales),import,510335135739297e8,430
library(smacof),import,510335135739297e8,430
rm(list = ls()),import,510335135739297e8,430
dev.off(),setup,510335135739297e8,430
"a3 <- ciOverlap(ci, sig2, 1e+06)",evaluation,324950942071155e8,434
counts[3] <- sum((!is.na(a3$int1) | !is.na(a3$int2))),evaluation,324950942071155e8,434
"a4 <- ciOverlap(ci, sig2, 5e+06)",evaluation,324950942071155e8,434
counts[4] <- sum((!is.na(a4$int1) | !is.na(a4$int2))),evaluation,324950942071155e8,434
"chrint <- subset(a4, !is.na(int1), select = c(Probe, PCHR, PBP,      SNP, SCHR, SBP, BSGS, LBC, int1, int2))",evaluation,324950942071155e8,434
"d = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_charmeans.csv"")[-1]",import,510335135739297e8,430
glimpse(d),exploratory,510335135739297e8,430
"dd = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_data_anonymized.csv"")[-1]",import,510335135739297e8,430
glimpse(dd),exploratory,510335135739297e8,430
"d_white = d %>% filter(ethnicity == ""white"")",data cleaning,510335135739297e8,430
"dd_white = dd %>% filter(ethnicity == ""white"")",data cleaning,510335135739297e8,430
"d_nonwhite = d %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,510335135739297e8,430
"dd_nonwhite = dd %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,510335135739297e8,430
"charmeans = dd %>% filter(phase == ""test"") %>% select(subid,      predicate, leftCharacter, rightCharacter, response, responseNum) %>%      mutate(grownup = ifelse(leftCharacter == ""grownup"", responseNum,          ifelse(rightCharacter == ""grownup"", -1 * responseNum,              NA)), kid = ifelse(leftCharacter == ""kid"", responseNum,          ifelse(rightCharacter == ""kid"", -1 * responseNum, NA)),          baby = ifelse(leftCharacter == ""baby"", responseNum, ifelse(rightCharacter ==              ""baby"", -1 * responseNum, NA)), dog = ifelse(leftCharacter ==              ""dog"", responseNum, ifelse(rightCharacter == ""dog"",              -1 * responseNum, NA)), bear = ifelse(leftCharacter ==              ""bear"", responseNum, ifelse(rightCharacter == ""bear"",              -1 * responseNum, NA)), bug = ifelse(leftCharacter ==              ""bug"", responseNum, ifelse(rightCharacter == ""bug"",              -1 * responseNum, NA)), robot = ifelse(leftCharacter ==              ""robot"", responseNum, ifelse(rightCharacter == ""robot"",              -1 * responseNum, NA)), computer = ifelse(leftCharacter ==              ""computer"", responseNum, ifelse(rightCharacter ==              ""computer"", -1 * responseNum, NA)), car = ifelse(leftCharacter ==              ""car"", responseNum, ifelse(rightCharacter == ""car"",              -1 * responseNum, NA)), stapler = ifelse(leftCharacter ==              ""stapler"", responseNum, ifelse(rightCharacter ==              ""stapler"", -1 * responseNum, NA))) %>% select(predicate,      subid, grownup, kid, baby, dog, bear, bug, robot, computer,      car, stapler) %>% gather(character, response, -predicate,      -subid) %>% group_by(predicate, character) %>% summarise(mean = mean(response,      na.rm = T))",data cleaning,510335135739297e8,430
glimpse(charmeans),exploratory,510335135739297e8,430
"charmeans_table = charmeans %>% spread(predicate, mean)",data cleaning,510335135739297e8,430
charnames = as.character(charmeans_table$character),setup,510335135739297e8,430
d1 = charmeans_table[-1],data cleaning,510335135739297e8,430
rownames(d1) = charnames,data cleaning,510335135739297e8,430
print(d1),visualization,510335135739297e8,430
demo = dd %>% distinct(subid),data cleaning,510335135739297e8,430
"seedling_mortality_data <- read.table(""./analysis/seedling_mortality_analysis/data/seedling_mortality_data.txt"",      header = TRUE)",import,936174685368314e8,233
"preds <- with(seedling_mortality_data, expand.grid(dia = mean(dia,      na.rm = T), ztopo = 0, f.time = ""3"", sp = levels(seedling_mortality_data$sp),      flood = levels(seedling_mortality_data$flood)))",data cleaning,936174685368314e8,233
siteSize = 2048,not sure,499398978194222e8,435
demo %>% summarise(n = length(subid)),exploratory,510335135739297e8,430
library(tidyverse),setup,936174685368314e8,233
dd %>% group_by(sequence) %>% distinct(subid) %>% summarise(n = length(subid)),exploratory,510335135739297e8,430
library(fst),setup,936174685368314e8,233
demo %>% count(gender),exploratory,510335135739297e8,430
demo %>% count(ethnicity),exploratory,510335135739297e8,430
"ed_in <- read_fst(""analysis/data/derived-data/ed-ensemble-out.fst"") %>%      as_tibble()",import,936174685368314e8,233
"params <- read_fst(""analysis/data/derived-data/ed-params.fst"") %>%      as_tibble()",import,936174685368314e8,233
"treatment = ""Copper""",setup,499398978194222e8,435
"demo %>% summarise(mean_age = mean(age, na.rm = T), sd_age = sd(age,      na.rm = T))",exploratory,510335135739297e8,430
qplot(demo$age),visualization,510335135739297e8,430
"strand = ""both""",setup,499398978194222e8,435
"params_sub <- params %>% semi_join(params %>% group_by(pft, variable) %>%      filter(sd(value) > 0) %>% ungroup() %>% distinct(variable)) %>%      rename(parameter = variable, parameter_value = value)",data cleaning,936174685368314e8,233
"params_wide <- spread(params_sub, variable, value)",data cleaning,936174685368314e8,233
"ed_summary <- ed_in %>% filter(lubridate::month(time) >= 6, lubridate::month(time) <=      8) %>% group_by(run_id, variable, yyear = lubridate::year(time)) %>%      summarize(value_mean = mean(value, na.rm = TRUE)) %>% ungroup(ed_summary)",data cleaning,936174685368314e8,233
"alt.name = paste0(treatment, ""."", siteSize, ""."", strand, "".alt"")",data cleaning,499398978194222e8,435
"null.name = paste0(treatment, ""."", siteSize, ""."", strand, "".null"")",data cleaning,499398978194222e8,435
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",data cleaning,499398978194222e8,435
"levels(demo$education) = c(""hs_some"", ""hs_diploma"", ""college_some"",      ""college_assocDegree"", ""college_bachDegree"", ""grad_some"",      ""grad_degree"", ""other_prefNo"")",data cleaning,510335135739297e8,430
demo %>% count(education),exploratory,510335135739297e8,430
demo %>% count(englishNative),exploratory,510335135739297e8,430
demo %>% count(religionChild),exploratory,510335135739297e8,430
"demo = demo %>% filter(religionChild != ""prefNo"" & religionChild !=      ""NA"") %>% mutate(religCat = ifelse(grepl(""christ"", religionChild) ==      T | religionChild == ""judaism"", ""judeo-christian"", ifelse(religionChild ==      ""none"", ""non-religious"", ""other religious"")))",data cleaning,510335135739297e8,430
demo %>% count(religCat),exploratory,510335135739297e8,430
demo %>% count(religionNow),exploratory,510335135739297e8,430
View(demo %>% mutate(job = factor(tolower(as.character(job)))) %>%      count(job)),exploratory,510335135739297e8,430
"pca_A2 = principal(d1, nfactors = 2, rotate = ""none"")",modeling,510335135739297e8,430
pca_A2,modeling,510335135739297e8,430
pca_A2$values,exploratory,510335135739297e8,430
"pca_A2_pc1 = pca_A2$loadings[, 1]",exploratory,510335135739297e8,430
sort(pca_A2_pc1),exploratory,510335135739297e8,430
"pca_A2_pc2 = pca_A2$loadings[, 2]",exploratory,510335135739297e8,430
sort(pca_A2_pc2),exploratory,510335135739297e8,430
"ggplot(data.frame(pca_A2$loadings[1:3, ]), aes(x = PC1, y = PC2,      label = names(d1))) + geom_text() + theme_bw() + labs(title = ""Factor loadings\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,510335135739297e8,430
"ggplot(data.frame(pca_A2$scores), aes(x = PC1, y = PC2, label = rownames(d1))) +      geom_text() + theme_bw() + labs(title = ""Raw character factor scores\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,510335135739297e8,430
"ggplot(data.frame(pca_A2$scores), aes(x = rescale(PC1, to = c(0,      1)), y = rescale(PC2, to = c(0, 1)), label = rownames(d1))) +      geom_point() + geom_text(angle = 0, vjust = -1, size = 6) +      xlim(-0.01, 1.01) + ylim(-0.01, 1.01) + theme_bw() + theme(text = element_text(size = 20)) +      labs(title = ""Adjusted character factor scores\n"", x = ""\nPrincipal Component 1, rescaled"",          y = ""Principal Component 2, rescaled\n"")",visualization,510335135739297e8,430
"pca_A2_rot = principal(d1, nfactors = 2, rotate = ""varimax"")",visualization,510335135739297e8,430
pca_A2_rot,modeling,510335135739297e8,430
pca_A2_rot$values,exploratory,510335135739297e8,430
"pca_A2_rot_pc1 = pca_A2_rot$loadings[, 1]",exploratory,510335135739297e8,430
sort(pca_A2_rot_pc1),exploratory,510335135739297e8,430
"pca_A2_rot_pc2 = pca_A2_rot$loadings[, 2]",exploratory,510335135739297e8,430
sort(pca_A2_rot_pc2),exploratory,510335135739297e8,430
"ggplot(data.frame(pca_A2_rot$loadings[1:3, ]), aes(x = PC1, y = PC2,      label = names(d1))) + geom_text() + theme_bw() + labs(title = ""Factor loadings\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,510335135739297e8,430
"ggplot(data.frame(pca_A2_rot$scores), aes(x = PC1, y = PC2, label = rownames(d1))) +      geom_text() + theme_bw() + labs(title = ""Raw character factor scores\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,510335135739297e8,430
"ggplot(data.frame(pca_A2_rot$scores), aes(x = rescale(PC1, to = c(0,      1)), y = rescale(PC2, to = c(0, 1)), label = rownames(d1))) +      geom_point() + geom_text(angle = 0, vjust = -1, size = 6) +      xlim(-0.01, 1.01) + ylim(-0.01, 1.01) + theme_bw() + theme(text = element_text(size = 20)) +      labs(title = ""Adjusted character factor scores\n"", x = ""\nPrincipal Component 1, rescaled"",          y = ""Principal Component 2, rescaled\n"")",visualization,510335135739297e8,430
dissim = NULL,setup,510335135739297e8,430
"dissim <- dd %>% filter(phase == ""test"") %>% mutate(character1 = array(),      character2 = array())",exploratory,510335135739297e8,430
"charsort = sort(levels(dissim$leftCharacter), decreasing = TRUE)",exploratory,510335135739297e8,430
"for (i in 1:length(charsort)) {     dissim <- dissim %>% mutate(character1 = ifelse(leftCharacter ==          charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%          mutate(character1 = factor(character1), character2 = factor(character2)) }",data cleaning,510335135739297e8,430
"dissim <- dissim %>% select(predicate, subid, character1, character2,      responseNum) %>% group_by(character1, character2) %>% mutate(dist = abs(responseNum)) %>%      summarise(mean = mean(dist, na.rm = TRUE)) %>% spread(character2,      mean)",data cleaning,510335135739297e8,430
"dissim <- dissim %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",exploratory,510335135739297e8,430
"dissim = dissim[, c(1, 11, 2:10)]",exploratory,510335135739297e8,430
"names = sort(charsort, decreasing = FALSE)",exploratory,510335135739297e8,430
"names = names[names != ""strawberries""]",exploratory,510335135739297e8,430
"names = names[names != ""grapes""]",data cleaning,510335135739297e8,430
"names = names[names != ""icecream""]",data cleaning,510335135739297e8,430
"names = names[names != ""pizza""]",data cleaning,510335135739297e8,430
dissim = dissim[-1],data cleaning,510335135739297e8,430
rownames(dissim) = names,data cleaning,510335135739297e8,430
colnames(dissim) = names,data cleaning,510335135739297e8,430
"for (i in 1:9) {     for (j in (i + 1):10) {         dissim[j, i] = dissim[i, j]     } }",data cleaning,510335135739297e8,430
dissim = as.dist(dissim),data cleaning,510335135739297e8,430
"mds_Aordinal = mds(dissim, ndim = 2, type = ""ordinal"")",modeling,510335135739297e8,430
summary(mds_Aordinal),evaluation,510335135739297e8,430
mds_Aordinal,exploratory,510335135739297e8,430
"plot(mds_Aordinal, plot.type = ""confplot"", xlim = c(-1, 1), ylim = c(-1,      1), main = ""MDS solution: All conditions"")",visualization,510335135739297e8,430
"plot(mds_Aordinal, plot.type = ""bubbleplot"", xlim = c(-1, 1),      ylim = c(-1, 1), main = ""MDS bubble plot: All conditions"")",visualization,510335135739297e8,430
"plot(mds_Aordinal, plot.type = ""stressplot"", main = ""MDS stress: All conditions"")",visualization,510335135739297e8,430
"plot(mds_Aordinal, plot.type = ""Shepard"", main = ""MDS Shepard plot: All conditions"")",visualization,510335135739297e8,430
"plot(mds_Aordinal, plot.type = ""resplot"", main = ""MDS residuals: All conditions"")",visualization,510335135739297e8,430
dissim_thinking = NULL,setup,510335135739297e8,430
"dissim_thinking <- dd %>% filter(predicate == ""thinking"") %>%      mutate(character1 = array(), character2 = array())",data cleaning,510335135739297e8,430
"charsort = sort(levels(dissim_thinking$leftCharacter), decreasing = TRUE)",data cleaning,510335135739297e8,430
"for (i in 1:length(charsort)) {     dissim_thinking <- dissim_thinking %>% mutate(character1 = ifelse(leftCharacter ==          charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%          mutate(character1 = factor(character1), character2 = factor(character2)) }",data cleaning,510335135739297e8,430
"dissim_thinking <- dissim_thinking %>% select(predicate, subid,      character1, character2, responseNum) %>% group_by(character1,      character2) %>% mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,      na.rm = TRUE)) %>% spread(character2, mean)",data cleaning,510335135739297e8,430
"dissim_thinking <- dissim_thinking %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,510335135739297e8,430
"dissim_thinking = dissim_thinking[, c(1, 11, 2:10)]",data cleaning,510335135739297e8,430
dissim_thinking = dissim_thinking[-1],data cleaning,510335135739297e8,430
rownames(dissim_thinking) = names,data cleaning,510335135739297e8,430
colnames(dissim_thinking) = names,data cleaning,510335135739297e8,430
"for (i in 1:9) {     for (j in (i + 1):10) {         dissim_thinking[j, i] = dissim_thinking[i, j]     } }",data cleaning,510335135739297e8,430
dissim_thinking = as.dist(dissim_thinking),data cleaning,510335135739297e8,430
dissim_feelings = NULL,setup,510335135739297e8,430
"dissim_feelings <- dd %>% filter(predicate == ""feelings"") %>%      mutate(character1 = array(), character2 = array())",data cleaning,510335135739297e8,430
"charsort = sort(levels(dissim_feelings$leftCharacter), decreasing = TRUE)",data cleaning,510335135739297e8,430
"for (i in 1:length(charsort)) {     dissim_feelings <- dissim_feelings %>% mutate(character1 = ifelse(leftCharacter ==          charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%          mutate(character1 = factor(character1), character2 = factor(character2)) }",data cleaning,510335135739297e8,430
"dissim_feelings <- dissim_feelings %>% select(predicate, subid,      character1, character2, responseNum) %>% group_by(character1,      character2) %>% mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,      na.rm = TRUE)) %>% spread(character2, mean)",data cleaning,510335135739297e8,430
"dissim_feelings <- dissim_feelings %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,510335135739297e8,430
"dissim_feelings = dissim_feelings[, c(1, 11, 2:10)]",data cleaning,510335135739297e8,430
dissim_feelings = dissim_feelings[-1],data cleaning,510335135739297e8,430
rownames(dissim_feelings) = names,data cleaning,510335135739297e8,430
colnames(dissim_feelings) = names,data cleaning,510335135739297e8,430
"for (i in 1:9) {     for (j in (i + 1):10) {         dissim_feelings[j, i] = dissim_feelings[i, j]     } }",data cleaning,510335135739297e8,430
dissim_feelings = as.dist(dissim_feelings),data cleaning,510335135739297e8,430
dissim_hunger = NULL,setup,510335135739297e8,430
"dissim_hunger <- dd %>% filter(predicate == ""hunger"") %>% mutate(character1 = array(),      character2 = array())",data cleaning,510335135739297e8,430
"charsort = sort(levels(dissim_hunger$leftCharacter), decreasing = TRUE)",data cleaning,510335135739297e8,430
"for (i in 1:length(charsort)) {     dissim_hunger <- dissim_hunger %>% mutate(character1 = ifelse(leftCharacter ==          charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%          mutate(character1 = factor(character1), character2 = factor(character2)) }",data cleaning,510335135739297e8,430
"dissim_hunger <- dissim_hunger %>% select(predicate, subid, character1,      character2, responseNum) %>% group_by(character1, character2) %>%      mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,      na.rm = TRUE)) %>% spread(character2, mean)",data cleaning,510335135739297e8,430
"dissim_hunger <- dissim_hunger %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,510335135739297e8,430
"dissim_hunger = dissim_hunger[, c(1, 11, 2:10)]",data cleaning,510335135739297e8,430
dissim_hunger = dissim_hunger[-1],data cleaning,510335135739297e8,430
rownames(dissim_hunger) = names,data cleaning,510335135739297e8,430
colnames(dissim_hunger) = names,data cleaning,510335135739297e8,430
"for (i in 1:9) {     for (j in (i + 1):10) {         dissim_hunger[j, i] = dissim_hunger[i, j]     } }",data cleaning,510335135739297e8,430
dissim_hunger = as.dist(dissim_hunger),data cleaning,510335135739297e8,430
"mds_thinking_Aordinal = mds(dissim_thinking, ndim = 2, type = ""ordinal"")",modeling,510335135739297e8,430
summary(mds_thinking_Aordinal),exploratory,510335135739297e8,430
mds_thinking_Aordinal,evaluation,510335135739297e8,430
"mds_feelings_Aordinal = mds(dissim_feelings, ndim = 2, type = ""ordinal"")",modeling,510335135739297e8,430
summary(mds_feelings_Aordinal),exploratory,510335135739297e8,430
mds_feelings_Aordinal,exploratory,510335135739297e8,430
"mds_hunger_Aordinal = mds(dissim_hunger, ndim = 2, type = ""ordinal"")",modeling,510335135739297e8,430
summary(mds_hunger_Aordinal),modeling,510335135739297e8,430
mds_hunger_Aordinal,modeling,510335135739297e8,430
"plot(mds_thinking_Aordinal, plot.type = ""confplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS solution: THINKING"", xlab = """")",visualization,510335135739297e8,430
"plot(mds_feelings_Aordinal, plot.type = ""confplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS solution: FEELINGS"", xlab = """")",visualization,510335135739297e8,430
"plot(mds_hunger_Aordinal, plot.type = ""confplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS solution: HUNGER"", xlab = """")",visualization,510335135739297e8,430
"plot(mds_thinking_Aordinal, plot.type = ""bubbleplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS bubble plot: THINKING"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_feelings_Aordinal, plot.type = ""bubbleplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS bubble plot: FEELINGS"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_hunger_Aordinal, plot.type = ""bubbleplot"", xlim = c(-1,      1), ylim = c(-1, 1), main = ""MDS bubble plot: HUNGER"", xlab = """")",visualization,510335135739297e8,430
"plot(mds_thinking_Aordinal, plot.type = ""stressplot"", main = ""MDS stress: THINKING"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_feelings_Aordinal, plot.type = ""stressplot"", main = ""MDS stress: FEELINGS"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_hunger_Aordinal, plot.type = ""stressplot"", main = ""MDS stress: HUNGER"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_thinking_Aordinal, plot.type = ""Shepard"", main = ""MDS Shepard plot: THINKING"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_feelings_Aordinal, plot.type = ""Shepard"", main = ""MDS Shepard plot: FEELINGS"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_hunger_Aordinal, plot.type = ""Shepard"", main = ""MDS Shepard plot: HUNGER"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_thinking_Aordinal, plot.type = ""resplot"", main = ""MDS residuals: THINKING"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_feelings_Aordinal, plot.type = ""resplot"", main = ""MDS residuals: FEELINGS"",      xlab = """")",visualization,510335135739297e8,430
"plot(mds_hunger_Aordinal, plot.type = ""resplot"", main = ""MDS residuals: HUNGER"",      xlab = """")",visualization,510335135739297e8,430
hcb = hclust(dissim),modeling,510335135739297e8,430
hcb,modeling,510335135739297e8,430
"par(mfrow = c(1, 2))",visualization,510335135739297e8,430
hcb$merge,exploratory,510335135739297e8,430
plot(hcb$height),visualization,510335135739297e8,430
plot(hcb),visualization,510335135739297e8,430
hcb_thinking = hclust(dissim_thinking),modeling,510335135739297e8,430
hcb_thinking,exploratory,510335135739297e8,430
"par(mfrow = c(1, 2))",visualization,510335135739297e8,430
hcb_thinking$merge,data cleaning,510335135739297e8,430
plot(hcb_thinking$height),visualization,510335135739297e8,430
plot(hcb_thinking),visualization,510335135739297e8,430
hcb_feelings = hclust(dissim_feelings),modeling,510335135739297e8,430
hcb_feelings,exploratory,510335135739297e8,430
"par(mfrow = c(1, 2))",visualization,510335135739297e8,430
hcb_feelings$merge,exploratory,510335135739297e8,430
plot(hcb_feelings$height),modeling,510335135739297e8,430
plot(hcb_feelings),modeling,510335135739297e8,430
hcb_hunger = hclust(dissim_hunger),modeling,510335135739297e8,430
hcb_hunger,exploratory,510335135739297e8,430
"par(mfrow = c(1, 2))",visualization,510335135739297e8,430
hcb_hunger$merge,visualization,510335135739297e8,430
plot(hcb_hunger$height),visualization,510335135739297e8,430
plot(hcb_hunger),visualization,510335135739297e8,430
"req <- c(""foreign"", ""Hmisc"", ""tables"")",setup,510335135739297e8,430
"lapply(req, library, character.only = TRUE)",import,510335135739297e8,430
"analysis <- read.dta(""./data/d00_analysis.dta"")",import,510335135739297e8,430
"tabdat <- with(analysis, data.frame(Sex = factor(sex, labels = c(""Male"",      ""Female"")), Country = factor(country, labels = c(""Czech Republic"",      ""Russia"", ""Romania"")), Diabetes = factor(diabete, labels = c(""Yes"",      ""No"")), Hypertension = factor(hypertension, labels = c(""Yes"",      ""No"")), Stage = factor(stage_imputed, labels = c(""I"", ""II"",      ""III"", ""IV"")), Grade = factor(grade), Histology = histo_grp,      Smoking = factor(smoke_status, labels = c(""Never smoker"",          ""Former smoker"", ""Current smoker"")), `Age at recruitment (years)` = cut(age_recruitment,          breaks = c(min(age_recruitment, na.rm = TRUE), 55, 65,              max(age_recruitment, na.rm = TRUE)), right = FALSE,          include.lowest = TRUE), `BMI (kg/m$^2$)` = cut(bmi_current,          breaks = c(min(bmi_current, na.rm = TRUE), 25, 30, max(bmi_current,              na.rm = TRUE)), right = FALSE, include.lowest = TRUE),      `Season-adjusted circulating 25(OH)D$_3$ category` = factor(d3_q4,          labels = c(""1 (lowest)"", ""2"", ""3"", ""4 (highest)"")), `Vital status` = factor(vitalstatus,          labels = c(""alive"", ""dead"")), Total = ""Total"", check.names = FALSE))",data cleaning,510335135739297e8,430
"addlevel <- function(x) factor(x, levels = c(levels(x), ""missing""))",data cleaning,510335135739297e8,430
"tabdat <- data.frame(lapply(tabdat, addlevel), stringsAsFactors = FALSE,      check.names = FALSE)",data cleaning,510335135739297e8,430
"tabdat[is.na(tabdat)] <- ""missing""",data cleaning,510335135739297e8,430
tabdat <- droplevels(tabdat),data cleaning,510335135739297e8,430
"t1 <- tabular(Total + Literal(""\\\\ %"") + Sex + Literal(""\\\\  %"") +      `Age at recruitment (years)` + Literal(""\\\\ %"") + Country +      Literal(""\\\\ %"") + `BMI (kg/m$^2$)` + Literal(""\\\\ %"") +      Smoking + Literal(""\\\\ %"") + Diabetes + Literal(""\\\\ %"") +      Hypertension + Literal(""\\\\ %"") + Stage + Literal(""\\\\ %"") +      Grade + Literal(""\\\\ %"") + Histology + Literal(""\\\\ %"") +      `Season-adjusted circulating 25(OH)D$_3$ category` ~ (`Vital status` *      ((n = 1) + Paste(Percent(""col""), digits = 0, prefix = ""("",          postfix = "")"", head = ""(\\%)"", justify = ""r"")) + (Total = (n = 1))),      data = tabdat)",data cleaning,510335135739297e8,430
"test <- booktabs(latex(t1, booktabs = TRUE, file = ""./analysis/output/o08_descriptive_by_vitstat.tex"",      caption = ""Demographic characteristics and covariates by vital status""))",exploratory,510335135739297e8,430
"latex(tabular(Factor(Smoking) + Literal(""\\newline %"") + Factor(Sex) ~      Factor(`Vital status`) * ((n = 1) + Paste(Percent(""col""),          digits = 0, prefix = ""("", postfix = "")"", head = ""(\\%)"",          justify = ""r"")), data = tabdat, suppressLabels = 0))",export,510335135739297e8,430
su_vitd <- summary(analysis$vd3_h),export,510335135739297e8,430
"pctiles_vitd <- quantile(analysis$vd3_h, probs = c(0.05, 0.25,      0.5, 0.75, 0.95), na.rm = TRUE)",exploratory,510335135739297e8,430
"sink(""./analysis/output/l08_vitd_summary.txt"")",export,510335135739297e8,430
su_vitd,exploratory,510335135739297e8,430
pctiles_vitd,exploratory,510335135739297e8,430
sink(),export,510335135739297e8,430
"vargha.delaney <- function(r1, r2) {     m <- length(r1)     n <- length(r2)     return((sum(rank(c(r1, r2))[seq_along(r1)])/m - (m + 1)/2)/n) }",data cleaning,510335135739297e8,430
"voteupTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50VoteUp.csv"",      header = TRUE, sep = "";"")",import,510335135739297e8,430
"votedownTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50VoteDown.csv"",      header = TRUE, sep = "";"")",import,510335135739297e8,430
"wc <- wilcox.test(voteupTop50$media, votedownTop50$media)",modeling,510335135739297e8,430
"effectSize <- vargha.delaney(voteupTop50$media, votedownTop50$media)",modeling,510335135739297e8,430
print(wc),exploratory,510335135739297e8,430
options(scipen = 999),setup,510335135739297e8,430
"print(paste(""Tamanho de efeito "", effectSize))",exploratory,510335135739297e8,430
"print(paste(""p-value "", wc$p.value))",exploratory,510335135739297e8,430
print(wc$p.value < 0.05),exploratory,510335135739297e8,430
"print(""********************************"")",exploratory,510335135739297e8,430
"wc <- wilcox.test(votedownTop50$media, voteupTop50$media)",modeling,510335135739297e8,430
"effectSize <- vargha.delaney(votedownTop50$media, voteupTop50$media)",data cleaning,510335135739297e8,430
print(wc),exploratory,510335135739297e8,430
options(scipen = 999),setup,510335135739297e8,430
"print(paste(""Tamanho de efeito "", effectSize))",exploratory,510335135739297e8,430
"print(paste(""p-value "", wc$p.value))",exploratory,510335135739297e8,430
print(wc$p.value < 0.05),exploratory,510335135739297e8,430
library(ogbox),import,510335135739297e8,430
"source(""R/rnaSeqTresh.R"")",import,510335135739297e8,430
"rnaSeq = read.table(""data/linnarsonSingleCell/mouseRNASeq_Zeisel 2015.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = F)",import,510335135739297e8,430
"rnaMeta = rnaSeq[1:10, 3:ncol(rnaSeq)]",import,510335135739297e8,430
rnaMeta = as.data.frame(t(rnaMeta)),data cleaning,510335135739297e8,430
"colnames(rnaMeta) = rnaSeq[1:10, 2]",data cleaning,510335135739297e8,430
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",data cleaning,510335135739297e8,430
"rnaExp = apply(rnaExp, 2, as.numeric)",data cleaning,510335135739297e8,430
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",data cleaning,510335135739297e8,430
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",data cleaning,510335135739297e8,430
"rnaCelIDs = as.numeric(as.character(rnaSeq[12:nrow(rnaSeq), 2]))",data cleaning,510335135739297e8,430
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",data cleaning,510335135739297e8,430
"tresh <- rnaSeqTresh(rnaExp, ""analysis/02.Mouse Single Cell/tresholds"",      cores = 16)",data cleaning,510335135739297e8,430
rn(rnaExp),data cleaning,510335135739297e8,430
"tresholds = matrix(rep(1, len(rn(rnaExp))))",data cleaning,510335135739297e8,430
rownames(tresholds) = rn(rnaExp),data cleaning,510335135739297e8,430
"write.table(tresholds, file = ""analysis/02.Mouse Single Cell/noTresh"",      col.names = F, row.names = T, quote = F)",export,510335135739297e8,430
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval.Robj"")",import,510335135739297e8,430
pval.null.ms = as.numeric(pval_list),data cleaning,510335135739297e8,430
done.null.ms = done_res,data cleaning,510335135739297e8,430
sum(done.null.ms),exploratory,510335135739297e8,430
"max(pval.null.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"min(pval.null.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval.Robj"")",import,510335135739297e8,430
pval.alt.ms = as.numeric(pval_list),exploratory,510335135739297e8,430
done.alt.ms = done_res,exploratory,510335135739297e8,430
sum(done.alt.ms),exploratory,510335135739297e8,430
"max(pval.alt.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"min(pval.alt.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"delIX = c(305, 368, 451, 464)",exploratory,510335135739297e8,430
pval.null.ms = pval.null.ms[-delIX],exploratory,510335135739297e8,430
pval.alt.ms = pval.alt.ms[-delIX],exploratory,510335135739297e8,430
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",exploratory,510335135739297e8,430
"disc.ms = c(rep(0, 574), rep(1, 574))",exploratory,510335135739297e8,430
rnk.ms = order(pval.ms),exploratory,510335135739297e8,430
p.ms = pval.ms[rnk.ms],exploratory,510335135739297e8,430
d.ms = disc.ms[rnk.ms],exploratory,510335135739297e8,430
fdp.ms = NULL,exploratory,510335135739297e8,430
sig.ms = NULL,exploratory,510335135739297e8,430
tpr.ms = NULL,setup,510335135739297e8,430
fpr.ms = NULL,setup,510335135739297e8,430
uni.p.ms = unique(p.ms),data cleaning,510335135739297e8,430
for (i in 1:length(uni.p.ms)) {     wh = which(p.ms <= uni.p.ms[i])     sig.ms[i] = length(wh)     fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh))     tpr.ms[i] = sum(d.ms[wh])/574     fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/574 },data cleaning,510335135739297e8,430
given.FDR = 0.05,setup,510335135739297e8,430
posi = max(which(fdp.ms <= given.FDR)),exploratory,510335135739297e8,430
tpr.ms[posi],exploratory,510335135739297e8,430
fdp.ms[posi],exploratory,510335135739297e8,430
fpr.ms.1000 = fpr.ms,exploratory,510335135739297e8,430
tpr.ms.1000 = tpr.ms,exploratory,510335135739297e8,430
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",data cleaning,510335135739297e8,430
"disc.ms = c(rep(0, 574), rep(1, 574))",data cleaning,510335135739297e8,430
rank.ms = rank(pval.ms),data cleaning,510335135739297e8,430
rank.ms.1000 = rank.ms,data cleaning,510335135739297e8,430
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum_10000/pval.Robj"")",import,510335135739297e8,430
pval.null.ms = as.numeric(pval_list),exploratory,510335135739297e8,430
done.null.ms = done_res,exploratory,510335135739297e8,430
sum(done.null.ms),exploratory,510335135739297e8,430
"max(pval.null.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"min(pval.null.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum_10000/pval.Robj"")",exploratory,510335135739297e8,430
pval.alt.ms = as.numeric(pval_list),data cleaning,510335135739297e8,430
done.alt.ms = done_res,data cleaning,510335135739297e8,430
sum(done.alt.ms),exploratory,510335135739297e8,430
"max(pval.alt.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"min(pval.alt.ms, na.rm = TRUE)",exploratory,510335135739297e8,430
"delIX = c(305, 368, 451, 464)",setup,510335135739297e8,430
pval.null.ms = pval.null.ms[-delIX],exploratory,510335135739297e8,430
pval.alt.ms = pval.alt.ms[-delIX],exploratory,510335135739297e8,430
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",exploratory,510335135739297e8,430
"disc.ms = c(rep(0, 574), rep(1, 574))",setup,510335135739297e8,430
rnk.ms = order(pval.ms),exploratory,510335135739297e8,430
p.ms = pval.ms[rnk.ms],data cleaning,510335135739297e8,430
d.ms = disc.ms[rnk.ms],data cleaning,510335135739297e8,430
fdp.ms = NULL,data cleaning,510335135739297e8,430
sig.ms = NULL,setup,510335135739297e8,430
tpr.ms = NULL,setup,510335135739297e8,430
fpr.ms = NULL,setup,510335135739297e8,430
uni.p.ms = unique(p.ms),data cleaning,510335135739297e8,430
for (i in 1:length(uni.p.ms)) {     wh = which(p.ms <= uni.p.ms[i])     sig.ms[i] = length(wh)     fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh))     tpr.ms[i] = sum(d.ms[wh])/574     fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/574 },data cleaning,510335135739297e8,430
given.FDR = 0.05,setup,510335135739297e8,430
posi = max(which(fdp.ms <= given.FDR)),exploratory,510335135739297e8,430
tpr.ms[posi],exploratory,510335135739297e8,430
fdp.ms[posi],exploratory,510335135739297e8,430
fpr.ms.10000 = fpr.ms,data cleaning,510335135739297e8,430
tpr.ms.10000 = tpr.ms,data cleaning,510335135739297e8,430
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",data cleaning,510335135739297e8,430
"disc.ms = c(rep(0, 574), rep(1, 574))",setup,510335135739297e8,430
library(e1071),setup,983112454880029e8,233
rank.ms = rank(pval.ms),exploratory,510335135739297e8,430
rank.ms.10000 = rank.ms,data cleaning,510335135739297e8,430
"agreement <- function(gear, year, species_def) {     if (species_def == ""mod"") {         df10 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-06/classify_mets/modified/2010/2010p"",              gear, year, "".RDS""))         df12 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-06/classify_mets/modified/2012/2012p"",              gear, year, "".RDS""))     }     else if (species_def == ""spid"") {         df10 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-06/classify_mets/spid/2010/2010p"",              gear, year, "".RDS""))         df12 <- readRDS(paste0(""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-06/classify_mets/spid/2012/2012p"",              gear, year, "".RDS""))     }     else {         warning(""species_def needs to be 'mod' or 'spid'"")     }     df10$predicted_metier <- paste0(df10$predicted_metier, ""_10"")     df12$predicted_metier <- paste0(df12$predicted_metier, ""_12"")     predicted_df <- merge(df10, df12, by = ""trip_id"")     table(predicted_df$predicted_metier.x, predicted_df$predicted_metier.y) }",import,983112454880029e8,233
"pdf(""simu574_ROCandRank_80_21_1000_vs_10000_ms.pdf"")",visualization,510335135739297e8,430
xmax = 1,setup,510335135739297e8,430
ymax = 1,setup,510335135739297e8,430
"years = c(2009, 2011, 2013)",setup,983112454880029e8,233
"plot(c(0, fpr.ms.10000), c(0, tpr.ms.10000), xlim = c(0, xmax),      ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"", ylab = ""TPR (Sensitivity)"",      col = ""red"", type = ""l"")",visualization,510335135739297e8,430
"mod_ari <- rep(NA, 3)",setup,983112454880029e8,233
"points(c(0, fpr.ms.1000), c(0, tpr.ms.1000), type = ""l"", col = ""blue"")",visualization,510335135739297e8,430
"legend(0.4, 0.12, c(""multi-scale 10000 permutatons"", ""multi-scale 1000 permutation""),      col = c(""red"", ""blue""), lty = c(1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,510335135739297e8,430
"for (i in 1:length(years)) {     mod_ari[i] <- classAgreement(agreement(""HKL"", years[i], ""mod""))$crand }",setup,983112454880029e8,233
"spid_ari <- rep(NA, 3)",setup,983112454880029e8,233
status.info = disc.ms,setup,510335135739297e8,430
rank.10000 = rank.ms.10000,setup,510335135739297e8,430
rank.1000 = rank.ms.1000,setup,510335135739297e8,430
ymax = max(rank.1000),data cleaning,510335135739297e8,430
ymin = min(rank.1000),data cleaning,510335135739297e8,430
xmax = max(rank.10000),data cleaning,510335135739297e8,430
"plot(rank.10000, rank.1000, xlim = c(0, xmax), ylim = c(0, ymax),      xlab = ""rank in 10000 permutations"", ylab = ""rank in 1000 permutations"",      col = c(""green"", ""darkgreen"")[status.info + 1], type = ""p"",      main = ""multi-scale based test (dark green: alt)"")",visualization,510335135739297e8,430
dev.off(),setup,510335135739297e8,430
rm(list = ls(all = TRUE)),setup,510335135739297e8,430
"base::source(""./scripts/graphing/graph-presets.R"")",import,510335135739297e8,430
library(magrittr),import,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
library(dplyr),import,510335135739297e8,430
options(show.signif.stars = F),setup,510335135739297e8,430
"path_input <- ""./data-public/raw/scenario-1/cash.txt""",setup,510335135739297e8,430
"ds <- readr::read_table2(path_input, col_names = FALSE)",import,510335135739297e8,430
"names(ds) <- c(""cash"", ""age_group"", ""sex"", ""group"")",setup,510335135739297e8,430
ds %>% glimpse(),exploratory,510335135739297e8,430
ds %>% head(),exploratory,510335135739297e8,430
"ds %>% dplyr::group_by(age_group) %>% dplyr::summarize(n = n(),      average = mean(cash))",exploratory,510335135739297e8,430
ds %>% dplyr::glimpse(),exploratory,510335135739297e8,430
"ds <- ds %>% dplyr::mutate(age_group = factor(x = age_group,      levels = c(1, 2, 3), labels = c(""young"", ""middle"", ""elderly"")),      sex = factor(x = sex, levels = c(1, 2), labels = c(""female"",          ""male""))) %>% dplyr::select(cash, age_group, sex)",data cleaning,510335135739297e8,430
ds %>% glimpse(),exploratory,510335135739297e8,430
ds %>% head(),exploratory,510335135739297e8,430
"g1 <- ds %>% ggplot2::ggplot(aes(x = age_group, y = cash))",visualization,510335135739297e8,430
"g1 <- g1 + geom_bar(mapping = aes(fill = sex), stat = ""identity"",      position = position_dodge(), color = ""black"", alpha = 0.2)",visualization,510335135739297e8,430
g1 <- g1 + main_theme,visualization,510335135739297e8,430
g1 <- g1 + ggplot2::theme(panel.grid = element_blank()),visualization,510335135739297e8,430
g1,visualization,510335135739297e8,430
"g2 <- ds %>% ggplot2::ggplot(aes(x = age_group, y = cash, fill = sex)) +      geom_boxplot(alpha = 0.5, show.legend = T) + geom_jitter(height = 0,      width = 0.2, shape = 21, size = 2, alpha = 0.5) + main_theme",visualization,510335135739297e8,430
g2,visualization,510335135739297e8,430
"d_group_means <- ds %>% dplyr::group_by(age_group, sex) %>% dplyr::summarize(n = n(),      cash_mean = mean(cash, na.rm = T))",data cleaning,510335135739297e8,430
d_group_means,exploratory,510335135739297e8,430
"g3 <- d_group_means %>% ggplot(aes(x = age_group, y = cash_mean,      fill = sex)) + geom_bar(stat = ""identity"", position = position_dodge())",visualization,510335135739297e8,430
g3,visualization,510335135739297e8,430
ds %>% head(),exploratory,510335135739297e8,430
"g4 <- ds %>% ggplot(aes(x = age_group, y = cash, fill = sex)) +      geom_bar(position = ""dodge"", stat = ""summary"", fun.y = ""mean"")",visualization,510335135739297e8,430
g4,visualization,510335135739297e8,430
"g3 <- d_group_means %>% ggplot(aes(x = age_group, y = cash_mean,      fill = sex)) + geom_bar(stat = ""identity"", position = position_dodge())",visualization,510335135739297e8,430
"g3 <- g3 + labs(x = ""Age Group"", y = ""Cash mean"", title = ""Cash mean by group"")",visualization,510335135739297e8,430
"g3 <- g3 + geom_text(aes(label = round(cash_mean, 2)), position = position_dodge(width = 1))",visualization,510335135739297e8,430
g3,visualization,510335135739297e8,430
"print_plot_basic <- function(g, path_output_folder, graph_name,      suffix = NA, ...) {     if (!dir.exists(path_output_folder)) {         dir.create(path_output_folder)     }     graph_name <- paste0(graph_name)     if (!is.na(suffix)) {         (path_save_plot <- paste0(path_output_folder, graph_name,              ""-"", suffix))     }     else {         (path_save_plot <- paste0(path_output_folder, graph_name))     }     jpeg(filename = paste0(path_save_plot, "".jpg""), ...)     g %>% print()     dev.off() }",visualization,510335135739297e8,430
"g <- ds %>% ggplot2::ggplot(aes(x = age_group, y = cash, fill = sex)) +      geom_boxplot(alpha = 0.5, show.legend = T) + geom_jitter(height = 0,      width = 0.2, shape = 21, size = 2, alpha = 0.5) + main_theme",visualization,510335135739297e8,430
"g %>% print_plot_basic(""./analysis/scenario-1/prints/"", ""example-1"",      width = 216, height = 140, units = ""mm"", quality = 100, res = 300)",visualization,510335135739297e8,430
"list.files(""./analysis/scenario-1/prints/"", full.names = TRUE)",setup,510335135739297e8,430
"path_publish_report_1 <- ""./analysis/scenario-1/scenario-1.Rmd""",setup,510335135739297e8,430
allReports <- c(path_publish_report_1),setup,510335135739297e8,430
pathFilesToBuild <- c(allReports),setup,510335135739297e8,430
"testit::assert(""The knitr Rmd files should exist."", base::file.exists(pathFilesToBuild))",setup,510335135739297e8,430
"for (pathFile in pathFilesToBuild) {     rmarkdown::render(input = pathFile, output_format = c(""html_document""),          clean = TRUE) }",communication,510335135739297e8,430
"source(""analysis/InitialSetup.R"")",import,510335135739297e8,430
"source(""analysis/Ordination.R"")",import,510335135739297e8,430
"source(""analysis/VariationPartitioning.R"")",import,510335135739297e8,430
"source(""analysis/Map.R"")",import,510335135739297e8,430
"pdf(""figures/Figure1_hja-map.pdf"", height = 6, width = 6)",visualization,510335135739297e8,430
hja.map,visualization,510335135739297e8,430
dev.off(),setup,510335135739297e8,430
"pdf(""figures/Figure2_hja-dbrda.pdf"", height = 6, width = 6, bg = ""white"")",visualization,510335135739297e8,430
"par(oma = c(0.1, 0.1, 0.1, 0.1), pty = ""s"")",setup,510335135739297e8,430
"plot(scores(hja.dbrda.env, display = ""sites""), xlab = paste(""dbRDA 1 ("",      explain.var(hja.dbrda.env, axis = 1), ""%)"", sep = """"), ylab = paste(""dbRDA 2 ("",      explain.var(hja.dbrda.env, axis = 2), ""%)"", sep = """"), pch = 21,      cex = 2, type = ""n"", cex.lab = 1.5, cex.axis = 1.2, axes = F,      xlim = c(-1, 2), ylim = c(-1.5, 1.5), asp = 1)",visualization,510335135739297e8,430
add.axes(),visualization,510335135739297e8,430
"abline(h = 0, v = 0, lty = 3)",visualization,510335135739297e8,430
"points(scores(hja.dbrda.env, display = ""sites"")[which(design$habitat ==      ""sediment""), ], pch = 21, bg = ""wheat"", cex = 2)",visualization,510335135739297e8,430
"points(scores(hja.dbrda.env, display = ""sites"")[which(design$habitat ==      ""water""), ], pch = 24, bg = ""skyblue"", cex = 2)",visualization,510335135739297e8,430
"ordiellipse(hja.dbrda.env, design$habitat, conf = 0.95, kind = ""se"",      lwd = 1, draw = ""polygon"", col = c(""wheat"", ""skyblue""), border = ""black"",      alpha = 63)",visualization,510335135739297e8,430
"vectors <- scores(hja.dbrda.env, display = ""bp"")",visualization,510335135739297e8,430
"text(1.5 * vectors[, 1], 1.5 * vectors[, 2], pos = c(4, 4, 4,      4), labels = rownames(vectors), offset = 0.2)",visualization,510335135739297e8,430
"legend(""topright"", legend = c(""Planktonic"", ""Sediment""), pch = c(24,      21), bty = ""n"", pt.bg = c(""skyblue"", ""wheat""))",visualization,510335135739297e8,430
dev.off(),visualization,510335135739297e8,430
"pdf(""figures/Figure4_RaupCrickBC.pdf"", width = 6, height = 6)",setup,510335135739297e8,430
"RC.brayplot <- ggplot(data = rc.dat) + geom_density(aes(x = rc.bray,      y = ..scaled.., fill = Habitat), alpha = 0.5) + labs(x = expression(paste(""RC""[""bray""])),      y = ""Frequency"") + scale_fill_manual(values = c(""skyblue"",      ""wheat"")) + theme_cowplot() + theme(axis.title = element_text(size = 16),      axis.text = element_text(size = 12))",visualization,510335135739297e8,430
RC.brayplot,visualization,510335135739297e8,430
dev.off(),visualization,510335135739297e8,430
"pdf(""figures/Figure5_CommAssembly.pdf"", width = 10, height = 6)",setup,510335135739297e8,430
assembly.counts,visualization,510335135739297e8,430
dev.off(),visualization,510335135739297e8,430
dev.off(),setup,510335135739297e8,430
"source(""analysis/InitialSetup.R"")",import,510335135739297e8,430
"data(""Orange"")",import,510335135739297e8,430
"temp <- read.csv(file = ""data/TEMP.csv"", header = TRUE)",import,510335135739297e8,430
"CityTemp <- read.csv(file = ""data/CityTemp.csv"", header = TRUE)",import,510335135739297e8,430
rm(list = ls()),setup,510335135739297e8,430
library(ggplot2),import,510335135739297e8,430
library(mixRSVP),import,510335135739297e8,430
library(dplyr),import,510335135739297e8,430
library(magrittr),import,510335135739297e8,430
library(BayesFactor),import,510335135739297e8,430
"setwd(""~/gitCode/nStream/"")",setup,510335135739297e8,430
"source(""ggplotElements.R"")",import,510335135739297e8,430
theme_set(theme_apa(base_size = 20)),setup,510335135739297e8,430
"inclusionBF <- function(priorProbs, variable) {     if (typeof(priorProbs) == ""S4"")          priorProbs <- as.vector(priorProbs)     theseNames <- names(priorProbs)     nProbs <- 1:length(priorProbs)     variableMatches <- grep(variable, theseNames)     if (grepl("":"", variable)) {         subordinateVariables <- variable %>% strsplit("":"") %>%              unlist()         thisRegex <- paste0(subordinateVariables, collapse = "".*\\+.*"")         subordinateEffects <- grep(thisRegex, theseNames, perl = T)         subordinateEffects <- subordinateEffects[!subordinateEffects %in%              variableMatches]         sum(priorProbs[variableMatches])/sum(priorProbs[subordinateEffects])     }     else {         interactionMatches <- grep(paste0(variable, ""(?=:)|(?<=:)"",              variable), theseNames, perl = T)         variableMainEffects <- variableMatches[!variableMatches %in%              interactionMatches]         otherMainEffects <- nProbs[!nProbs %in% c(variableMainEffects,              interactionMatches)]         sum(priorProbs[variableMainEffects])/sum(priorProbs[otherMainEffects])     } }",data cleaning,510335135739297e8,430
testPositions = T,setup,510335135739297e8,430
plots <- F,setup,510335135739297e8,430
if (plots) {     savePlots <- F },setup,510335135739297e8,430
saveIndividualTSV <- F,setup,510335135739297e8,430
saveAllErrorsTSV <- F,setup,510335135739297e8,430
participantPlots <- T,setup,510335135739297e8,430
bootstrapPredictions <- F,setup,510335135739297e8,430
nRepetitions <- 1000,setup,510335135739297e8,430
"dataPath <- ""rawData/18Streams""",setup,510335135739297e8,430
pracTrials <- 1:20,setup,510335135739297e8,430
maxTrials <- 270,setup,510335135739297e8,430
"group = ""SONA/18Streams""",setup,510335135739297e8,430
"if (plots) {     if (savePlots) {         if (!""plots"" %in% list.dirs(full.names = F)) {             dir.create(""plots"")         }         if (!group %in% list.dirs(path = ""plots"", full.names = F)) {             dir.create(paste0(""plots/"", group))         }     } }",setup,510335135739297e8,430
"files <- list.files(pattern = ""^18[A-Z][A-Z].*\\.txt$"", path = dataPath,      full.names = T)",setup,510335135739297e8,430
print(files),exploratory,510335135739297e8,430
widthPix = 1024,setup,510335135739297e8,430
heightPix = 768,setup,510335135739297e8,430
monitorwidth = 40.5,setup,510335135739297e8,430
viewingDist = 42,setup,510335135739297e8,430
pixelsPerDegree = widthPix/(atan(monitorwidth/viewingDist)/pi *      180),setup,510335135739297e8,430
rate = 1000/12,setup,510335135739297e8,430
"eyetrackerFiles <- list.files(path = ""rawData/18Streams/Eyetracker"",      full.names = T)",setup,510335135739297e8,430
criterion = 1,setup,510335135739297e8,430
"skew <- function(x) {     denom <- (sd(x, na.rm = T)^3) * (length(which(!is.na(x))) -          1) * (length(which(!is.na(x))) - 2)     deviation <- x[!is.na(x)] - mean(x, na.rm = T)     numer <- sum(deviation^3) * length(which(!is.na(x)))     numer/denom }",data cleaning,510335135739297e8,430
totalRows <- length(files) * 250,setup,510335135739297e8,430
"allErrors <- data.frame(exp = character(totalRows), condition = character(totalRows),      SPE = numeric(totalRows), targetSP = numeric(totalRows),      ID = character(totalRows), fixationReject = logical(totalRows),      button = numeric(totalRows), ring = numeric(totalRows), stringsAsFactors = F)",setup,510335135739297e8,430
startRow <- 1,setup,510335135739297e8,430
"for (dataset in files) {     temp <- read.table(dataset, sep = ""\t"", header = T, stringsAsFactors = F)     if (testPositions) {         print(xtabs(~ring + nStreams, data = temp))         print(xtabs(~whichStreamCuedAngle0 + ring, data = temp))     }     temp <- temp[-pracTrials, ]     participant <- temp$subject[1]     temp %<>% mutate(responsePos = cuePos0 + responsePosRelative0)     thisEyetrackerFile <- eyetrackerFiles[grepl(paste0("".*"",          participant, "".*""), eyetrackerFiles)]     temp %<>% mutate(fixationReject = FALSE)     if (length(thisEyetrackerFile) > 0) {         theseFixations <- read.table(thisEyetrackerFile, sep = ""\t"",              stringsAsFactors = F, header = T)         theseFixations %<>% mutate(CURRENT_FIX_X_DEG = CURRENT_FIX_X/pixelsPerDegree)         theseFixations %<>% mutate(CURRENT_FIX_Y_DEG = CURRENT_FIX_Y/pixelsPerDegree)         theseFixations %<>% filter(!TRIAL_INDEX %in% pracTrials)         theseFixations %<>% mutate(fixationDistance = 0)         for (index in unique(theseFixations$TRIAL_INDEX)) {             theseFixationsThisTrial = which(theseFixations$TRIAL_INDEX ==                  index)             nFixationsThisTrial <- length(theseFixationsThisTrial)             if (nFixationsThisTrial > 1) {                 initialFixationX = theseFixations$CURRENT_FIX_X_DEG[theseFixationsThisTrial[1]]                 initialFixationY = theseFixations$CURRENT_FIX_Y_DEG[theseFixationsThisTrial[1]]                 for (thisFixationRow in theseFixationsThisTrial) {                   if (thisFixationRow == theseFixationsThisTrial[1]) {                   }                   else {                     xVector <- theseFixations$CURRENT_FIX_X_DEG[thisFixationRow] -                        initialFixationX                     yVector <- theseFixations$CURRENT_FIX_Y_DEG[thisFixationRow] -                        initialFixationY                     fixationDistance <- sqrt(xVector^2 + yVector^2)                     theseFixations$fixationDistance[thisFixationRow] <- fixationDistance                     if (fixationDistance >= criterion) {                       if (!theseFixations$CURRENT_FIX_BLINK_AROUND[thisFixationRow] %in%                          c(""BEFORE"", ""AFTER"")) {                         temp %<>% mutate(fixationReject = replace(fixationReject,                            trialnum == index - 1, TRUE))                       }                     }                   }                 }             }         }         if (mean(temp$fixationReject) > 0.4) {             next         }     }     streamColumns <- grep(""streamLtrSequence"", colnames(temp))     endRow = startRow + nrow(temp) - 1     allErrors[startRow:endRow, ] <- temp[, c(1, 4, 16, 8, 3,          37, 7, 5)]     startRow <- endRow + 1     if (saveIndividualTSV) {         write.table(twoStreams[!twoStreams$fixationReject, ],              paste0(""wrangledData/"", group, ""/twoStreams/"", participant,                  "".txt""), sep = ""\t"", col.names = T, row.names = F)         write.table(eighteenStreams[!eighteenStreams$fixationReject,              ], paste0(""wrangledData/"", group, ""/eighteenStreams/"",              participant, "".txt""), sep = ""\t"", col.names = T,              row.names = F)     }     print(mean(temp$fixationReject)) }",import,510335135739297e8,430
print(Sys.getpid()),exploratory,381895688129589e8,436
library(dplyr),setup,381895688129589e8,436
library(cmapQuery),setup,381895688129589e8,436
library(magrittr),setup,381895688129589e8,436
library(glue),setup,381895688129589e8,436
library(homologene),setup,381895688129589e8,436
"dir.create(""analysis/01.L1000Analysis/fwdWebRun/similar"", showWarnings = FALSE,      recursive = TRUE)",setup,381895688129589e8,436
"dir.create(""analysis/01.L1000Analysis/fwdWebRun/opposite"", showWarnings = FALSE,      recursive = TRUE)",setup,381895688129589e8,436
"print(""loading data"")",setup,381895688129589e8,436
"load(""data/genesEdgerNoOutlier.rda"")",import,381895688129589e8,436
dataset = genesEdgerNoOutlier,not sure,381895688129589e8,436
"groups = c(""E12_1_week_IP_vs_naive_adult_3_IP"", ""E12_2_week_IP_vs_naive_adult_3_IP"",      ""E12_3_day_IP_vs_naive_adult_3_IP"", ""naive_1_week_IP_vs_naive_adult_3_IP"",      ""naive_2_weeks_IP_vs_naive_adult_3_IP"", ""naive_3_days_IP_vs_naive_adult_3_IP"")",data cleaning,381895688129589e8,436
options(httr_oob_default = TRUE),setup,614365294342861e8,434
googledrive::drive_auth(),setup,614365294342861e8,434
"raw_path <- ""analysis/data/raw_data""",evaluation,614365294342861e8,434
"figure_path <- ""analysis/figures""",evaluation,614365294342861e8,434
"output_folder <- googledrive::drive_mkdir(""analysis/output"",      parent = ""temp_for_scott"")",evaluation,614365294342861e8,434
"output_folder_spring <- googledrive::drive_mkdir(""spring"", parent = ""temp_for_scott/analysis/output"")",evaluation,614365294342861e8,434
"output_folder_fall <- googledrive::drive_mkdir(""fall"", parent = ""temp_for_scott/analysis/output"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""data"", parent = ""temp_for_scott/analysis/"")",evaluation,614365294342861e8,434
"raw_data_folder <- googledrive::drive_mkdir(""raw_data"", parent = ""temp_for_scott/analysis/data"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""fall"", parent = ""temp_for_scott/analysis/data/raw_data"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""spring"", parent = ""temp_for_scott/analysis/data/raw_data"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""derived_data"", parent = ""temp_for_scott/analysis/data"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""fall"", parent = ""temp_for_scott/analysis/data/derived_data"")",evaluation,614365294342861e8,434
"googledrive::drive_mkdir(""spring"", parent = ""temp_for_scott/analysis/data/derived_data"")",evaluation,614365294342861e8,434
"raw_files <- file.path(raw_path, grep(""biomass_habmod-.*.rds"",      list.files(raw_path), value = TRUE))",evaluation,614365294342861e8,434
"rw_dat <- googledrive::as_dribble(""temp_for_scott/analysis/output/fall/"")",evaluation,614365294342861e8,434
"files <- purrr::map(raw_files, googledrive::drive_upload, path = raw_data_folder,      verbose = TRUE)",export,614365294342861e8,434
"spring_figures <- list.files(file.path(figure_path, ""spring""),      full.names = TRUE)",import,614365294342861e8,434
"sfigures <- purrr::map(spring_figures, googledrive::drive_upload,      path = output_folder_spring, verbose = TRUE)",export,614365294342861e8,434
"fall_figures <- file.path(figure_path, grep(""fall.*"", list.files(figure_path),      value = TRUE))",evaluation,614365294342861e8,434
"output_folder_fall <- googledrive::as_dribble(""temp_for_scott/analysis/output/fall/"")",evaluation,614365294342861e8,434
library(scater),import,958044198341668e8,437
"ffigures <- purrr::map(fall_figures, googledrive::drive_upload,      path = output_folder_fall, verbose = TRUE)",export,614365294342861e8,434
"derived_fall <- file.path(paste0(derived_path, ""fall""), list.files(file.path(derived_path,      ""fall"")))",evaluation,614365294342861e8,434
library(limma),import,958044198341668e8,437
library(edgeR),import,958044198341668e8,437
library(readr),import,958044198341668e8,437
library(aargh),import,958044198341668e8,437
library(magrittr),import,958044198341668e8,437
library(dplyr),import,958044198341668e8,437
"derived_folder_fall <- googledrive::as_dribble(""temp_for_scott/analysis/data/derived_data/fall/"")",evaluation,614365294342861e8,434
"fderived <- purrr::map(derived_fall, googledrive::drive_upload,      path = derived_folder_fall, verbose = TRUE)",export,614365294342861e8,434
"derived_spring <- file.path(paste0(derived_path, ""spring""), list.files(file.path(derived_path,      ""spring"")))",evaluation,614365294342861e8,434
"derived_folder_spring <- googledrive::as_dribble(""temp_for_scott/analysis/data/derived_data/spring/"")",evaluation,614365294342861e8,434
"sderived <- purrr::map(derived_spring, googledrive::drive_upload,      path = derived_folder_spring, verbose = TRUE)",export,614365294342861e8,434
"fall_dat <- list.files(""analysis/data/derived_data/fall"", full.names = TRUE)",evaluation,614365294342861e8,434
"fall_dat <- fall_dat[!grepl(""-fall"", fall_dat)]",data cleaning,614365294342861e8,434
"new_fall_dat <- sub(""-"", ""-fall-"", fall_dat)",data cleaning,614365294342861e8,434
"file.rename(fall_dat, new_fall_dat)",setup,614365294342861e8,434
"spring_figs <- file.path(figure_path, list.files(figure_path)[grepl(""spring.*"",      list.files(figure_path))])",evaluation,614365294342861e8,434
"new_spring_figs <- file.path(figure_path, ""spring"", grep(""spring.*"",      list.files(figure_path), value = TRUE))",evaluation,614365294342861e8,434
"file.rename(spring_figs, new_spring_figs)",not sure,614365294342861e8,434
"fall_figs <- file.path(figure_path, list.files(figure_path)[grepl(""fall.*"",      list.files(figure_path))])",export,614365294342861e8,434
"new_fall_figs <- file.path(figure_path, ""fall"", grep(""fall.*"",      list.files(figure_path), value = TRUE))",evaluation,614365294342861e8,434
"file.rename(fall_figs, new_fall_figs)",export,614365294342861e8,434
googledrive::drive_ls(rw_dat),evaluation,614365294342861e8,434
googledrive::drive_rm(rw_dat),evaluation,614365294342861e8,434
"subDirs <- c(""static_vars"")",evaluation,614365294342861e8,434
"gd_loader <- function(gdDir, subDir, mainDir) {     library(magrittr)     drive_files <- googledrive::drive_ls(paste0(gdDir, subDir),          pattern = "".rdata|.RData"")     cat(""Found "", nrow(drive_files), "" files in "", subDir, "".\n"",          sep = """")     ifelse(!dir.exists(file.path(mainDir, subDir)), dir.create(file.path(mainDir,          subDir), recursive = TRUE), FALSE)     cat(""\nAttempting to download.\n"")     drive_d <- function(d, mainDir, subDir, verbose, overwrite) {         path_name <- file.path(mainDir, subDir, d[""name""])         file_name <- d         googledrive::drive_download(file = file_name, path = path_name,              verbose = verbose, overwrite = overwrite)     }     drive_files %>% split(.$name) %>% purrr::map(drive_d, mainDir = mainDir,          subDir = subDir, verbose = FALSE, overwrite = TRUE) }",export,614365294342861e8,434
"source(""R/geneSelect.R"")",setup,624446473317221e8,438
"source(""R/microglialException.R"")",setup,624446473317221e8,438
"source(""R/rotateSelect.R"")",import,624446473317221e8,438
"dataDir = ""data/""",import,624446473317221e8,438
"geneOut = ""analysis//01.Gene Selection/Fold""",setup,624446473317221e8,438
"rotationOut = ""analysis//01.Gene Selection/Rotation""",export,624446473317221e8,438
"rotSelOut = ""analysis/01.Gene Selection/RotSel""",export,624446473317221e8,438
"groupNames = c(""PyramidalDeep"", ""MajorType"", ""DopaSelect"")",export,624446473317221e8,438
"regionNames = ""Region""",setup,624446473317221e8,438
cores = 15,setup,624446473317221e8,438
"dir.create(geneOut, showWarnings = F, recursive = T)",setup,624446473317221e8,438
"geneSelect(paste0(dataDir, ""/meltedDesign.tsv""), paste0(dataDir,      ""/"", ""finalExp.csv""), geneOut, groupNames, regionNames, cores = cores,      )",export,624446473317221e8,438
"geneSelect(paste0(dataDir, ""/meltedDesign2.tsv""), paste0(dataDir,      ""/"", ""finalExp2.csv""), paste0(geneOut, 2), groupNames, regionNames,      cores = cores)",export,624446473317221e8,438
"for (i in 1:500) {     print(i)     geneSelect(paste0(dataDir, ""/meltedDesign.tsv""), paste0(dataDir,          ""/"", ""finalExp.csv""), paste0(rotationOut, ""/"", i), groupNames,          regionNames, rotate = 0.33, cores = cores) }",export,624446473317221e8,438
"for (i in 1:500) {     print(i)     geneSelect(paste0(dataDir, ""/meltedDesign2.tsv""), paste0(dataDir,          ""/"", ""finalExp2.csv""), paste0(rotationOut, ""2"", ""/"",          i), groupNames, regionNames, rotate = 0.33, cores = cores) }",export,624446473317221e8,438
"rotateSelect(rotationOut, rotSelOut, cores = cores)",export,624446473317221e8,438
"rotateSelect(paste0(rotationOut, 2), paste0(rotSelOut, 2), cores = cores)",evaluation,624446473317221e8,438
"allGenes = list(genes1 = allPuristOut(paste0(rotSelOut, ""/Relax"")),      genes2 = allPuristOut(paste0(rotSelOut, ""2"", ""/Relax"")))",evaluation,624446473317221e8,438
"for (n in 1:len(allGenes)) {     genes = allGenes[[n]]     for (i in 1:len(genes)) {         pieces = strsplit(names(genes)[i], ""_"")[[1]]         if (is.na(pieces[2])) {             pieces[2] = pieces[1]             pieces[1] = ""All""         }         dir.create(paste0(""analysis//01.Gene Selection/FinalGenes"",              n, ""/"", pieces[2], ""/"", pieces[1]), showWarnings = F,              recursive = T)         for (j in 1:len(genes[[i]])) {             write.table(genes[[i]][[j]], paste0(""analysis/01.Gene Selection/FinalGenes"",                  n, ""/"", pieces[2], ""/"", pieces[1], ""/"", names(genes[[i]])[j]),                  row.names = F, quote = F, col.names = F)         }     } }",data cleaning,624446473317221e8,438
"system(""rm -rf \""analysis/01.Gene Selection/FinalGenes/\"""")",export,624446473317221e8,438
"file.rename(""analysis/01.Gene Selection/FinalGenes1/"", ""analysis/01.Gene Selection/FinalGenes/"")",data cleaning,624446473317221e8,438
"microglialException(""analysis/01.Gene Selection/FinalGenes/"",      cores = cores)",setup,624446473317221e8,438
"microglialException(""analysis/01.Gene Selection/FinalGenes2/"",      cores = cores)",not sure,624446473317221e8,438
"microglialException(""analysis/01.Gene Selection/FinalGenes2/"",      cores = cores)",not sure,624446473317221e8,438
"setwd(""E:/Git/github/r-scripts/analysis/"")",setup,624446473317221e8,438
library(data.table),setup,624446473317221e8,438
"posts_score <- fread(""data/posts_score.csv"", header = FALSE,      sep = "","", quote = ""\"""", strip.white = TRUE, showProgress = TRUE,      encoding = ""UTF-8"", na.strings = c("""", ""null""), stringsAsFactors = FALSE)",import,624446473317221e8,438
"names(posts_score) <- c(""PostId"", ""PostTypeId"", ""Score"")",data cleaning,624446473317221e8,438
summary(posts_score$Score),exploratory,624446473317221e8,438
"quantile(posts_score$Score, seq(0.9, 1, by = 0.01))",exploratory,624446473317221e8,438
length(posts_score$Score[posts_score$Score >= 1])/nrow(posts_score) *      100,exploratory,624446473317221e8,438
length(posts_score$Score[posts_score$Score >= 5])/nrow(posts_score) *      100,exploratory,624446473317221e8,438
rm(list = ls()),setup,624446473317221e8,438
"setwd(""C:/Users/Xuebert/Dropbox/Albert Xue/Research/Deployment/SHAPE-Seq_event_detector/"")",setup,624446473317221e8,438
"source(""support_functions/plotting/make_visual.R"")",setup,624446473317221e8,438
"source(""support_functions/utility_functions.R"")",setup,624446473317221e8,438
"source(""support_functions/color_to_hex.R"")",setup,624446473317221e8,438
"source(""support_functions/find_ND.R"")",setup,624446473317221e8,438
library(ogbox),setup,666824544547126e8,439
"source(""R/geneSelect.R"")",setup,666824544547126e8,439
"source(""R/microglialException.R"")",import,666824544547126e8,439
"source(""R/rotateSelect.R"")",import,666824544547126e8,439
"compare_optimized <- function(optimized_file, original_file,      outfile_name = ""outfile"") {     load(optimized_file)     data_mat = Reduce(""+"", data_mat)     original_events = read.csv(original_file)     original_events[original_events == -3] = -1     original_events[original_events == -1.5] = 1     original_events[original_events == 3] = 1     original_events[original_events == 1.5] = 1     original_events[original_events == 2] = 0     original_events[original_events == -2] = 0     concurrent_events = matrix(NA, nrow = 0, ncol = 4)     event_locations = expand_runs(event_scan[winner][[1]], data_mat)     event_locations[is.na(event_locations)] = 0     agreement = which((event_locations == original_events) &          (event_locations != 0) & (original_events != 0), arr.ind = T)     disagreement_FP = which((event_locations != original_events) &          (original_events == 0), arr.ind = T)     disagreement_FN = which((event_locations != original_events) &          (event_locations == 0), arr.ind = T)     disagreement_TN = which((original_events == 0) & (event_locations ==          0), arr.ind = T)     pdf(paste(outfile_name, "".pdf"", sep = """"), width = 14, height = 14,          useDingbats = F)     temp = data_mat * 0     temp[agreement] = event_locations[agreement]     make_visual(data_mat, temp, concurrent_events)     par(new = T)     event_colors = list(upswing = color_to_hex(""purple"", 0.1),          downswing = color_to_hex(""purple"", 0.1))     temp = data_mat * 0     temp[disagreement_FP] = event_locations[disagreement_FP]     make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3,          3), ramp_draw = c(-1, 1), event_colors = event_colors,          box_resize = 1, lwd = 2)     par(new = T)     event_colors = list(upswing = color_to_hex(""forestgreen"",          0.1), downswing = color_to_hex(""forestgreen"", 0.1))     temp = data_mat * 0     temp[disagreement_FN] = original_events[disagreement_FN]     make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3,          3), ramp_draw = c(-1, 1), event_colors = event_colors,          box_resize = 1, lwd = 2)     par(new = F)     make_visual(data_mat, original_events, concurrent_events)     title(""Original"")     make_visual(data_mat, event_locations, concurrent_events)     title(""Optimized"")     temp = cbind(matrix(threshold_distance/max(threshold_distance),          ncol = 1), matrix(event_distance, ncol = 1))     ND = find_ND(temp)     par(mar = c(8, 8, 8, 8))     plot(x = temp[ND, 1], y = temp[ND, 2], xlab = ""Normalized threshold sum"",          ylab = ""Normalized event number"", xlim = c(0, 1), ylim = c(0,              1), col = ""grey50"", pch = 20, cex = 2)     par(new = T)     plot(x = threshold_distance[winner]/max(threshold_distance),          y = event_distance[winner], xaxt = ""n"", yaxt = ""n"", xlim = c(0,              1), ylim = c(0, 1), xlab = """", ylab = """", bty = ""n"",          pch = 20, col = ""red"", cex = 3)     lines(x = c(0, threshold_distance[winner]/max(threshold_distance)),          y = c(0, event_distance[winner]), lty = 2)     dev.off()     TP = nrow(agreement)     FP = nrow(disagreement_FP)     FN = nrow(disagreement_FN)     TN = nrow(disagreement_TN)     TPR = TP/(TP + FN)     FPR = FP/(FP + TN)     precision = TP/(TP + FP)     return(list(TPR = TPR, FPR = FPR, precision = precision)) }",evaluation,624446473317221e8,438
"compare_optimized(""optimized_thresholds_SRP_2.RData"", ""analysis/SRP/replicates/SRP.csv"",      ""optimized_comparison_SRP_2"")",evaluation,624446473317221e8,438
"dataDir = ""data/""",import,666824544547126e8,439
"compare_optimized(""optimized_thresholds_F_0mM_2.RData"", ""analysis/F/replicates/F_0mM.csv"",      ""optimized_comparison_F_0mM_2"")",evaluation,624446473317221e8,438
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",not sure,624446473317221e8,438
"geneOut = ""analysis//01.Gene Selection/Fold""",import,666824544547126e8,439
"rotationOut = ""analysis//01.Gene Selection/Rotation""",import,666824544547126e8,439
"rotSelOut = ""analysis/01.Gene Selection/RotSel""",import,666824544547126e8,439
"groupNames = c(""PyramidalDeep"", ""MajorType"", ""DopaSelect"")",data cleaning,666824544547126e8,439
"regionNames = ""Region""",data cleaning,666824544547126e8,439
cores = 15,setup,666824544547126e8,439
"dir.create(geneOut, showWarnings = F, recursive = T)",not sure,666824544547126e8,439
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null > x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null < x))         }, statistic.null = statistic.null)     }     numEqual = sapply(statistic.alt, function(x, statistic.null) {         return(sum(statistic.null == x))     }, statistic.null = statistic.null)     Uval = runif(length(statistic.alt))     pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +          1)     return(pval.list) }",evaluation,929883772274479e8,440
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,929883772274479e8,440
siteSize = 2048,not sure,929883772274479e8,440
"treatment = ""Copper""",modeling,929883772274479e8,440
null = FALSE,data cleaning,929883772274479e8,440
"strand = ""both""",modeling,929883772274479e8,440
window.size = 300,visualization,929883772274479e8,440
numSam = 6,not sure,929883772274479e8,440
setwd(wd.path),setup,929883772274479e8,440
filter.cut = 60,data cleaning,929883772274479e8,440
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",export,929883772274479e8,440
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",export,929883772274479e8,440
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,929883772274479e8,440
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",evaluation,929883772274479e8,440
num.tests = length(deseq.alt),modeling,929883772274479e8,440
"pval.deseq.3.60 = rep(NA, num.tests)",evaluation,929883772274479e8,440
ix.final = (1:num.tests)[-del.ix.deseq],data cleaning,929883772274479e8,440
pval.deseq.3.60[ix.final] = pval.deseq,data cleaning,929883772274479e8,440
length(del.ix.deseq),not sure,929883772274479e8,440
filter.cut = 30,exploratory,929883772274479e8,440
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",import,929883772274479e8,440
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",import,929883772274479e8,440
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,929883772274479e8,440
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,950886615784839e8,441
"pval.deseq = get.pval.from.empirical.null.dist.discrete(statistic.null = deseq.null[-del.ix.deseq],      statistic.alt = deseq.alt[-del.ix.deseq], big.sig = FALSE)",evaluation,929883772274479e8,440
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,950886615784839e8,441
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,950886615784839e8,441
"pval.deseq.3.30 = rep(NA, num.tests)",evaluation,929883772274479e8,440
ix.final = (1:num.tests)[-del.ix.deseq],data cleaning,929883772274479e8,440
pval.deseq.3.30[ix.final] = pval.deseq,data cleaning,929883772274479e8,440
length(del.ix.deseq),exploratory,929883772274479e8,440
filter.cut = 20,data cleaning,929883772274479e8,440
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,759728535544127e8,442
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,759728535544127e8,442
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",import,929883772274479e8,440
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.noC.min.pval."",      filter.cut, "".txt""))[, 1])",import,929883772274479e8,440
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,929883772274479e8,440
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,330289807170629e8,443
library(caret),modeling,721855455776677e8,444
library(doMC),setup,721855455776677e8,444
library(mmadsenr),setup,721855455776677e8,444
library(futile.logger),setup,721855455776677e8,444
library(dplyr),setup,721855455776677e8,444
library(ggthemes),setup,721855455776677e8,444
"log_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",      filename = ""population-classification.log"")",visualization,721855455776677e8,444
"flog.appender(appender.file(log_file), name = ""cl"")",not sure,721855455776677e8,444
clargs <- commandArgs(trailingOnly = TRUE),not sure,721855455776677e8,444
"if (length(clargs) == 0) {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-4-population-data.rda"") } else {     pop_data_file <- get_data_path(suffix = ""experiment-ctmixtures/equifinality-4"",          filename = ""equifinality-4-population-data.rda"", args = clargs) }",setup,721855455776677e8,444
library(knitr),setup,959852369036525e8,445
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,959852369036525e8,445
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,959852369036525e8,445
"for (i in seq(1, (dim(mastersheet)[1]))) {     strain <- mastersheet[i, 1]     dir <- mastersheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain) }",exploratory,959852369036525e8,445
rm(list = ls()),setup,484889970393851e8,446
"library(""EpiModelHIV"")",setup,484889970393851e8,446
"library(""EpiModelHPC"")",setup,484889970393851e8,446
"library(""dplyr"")",setup,484889970393851e8,446
"source(""analysis/fx.R"")",import,484889970393851e8,446
library(ggplot2),setup,484889970393851e8,446
library(ggridges),setup,484889970393851e8,446
library(gridExtra),setup,484889970393851e8,446
"load(""data/t1/sim.n2000.rda"")",import,484889970393851e8,446
sim.base <- sim,exploratory,484889970393851e8,446
sims <- 2132:2162,exploratory,484889970393851e8,446
length(sims),exploratory,484889970393851e8,446
"vals <- seq(0.5, 2, 0.05)",exploratory,484889970393851e8,446
"for (i in seq_along(sims)) {     fn <- list.files(""data/f1"", pattern = as.character(sims[i]),          full.names = TRUE)     load(fn)     i.prev.W <- as.numeric(sim$epi$i.prev.W[520, ])     i.prev.B <- as.numeric(sim$epi$i.prev.B[520, ])     haz.W <- as.numeric(colMeans(tail(sim$epi$ir100.W, 52)))     haz.B <- as.numeric(colMeans(tail(sim$epi$ir100.B, 52)))     new.df <- data.frame(scenario = sims[i], simno = 1:sim$control$nsims,          param = vals[i], prev.B = i.prev.B, prev.W = i.prev.W,          inc.B = haz.B, inc.W = haz.W)     if (i == 1) {         df <- new.df     }     else {         df <- rbind(df, new.df)     }     cat(""*"") }",visualization,484889970393851e8,446
rm(list = ls()),setup,855287141632289e8,447
"setwd(""meta-analysis/analysis"")",setup,855287141632289e8,447
"setwd(""C:/Users/Amir/Documents/GitHub/structural_prediction_of_ER/"")",setup,823398808948696e8,448
"data_1RD8_AB = read.csv(""correlation_analysis/combined_data/data_1RD8_AB.csv"")",import,823398808948696e8,448
"data_2FP7_B = read.csv(""correlation_analysis/combined_data/data_2FP7_B.csv"")",import,823398808948696e8,448
"data_2Z83_A = read.csv(""correlation_analysis/combined_data/data_2Z83_A.csv"")",import,823398808948696e8,448
"data_2JLY_A = read.csv(""correlation_analysis/combined_data/data_2JLY_A.csv"")",import,823398808948696e8,448
"data_3GOL_A = read.csv(""correlation_analysis/combined_data/data_3GOL_A.csv"")",import,823398808948696e8,448
"data_3LYF_A = read.csv(""correlation_analysis/combined_data/data_3LYF_A.csv"")",import,823398808948696e8,448
"data_4AQF_B = read.csv(""correlation_analysis/combined_data/data_4AQF_B.csv"")",import,823398808948696e8,448
"data_4GHA_A = read.csv(""correlation_analysis/combined_data/data_4GHA_A.csv"")",import,823398808948696e8,448
"data_4IRY_A = read.csv(""correlation_analysis/combined_data/data_4IRY_A.csv"")",import,823398808948696e8,448
"ASAP_res_prop = rbind(data_1RD8_AB, data_2FP7_B, data_2Z83_A,      data_2JLY_A, data_3GOL_A, data_3LYF_A, data_4AQF_B, data_4GHA_A,      data_4IRY_A)",data cleaning,823398808948696e8,448
ASAP_res_prop$protein = factor(ASAP_res_prop$protein),data cleaning,823398808948696e8,448
ASAP_pdb_prop = data.frame(),data cleaning,823398808948696e8,448
counter = 0,data cleaning,823398808948696e8,448
"for (pdb in levels(ASAP_res_prop$protein)) {     counter = counter + 1     cat(counter[[1]][1], "" "", pdb, ""\n"")     pdb_data = ASAP_res_prop[ASAP_res_prop$protein == pdb, ]     x = cor.test(pdb_data$entropy, pdb_data$rsa_avg_md, method = ""spearman"")     r.seqent.rsa = x$estimate     x = cor.test(pdb_data$entropy, pdb_data$wcn_avg_md, method = ""spearman"")     r.seqent.wcnCA = x$estimate     x = cor.test(pdb_data$entropy, pdb_data$bfca, method = ""spearman"")     r.seqent.bfCA = x$estimate     row = data.frame(pdb = pdb, nres = length(pdb_data$entropy),          r.seqent.rsa = r.seqent.rsa, r.seqent.wcnCA = r.seqent.wcnCA,          r.seqent.bfCA = r.seqent.bfCA, sd.seqent = sd(pdb_data$entropy),          mean.seqent = mean(pdb_data$entropy), median.seqent = median(pdb_data$entropy),          sd.wcnCA = sd(pdb_data$wcn_avg_md), mean.wcnCA = mean(pdb_data$wcn_avg_md),          median.wcnCA = median(pdb_data$wcn_avg_md), sd.rsa = sd(pdb_data$rsa_avg_md),          mean.rsa = mean(pdb_data$rsa_avg_md), median.rsa = median(pdb_data$rsa_avg_md))     ASAP_pdb_prop = rbind(ASAP_pdb_prop, row) }",data cleaning,823398808948696e8,448
"setwd(""C:/Users/Amir/Documents/GitHub/cordiv/analysis/src"")",setup,823398808948696e8,448
"write.csv(ASAP_pdb_prop, ""../tables/ASAP_pdb_prop.csv"", row.names = F)",export,823398808948696e8,448
"setwd(""/Users/t-rex-Box/Desktop/work/nba-predictor/"")",setup,173459456535056e8,449
"source(""analysis/yhatConfig.R"")",import,173459456535056e8,449
model.require <- function() { },not sure,173459456535056e8,449
model.transform <- function(df) {     df$Team1_win_last_6 = as.numeric(df$Team1_win_last_6)     df$Team2_win_last_6 = as.numeric(df$Team2_win_last_6)     df$Team1_away_win_percentage_10 = as.numeric(df$Team1_away_win_percentage_10)     df$Team2_away_win_percentage_10 = as.numeric(df$Team2_away_win_percentage_10)     df$Team1_avg_pnt_top_3_players_6 = as.numeric(df$Team1_avg_pnt_top_3_players_6)     df$Team2_avg_pnt_top_3_players_6 = as.numeric(df$Team2_avg_pnt_top_3_players_6)     df },setup,173459456535056e8,449
"model.predict <- function(df) {     p.hats = predict(train.glm, newdata = df)     return(data.frame(result = p.hats)) }",evaluation,173459456535056e8,449
"yhat.deploy(""nbaGLM"")",not sure,173459456535056e8,449
"yhat.predict(model_name = ""nbaGLM"", test[1, ])",evaluation,173459456535056e8,449
"predict.glm(train.glm, newdata = test[1, ], type = ""response"")",evaluation,173459456535056e8,449
model.require <- function() {     library(e1071) },setup,173459456535056e8,449
model.transform <- function(df) {     df$Team1_win_last_6 = as.numeric(df$Team1_win_last_6)     df$Team2_win_last_6 = as.numeric(df$Team2_win_last_6)     df$Team1_away_win_percentage_10 = as.numeric(df$Team1_away_win_percentage_10)     df$Team2_away_win_percentage_10 = as.numeric(df$Team2_away_win_percentage_10)     df$Team1_avg_pnt_top_3_players_6 = as.numeric(df$Team1_avg_pnt_top_3_players_6)     df$Team2_avg_pnt_top_3_players_6 = as.numeric(df$Team2_avg_pnt_top_3_players_6)     df },data cleaning,173459456535056e8,449
"model.predict <- function(df) {     p.hats = predict(train.svm.1, newdata = df)     return(data.frame(result = p.hats)) }",evaluation,173459456535056e8,449
"yhat.deploy(""nbaSVM"")",not sure,173459456535056e8,449
library(dplyr),import,600206324597821e8,450
library(rstan),import,600206324597821e8,450
library(matrixStats),import,600206324597821e8,450
"fits <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit4.RDS"")",import,600206324597821e8,450
"mats <- data.frame(Int1 = NULL, Slope1 = NULL, Slope2 = NULL,      Int2 = NULL, lp__ = NULL, s = NULL)",data cleaning,600206324597821e8,450
library(pwr),setup,771128467749804e8,451
library(TOSTER),setup,771128467749804e8,451
library(BEST),setup,771128467749804e8,451
library(dplyr),setup,771128467749804e8,451
library(ggplot2),setup,771128467749804e8,451
"source(""../R-Scripts/BF10_tTest_Informed.R"")",setup,771128467749804e8,451
d.sesoi <- 0.3,modeling,771128467749804e8,451
alpha.level <- 0.01,modeling,771128467749804e8,451
priori.power <- 0.9,modeling,771128467749804e8,451
"pwr.t.test(d = d.sesoi, sig.level = alpha.level, power = priori.power)",modeling,771128467749804e8,451
"df <- read.csv(""../Example Data/Example_Data.csv"")",import,771128467749804e8,451
"plot(DV ~ Group, data = df)",visualization,771128467749804e8,451
"summarise(group_by(df, Group), mean = mean(DV), sd = sd(DV),      count = n(), min = min(DV), max = max(DV))",exploratory,771128467749804e8,451
"t.test(DV ~ Group, data = df, alternative = ""two.sided"")",modeling,771128467749804e8,451
"TOSTtwo.raw(mean(df[df$Group == ""Meditation"", ]$DV), mean(df[df$Group ==      ""Waiting List"", ]$DV), sd(df[df$Group == ""Meditation"", ]$DV),      sd(df[df$Group == ""Waiting List"", ]$DV), length(df[df$Group ==          ""Meditation"", ]$DV), length(df[df$Group == ""Waiting List"",          ]$DV), low_eqbound = -9, high_eqbound = +9, alpha = 0.01,      var.equal = F, plot = T)",modeling,771128467749804e8,451
"best <- BESTmcmc(df[df$Group == ""Meditation"", ]$DV, df[df$Group ==      ""Waiting List"", ]$DV, rnd.seed = 20180309, verbose = FALSE,      numSavedSteps = 10000, parallel = TRUE)",modeling,771128467749804e8,451
df.best <- data.frame(diff = (best$mu1 - best$mu2)),modeling,771128467749804e8,451
summary(best),exploratory,771128467749804e8,451
"posterior.mode <- summary(best)[""muDiff"", ""mode""]",modeling,771128467749804e8,451
"hdi <- hdi(df.best$diff, credMass = 0.95)",modeling,771128467749804e8,451
"hdi[""lower""]",modeling,771128467749804e8,451
"hdi[""upper""]",modeling,771128467749804e8,451
"ggplot(data = df.best, aes(x = diff)) + geom_histogram(aes(y = ..density..),      fill = ""white"", color = ""darkgrey"", binwidth = 0.25) + geom_density(color = ""darkgrey"") +      geom_vline(xintercept = -9, linetype = ""dashed"") + geom_vline(xintercept = 9,      linetype = ""dashed"") + geom_vline(xintercept = 0, linetype = ""dashed"",      color = ""grey"") + geom_segment(x = hdi[""lower""], xend = hdi[""upper""],      y = 0, yend = 0, size = 1.1) + geom_point(x = posterior.mode,      y = 0, color = ""black"", shape = 15, size = 3) + scale_x_continuous(name = expression(paste(mu[1],      "" - "", mu[2]))) + scale_y_continuous(name = ""Density"")",visualization,771128467749804e8,451
bf.alt.mu <- 0.62,modeling,771128467749804e8,451
bf.alt.sd <- (0.98 - 0.25)/(2 * qnorm(0.975)) * sqrt(4),modeling,771128467749804e8,451
"bf10 <- BayesFactor_InformedNormal(abs(t.test(DV ~ Group, data = df,      alternative = ""two.sided"")$statistic), nrow(df)/2, nrow(df)/2,      prior.mean = bf.alt.mu, prior.variance = bf.alt.sd^2)",modeling,771128467749804e8,451
bf10,modeling,771128467749804e8,451
1/bf10,modeling,771128467749804e8,451
library(SimSurvey),import,63736497447826e9,452
set.seed(438),modeling,63736497447826e9,452
"pop <- sim_abundance(ages = 1:20, years = 1:20, R = sim_R(mean = 3e+07,      log_sd = 0.5, random_walk = TRUE), Z = sim_Z(mean = 0.5,      log_sd = 0.2, phi_age = 0.9, phi_year = 0.5), growth = sim_vonB(Linf = 120,      L0 = 5, K = 0.1, log_sd = 0.1, length_group = 3, digits = 0)) %>%      sim_distribution(grid = make_grid(x_range = c(-140, 140),          y_range = c(-140, 140), res = c(3.5, 3.5), shelf_depth = 200,          shelf_width = 100, depth_range = c(0, 1000), n_div = 1,          strat_breaks = seq(0, 1000, by = 40), strat_splits = 2),          ays_covar = sim_ays_covar(sd = 2.8, range = 300, phi_age = 0.5,              phi_year = 0.9, group_ages = 5:20), depth_par = sim_parabola(mu = 200,              sigma = 70))",exploratory,63736497447826e9,452
setMKLthreads(1),not sure,63736497447826e9,452
"surveys <- expand_surveys(set_den = c(0.5, 1, 2, 5, 10)/1000,      lengths_cap = c(5, 10, 20, 50, 100, 500, 1000), ages_cap = c(2,          5, 10, 20, 50))",setup,63736497447826e9,452
"surveys[surveys$set_den == 0.002 & surveys$lengths_cap == 500 &      surveys$ages_cap == 10, ]",data cleaning,63736497447826e9,452
"sim <- test_surveys(pop, surveys = surveys, keep_details = 98,      n_sims = 5, n_loops = 200, cores = 7, q = sim_logistic(k = 2,          x0 = 3), export_dir = ""analysis/cod_sim_exports/2018-10-26_age_clust_test"")",modeling,63736497447826e9,452
setMKLthreads(),visualization,63736497447826e9,452
rm(pop),setup,63736497447826e9,452
rm(sim),setup,63736497447826e9,452
gc(),setup,63736497447826e9,452
set.seed(438),modeling,63736497447826e9,452
"pop <- sim_abundance(ages = 1:20, years = 1:20, R = sim_R(mean = 3e+07,      log_sd = 0.5, random_walk = TRUE), Z = sim_Z(mean = 0.5,      log_sd = 0.2, phi_age = 0.9, phi_year = 0.5), growth = sim_vonB(Linf = 120,      L0 = 5, K = 0.1, length_group = 3, digits = 0)) %>% sim_distribution(grid = make_grid(x_range = c(-140,      140), y_range = c(-140, 140), res = c(3.5, 3.5), shelf_depth = 200,      shelf_width = 100, depth_range = c(0, 1000), n_div = 1, strat_breaks = seq(0,          1000, by = 40), strat_splits = 2), ays_covar = sim_ays_covar(sd = 2.8,      range = 300, phi_age = 0.5, phi_year = 0.9, group_ages = 1:20),      depth_par = sim_parabola(mu = 200, sigma = 70))",modeling,63736497447826e9,452
setMKLthreads(1),communication,63736497447826e9,452
"surveys <- expand_surveys(set_den = c(0.5, 1, 2, 5, 10)/1000,      lengths_cap = c(5, 10, 20, 50, 100, 500, 1000), ages_cap = c(2,          5, 10, 20, 50))",communication,63736497447826e9,452
"surveys[surveys$set_den == 0.002 & surveys$lengths_cap == 500 &      surveys$ages_cap == 10, ]",data cleaning,63736497447826e9,452
"sim <- test_surveys(pop, surveys = surveys, keep_details = 98,      n_sims = 5, n_loops = 200, cores = 7, q = sim_logistic(k = 2,          x0 = 3), export = ""analysis/cod_sim_exports/2018-10-28_no_age_clust_test"")",evaluation,63736497447826e9,452
setMKLthreads(),export,63736497447826e9,452
setMKLthreads(),export,63736497447826e9,452
library(quickpsy),setup,887515881564468e8,453
library(tidyverse),setup,887515881564468e8,453
library(circular),setup,887515881564468e8,453
library(cowplot),import,887515881564468e8,453
library(PropCIs),import,887515881564468e8,453
library(R.utils),setup,887515881564468e8,453
"sourceDirectory(""R"")",setup,887515881564468e8,453
"library(RItools, lib.loc = "".local"")",import,883967048954219e8,454
"load(""data/twins.rda"")",import,883967048954219e8,454
"load(""analysis/balance.rda"")",import,883967048954219e8,454
set.seed(20110330),setup,883967048954219e8,454
samples <- 1000,evaluation,883967048954219e8,454
"additive.model <- function(y, z, b, tau) {     y - as.numeric(z) * tau }",modeling,883967048954219e8,454
"model1 <- min.max.model(additive.model, lower = 0, upper = 6)",modeling,883967048954219e8,454
twins$match <- propensity$matching[row.names(twins)],not sure,883967048954219e8,454
"twins.complete <- twins[twins$ideology.complete & !is.na(twins$match),      ]",data cleaning,883967048954219e8,454
"analysis.m1 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,      twins.complete$treated * 1, test.stat = mean.difference,      moe = model1, samples = samples, parameters = list(tau = seq(-0.9,          0.3, 0.05)))",not sure,883967048954219e8,454
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,518718792125583e8,455
"source(""Data/GatherSource/F2_EW_MakeLikeFile.R"")",setup,518718792125583e8,455
library(MuMIn),setup,518718792125583e8,455
library(lme4),setup,518718792125583e8,455
library(data.table),setup,518718792125583e8,455
library(coefplot2),setup,518718792125583e8,455
"source(""Data/GatherSource/CovariateStandardization.R"")",setup,518718792125583e8,455
"abbreviate(c(""response"", ""explanatory"", ""abundance"", ""biomass"",      ""biodiversity""), 3)",setup,518718792125583e8,455
"dt.rsp.abn <- as.data.table(data[, c(""anc"", ""ancad"", ""endo"",      ""endad"", ""N"")])",setup,518718792125583e8,455
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"dt.rsp.abn[, `:=`(anc.juv, anc - ancad)]",import,518718792125583e8,455
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",export,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,302739618346095e8,456
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,744753797305748e8,457
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,744753797305748e8,457
siteSize = 2048,setup,744753797305748e8,457
"treatment = ""Copper""",setup,744753797305748e8,457
"strand = ""both""",setup,744753797305748e8,457
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",data cleaning,744753797305748e8,457
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/deseq."",      all.name, "".Robj""))",import,744753797305748e8,457
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/wave.new."",      all.name, "".Robj""))",import,744753797305748e8,457
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/ms.new."",      all.name, "".Robj""))",import,744753797305748e8,457
"library(""qvalue"")",setup,744753797305748e8,457
rm(list = ls()),setup,242642436409369e8,262
"source(""./R/helper/00_helper_lib_load.R"")",import,242642436409369e8,262
"source(""./R/helper/00_helper_model_fcts.R"")",import,242642436409369e8,262
"source(""./R/helper/00_helper_simulation_data.R"")",import,242642436409369e8,262
"source(""./R/helper/01_helper_cBPF_as.R"")",import,242642436409369e8,262
"source(""./R/helper/02_helper_pgas.R"")",import,242642436409369e8,262
"source(""./R/01_cBPF_as.R"")",import,242642436409369e8,262
"source(""./R/02_pgas.R"")",import,242642436409369e8,262
init_at_true <- TRUE,import,242642436409369e8,262
pgas_run <- TRUE,setup,242642436409369e8,262
set.seed(123),setup,242642436409369e8,262
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test.R"")",setup,242642436409369e8,262
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test_init.R"")",import,242642436409369e8,262
"out_pgas <- pgas(N = num_particles, MM = num_mcmc, KK = KK, TT = TT,      y = y_t, yz = yz_t, Za = za_t, Zb = zb_t, Zp = zp_t, Zq = zq_t,      priors = c(prior_a, prior_b), par_init = par_init, par_true = true_vals,      traj_init = deviate_states_init, filtering = pgas_run, num_plots_states = 1)",import,242642436409369e8,262
"source(""./analysis/2018-11-30/testing/99_analyse_convergence_test.R"")",modeling,242642436409369e8,262
"source(""./analysis/2018-11-30/testing/99_analyse_convergence_test.R"")",import,242642436409369e8,262
library(edgeR),setup,950497935991734e8,458
library(ggplot2),setup,950497935991734e8,458
library(testthat),setup,950497935991734e8,458
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null > x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null < x))         }, statistic.null = statistic.null)     }     numEqual = sapply(statistic.alt, function(x, statistic.null) {         return(sum(statistic.null == x))     }, statistic.null = statistic.null)     Uval = runif(length(statistic.alt))     pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +          1)     return(pval.list) }",communication,283352516358718e8,459
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,283352516358718e8,459
siteSize = 2048,setup,283352516358718e8,459
"treatment = ""Copper""",not sure,283352516358718e8,459
null = FALSE,communication,283352516358718e8,459
"strand = ""both""",communication,283352516358718e8,459
window.size = 100,setup,283352516358718e8,459
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/cluster_sol_objectives_asw.Rdata"")",not sure,787459399318322e8,460
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/propTable_tickets.Rdata"")",not sure,787459399318322e8,460
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/bin/plot_clusters.R"")",not sure,787459399318322e8,460
"pdf(file = ""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-06-27/cp_composition.pdf"",      width = 14, height = 10)",export,787459399318322e8,460
"plot_cp(target_mgmt = ""SAMN"", cp = 7, prop_table = prop_table,      cluster_ind = cluster_ind)",export,787459399318322e8,460
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,549942604266107e8,461
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,549942604266107e8,461
"south_african_rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/South_africa.shp"")",import,549942604266107e8,461
"south_african_rails@data <- rails@data[1:length(south_african_rails),      ]",data cleaning,549942604266107e8,461
south_african_rails@data[1] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[2] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[3] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[4] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[5] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[6] <- NA,data cleaning,549942604266107e8,461
south_african_rails@data[7] <- NA,data cleaning,549942604266107e8,461
"south_african_rails <- spTransform(south_african_rails, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,549942604266107e8,461
"rails <- spTransform(rails, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,549942604266107e8,461
"all_rails <- rbind(rails, south_african_rails)",data cleaning,549942604266107e8,461
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,549942604266107e8,461
opt_loc$dist2rail <- NA,data cleaning,549942604266107e8,461
opt_loc$id_closest_rail <- NA,data cleaning,549942604266107e8,461
"for (i in 1:nrow(opt_loc)) {     loc <- c(opt_loc$x[i], opt_loc$y[i])     dist <- dist2Line(loc, all_rails)     opt_loc$dist2rail[i] <- dist[1]/1000     opt_loc$id_closest_rail[i] <- dist[4]     print(i) }",data cleaning,549942604266107e8,461
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,549942604266107e8,461
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,549942604266107e8,461
"df <- opt_loc[!is.na(opt_loc$zeta), ]",not sure,549942604266107e8,461
row.names(df) <- 1:nrow(df),data cleaning,549942604266107e8,461
df$bl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$tl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$br_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$tr_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$bl_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tl_y <- df$y + 0.25,data cleaning,549942604266107e8,461
df$br_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tr_y <- df$y + 0.25,data cleaning,549942604266107e8,461
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,549942604266107e8,461
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,549942604266107e8,461
opt_loc$RailKM <- NA,data cleaning,549942604266107e8,461
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, all_rails)) {         intersect <- gIntersection(single_cell, all_rails)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""RailKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""RailKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""RailKM""] <- 0     } }",data cleaning,549942604266107e8,461
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,549942604266107e8,461
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,549942604266107e8,461
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,549942604266107e8,461
"df <- opt_loc[!is.na(opt_loc$zeta), ]",not sure,549942604266107e8,461
row.names(df) <- 1:nrow(df),data cleaning,549942604266107e8,461
df$bl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$tl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$br_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$tr_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$bl_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tl_y <- df$y + 0.25,data cleaning,549942604266107e8,461
df$br_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tr_y <- df$y + 0.25,data cleaning,549942604266107e8,461
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,549942604266107e8,461
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,549942604266107e8,461
opt_loc$RailKM_military <- 0,data cleaning,549942604266107e8,461
opt_loc$RailKM_mining <- 0,data cleaning,549942604266107e8,461
"for (i in 1:nrow(polygon_dataframe)) {     if (opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""RailKM""] >          0 & !is.na(opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],          ""RailKM""])) {         single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==              polygon_dataframe@data$ID[i]), ]         if (gIntersects(single_cell, all_rails[all_rails@data$military ==              1, ])) {             intersect <- gIntersection(single_cell, all_rails[all_rails@data$military ==                  1, ])             if (!(""coords"" %in% slotNames(intersect))) {                 if (""lineobj"" %in% slotNames(intersect)) {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_military""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                      function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                        longlat = T))))                   print(c(i, ""with multiple""))                 }                 else {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_military""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                      longlat = T)                   print(i)                 }             }         }         if (gIntersects(single_cell, all_rails[all_rails@data$mining ==              1, ])) {             intersect <- gIntersection(single_cell, all_rails[all_rails@data$mining ==                  1, ])             if (!(""coords"" %in% slotNames(intersect))) {                 if (""lineobj"" %in% slotNames(intersect)) {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_mining""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                      function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                        longlat = T))))                   print(c(i, ""with multiple""))                 }                 else {                   opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                      ""RailKM_mining""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                      longlat = T)                   print(i)                 }             }         }     } }",data cleaning,549942604266107e8,461
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,549942604266107e8,461
library(scales),setup,549942604266107e8,461
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/Railroads.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",export,549942604266107e8,461
"print(plot(polygon_dataframe, lwd = 0.5, border = alpha(""black"",      0.5)))",visualization,549942604266107e8,461
"print(plot(all_rails, lwd = 1.5, col = ""red"", add = T))",visualization,549942604266107e8,461
dev.off(),visualization,549942604266107e8,461
"placebo <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Placebo/placebo_1916_1922.TAB"")",import,549942604266107e8,461
"south_african_placebo <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/South_Africa_placebo.shp"")",import,549942604266107e8,461
"south_african_placebo@data <- as.data.frame(placebo@data[1:length(south_african_placebo),      ])",data cleaning,549942604266107e8,461
"colnames(south_african_placebo@data) <- ""placebo_year""",data cleaning,549942604266107e8,461
south_african_placebo@data[1] <- NA,data cleaning,549942604266107e8,461
"south_african_placebo <- spTransform(south_african_placebo, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,549942604266107e8,461
"placebo <- spTransform(placebo, CRS(""+proj=longlat +ellps=WGS84 +datum=WGS84""))",data cleaning,549942604266107e8,461
"all_placebo <- rbind(placebo, south_african_placebo)",data cleaning,549942604266107e8,461
"nodes <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/EMST_Lines/nodes.TAB"")",import,549942604266107e8,461
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,549942604266107e8,461
"cape <- c(18.598227, -34.10779)",data cleaning,549942604266107e8,461
"beaufort_west <- c(22.561545, -32.305843)",data cleaning,549942604266107e8,461
"bleomfontain <- c(26.087945, -29.105537)",data cleaning,549942604266107e8,461
"port_elizabeth <- c(25.670227, -33.844601)",data cleaning,549942604266107e8,461
"johannesburg <- c(28.024229, -26.17397)",data cleaning,549942604266107e8,461
"pretoria <- c(28.13889, -25.792591)",data cleaning,549942604266107e8,461
"eendekuil <- c(18.886597, -32.688726)",data cleaning,549942604266107e8,461
"port_nolloth <- c(16.875627, -29.224785)",data cleaning,549942604266107e8,461
"de_aar <- c(23.974669, -30.668652)",data cleaning,549942604266107e8,461
"george <- c(22.500869, -33.997303)",data cleaning,549942604266107e8,461
"port_alfred <- c(26.867809, -33.624552)",data cleaning,549942604266107e8,461
"east_london <- c(27.890928, -33.04099)",data cleaning,549942604266107e8,461
"kimberley <- c(24.733504, -28.766301)",data cleaning,549942604266107e8,461
"vryburg <- c(24.755151, -26.932349)",data cleaning,549942604266107e8,461
"sa_nodes <- rbind(cape, beaufort_west, bleomfontain, port_elizabeth,      johannesburg, pretoria, eendekuil, port_nolloth, de_aar,      george, port_alfred, east_london, kimberley, vryburg)",data cleaning,549942604266107e8,461
"dta <- as.data.frame(rep(1, nrow(sa_nodes)))",data cleaning,549942604266107e8,461
"colnames(dta) <- ""node""",data cleaning,549942604266107e8,461
"sa_pts <- SpatialPointsDataFrame(SpatialPoints(sa_nodes, proj4string = CRS(proj4string(nodes))),      data = dta)",data cleaning,549942604266107e8,461
"all_nodes <- rbind(nodes, sa_pts)",data cleaning,549942604266107e8,461
"dist_matrix <- matrix(0, nrow = length(all_nodes), ncol = length(all_nodes))",data cleaning,549942604266107e8,461
"for (i in 1:length(all_nodes)) {     for (j in i:length(all_nodes)) {         dist_matrix[i, j] <- gdist(as.numeric(all_nodes@coords[i,              1]), as.numeric(all_nodes@coords[i, 2]), as.numeric(all_nodes@coords[j,              1]), as.numeric(all_nodes@coords[j, 2]), units = ""km"")         dist_matrix[j, i] <- dist_matrix[i, j]     } }",data cleaning,549942604266107e8,461
"connections <- as.data.frame(cbind(2:length(all_nodes), spantree(dist_matrix)$kid))",data cleaning,549942604266107e8,461
row.names(connections) <- 1:nrow(connections),data cleaning,549942604266107e8,461
"my_emst <- (SpatialLinesDataFrame(SpatialLines(lapply(1:nrow(connections),      function(x) Lines(list(Line(rbind(cbind(as.numeric(all_nodes@coords[connections[x,          1], 1]), as.numeric(all_nodes@coords[connections[x, 1],          2])), cbind(as.numeric(all_nodes@coords[connections[x,          2], 1]), as.numeric(all_nodes@coords[connections[x, 2],          2]))))), paste(x))), proj4string = CRS(proj4string(nodes))),      connections))",data cleaning,549942604266107e8,461
opt_loc$dist2emst <- NA,data cleaning,549942604266107e8,461
"for (i in 1:nrow(opt_loc)) {     loc <- c(opt_loc$x[i], opt_loc$y[i])     dist <- dist2Line(loc, my_emst)     opt_loc$dist2emst[i] <- dist[1]/1000     print(i) }",not sure,549942604266107e8,461
"df_coords <- rbind(nodes@coords, sa_nodes)",data cleaning,549942604266107e8,461
row.names(df_coords) <- 1:nrow(df_coords),data cleaning,549942604266107e8,461
opt_loc$isnode <- 0,data cleaning,549942604266107e8,461
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, all_nodes)) {         opt_loc[i, ""isnode""] <- 1     } }",modeling,549942604266107e8,461
"rails <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Built/Railroads.TAB"")",import,549942604266107e8,461
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"")",import,549942604266107e8,461
"df <- opt_loc[!is.na(opt_loc$zeta), ]",data cleaning,549942604266107e8,461
row.names(df) <- 1:nrow(df),data cleaning,549942604266107e8,461
df$bl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$tl_x <- df$x - 0.25,data cleaning,549942604266107e8,461
df$br_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$tr_x <- df$x + 0.25,data cleaning,549942604266107e8,461
df$bl_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tl_y <- df$y + 0.25,data cleaning,549942604266107e8,461
df$br_y <- df$y - 0.25,data cleaning,549942604266107e8,461
df$tr_y <- df$y + 0.25,data cleaning,549942604266107e8,461
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,549942604266107e8,461
"polygon_dataframe = SpatialPolygonsDataFrame(polygon_file, df)",data cleaning,549942604266107e8,461
opt_loc$emstKM <- NA,data cleaning,549942604266107e8,461
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, my_emst)) {         intersect <- gIntersection(single_cell, my_emst)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""emstKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""emstKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""emstKM""] <- 0     } }",modeling,549942604266107e8,461
"write.csv(opt_loc, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/opt_loc_with_raildist.csv"",      row.names = FALSE)",export,549942604266107e8,461
"buffer_emst <- spTransform(buffer(spTransform(my_emst, CRS(""+proj=robin +datum=WGS84"")),      width = 40000), CRS(""+proj=longlat +datum=WGS84""))",data cleaning,549942604266107e8,461
"rails_in_buffer <- gIntersection(buffer_emst, all_rails)",modeling,549942604266107e8,461
opt_loc$bufferKM <- NA,data cleaning,549942604266107e8,461
"for (i in 1:nrow(polygon_dataframe)) {     single_cell <- polygon_dataframe[which(polygon_dataframe@data$ID ==          polygon_dataframe@data$ID[i]), ]     if (gIntersects(single_cell, rails_in_buffer)) {         intersect <- gIntersection(single_cell, rails_in_buffer)         if (!(""coords"" %in% slotNames(intersect))) {             if (""lineobj"" %in% slotNames(intersect)) {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""bufferKM""] <- Reduce(""+"", lapply(1:length(intersect@lineobj@lines),                    function(j) sum(LineLength(intersect@lineobj@lines[[j]]@Lines[[1]]@coords,                      longlat = T))))                 print(c(i, ""with multiple""))             }             else {                 opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i],                    ""bufferKM""] <- LineLength(intersect@lines[[1]]@Lines[[1]]@coords,                    longlat = T)                 print(i)             }         }     }     else {         opt_loc[opt_loc$ID == polygon_dataframe@data$ID[i], ""bufferKM""] <- 0     } }",modeling,549942604266107e8,461
"write.csv(opt_loc[, c(""ID"", ""bufferKM"")], file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/temp/ID_bufferKM.csv"",      row.names = FALSE)",export,549942604266107e8,461
"africa <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/Railroads/Territory/Africa.TAB"")",import,549942604266107e8,461
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/all_rails.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",export,549942604266107e8,461
plot(africa),visualization,549942604266107e8,461
"plot(all_rails, col = ""red"", add = T)",visualization,549942604266107e8,461
"plot(all_placebo, col = ""blue"", add = T, lty = 2)",visualization,549942604266107e8,461
dev.off(),visualization,549942604266107e8,461
"png(filename = paste(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/output/other_maps/emst.png"",      sep = """"), width = 6, height = 6, units = ""in"", res = 300)",export,549942604266107e8,461
plot(africa),visualization,549942604266107e8,461
"plot(my_emst, col = ""orange"", add = T)",visualization,549942604266107e8,461
"plot(buffer_emst, col = alpha(""orange"", 0.1), add = T, border = alpha(""grey"",      0.3))",visualization,549942604266107e8,461
"plot(all_nodes, add = T, col = alpha(""red"", 0.5), pch = 20, cex = 0.5)",visualization,549942604266107e8,461
dev.off(),visualization,549942604266107e8,461
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,549942604266107e8,461
"synapse <- import(""synapseclient"")",import,549942604266107e8,461
syn <- synapse$Synapse(),not sure,549942604266107e8,461
syn$login(),not sure,549942604266107e8,461
require(tidyverse),setup,549942604266107e8,461
"syn_file = ""syn18349249""",not sure,549942604266107e8,461
expData <- read.csv(gzfile(syn$get(syn_file)$path)),import,549942604266107e8,461
require(singleCellSeq),setup,549942604266107e8,461
"rmd <- system.file(""heatmap_vis.Rmd"", package = ""singleCellSeq"")",import,549942604266107e8,461
"this.code = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/analysis/2019-02-19/panNF_immune_sigs.R""",import,549942604266107e8,461
"source(""../../bin/sigSurvAnalysis.R"", chdir = T)",setup,469958954490721e7,462
"combined.mat = reshape2::acast(expData, Symbol ~ id, value.var = ""zScore"")",data cleaning,549942604266107e8,461
"missing = which(apply(combined.mat, 1, function(x) any(is.na(x))))",data cleaning,549942604266107e8,461
"combined.mat = combined.mat[-missing, ]",data cleaning,549942604266107e8,461
"phenData <- expData %>% select(id, age, Sex, tumorType, isCellLine,      study) %>% unique()",exploratory,549942604266107e8,461
rownames(phenData) <- phenData$id,data cleaning,549942604266107e8,461
phenData$isCellLine <- tolower(phenData$isCellLine),data cleaning,549942604266107e8,461
"gene = ""NF1""",data cleaning,469958954490721e7,462
"kf <- rmarkdown::render(rmd, rmarkdown::html_document(), output_file = paste(getwd(),      ""/"", lubridate::today(), ""panNFHeatmap.html"", sep = """"),      params = list(samp.mat = combined.mat, cell.annotations = phenData %>%          select(-id), seqData = TRUE))",communication,549942604266107e8,461
"analysis_dir = ""syn18134642""",not sure,549942604266107e8,461
"syn$store(synapse$File(kf, parentId = analysis_dir), used = syn_file,      executed = this.code)",not sure,549942604266107e8,461
print(Sys.getpid()),not sure,549942604266107e8,461
"print(""reading data"")",not sure,549942604266107e8,461
"for (dis in tcga.cancer.types) {     sapply(list(c(""CDC27"", ""CREBBP""), ""CREBBP"", ""CDC27""), function(g) {         mut.sig <- survivalAnalysisByMutationAndExpression(dis,              mutGene = c(g), exprGene = c(gene))     }) }",data cleaning,469958954490721e7,462
"L1000geneAnnots = readRDS(""analysis/00.cmapRanks/FWDgeneAnnots.rds"")",import,549942604266107e8,461
"inst = readRDS(""analysis/00.cmapRanks/FWDinstances.rds"")",import,549942604266107e8,461
library(cmapQuery),setup,549942604266107e8,461
library(dplyr),setup,549942604266107e8,461
library(magrittr),setup,549942604266107e8,461
calculateKs = TRUE,not sure,549942604266107e8,461
library(RnBeads),setup,469958954490721e7,462
calculateSpecificity = FALSE,not sure,549942604266107e8,461
library(biomaRt),setup,469958954490721e7,462
library(org.Hs.eg.db),setup,469958954490721e7,462
library(annotate),setup,469958954490721e7,462
"source(""my.get.top.DMR.queries.R"")",setup,469958954490721e7,462
"if (calculateKs) {     print(""pre-calcing random Ks"")     L1000PreCalc = preCalcRandomKs(inst$pert_iname)     saveRDS(L1000PreCalc, ""analysis/00.cmapRanks/FWDPreCalc.rds"") }",export,549942604266107e8,461
"source(""my.get.top.DMR.queries.2.R"")",setup,469958954490721e7,462
"source(""my.get.GO.gene.sets.R"")",setup,469958954490721e7,462
"if (calculateSpecificity) {     L1000PreCalc = readRDS(""analysis/00.cmapRanks/FWDPreCalc.rds"")     print(""getting msigdb groups"")     rankMatrix = readRDS(""analysis/00.cmapRanks/FWDranks.rds"")     gpl96 = gemmaAPI::getAnnotation(""GPL96"")     MSigDBLegacyL1000IDs = MSigDBLegacy %>% lapply(function(x) {         x$upTags = gemmaAPI::annotationGeneMatch(x$upTags, gpl96,              removeNAs = TRUE)         x$downTags = gemmaAPI::annotationGeneMatch(x$downTags,              gpl96, removeNAs = TRUE)         x$downTags = L1000geneAnnots %>% filter(pr_gene_symbol %in%              x$downTags) %$% pr_gene_id         x$upTags = L1000geneAnnots %>% filter(pr_gene_symbol %in%              x$upTags) %$% pr_gene_id         return(x)     })     print(""pre-calcing specificity for legacy msigdb"")     L1000MsigDBLegacyPreCalc = specificityPreCalculation(signatures = MSigDBLegacyL1000IDs,          rankMatrix = rankMatrix, chems = inst$pert_iname, preCalc = L1000PreCalc,          cores = 2)     saveRDS(L1000MsigDBPreCalc, ""analysis/00.cmapRanks/L1000MsigDBLegacyPreCalc.rds"") }",export,549942604266107e8,461
library(tidyverse),setup,549942604266107e8,461
"param.summ <- read_csv(""results/hyperparameter/summary.txt"")",import,549942604266107e8,461
param.summ$emsize <- as.factor(param.summ$emsize),data cleaning,549942604266107e8,461
param.summ$nhid <- as.factor(param.summ$nhid),data cleaning,549942604266107e8,461
param.summ$nlayers <- as.factor(param.summ$nlayers),data cleaning,549942604266107e8,461
summary(param.summ),exploratory,549942604266107e8,461
"ggplot(param.summ) + geom_bar(aes(epoch, val_acc, fill = ""val_acc""),      stat = ""summary"", fun.y = ""mean"") + geom_bar(aes(epoch, val_prec,      fill = ""val_prec""), stat = ""summary"", fun.y = ""mean"")",visualization,549942604266107e8,461
"labels_layers <- c(`1` = ""1 Layer"", `2` = ""2 Layers"")",visualization,549942604266107e8,461
"labels_hid <- c(`32` = ""32 Units"", `64` = ""64 Units"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch, y = val_acc, color = emsize,      group = interaction(condition, run))) + geom_line() + facet_grid(nlayers ~      nhid, labeller = labeller(nlayers = labels_layers, nhid = labels_hid)) +      labs(title = ""Accuracy on validation set by epochs\n       Grouped by embedding size, LSTM layer size,\n       and number of LSTM layers"",          x = ""Number of epochs"", y = ""Accuracy on validation set"") +      theme(plot.title = element_text(hjust = 0.5)) + ggsave(""analysis/charts/epoch-val_acc_facets.jpeg"",      device = ""jpeg"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_acc,      color = nhid), fun.y = ""mean"", geom = ""line"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_acc,      color = nlayers), fun.y = ""mean"", geom = ""line"") + labs(title = ""Mean accuracy on validation set by epochs\n       Ignoring Speaker Info"",      x = ""Number of epochs"", y = ""Accuracy on validation set"") +      theme(plot.title = element_text(hjust = 0.5)) + ggsave(""analysis/charts/epoch-val_acc_nlayers.jpeg"",      device = ""jpeg"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_loss,      color = emsize), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_loss-emsize.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_loss,      color = nhid), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_loss-nhid.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_loss,      color = nlayers), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_loss-nlayers.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_f,      color = emsize), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_f-emsize.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_f,      color = nhid), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_f-nhid.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = val_f,      color = nlayers), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-val_f-nlayers.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = train_loss,      color = emsize), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-train_loss-emsize.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = train_loss,      color = nhid), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-train_loss-nhid.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = train_loss,      color = nlayers), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-train_loss-nlayers.pdf"",      device = ""pdf"")",visualization,549942604266107e8,461
"ggplot(param.summ) + geom_bar(aes(emsize, epoch_time), stat = ""summary"",      fun.y = ""mean"")",visualization,549942604266107e8,461
"ggplot(param.summ) + geom_bar(aes(nlayers, epoch_time), stat = ""summary"",      fun.y = ""mean"")",visualization,549942604266107e8,461
"param.summ.optimal <- subset(param.summ, nhid == ""64"" & emsize ==      ""500"" & nlayers == ""2"")",visualization,549942604266107e8,461
"param.summ.speaker <- read_csv(""results/include_speaker/summary.txt"")",import,549942604266107e8,461
"param.summ.speaker <- merge(param.summ.optimal, param.summ.speaker,      all = TRUE)",data cleaning,549942604266107e8,461
param.summ.speaker$emsize <- as.factor(param.summ.speaker$emsize),data cleaning,549942604266107e8,461
param.summ.speaker$nhid <- as.factor(param.summ.speaker$nhid),data cleaning,549942604266107e8,461
param.summ.speaker$nlayers <- as.factor(param.summ.speaker$nlayers),data cleaning,549942604266107e8,461
summary(param.summ.speaker),exploratory,549942604266107e8,461
"spkr.acc = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_acc,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""Accuracy"", x = ""Number of epochs"", y = ""Mean proportion correct\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"spkr.loss = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_loss,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""Loss"", x = ""Number of epochs"", y = ""Mean loss\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"spkr.f = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_f,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""F-Score"", x = ""Number of epochs"", y = ""Mean F-score\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"ggsave(""analysis/charts/spkr/epoch-val-acc.jpeg"", spkr.acc +      guides(color = FALSE), width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/spkr/epoch-val-f.jpeg"", spkr.f + guides(color = FALSE),      width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/spkr/epoch-val-loss.jpeg"", spkr.loss,      width = 3.375, height = 2)",export,549942604266107e8,461
"param.summ.optimal <- subset(param.summ.speaker, ignore_speaker ==      ""False"")",data cleaning,549942604266107e8,461
"param.summ.optimal$full_context = rep(""True"", nrow(param.summ.optimal))",data cleaning,549942604266107e8,461
"param.summ.context <- read_csv(""results/partial_context/summary.txt"")",data cleaning,549942604266107e8,461
"param.summ.context <- merge(param.summ.context, param.summ.optimal,      all = TRUE)",data cleaning,549942604266107e8,461
"cont.acc = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_acc,      color = full_context, group = save) + geom_line() + labs(title = ""Accuracy"",      x = ""Number of epochs"", y = ""Proportion correct\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"cont.loss = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_loss,      color = full_context, group = save) + geom_line() + labs(title = ""Loss"",      x = ""Number of epochs"", y = ""Loss\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"cont.f = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_f,      color = full_context, group = save) + geom_line() + labs(title = ""F-score"",      x = ""Number of epochs"", y = ""F-score\non validation set"",      color = ""Amount of context"") + theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"ggsave(""analysis/charts/context/epoch-val-acc.jpeg"", cont.acc +      guides(color = FALSE), width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/context/epoch-val-f.jpeg"", cont.f + guides(color = FALSE),      width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/context/epoch-val-loss.jpeg"", cont.loss +      labs(color = ""Amount of context"") + scale_color_manual(labels = c(""Current utterance"",      ""Full discourse""), values = c(""#F8766D"", ""#00BFC4"")), width = 3.375,      height = 2)",export,549942604266107e8,461
"param.summ.rnn <- read_csv(""results/rnns/summary.txt"")",import,549942604266107e8,461
"param.summ.rnn <- merge(param.summ.rnn, param.summ.optimal, all = TRUE)",data cleaning,549942604266107e8,461
"param.summ.rnn <- subset(param.summ.rnn, model != ""RNN_RELU"")",data cleaning,549942604266107e8,461
"rnn.acc = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_acc,      color = model, group = save) + geom_line() + labs(title = ""Accuracy"",      x = ""Number of epochs"", y = ""Proportion correct\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"rnn.loss = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_loss,      color = model, group = save) + geom_line() + labs(title = ""Loss"",      x = ""Number of epochs"", y = ""Loss\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"rnn.f = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_f,      color = model, group = save) + geom_line() + labs(title = ""F-score"",      x = ""Number of epochs"", y = ""F-score\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,549942604266107e8,461
"ggsave(""analysis/charts/rnn/epoch-val-acc.jpeg"", rnn.acc + guides(color = FALSE),      width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/rnn/epoch-val-f.jpeg"", rnn.f + guides(color = FALSE),      width = 2.25, height = 2)",export,549942604266107e8,461
"ggsave(""analysis/charts/rnn/epoch-val-loss.jpeg"", rnn.loss +      labs(color = ""Recurrent Unit Type""), width = 3.375, height = 2)",export,549942604266107e8,461
"library(""R6"")",setup,549942604266107e8,461
"library(""stringr"")",setup,549942604266107e8,461
"TimeAnalysis = R6Class(""TimeAnalysis"", public = list(name = NA,      session = NA, logTable = NA, eventTable = NA, header = NA,      betterEventTable = NA, initialize = function(path) {         if (!missing(path)) {             self$name = gsub(""(.*[/])"", """", path)             self$session = gsub(""(.*[_])"", """", self$name)             ls = ReadMouseLog(path)             if (!is.null(ls)) {                 self$logTable = ls[[""table""]]                 self$eventTable = ls[[""events""]]                 self$header = ls[[""header""]]             }             self$FillInData()         }     }, MakeBetterEventTable = function() {         self$betterEventTable = create_better_dt_events(self$eventTable)     }, FillInData = function() {         self$session = as.numeric(str_extract(self$name, ""\\d+""))     }))",not sure,549942604266107e8,461
library(data.table),setup,549942604266107e8,461
library(plyr),setup,549942604266107e8,461
"setwd(""/Users/Hannah-Cutler/Desktop/summer-2016/Microsoft/data-collection-civic-graph/Analysis/General analysis"")",setup,549942604266107e8,461
"blog <- read.csv(""blog_entities.csv"", sep = "","")",import,549942604266107e8,461
"graph <- read.csv(""cg_entities.csv"", sep = "","")",import,549942604266107e8,461
d1 <- data.frame(blog),data cleaning,549942604266107e8,461
d2 <- data.frame(graph),data cleaning,549942604266107e8,461
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",data cleaning,549942604266107e8,461
"write.csv(both, ""both.csv"", row.names = FALSE, quote = FALSE)",export,549942604266107e8,461
"bNOTg <- read.csv(""blog_not_graph.csv"", sep = "","")",import,549942604266107e8,461
d3 <- data.frame(bNOTg),data cleaning,549942604266107e8,461
library(stats),setup,549942604266107e8,461
library(rcompanion),setup,549942604266107e8,461
"Normal <- read.csv(file = ""Analysis/Data/kc_house_data.csv"",      sep = "","", header = TRUE)",import,549942604266107e8,461
"Enriched <- read.table(file = ""Analysis/Data/MainData"", sep = "","",      header = TRUE)",import,549942604266107e8,461
"PCAData2 <- Enriched[, c(""price"", ""NumberOfBedrooms"", ""NumberOfBathrooms"",      ""LivingSpace"", ""TotalArea"", ""NumberOfFloors"", ""WaterfrontView"",      ""View"", ""YearBuilt"", condition)]",data cleaning,549942604266107e8,461
"PComp <- prcomp(PCADataAll, center = TRUE, scale = TRUE)",not sure,549942604266107e8,461
"PCADataAll2 <- predict(PComp, PCADataAll)",modeling,549942604266107e8,461
S <- cov(PCADataAll2),exploratory,549942604266107e8,461
Sinv <- solve(S),evaluation,549942604266107e8,461
"d <- rep(0, times = 21436)",evaluation,549942604266107e8,461
"for (i in c(1:21436)) {     d[i] <- crossprod(PCADataAll2[i, ], crossprod(Sinv, PCADataAll2[i,          ])) }",modeling,549942604266107e8,461
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/cluster_sol_objectives_asw.Rdata"")",setup,549942604266107e8,461
"load(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/propTable_tickets.Rdata"")",setup,549942604266107e8,461
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/bin/plot_clusters.R"")",import,549942604266107e8,461
"pdf(file = ""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-06-27/cp_composition.pdf"",      width = 14, height = 10)",export,549942604266107e8,461
"plot_cp(target_mgmt = ""SAMN"", cp = 7, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""CRAB"", cp = 1, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""SRMP"", cp = 6, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""SHLL"", cp = 4, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""GRND"", cp = 8, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""HMSP"", cp = 2, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""OTHR"", cp = 3, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
"plot_cp(target_mgmt = ""CPEL"", cp = 5, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,549942604266107e8,461
dev.off(),visualization,549942604266107e8,461
rm(list = ls()),setup,549942604266107e8,461
"booted_seedling_mortality <- read.table(""./analysis/seedling_mortality_analysis/bootstrapping/bootstrapping_parallel/ bootstrapped_seedling_mortality_glmer_nAGQ=1.txt"",      header = TRUE)",import,549942604266107e8,461
str(booted_seedling_mortality),exploratory,549942604266107e8,461
"load(""./analysis/seedling_mortality_analysis/models/seedling_mortality_model.R"")",import,549942604266107e8,461
"source(""./analysis/seedling_mortality_analysis/data/prediction_species_inundation_interaction.R"")",import,549942604266107e8,461
"sensAnalysisMultPoints <- function(sRandTs, png = FALSE, pngDir = ""M:/thesis_MSc/visualizations/sensAnalysis/"") {     sensRandTS <- NULL     ewsRandTSwins50bw4 <- NULL     ewsRandTSwins50bw7 <- NULL     ewsRandTSwins70bw4 <- NULL     ewsRandTSwins70bw7 <- NULL     for (randPoint in 1:nrow(sRandTs)) {         ts <- sRandTs[randPoint, 2:ncol(sRandTs)]         ts <- removeoutliers(ts, mildness = 1.5)         timeSteps <- (1:length(ts))         tsNames <- t(rbind(timeSteps, ts))         colnames(tsNames) <- c(""ndvi"", ""day16x"")         rownames(tsNames) <- (1:length(ts))         sensRandTS[[randPoint]] <- sensitivity_ews(tsNames, indicator = ""acf1"",              interpolate = T, detrending = ""gaussian"", bandwidthrange = c(2,                  10), incrbandwidth = 1, winsizerange = c(10,                  75), incrwinsize = 5)         if (png == TRUE) {             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, "".png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, "".png""), width = 600, height = 600)             ewsRandTSwins50bw4[[randPoint]] <- generic_ews(tsNames,                  winsize = 50, detrending = ""gaussian"", bandwidth = 4,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins50bw4.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins50bw4.png""), width = 600, height = 600)             ewsRandTSwins50bw7[[randPoint]] <- generic_ews(tsNames,                  winsize = 50, detrending = ""gaussian"", bandwidth = 7,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins50bw7.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins50bw7.png""), width = 600, height = 600)             ewsRandTSwins70bw4[[randPoint]] <- generic_ews(tsNames,                  winsize = 70, detrending = ""gaussian"", bandwidth = 4,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins70bw4.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins70bw4.png""), width = 600, height = 600)             ewsRandTSwins70bw7[[randPoint]] <- generic_ews(tsNames,                  winsize = 70, detrending = ""gaussian"", bandwidth = 7,                  interpolate = T)             if (randPoint <= 15)                  dev.print(png, file = paste0(pngDir, ""declineP"",                    randPoint, ""wins70bw7.png""), width = 600, height = 600)             else dev.print(png, file = paste0(pngDir, ""nDeclineP"",                  randPoint, ""wins70bw7.png""), width = 600, height = 600)             graphics.off()         }     }     return(list(sensRandTS, ewsRandTSwins50bw4, ewsRandTSwins50bw7,          ewsRandTSwins70bw4, ewsRandTSwins70bw7)) }",setup,87524406472221e9,463
"source(""./colors.R"")",import,549942604266107e8,461
"pelev_data <- read.table(""./data/pelev_data.txt"", header = TRUE)",import,549942604266107e8,461
"mortality <- predict(r3, preds, type = ""response"", re.form = NA)",modeling,549942604266107e8,461
require(ggplot2),setup,549942604266107e8,461
"pred_diff <- preds[1:16, ]",data cleaning,549942604266107e8,461
"path2read = ""~/Desktop/gitHub/protracted_sp/analysis/R/""",import,87524406472221e9,463
pred_diff$diff_mort <- mortality[17:32] - mortality[1:16],data cleaning,549942604266107e8,461
"pred_diff$CI025 <- as.numeric(booted_seedling_mortality[1, 33:48])",data cleaning,549942604266107e8,461
"pred_diff$CI975 <- as.numeric(booted_seedling_mortality[2, 33:48])",data cleaning,549942604266107e8,461
pred_diff$pe <- pelev_data$pe,data cleaning,549942604266107e8,461
"path2data = ""~/Desktop/gitHub/protracted_sp/analysis/data/""",import,87524406472221e9,463
"pred_diff$`Different from Zero` <- rep(""diff"", 16)",data cleaning,549942604266107e8,461
"pred_diff$`Different from Zero`[which(pred_diff$CI025 < 0)] <- ""no diff""",data cleaning,549942604266107e8,461
"pred_diff$Wooddensity <- read.table(""./data/dden_adult.txt"",      header = TRUE)$dden_adult",import,549942604266107e8,461
"write.table(pred_diff, file = ""./analysis/inundation_predicts_species_distributions/data/riskratio.txt"")",export,549942604266107e8,461
"path2plot = ""~/Desktop/gitHub/protracted_sp/analysis/output/""",not sure,87524406472221e9,463
"p1 <- ggplot(pred_diff, aes(x = reorder(sp, pe), y = diff_mort,      color = `Different from Zero`)) + geom_errorbar(aes(ymin = CI025,      ymax = CI975), width = 0.5, alpha = 0.5, size = 1) + theme_bw() +      xlab(""Species"") + ylab(""Risk ratio (Mortality)"") + theme(axis.text.x = element_text(face = ""italic"",      angle = 45, vjust = 0.7)) + scale_color_manual(values = c(""black"",      cols[4])) + geom_point(size = 3, pch = 21, fill = ""white"") +      geom_hline(aes(yintercept = 0), linetype = 2, col = cols[5]) +      theme(legend.position = c(0.15, 0.8)) + theme(text = element_text(size = 20))",visualization,549942604266107e8,461
p1,visualization,549942604266107e8,461
"source(paste0(path2read, ""plot_functions.R""))",not sure,87524406472221e9,463
"ggsave(p1, file = ""./analysis/seedling_mortality_analysis/graph_code/graphs/species_interaction_mortality_difference.png"",      width = 13, height = 6)",export,549942604266107e8,461
rm(list = ls()),setup,549942604266107e8,461
library(ggplot2),setup,549942604266107e8,461
library(reshape2),setup,549942604266107e8,461
library(plyr),setup,549942604266107e8,461
"par = get_param(output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",import,87524406472221e9,463
"setwd(""/Users/pascaltimshel/git/snpsnap/analysis/validation_summary_stats_inputEQmatched"")",setup,549942604266107e8,461
"path.base = ""/Users/pascaltimshel/snpsnap/validation_07-08-2014""",setup,549942604266107e8,461
head(par),exploratory,87524406472221e9,463
"analysis_name = ""SNPsnap_rand100_defaultMatchCrit_n100_excludeInputHLA""",setup,549942604266107e8,461
str(par),exploratory,87524406472221e9,463
"path.analysis = file.path(path.base, analysis_name)",setup,549942604266107e8,461
"file.annotation.input = file.path(path.analysis, ""input_snps_annotated.tab"")",setup,549942604266107e8,461
"file.annotation.matched = file.path(path.analysis, ""matched_snps_annotated.tab"")",setup,549942604266107e8,461
"res = read.BPBD(chains = 2, output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",import,87524406472221e9,463
df.input = read.delim(file.annotation.input),import,549942604266107e8,461
df.matched = read.delim(file.annotation.matched),import,549942604266107e8,461
"save(res, file = paste0(path2data, ""simulation_study_results.RData""))",export,87524406472221e9,463
"df.matched[, ""set""] <- as.factor(df.matched[, ""set""])",data cleaning,549942604266107e8,461
str(df.matched),exploratory,549942604266107e8,461
"accp = check_MCMC(res$samples, ""acc"")",evaluation,87524406472221e9,463
"df.stat.input <- summarise(df.input, set = as.factor(""input""),      origin = as.factor(""input""), N = nrow(df.input), mean_freq_bin = mean(freq_bin),      mean_gene_count = mean(gene_count), mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",modeling,549942604266107e8,461
"gg0 = ggplot(melt(accp), aes(value)) + geom_histogram() + facet_grid(. ~      variable) + geom_vline(aes(xintercept = 0.3), colour = ""red"")",visualization,87524406472221e9,463
"ggsave(filename = paste0(path2plot, ""Simulation_study_accpRatio.pdf""),      plot = gg0)",export,87524406472221e9,463
ptm <- proc.time(),not sure,549942604266107e8,461
"df.stat.matched <- ddply(df.matched, c(""set""), summarise, origin = as.factor(""matched""),      N = length(set), mean_freq_bin = mean(freq_bin), mean_gene_count = mean(gene_count),      mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",data cleaning,549942604266107e8,461
proc.time() - ptm,not sure,549942604266107e8,461
"(ZERO = check_MCMC(res$samples, ""all""))",evaluation,87524406472221e9,463
"df.stat <- rbind(df.stat.input, df.stat.matched)",data cleaning,549942604266107e8,461
plot(res$mcmc[[1]]),visualization,87524406472221e9,463
"csv.filename <- paste(analysis_name, ""_stat.csv"", sep = """")",not sure,549942604266107e8,461
"write.csv(df.stat, file = csv.filename, row.names = FALSE)",export,549942604266107e8,461
library(coda),setup,87524406472221e9,463
"df.compare <- ddply(df.stat, .(origin), summarise, mean_freq_bin = mean(mean_freq_bin),      mean_gene_count = mean(mean_gene_count), mean_dist_nearest_gene_snpsnap = mean(mean_dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(mean_friends_ld05))",data cleaning,549942604266107e8,461
"gelman = lapply(res$mcmc, gelman.diag)",data cleaning,87524406472221e9,463
"df.ratio <- df.compare[1, -1]/df.compare[2, -1] * 100",data cleaning,549942604266107e8,461
"df.compare <- rbind.fill(df.compare, df.ratio)",data cleaning,549942604266107e8,461
"csv.filename <- paste(analysis_name, ""_compare.csv"", sep = """")",not sure,549942604266107e8,461
"write.csv(df.compare, file = csv.filename, row.names = FALSE)",export,549942604266107e8,461
"conver = do.call(rbind, lapply(gelman, function(x) setNames(c(x[[2]],      x[[1]][, 1]), c(""mult"", ""b"", ""mu1"", ""la1"", ""mu2""))))",data cleaning,87524406472221e9,463
library(ggbiplot),setup,549942604266107e8,461
"gg = ggplot(melt(conver), aes(value)) + geom_histogram() + facet_grid(. ~      Var2) + geom_vline(aes(xintercept = 1.1), colour = ""red"")",visualization,87524406472221e9,463
"source(""../../bin/ncatsSingleAgentScreens.R"")",import,549942604266107e8,461
"source(""../../bin/RNASeqData.R"")",import,549942604266107e8,461
"ggsave(filename = paste0(path2plot, ""Simulation_study_convergence.pdf""),      plot = gg)",export,87524406472221e9,463
"do.pc <- function(mat) {     zr = which(apply(mat, 1, var, na.rm = T) == 0)     zc = which(apply(mat, 2, var, na.rm = T) == 0)     if (length(zr) > 0)          mat = mat[-zr, ]     if (length(zc) > 0)          mat = mat[, -zc]     pcp = prcomp(t(mat), scale = T, center = T)     pcp }",modeling,549942604266107e8,461
"ml = mclapply(X = branches, FUN = function(b) pbd_ML(brts = b,      initparsopt = c(1, 0.5, 3, 2), exteq = 0, verbose = FALSE),      mc.cores = 3)",evaluation,87524406472221e9,463
"computePCAcor <- function(pca1, pca2, names1, names2) {     min.pc = min(10, min(ncol(pca1$x), ncol(pca2$x)))     sd1 = pca1$sdev[1:min.pc]     sd2 = pca2$sdev[1:min.pc]     names(sd1) <- names(sd2) <- colnames(pca1$x)[1:min.pc]     cmat = cor(pca1$x[, 1:min.pc], pca2$x[, 1:min.pc])     pheatmap(cmat, cluster_rows = F, cluster_cols = F, annotation_row = data.frame(Variance = sd1/sum(sd1)),          labels_row = paste(names1, names(sd1)), annotation_col = data.frame(Variance = sd2/sum(sd2)),          labels_col = paste(names2, names(sd2)), filename = paste(names1,              ""vs"", names2, ""PCcorrelations.png"", sep = ""_""))     return(cmat) }",modeling,549942604266107e8,461
orig.par = par(),not sure,87524406472221e9,463
"computePCAMatCor <- function(pca1, mat2, names1, names2) {     sd1 = pca1$sdev     names(sd1) <- colnames(pca1$x)     over = intersect(rownames(pca1$x), colnames(mat2))     cmat = cor(pca1$x[over, ], t(mat2[, over]))     cmat[which(is.na(cmat))] <- 0     high.cor = union(which(abs(cmat[1, ]) > 0.8), which(abs(cmat[2,          ]) > 0.8))     plot(cmat[1, ], cmat[2, ], main = paste(names1, ""PCs 1 vs 2 correlated with"",          names2), xlab = ""PC1"", ylab = ""PC2"")     return(cmat) }",visualization,549942604266107e8,461
"genCodeMat <- rnaGencodeKallistoMatrix(useCellNames = TRUE, byGene = TRUE)",modeling,549942604266107e8,461
"pdf(paste0(path2plot, ""Simulation_study.pdf""))",export,87524406472221e9,463
"genePathMat <- read.table(synGet(""syn5689231"")@filePath)",import,549942604266107e8,461
"ncatsMat <- getValueForAllCells(""FAUC"")",data cleaning,549942604266107e8,461
"ncatsMat[which(is.na(ncatsMat), arr.ind = TRUE)] <- 0",data cleaning,549942604266107e8,461
ncatsReMat = getRecalculatedAUCMatrix(),data cleaning,549942604266107e8,461
"ncats.cells = intersect(colnames(genCodeMat), colnames(ncatsMat))",data cleaning,549942604266107e8,461
"ncats.genotype = dfiles$entity.sampleGenotype[match(ncats.cells,      dfiles$entity.sampleName)]",data cleaning,549942604266107e8,461
names(ncats.genotype) <- ncats.cells,data cleaning,549942604266107e8,461
"for (w in 1:length(res$samples)) {     this_par = as.numeric(strsplit(names(res$samples)[w], split = ""_"")[[1]])     layout(matrix(1:2, ncol = 2), widths = c(3, 1))     par(mai = (c(0.5, 0.8, 0.8, 0)))     boxplot(res$samples[[w]][, c(""b"", ""mu1"", ""mu2"")])     points(x = 1:3, y = this_par[c(1, 4, 5)], col = ""red"")     points(x = 1:3, y = ml[[w]][c(1, 2, 4)], col = ""green"")     title(main = paste(""b ="", this_par[1], ""mu1 ="", this_par[4],          ""mu2 ="", this_par[5], ""la1 ="", this_par[2], ""phylog"",          this_par[6]))     par(mai = (c(0.5, 0, 0.8, 0.8)))     boxplot(res$samples[[w]][, ""la1""], ylab = """", yaxt = ""n"",          xlab = ""la1"")     axis(4)     points(x = 1, y = this_par[2], col = ""red"")     points(x = 1, y = ml[[w]][3], col = ""green"") }",data cleaning,87524406472221e9,463
"rna.pc = do.pc(genCodeMat[, ncats.cells])",not sure,549942604266107e8,461
"ncats.pc = do.pc(ncatsMat[, ncats.cells])",not sure,549942604266107e8,461
dev.off(),export,87524406472221e9,463
targs <- ncatsDrugTargets(),not sure,549942604266107e8,461
par(orig.par),exploratory,87524406472221e9,463
tvals = as.character(targs$Target),data cleaning,549942604266107e8,461
names(tvals) <- targs$Drug,data cleaning,549942604266107e8,461
"all_par = data.frame(t(sapply(names(res$samples), function(x) as.numeric(strsplit(x,      split = ""_"")[[1]]))))",data cleaning,87524406472221e9,463
"c1 = computePCAMatCor(rna.pc, ncatsMat, ""RNA"", ""NCATS"")",modeling,549942604266107e8,461
"sset = colnames(c1)[grep(""inib"", colnames(c1))]",data cleaning,549942604266107e8,461
wd = getwd(),setup,889627031283453e8,464
"source(""../../../RASPathwaySig/bin/cBioPortalData.R"", chdir = T)",setup,889627031283453e8,464
"pheatmap(c1[, sset], annotation_col = data.frame(Target = tvals[sset]),      cluster_rows = F, filename = ""RNAPcsVsDrugSubset.png"")",visualization,549942604266107e8,461
setwd(wd),setup,889627031283453e8,464
"c2 = computePCAMatCor(ncats.pc, genCodeMat, ""NCATS"", ""RNA"")",modeling,549942604266107e8,461
"source(""../../../dermalNF/bin/dermalNFData.R"")",setup,889627031283453e8,464
dt = which(colnames(c2) %in% targs$Target),data cleaning,549942604266107e8,461
tcounts = as.numeric(table(targs$Target)),data cleaning,549942604266107e8,461
names(tcounts) <- names(table(targs$Target)),data cleaning,549942604266107e8,461
"dt = intersect(names(sort(tcounts)), colnames(c2))",data cleaning,549942604266107e8,461
"load(""../../../RASPathwaySig/analysis/2016-08-23/exprData.Rdata"")",import,889627031283453e8,464
"pheatmap(t(c2[, dt]), cluster_cols = F, cluster_rows = F, cellwidth = 10,      cellheight = 10, annotation_row = data.frame(NumDrugs = tcounts),      filename = ""drugTargetsVsDrugPCs.png"")",visualization,549942604266107e8,461
tcga.mat <- exprData,not sure,889627031283453e8,464
"ddt = intersect(names(sort(tcounts[which(tcounts > 5)])), colnames(c2))",data cleaning,549942604266107e8,461
"tcga.dis.averages <- sapply(setdiff(tcga.cancer.types, c(""lgggbm"",      ""nsclc"")), function(x) {     samps <- getSamplesForDisease(x)     samps <- sapply(samps, function(y) gsub(""-"", ""."", y, fixed = T))     cols <- match(samps, colnames(tcga.mat))     cols <- cols[!is.na(cols)]     if (length(cols) > 1)          return(rowMeans(tcga.mat[, cols], na.rm = T))     else return(tcga.mat[, cols]) })",not sure,889627031283453e8,464
"pheatmap(t(c2[, ddt]), cluster_cols = F, cluster_rows = F, cellwidth = 10,      cellheight = 10, annotation_row = data.frame(NumDrugs = tcounts),      filename = ""fiveOrMoredrugTargetsVsDrugPCs.png"")",visualization,549942604266107e8,461
"ncatsReMat[which(is.na(ncatsReMat), arr.ind = T)] <- 0",data cleaning,549942604266107e8,461
"ncatsr.pc = do.pc(ncatsReMat[, ncats.cells])",not sure,549942604266107e8,461
require(synapseClient),setup,889627031283453e8,464
"this.script = ""https://raw.githubusercontent.com/Sage-Bionetworks/NTAP/master/pnfCellLines/analysis/2016-02-25/drug_trans_pca_analysis.R""",not sure,549942604266107e8,461
"for (file in list.files(""."")) if (length(grep(""png"", file)) >      0) { }",not sure,549942604266107e8,461
synapseLogin(),setup,889627031283453e8,464
"source(""https://bioconductor.org/biocLite.R"")",setup,549942604266107e8,461
"zscore <- function(x) {     x <- unlist(x)     (x - mean(x, na.rm = T))/sd(x) }",modeling,889627031283453e8,464
dermalSamps <- rna_fpkm_matrix(),not sure,889627031283453e8,464
"normDermData <- apply(dermalSamps, 2, zscore)",data cleaning,889627031283453e8,464
phenoData <- fpkm_annotations(),modeling,889627031283453e8,464
"phenoData <- unique(phenoData[, c(1, 2, 5)])",exploratory,889627031283453e8,464
"pats <- paste(""patient"", apply(phenoData[match(colnames(normDermData),      phenoData$sample), c(1, 3)], 1, paste, collapse = "" tumor""))",data cleaning,889627031283453e8,464
colnames(normDermData) <- pats,data cleaning,889627031283453e8,464
"comm.genes <- intersect(rownames(tcga.dis.averages), rownames(normDermData))",data cleaning,889627031283453e8,464
library(pheatmap),setup,889627031283453e8,464
"cmat <- cbind(normDermData[comm.genes, ], tcga.dis.averages[comm.genes,      ])",data cleaning,889627031283453e8,464
"png(""tcga_dermal_dendrogram.png"", width = 800)",visualization,889627031283453e8,464
"plot(hclust(dist(t(cmat))), main = ""TCGA Samples with dermal NF data"")",visualization,889627031283453e8,464
dev.off(),evaluation,889627031283453e8,464
"png(""tcga_dermal_cor_dendrogram.png"", width = 800)",visualization,889627031283453e8,464
"plot(hclust(as.dist(1 - cor(cmat, use = ""pairwise.complete.obs""))),      main = ""TCGA Samples with Dermal Data"")",visualization,889627031283453e8,464
dev.off(),visualization,889627031283453e8,464
library(ggbiplot),setup,889627031283453e8,464
"rcol <- setdiff(colnames(cmat), c(""pcpg"", ""lihc""))",data cleaning,889627031283453e8,464
"pc <- prcomp(t(cmat), center = T, scale = T)",data cleaning,889627031283453e8,464
"ggbiplot(pc, var.axes = F, labels = colnames(cmat), choices = 1:2,      center = T, scale = T)",visualization,889627031283453e8,464
"detach(""package:StockPriceSimulator"", unload = T)",setup,958427769364789e8,465
"ggsave(""tcga_dermalNF_samps_pca12.png"")",export,889627031283453e8,464
library(StockPriceSimulator),setup,958427769364789e8,465
"ggbiplot(pc, var.axes = F, labels = colnames(cmat), choices = 2:3,      center = T, scale = T)",visualization,889627031283453e8,464
library(pracma),setup,958427769364789e8,465
library(ggplot2),setup,958427769364789e8,465
library(purrr),setup,958427769364789e8,465
"ggsave(""tcga_dermalNF_samps_pca23.png"")",export,889627031283453e8,464
"setwd(""c:/Users/ATE/thesisDoc/data"")",setup,958427769364789e8,465
rm(list = ls()),setup,958427769364789e8,465
"load(file = ""u_merton.RData"")",import,958427769364789e8,465
"for (f in list.files(""."", "".png"")) synStore(File(f, parentId = ""syn5821631""),      executed = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-09-06/clusterCellLinesByExpression.R"")))",not sure,889627031283453e8,464
"load(file = ""DOMAIN.RData"")",import,958427769364789e8,465
"pi <- map(U_merton, function(u) {     purrr::map(u, function(x) {         purrr::map_dbl(x, ~dplyr::last(.x$delta) * dplyr::last(.x$s) +              dplyr::last(.x$p) - dplyr::last(.x$option))     }) })",data cleaning,958427769364789e8,465
"pi_bsm <- map(U_merton, function(u) {     purrr::map(u, function(x) {         purrr::map_dbl(x, ~dplyr::last(.x$delta.bsm) * dplyr::last(.x$s) +              dplyr::last(.x$p.bsm) - dplyr::last(.x$option))     }) })",data cleaning,958427769364789e8,465
"pl <- pmap(list(U_merton, pi), function(u, pi) {     pmap(list(u, pi), function(x, y) {         y/dplyr::first(x[[1]]$option)     }) })",data cleaning,958427769364789e8,465
"pl_bsm <- pmap(list(U_merton, pi_bsm), function(u, pi_bsm) {     pmap(list(u, pi_bsm), function(x, y) {         y/dplyr::first(x[[1]]$option)     }) })",data cleaning,958427769364789e8,465
"l <- map(1:3, function(x) {     map(pl, function(y) {         map_dbl(y[seq(x, 15, by = 3)], mean) %>% round(3)     }) %>% pmap(c) %>% unlist })",data cleaning,958427769364789e8,465
library(mmadsenr),setup,288448976352811e7,466
library(caret),setup,288448976352811e7,466
"l_bsm <- map(1:3, function(x) {     map(pl_bsm, function(y) {         map_dbl(y[seq(x, 15, by = 3)], mean) %>% round(3)     }) %>% pmap(c) %>% unlist })",data cleaning,958427769364789e8,465
library(doMC),setup,288448976352811e7,466
library(futile.logger),setup,288448976352811e7,466
library(dplyr),setup,288448976352811e7,466
library(ggthemes),setup,288448976352811e7,466
ptm <- proc.time(),evaluation,288448976352811e7,466
"gbm_grid <- expand.grid(interaction.depth = (1:6) * 2, n.trees = (2:10) *      50, shrinkage = 0.05, n.minobsinnode = 10)",evaluation,288448976352811e7,466
"xt <- pmap(list(l, l_bsm), list) %>% as.data.frame",data cleaning,958427769364789e8,465
"training_control <- trainControl(method = ""repeatedcv"", number = 10,      repeats = 5)",evaluation,288448976352811e7,466
colnames(xt) <- 1:6,data cleaning,958427769364789e8,465
"xt <- data.frame(strike = as.integer(domain$strike), frequency = rep(c(""intraday"",      ""daily"", ""weekly""), length(unique(domain$strike))), xt, stringsAsFactors = F)",data cleaning,958427769364789e8,465
"xt <- rbind(c(rep("""", 2), map_chr(c(91, 91, 182, 182, 399, 399),      paste, ""days before maturity"")), c(rep("""", 2), rep(c(""$\\Delta_{mrt}$"",      ""$\\Delta_{bsm}$""), 3)), xt)",data cleaning,958427769364789e8,465
"print(xtable::xtable(xt, align = ""lllllllll"", caption = ""Hedging with MJD: Relative P&L"",      label = ""t:analysis:merton:pl""), include.rownames = FALSE,      include.colnames = FALSE)",exploratory,958427769364789e8,465
"S <- map(U_merton[[2]][[3]], ~data.frame(stock = .x$s, time = .x$time.period))[1:50]",data cleaning,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc"")",setup,958427769364789e8,465
"tikzDevice::tikz(file = ""figures/analysis.mjd.stocks.tex"", width = 4,      height = 2)",visualization,958427769364789e8,465
"ggplot2::ggplot(dplyr::bind_rows(S, .id = ""uniqueID""), ggplot2::aes(x = time:w,      y = stock, group = uniqueID)) + ggplot2::geom_line(ggplot2::aes(alpha = 0.5)) +      theme(legend.position = ""none"") + ggplot2::labs(x = ""Time period"",      y = ""Stock price"")",visualization,958427769364789e8,465
dev.off(),visualization,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc/data"")",setup,958427769364789e8,465
domain,setup,958427769364789e8,465
"ppl1 <- map(1:nrow(domain), function(x) {     list(pl[[1]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[1]][[x]]))) }) %>% map(function(x) {     data.frame(ppl1 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"ppl2 <- map(1:nrow(domain), function(x) {     list(pl[[2]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[2]][[x]]))) }) %>% map(function(x) {     data.frame(ppl2 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"ppl3 <- map(1:nrow(domain), function(x) {     list(pl[[3]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[3]][[x]]))) }) %>% map(function(x) {     data.frame(ppl3 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc"")",setup,958427769364789e8,465
"tikzDevice::tikz(file = ""figures/p.analysis.merton.pl.dist.big.tex"",      width = 6, height = 5)",visualization,958427769364789e8,465
"ggplot(ppl1) + stat_density(aes(ppl1), fill = ""seagreen4"", alpha = 0.7) +      stat_density(data = ppl2, aes(ppl2), fill = ""steelblue"",          alpha = 0.7) + stat_density(data = ppl3, aes(ppl3), fill = ""darkred"",      alpha = 0.7) + xlab(""Relative profit and loss"") + ylab(""Density"") +      xlim(-3, 3) + facet_wrap(~pivot, ncol = 3, scales = ""free_y"")",visualization,958427769364789e8,465
dev.off(),visualization,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc/data"")",setup,958427769364789e8,465
domain,setup,958427769364789e8,465
"ppl1 <- map(1:6, function(x) {     list(pl[[1]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[1]][[x]]))) }) %>% map(function(x) {     data.frame(ppl1 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"ppl2 <- map(1:6, function(x) {     list(pl[[2]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[2]][[x]]))) }) %>% map(function(x) {     data.frame(ppl2 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"ppl3 <- map(1:6, function(x) {     list(pl[[3]][[x]], rep(paste0(""K = "", domain$strike[x], "" - dbm = "",          domain$maturity[x]), length(pl[[3]][[x]]))) }) %>% map(function(x) {     data.frame(ppl3 = x[[1]], pivot = x[[2]]) }) %>% do.call(what = ""rbind"")",data cleaning,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc"")",setup,958427769364789e8,465
"tikzDevice::tikz(file = ""figures/p.analysis.merton.pl.dist.in.tex"",      width = 6, height = 4)",visualization,958427769364789e8,465
"ggplot(ppl1) + stat_density(aes(ppl1), fill = ""seagreen4"", alpha = 0.7) +      stat_density(data = ppl2, aes(ppl2), fill = ""steelblue"",          alpha = 0.7) + stat_density(data = ppl3, aes(ppl3), fill = ""darkred"",      alpha = 0.7) + xlab(""Relative profit and loss"") + ylab(""Density"") +      xlim(-0.025, 0.05) + facet_wrap(~pivot, ncol = 3, scales = ""free_y"")",visualization,958427769364789e8,465
dev.off(),visualization,958427769364789e8,465
"setwd(""c:/Users/ATE/thesisDoc/data"")",setup,958427769364789e8,465
domain,setup,958427769364789e8,465
186.31,setup,958427769364789e8,465
"u_91 <- map_dbl(U_merton[[3]][[1]], function(x) {     dplyr::last(x$s) })",data cleaning,958427769364789e8,465
"u_182 <- map_dbl(U_merton[[3]][[2]], function(x) {     dplyr::last(x$s) })",data cleaning,958427769364789e8,465
"u_399 <- map_dbl(U_merton[[3]][[3]], function(x) {     dplyr::last(x$s) })",data cleaning,958427769364789e8,465
"df <- data.frame(u_91, u_182, u_399)",data cleaning,958427769364789e8,465
library(synapseClient),setup,191354127600789e7,467
synapseLogin(),communication,191354127600789e7,467
library(data.table),communication,191354127600789e7,467
"setwd(""D:/yr4/Big_Data/Project/ipl/InitialDatasets"")",setup,488020292948931e8,468
library(sqldf),import,488020292948931e8,468
"setwd(""C:/Users/Amir/Documents/GitHub/structural_prediction_of_ER/"")",setup,43648015963845e9,469
library(readr),import,488020292948931e8,468
"data_1RD8_AB = read.csv(""correlation_analysis/combined_data/data_1RD8_AB.csv"")",setup,43648015963845e9,469
"allMatches = read_csv(""matches.csv"")",import,488020292948931e8,468
"data_2FP7_B = read.csv(""correlation_analysis/combined_data/data_2FP7_B.csv"")",setup,43648015963845e9,469
"data_2Z83_A = read.csv(""correlation_analysis/combined_data/data_2Z83_A.csv"")",setup,43648015963845e9,469
"data_2JLY_A = read.csv(""correlation_analysis/combined_data/data_2JLY_A.csv"")",import,43648015963845e9,469
"completedMatches <- sqldf(""SELECT * FROM allMatches where dl_applied == 0 AND result != \""no result\"""")",import,488020292948931e8,468
"data_3GOL_A = read.csv(""correlation_analysis/combined_data/data_3GOL_A.csv"")",import,43648015963845e9,469
"write.csv(completedMatches, ""../Analysis/matches.csv"")",export,488020292948931e8,468
"data_3LYF_A = read.csv(""correlation_analysis/combined_data/data_3LYF_A.csv"")",import,43648015963845e9,469
"data_4AQF_B = read.csv(""correlation_analysis/combined_data/data_4AQF_B.csv"")",import,43648015963845e9,469
"data_4GHA_A = read.csv(""correlation_analysis/combined_data/data_4GHA_A.csv"")",import,43648015963845e9,469
"data_4IRY_A = read.csv(""correlation_analysis/combined_data/data_4IRY_A.csv"")",import,43648015963845e9,469
"deliveries <- read.csv(""deliveries.csv"")",import,488020292948931e8,468
"ASAP_res_prop = rbind(data_1RD8_AB, data_2FP7_B, data_2Z83_A,      data_2JLY_A, data_3GOL_A, data_3LYF_A, data_4AQF_B, data_4GHA_A,      data_4IRY_A)",data cleaning,43648015963845e9,469
ASAP_res_prop$protein = factor(ASAP_res_prop$protein),data cleaning,43648015963845e9,469
"deliveriesFromCompletedMatches <- sqldf(""select * from deliveries where match_id in (select id from completedMatches)"")",data cleaning,488020292948931e8,468
ASAP_pdb_prop = data.frame(),not sure,43648015963845e9,469
"write.csv(deliveriesFromCompletedMatches, ""../Analysis/deliveries.csv"")",export,488020292948931e8,468
counter = 0,not sure,43648015963845e9,469
"library(""ggplot2"")",setup,488020292948931e8,468
"library(""plyr"")",setup,488020292948931e8,468
"library(""binom"")",setup,488020292948931e8,468
"library(""lme4"")",setup,488020292948931e8,468
"library(""arm"")",setup,488020292948931e8,468
"library(""sjPlot"")",setup,488020292948931e8,468
"library(""scales"")",setup,488020292948931e8,468
"library(""saccades"")",setup,488020292948931e8,468
"library(""boot"")",setup,488020292948931e8,468
"library(""apaTables"")",setup,488020292948931e8,468
"data_dir = ""C:\\Users\\me\\Desktop\\learning_at_a_glance\\data""",setup,488020292948931e8,468
"analysis_dir = ""C:\\Users\\me\\Desktop\\learning_at_a_glance\\analysis""",setup,488020292948931e8,468
"for (pdb in levels(ASAP_res_prop$protein)) {     counter = counter + 1     cat(counter[[1]][1], "" "", pdb, ""\n"")     pdb_data = ASAP_res_prop[ASAP_res_prop$protein == pdb, ]     x = cor.test(pdb_data$entropy, pdb_data$rsa_avg_md, method = ""spearman"")     r.seqent.rsa = x$estimate     x = cor.test(pdb_data$entropy, pdb_data$wcn_avg_md, method = ""spearman"")     r.seqent.wcnCA = x$estimate     x = cor.test(pdb_data$entropy, pdb_data$bfca, method = ""spearman"")     r.seqent.bfCA = x$estimate     row = data.frame(pdb = pdb, nres = length(pdb_data$entropy),          r.seqent.rsa = r.seqent.rsa, r.seqent.wcnCA = r.seqent.wcnCA,          r.seqent.bfCA = r.seqent.bfCA, sd.seqent = sd(pdb_data$entropy),          mean.seqent = mean(pdb_data$entropy), median.seqent = median(pdb_data$entropy),          sd.wcnCA = sd(pdb_data$wcn_avg_md), mean.wcnCA = mean(pdb_data$wcn_avg_md),          median.wcnCA = median(pdb_data$wcn_avg_md), sd.rsa = sd(pdb_data$rsa_avg_md),          mean.rsa = mean(pdb_data$rsa_avg_md), median.rsa = median(pdb_data$rsa_avg_md))     ASAP_pdb_prop = rbind(ASAP_pdb_prop, row) }",modeling,43648015963845e9,469
"setwd(""C:/Users/Amir/Documents/GitHub/cordiv/analysis/src"")",setup,43648015963845e9,469
"write.csv(ASAP_pdb_prop, ""../tables/ASAP_pdb_prop.csv"", row.names = F)",export,43648015963845e9,469
"subjects = c(""Colleen"", ""Jeremy"", ""Tricia"", ""Wes"", ""Matt"", ""Tim"",      ""Heather"", ""Kelly"", ""Anja"", ""Steph"")",not sure,488020292948931e8,468
"learn_test = c(""*learn*"", ""*test*"")",not sure,488020292948931e8,468
"survey_data = read.csv(paste(data_dir, ""survey_data.csv"", sep = ""\\""))",import,488020292948931e8,468
"for (lt in 1:2) {     for (s in 1:length(subjects)) {         csvlist = list.files(path = paste(data_dir, subjects[s],              sep = ""\\""), pattern = learn_test[lt])         for (i in 1:length(csvlist)) {             tmp = read.csv(paste(data_dir, subjects[s], csvlist[i],                  sep = ""\\""))             if (s == 1 & i == 1) {                 all_data = tmp             }             else {                 all_data = rbind(all_data, tmp)             }         }     }     if (lt == 1) {         learn_data = all_data     }     else {         test_data = all_data     } }",import,488020292948931e8,468
"answer_data = subset(test_data, isAnswer == 1 & region >= 0)",data cleaning,488020292948931e8,468
"answer_data$isCorrect = mapply(function(x, y) x == y, answer_data$region,      answer_data$region_tested)",data cleaning,488020292948931e8,468
"accuracy <- ddply(answer_data, c(""stimulus"", ""input"", ""participant""),      summarise, acc = mean(isCorrect == 1), CI = 1.96 * sqrt(mean(isCorrect ==          1) * (1 - mean(isCorrect == 1))/length(isCorrect)))",modeling,488020292948931e8,468
"ggplot(data = accuracy, aes(x = stimulus, y = acc, fill = input)) +      geom_bar(stat = ""identity"", position = position_dodge()) +      geom_errorbar(aes(ymax = acc + CI, ymin = acc - CI), position = ""dodge"") +      facet_grid(. ~ participant)",visualization,488020292948931e8,468
"apa.2way.table(stimulus, input, acc, accuracy, filename = paste(analysis_dir,      ""accuracy_apatable.doc"", sep = ""\\""))",communication,488020292948931e8,468
"ggplot(data = accuracy, aes(x = stimulus, y = acc, fill = input)) +      geom_bar(stat = ""identity"", position = position_dodge()) +      geom_errorbar(aes(ymax = acc + CI, ymin = acc - CI), position = ""dodge"")",visualization,488020292948931e8,468
"accuracy <- ddply(answer_data, c(""input""), summarise, acc = mean(isCorrect ==      1), CI = 1.96 * sqrt(mean(isCorrect == 1) * (1 - mean(isCorrect ==      1))/length(isCorrect)))",modeling,488020292948931e8,468
"ggplot(data = accuracy, aes(x = input, y = acc, fill = input)) +      scale_fill_manual(name = """", values = c(""#b491b5"", ""#83bbe5"")) +      geom_bar(stat = ""identity"", position = position_dodge()) +      scale_color_manual(values = c(""#b491b5"", ""#83bbe5"")) + coord_cartesian(ylim = c(0.6,      0.8)) + labs(y = ""Accuracy"", x = ""Input"", title = paste(""Learning Effectiveness"",      """")) + theme(text = element_text(size = 35), legend.position = ""none"") +      ggsave(filename = paste(analysis_dir, ""\\"", ""overall_acc"",          "".png"", sep = """"), height = 20, width = 20, units = ""cm"")",visualization,488020292948931e8,468
siteSize = 2048,setup,512227852828801e8,470
"apa.d.table(input, acc, accuracy, filename = paste(analysis_dir,      ""input_accuracy_d_table.doc"", sep = ""\\""))",communication,488020292948931e8,468
"treatment = ""Copper""",setup,512227852828801e8,470
"strand = ""both""",setup,512227852828801e8,470
"learning_time <- ddply(learn_data, c(""input"", ""participant"",      ""stimulus""), summarise, total_time = (max(timestamp) - min(timestamp))/1000)",modeling,488020292948931e8,468
library(metafor),setup,401969793485478e8,471
"learning_time = ddply(learning_time, c(""input""), summarise, mean = mean(total_time))",modeling,488020292948931e8,468
library(readxl),setup,401969793485478e8,471
window.size = 300,setup,512227852828801e8,470
numSam = 6,setup,512227852828801e8,470
"dataSetOri <- read_excel(""PhD/Systematic Reviews/History of Power Estimation Studies/SecondaryAnalysisData2018.03.25.xlsx"",      sheet = ""Data_prop_reporting_PA"")",import,401969793485478e8,471
"apa.2way.table(stimulus, input, total_time, learning_time, filename = paste(analysis_dir,      ""learningtime_apatable.doc"", sep = ""\\""))",communication,488020292948931e8,468
dataSetOri <- as.data.frame(dataSetOri),import,401969793485478e8,471
"ggplot(data = learning_time, aes(x = input, y = mean, fill = input)) +      scale_fill_manual(name = """", values = c(""#b491b5"", ""#83bbe5"")) +      geom_bar(stat = ""identity"", position = position_dodge()) +      scale_color_manual(values = c(""#b491b5"", ""#83bbe5"")) + coord_cartesian(ylim = c(80,      105)) + labs(y = ""Learning Time"", x = ""Input"", title = paste(""Learning Time"",      """")) + theme(text = element_text(size = 35), legend.position = ""none"") +      ggsave(filename = paste(analysis_dir, ""\\"", ""overall_speed"",          "".png"", sep = """"), height = 20, width = 20, units = ""cm"")",visualization,488020292948931e8,468
"ggplot(data = learning_time, aes(x = stimulus, y = total_time,      fill = input)) + geom_bar(stat = ""identity"", position = position_dodge())",visualization,488020292948931e8,468
dataSet <- dataSetOri,not sure,401969793485478e8,471
years <- dataSet$YearsStudied,not sure,401969793485478e8,471
medianYear <- as.numeric(years),data cleaning,401969793485478e8,471
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",data cleaning,512227852828801e8,470
"apa.d.table(input, total_time, learning_time, filename = paste(analysis_dir,      ""input_learningtime_d_table.doc"", sep = ""\\""))",communication,488020292948931e8,468
"ggplot(data = learning_time, aes(x = stimulus, y = total_time,      fill = input)) + geom_bar()",visualization,488020292948931e8,468
"ggplot(data = learning_time, aes(x = input, y = total_time, fill = input)) +      stat_boxplot(geom = ""errorbar"") + geom_boxplot() + geom_point(position = ""jitter"",      size = 10, alpha = 0.5)",visualization,488020292948931e8,468
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.pval.discrete.Robj"")",setup,512227852828801e8,470
"for (i in 1:length(years)) {     if ((is.na(as.numeric(years)[i])) && (!is.na(as.numeric(unlist(strsplit(years[i],          ""-""))[2])))) {         minYear <- unlist(strsplit(years[i], ""-""))[1]         maxYear <- unlist(strsplit(years[i], ""-""))[2]         yearRange <- (minYear:maxYear)         medianYear[i] <- median(yearRange)     } }",data cleaning,401969793485478e8,471
load(out.path),import,512227852828801e8,470
"acc_diff <- ddply(answer_data, c(""input"", ""participant""), summarise,      acc = mean(isCorrect == 1))",communication,488020292948931e8,468
dataSet$medianYear <- medianYear,data cleaning,401969793485478e8,471
"acc_diff <- ddply(acc_diff, ""participant"", summarise, acc_increase = acc[input ==      ""gaze""] - acc[input == ""mouse""])",not sure,488020292948931e8,468
"trigs <- ddply(learn_data, c(""input"", ""participant""), summarise,      trig_total = sum(triggered))",not sure,488020292948931e8,468
"trigs <- ddply(trigs, ""participant"", summarise, trig_increase = trig_total[input ==      ""gaze""] - trig_total[input == ""mouse""])",not sure,488020292948931e8,468
"just_input_participant = ddply(learning_time, c(""input"", ""participant""),      summarise, total_time = sum(total_time))",not sure,488020292948931e8,468
"time_diff <- ddply(just_input_participant, ""participant"", summarise,      speedup = total_time[input == ""mouse""] - total_time[input ==          ""gaze""])",not sure,488020292948931e8,468
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.pval.discrete."",      600, "".Robj"")",setup,512227852828801e8,470
"diff = merge(acc_diff, time_diff, by = ""participant"")",data cleaning,488020292948931e8,468
load(out.path),import,512227852828801e8,470
"diff = merge(diff, trigs, by = ""participant"")",data cleaning,488020292948931e8,468
"library(""qvalue"")",setup,512227852828801e8,470
"diff = merge(diff, survey_data, by = ""participant"")",data cleaning,488020292948931e8,468
"ggplot(data = diff, aes(x = acc_increase, y = speedup)) + geom_point(size = 10) +      theme(plot.title = element_text(size = 20, face = ""bold"",          vjust = 2)) + labs(y = ""Gaze Speed Up (Seconds)"", x = ""Gaze Accuracy Improvements"",      title = paste(""Gaze Benefit"", """")) + ylim(c(-60, 120)) +      xlim(c(-0.6, 0.6)) + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +      theme(text = element_text(size = 35), legend.position = ""none"")",visualization,488020292948931e8,468
"ggsave(filename = paste(analysis_dir, ""\\"", ""just_dots"", "".png"",      sep = """"), height = 20, width = 30, units = ""cm"")",export,488020292948931e8,468
library(schoRsch),setup,488020292948931e8,468
"t_out(t.test(diff$speedup, data = diff))",evaluation,488020292948931e8,468
"t_out(t.test(diff$acc_increase, data = diff))",evaluation,488020292948931e8,468
"setwd(""~/M.S. Thesis/Data/GitHubProjects/LaSelvaSeedRain/Data/TidyData"")",setup,712896281387657e8,472
library(ggplot2),setup,712896281387657e8,472
library(car),setup,712896281387657e8,472
library(lsmeans),setup,712896281387657e8,472
library(stats),setup,712896281387657e8,472
library(lme4),setup,712896281387657e8,472
library(dplyr),setup,712896281387657e8,472
library(readr),setup,712896281387657e8,472
library(multcomp),setup,712896281387657e8,472
library(ggResidpanel),setup,712896281387657e8,472
"wind_a_analysis <- read.csv(""wind_abund_tidy.csv"", header = TRUE)",import,712896281387657e8,472
str(wind_a_analysis),exploratory,712896281387657e8,472
wind_a_analysis$block <- as.factor(wind_a_analysis$block),data cleaning,712896281387657e8,472
"animal_a_analysis <- read.csv(""animal_abund_tidy.csv"", header = TRUE)",import,712896281387657e8,472
animal_a_analysis$block <- as.factor(animal_a_analysis$block),import,712896281387657e8,472
str(animal_a_analysis),exploratory,712896281387657e8,472
"mech_a_analysis <- read.csv(""mech_abund_tidy.csv"", header = TRUE)",import,712896281387657e8,472
mech_a_analysis$block <- as.factor(mech_a_analysis$block),data cleaning,712896281387657e8,472
str(mech_a_analysis),exploratory,712896281387657e8,472
"mech_a_analysis <- mech_a_analysis[complete.cases(mech_a_analysis),      ]",not sure,712896281387657e8,472
"abiotic_a_analysis <- read.csv(""abiotic_abund_tidy.csv"", header = TRUE)",import,712896281387657e8,472
str(abiotic_a_analysis),exploratory,712896281387657e8,472
abiotic_a_analysis$block <- as.factor(abiotic_a_analysis$block),data cleaning,712896281387657e8,472
hist(wind_a_analysis$seednum),visualization,712896281387657e8,472
"boxplot(wind_a_analysis$seednum ~ wind_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Seed abundance per treatment"")",visualization,712896281387657e8,472
"with(wind_a_analysis, plot(treatment, seednum))",visualization,712896281387657e8,472
"vif(glm(seednum ~ treatment + block, data = wind_a_analysis))",modeling,712896281387657e8,472
"ggplot(wind_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,712896281387657e8,472
"ggplot(wind_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,712896281387657e8,472
"ggplot(wind_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,712896281387657e8,472
"ggplot(wind_a_analysis, aes(block, seednum, color = block)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,712896281387657e8,472
"with(wind_a_analysis, table(block, treatment))",not sure,712896281387657e8,472
"ggplot(wind_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,712896281387657e8,472
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",visualization,712896281387657e8,472
"wind_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() + geom_bar(aes(treatment,      fill = as.factor(treatment))) + facet_grid(plot ~ .) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,712896281387657e8,472
"ggplot(wind_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,712896281387657e8,472
"wind.abund.glm <- glmer(seednum ~ block + treatment + (1 | plot),      data = wind_a_analysis, family = poisson)",modeling,712896281387657e8,472
"wind_resid <- resid_panel(resid(wind.abund.glm), fitted(wind.abund.glm),      bins = 20)",modeling,712896281387657e8,472
wind.abund.res <- resid(wind.abund.glm),evaluation,712896281387657e8,472
wind.abund.pred <- predict(wind.abund.glm),evaluation,712896281387657e8,472
"plot(wind.abund.pred, wind.abund.res, ylab = ""Residuals"", xlab = ""predicted values"",      main = ""resid vs pred"")",visualization,712896281387657e8,472
"abline(0, 0)",visualization,712896281387657e8,472
qqnorm(wind.abund.res),visualization,712896281387657e8,472
"qqline(wind.abund.res, col = ""red"")",evaluation,712896281387657e8,472
hist(wind.abund.res),visualization,712896281387657e8,472
"anova(wind.abund.glm, test = ""Chi"")",modeling,712896281387657e8,472
summary(wind.abund.glm),evaluation,712896281387657e8,472
"summary(glht(wind.abund.glm, mcp(treatment = ""Tukey"")))",evaluation,712896281387657e8,472
"1 - pf(1.4454, 3, 7)",evaluation,712896281387657e8,472
"ptukey(abs(-0.748) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
"ptukey(abs(-2.469) * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
"ptukey(0.562 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
"ptukey(1.708 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
"ptukey(0.128 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
"ptukey(1.672 * sqrt(2), nmeans = 4, df = 8, lower = F)",evaluation,712896281387657e8,472
hist(animal_a_analysis$seednum),visualization,712896281387657e8,472
"boxplot(animal_a_analysis$seednum ~ animal_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""Animal seed dispersed abundance per treatment"")",visualization,712896281387657e8,472
"with(animal_a_analysis, plot(treatment, seednum))",not sure,712896281387657e8,472
"vif(glm(seednum ~ treatment + block, data = animal_a_analysis))",not sure,712896281387657e8,472
"ggplot(animal_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",not sure,712896281387657e8,472
"ggplot(animal_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,712896281387657e8,472
"ggplot(animal_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,712896281387657e8,472
"ggplot(animal_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,712896281387657e8,472
library(tidyverse),setup,7583430968225e9,473
library(data.table),setup,7583430968225e9,473
library(furrr),setup,7583430968225e9,473
workflow_id <- 99000000066,setup,7583430968225e9,473
"outdir <- file.path(""analysis"", ""data"", ""model_output"", workflow_id)",export,7583430968225e9,473
runs <- list.files(outdir),export,7583430968225e9,473
"get_monthly_lai <- function(rundir, year) {     filename <- file.path(rundir, glue::glue(""analysis-T-{year}-00-00-000000-g01.h5""))     nc <- ncdf4::nc_open(filename)     lai_raw <- ncdf4::ncvar_get(nc, ""LAI_PY"", start = c(6, 1,          1, 1), count = c(6, -1, -1, -1))[-2, , ]     pft_levels <- c(""Early hardwood"", ""Mid hardwood"", ""Late hardwood"",          ""Pine"", ""Late conifer"")     pftnames <- factor(pft_levels[c(4, 5, 1:3)], pft_levels)     basedate <- ISOdate(year, 1, 1, 0, 0, 0, ""UTC"")     data.table::melt(lai_raw) %>% tibble::as_tibble() %>% dplyr::rename(ipft = Var1,          cohort = Var2, timestep = Var3) %>% dplyr::mutate(pft = pftnames[ipft],          dt = basedate + lubridate::dhours((timestep - 1)/2),          month = lubridate::floor_date(dt, ""month"")) %>% dplyr::group_by(month,          pft, cohort) %>% dplyr::summarize(lai = mean(value)) %>%          dplyr::ungroup() %>% dplyr::group_by(month, pft) %>%          dplyr::summarize(lai = sum(lai)) %>% dplyr::ungroup() }",data cleaning,7583430968225e9,473
"get_ensemble_lai <- function(rundir, years = seq(1902, 1990)) {     ensemble <- basename(rundir)     future_map_dfr(years, get_monthly_lai, rundir = rundir) %>%          dplyr::mutate(ensemble = !!ensemble) }",evaluation,7583430968225e9,473
"all_lai <- future_map_dfr(file.path(outdir, runs), possibly(get_ensemble_lai,      NULL), .progress = TRUE)",setup,7583430968225e9,473
"fst::write_fst(all_lai, ""analysis/data/derived-data/ed-lai-output.fst"")",export,7583430968225e9,473
"fst::write_fst(all_lai, ""analysis/data/derived-data/ed-lai-output.fst"")",export,7583430968225e9,473
library(tidyverse),setup,7583430968225e9,473
library(plyr),setup,7583430968225e9,473
library(stringr),setup,7583430968225e9,473
library(reshape2),setup,7583430968225e9,473
library(grid),setup,7583430968225e9,473
library(gridExtra),setup,7583430968225e9,473
"source(""powerAnalysis/lib.R"")",setup,7583430968225e9,473
"VpLayout <- function(x, y) {     viewport(layout.pos.row = x, layout.pos.col = y) }",setup,7583430968225e9,473
"GetLegend <- function(a.gplot) {     tmp <- ggplot_gtable(ggplot_build(a.gplot))     leg <- which(sapply(tmp$grobs, function(x) x$name) == ""guide-box"")     legend <- tmp$grobs[[leg]]     return(legend) }",setup,7583430968225e9,473
cluster.env <- new.env(),setup,7583430968225e9,473
"load(""powerAnalysis/output_cluster_power.RData"", envir = cluster.env)",setup,7583430968225e9,473
parzen.env <- new.env(),setup,7583430968225e9,473
"load(""powerAnalysis/output_parzen_window_power.RData"", envir = parzen.env)",setup,7583430968225e9,473
normal.env <- new.env(),setup,7583430968225e9,473
"normal.env$power.cluster <- read.table(""comparisons/out/NOrMAL.tsv"",      header = TRUE, sep = ""\t"")",setup,7583430968225e9,473
normal.env$power.cluster$coverage <- as.numeric(as.character(normal.env$power.cluster$coverage)),setup,7583430968225e9,473
"cluster.env$power.cluster$Method <- ""Cluster estimand""",setup,7583430968225e9,473
"parzen.env$power.cluster$Method <- ""Parzen window""",setup,7583430968225e9,473
"normal.env$power.cluster$Method <- ""NOrMAL""",setup,7583430968225e9,473
"p.detected.df <- rbind(cluster.env$power.cluster, parzen.env$power.cluster,      normal.env$power.cluster)",setup,7583430968225e9,473
"p.detected.df$coverage <- round(p.detected.df$coverage, 2)",setup,7583430968225e9,473
"p.detected.df$se.power <- with(p.detected.df, sqrt(p.detected.primary *      (1 - p.detected.primary)/n))",setup,7583430968225e9,473
"power.by.eff.magnitude <- ddply(p.detected.df, .(Method, eff.magnitude),      summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),      mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",setup,7583430968225e9,473
"power.by.offset <- ddply(p.detected.df, .(Method, offset.primary),      summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),      mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",setup,7583430968225e9,473
"power.by.coverage <- ddply(p.detected.df, .(Method, coverage),      summarise, power = mean(p.detected.primary), se.power = sqrt(mean(se.power^2)/length(p.detected.primary)),      mean.err = mean(mean.err), se.err = sqrt(mean(se.err^2)/length(se.err)))",setup,7583430968225e9,473
"blank_legend <- theme(legend.key = element_rect(color = ""white""),      legend.text = element_blank(), legend.title = element_blank())",setup,7583430968225e9,473
panel.list <- list(),setup,7583430968225e9,473
rm(list = ls()),setup,359784925822169e8,474
"booted_seedling_mortality <- read.table(""./analysis/seedling_mortality_analysis/bootstrapping/bootstrapping_parallel/ bootstrapped_seedling_mortality_glmer_nAGQ=1.txt"",      header = TRUE)",import,359784925822169e8,474
str(booted_seedling_mortality),exploratory,359784925822169e8,474
"load(""./analysis/seedling_mortality_analysis/models/seedling_mortality_model.R"")",import,359784925822169e8,474
"source(""./analysis/seedling_mortality_analysis/data/prediction_species_inundation_interaction.R"")",setup,359784925822169e8,474
"pelev_data <- read.table(""./data/pelev_data.txt"", header = TRUE)",import,359784925822169e8,474
"preds$mortality <- predict(r3, preds, type = ""response"", re.form = NA)",modeling,359784925822169e8,474
"preds$CI025 <- as.numeric(booted_seedling_mortality[1, 1:32])",data cleaning,359784925822169e8,474
"preds$CI975 <- as.numeric(booted_seedling_mortality[2, 1:32])",data cleaning,359784925822169e8,474
"preds$pe <- rep(pelev_data$pe, times = 2)",data cleaning,359784925822169e8,474
require(ggplot2),setup,359784925822169e8,474
"cols <- c(""#8CB369"", ""#F4E285"", ""#4C8577"", ""#F4A259"", ""#BC4B51"")",visualization,359784925822169e8,474
"colnames(preds)[5] <- ""Water inundation""",data cleaning,359784925822169e8,474
"levels(preds$`Water inundation`) <- c(""Dry"", ""Wet"")",data cleaning,359784925822169e8,474
"p1 <- ggplot(preds, aes(x = reorder(sp, pe), y = mortality, group = `Water inundation`)) +      geom_errorbar(aes(ymin = CI025, ymax = CI975), width = 0.3,          alpha = 0.2) + theme_classic() + geom_point(size = 4) +      geom_point(size = 3, aes(color = `Water inundation`)) + theme(legend.position = c(0.25,      0.8)) + xlab(""Species"") + ylab(""p(Mortality)"") + theme(axis.text.x = element_text(face = ""italic"",      angle = 45, vjust = 0.7)) + scale_color_manual(values = c(""light grey"",      cols[c(5)])) + theme(text = element_text(size = 20))",visualization,359784925822169e8,474
p1,not sure,359784925822169e8,474
"ggsave(p1, file = ""./analysis/seedling_mortality_analysis/graph_code/graphs/species_interaction_mortality_Fig2.png"",      width = 13, height = 6)",export,359784925822169e8,474
library(pROC),evaluation,339576536091045e8,475
library(SDMTools),modeling,339576536091045e8,475
library(dplyr),setup,378124279668555e8,476
library(viridis),setup,378124279668555e8,476
library(ggplot2),setup,378124279668555e8,476
library(reshape2),setup,378124279668555e8,476
library(cowplot),setup,378124279668555e8,476
library(ogbox),setup,378124279668555e8,476
library(homologene),setup,378124279668555e8,476
library(scales),setup,378124279668555e8,476
library(gplots),setup,378124279668555e8,476
library(stringr),setup,378124279668555e8,476
library(magrittr),setup,378124279668555e8,476
library(pheatmap),setup,378124279668555e8,476
"source(""R/cellColors.R"")",setup,378124279668555e8,476
"source(""R/puristOut.R"")",setup,378124279668555e8,476
"source(""R/heatmap.3.R"")",setup,378124279668555e8,476
"source(""R/regionize.R"")",setup,378124279668555e8,476
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,360661207698286e8,477
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,360661207698286e8,477
library(dplyr),modeling,360661207698286e8,477
script.dir <- function() {     dirname(sys.frame(1)$ofile) },not sure,98068725829944e9,478
library(viridis),modeling,360661207698286e8,477
"projectDir <- ""/home/wespisea/work/research//researchProjects/coexpr/lncNET/""",setup,98068725829944e9,478
"getFullPath <- function(subpath) {     file.path(projectDir, subpath) }",setup,98068725829944e9,478
"homeFolder <- path.expand(""~"")",setup,98068725829944e9,478
"getDataFile <- function(subpath) {     file.path(homeFolder, ""data"", subpath) }",setup,98068725829944e9,478
"getFullPlotPath <- function(subpath) {     file.path(plotFolder, subpath) }",setup,98068725829944e9,478
"getDropboxPath <- function(subpath) {     file.path(dataFolder, subpath) }",setup,98068725829944e9,478
"exportAsTable <- function(df, file) {     write.table(df, file = file, quote = FALSE, row.names = FALSE,          sep = ""\t"") }",setup,98068725829944e9,478
library(allenBrain),setup,767246168106794e6,479
library(assertthat),setup,767246168106794e6,479
library(magick),setup,767246168106794e6,479
devtools::load_all(),setup,767246168106794e6,479
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,901742411544546e8,480
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,901742411544546e8,480
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,901742411544546e8,480
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,901742411544546e8,480
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,901742411544546e8,480
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,901742411544546e8,480
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",import,901742411544546e8,480
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",import,901742411544546e8,480
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",import,901742411544546e8,480
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",import,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
gc(),not sure,901742411544546e8,480
set.seed(231),modeling,901742411544546e8,480
ncores = 40,setup,901742411544546e8,480
"source(""butler_nickerson_analysis.R"")",modeling,901742411544546e8,480
"source(""butler_tables.R"")",data cleaning,901742411544546e8,480
"setwd(""C:/Documents and Settings/mcolvin/My Documents/projects/"")",setup,901742411544546e8,480
"source(""./src/1_global.R"")",import,901742411544546e8,480
"source(""./src/2_functions.R"")",import,901742411544546e8,480
"source(""./src/3_load.R"")",import,901742411544546e8,480
"source(""./src/4_clean.R"")",data cleaning,901742411544546e8,480
"source(""./src/5_tables.R"")",modeling,901742411544546e8,480
"source(""./src/6_figures.R"")",visualization,901742411544546e8,480
"source(""./src/7_analysis.R"")",modeling,901742411544546e8,480
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",modeling,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
"suppressMessages(library(""EpiModelHIV""))",import,901742411544546e8,480
"library(""EpiModelHPC"")",import,901742411544546e8,480
"library(""dplyr"")",import,901742411544546e8,480
"source(""analysis/fx.R"")",import,901742411544546e8,480
"library(""wesanderson"")",import,901742411544546e8,480
"par(mfrow = c(1, 2), mar = c(3, 3, 2.5, 1), mgp = c(2, 1, 0))",visualization,901742411544546e8,480
"pal <- wesanderson::wes_palette(""Moonrise1"", n = 9, type = ""continuous"")",visualization,901742411544546e8,480
"load(""data/followup/sim.n3003.rda"")",import,901742411544546e8,480
sim.base <- sim,not sure,901742411544546e8,480
mn.base <- as.data.frame(sim.base),data cleaning,901742411544546e8,480
ir.base <- (sum(mn.base$incid)/sum((1 - mn.base$i.prev) * mn.base$num)) *      52 * 1e+05,data cleaning,901742411544546e8,480
ir.gc.base <- (sum(mn.base$incid.gc)/sum((1 - mn.base$prev.gc) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.ct.base <- (sum(mn.base$incid.ct)/sum((1 - mn.base$prev.ct) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.syph.base <- (sum(mn.base$incid.syph)/sum((1 - mn.base$prev.syph) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.sti.base <- (sum(mn.base$incid.sti)/sum((1 - mn.base$prev.sti) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
incid.base <- sum(mn.base$incid),data cleaning,901742411544546e8,480
incid.gc.base <- sum(mn.base$incid.gc),data cleaning,901742411544546e8,480
incid.ct.base <- sum(mn.base$incid.ct),data cleaning,901742411544546e8,480
incid.syph.base <- sum(mn.base$incid.syph),data cleaning,901742411544546e8,480
incid.sti.base <- sum(mn.base$incid.sti),data cleaning,901742411544546e8,480
"sims <- c(3003, 3490:3498)",data cleaning,901742411544546e8,480
"df.hiv.pia <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.hivonly.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.hiv.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.gc.pia <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.gc.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.ct.pia <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.ct.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.syph.pia <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.syph.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.sti.pia <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"df.sti.nnt <- data.frame(rep(NA, 256))",data cleaning,901742411544546e8,480
"for (i in seq_along(sims)) {     load(list.files(""data/followup/"", pattern = as.character(sims[i]),          full.names = TRUE))     mn <- as.data.frame(sim)     ir <- (colSums(sim$epi$incid, na.rm = TRUE))/sum((1 - mn$i.prev) *          mn$num) * 52 * 1e+05     ir.gc <- (colSums(sim$epi$incid.gc, na.rm = TRUE))/sum((1 -          mn$prev.gc) * mn$num) * 52 * 1e+05     ir.ct <- (colSums(sim$epi$incid.ct, na.rm = TRUE))/sum((1 -          mn$prev.ct) * mn$num) * 52 * 1e+05     ir.syph <- (colSums(sim$epi$incid.syph, na.rm = TRUE))/sum((1 -          mn$prev.syph) * mn$num) * 52 * 1e+05     ir.sti <- (colSums(sim$epi$incid.sti, na.rm = TRUE))/sum((1 -          mn$prev.sti) * mn$num) * 52 * 1e+05     vec.hiv.nia <- round(ir.base - unname(ir), 1)     df.hiv.pia[, i] <- vec.hiv.nia/ir.base     vec.gc.nia <- round(ir.gc.base - unname(ir.gc), 1)     df.gc.pia[, i] <- vec.gc.nia/ir.gc.base     vec.ct.nia <- round(ir.ct.base - unname(ir.ct), 1)     df.ct.pia[, i] <- vec.ct.nia/ir.ct.base     vec.syph.nia <- round(ir.syph.base - unname(ir.syph), 1)     df.syph.pia[, i] <- vec.syph.nia/ir.syph.base     vec.sti.nia <- round(ir.sti.base - unname(ir.sti), 1)     df.sti.pia[, i] <- vec.sti.nia/ir.sti.base     hiv.tests <- unname(colSums(tail(sim$epi$hivtests.nprep)))     gc.asympt.tests <- unname(colSums(tail(sim$epi$GCasympttests)))     ct.asympt.tests <- unname(colSums(tail(sim$epi$CTasympttests)))     syph.asympt.tests <- unname(colSums(tail(sim$epi$syphasympttests)))     df.hivonly.nnt[, i] <- (hiv.tests)/(incid.base - unname(colSums(sim$epi$incid)))     df.hiv.nnt[, i] <- (gc.asympt.tests + gc.asympt.tests + syph.asympt.tests)/(incid.base -          unname(colSums(sim$epi$incid)))     df.gc.nnt[, i] <- gc.asympt.tests/(incid.gc.base - unname(colSums(sim$epi$incid.gc)))     df.ct.nnt[, i] <- ct.asympt.tests/(incid.ct.base - unname(colSums(sim$epi$incid.ct)))     df.syph.nnt[, i] <- syph.asympt.tests/(incid.syph.base -          unname(colSums(sim$epi$incid.syph)))     df.sti.nnt[, i] <- syph.asympt.tests/(incid.syph.base - unname(colSums(sim$epi$incid.syph))) }",modeling,901742411544546e8,480
"names(df.hiv.pia) <- names(df.gc.pia) <- names(df.gc.nnt) <- names(df.ct.pia) <- names(df.sti.pia) <- names(df.hivonly.nnt) <- names(df.hiv.nnt) <- names(df.ct.nnt) <- names(df.syph.pia) <- names(df.syph.nnt) <- names(df.sti.nnt) <- c(""1"",      ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"")",data cleaning,901742411544546e8,480
head(df.hiv.pia),exploratory,901742411544546e8,480
head(df.gc.pia),exploratory,901742411544546e8,480
head(df.ct.pia),exploratory,901742411544546e8,480
head(df.syph.pia),exploratory,901742411544546e8,480
head(df.sti.pia),exploratory,901742411544546e8,480
head(df.hiv.nnt),exploratory,901742411544546e8,480
head(df.gc.nnt),exploratory,901742411544546e8,480
head(df.ct.nnt),exploratory,901742411544546e8,480
head(df.syph.nnt),exploratory,901742411544546e8,480
head(df.sti.nnt),exploratory,901742411544546e8,480
"pal <- wes_palette(""Zissou"")[c(1, 5)]",visualization,901742411544546e8,480
"par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1), oma = c(0, 0, 2,      0), mgp = c(3, 0.75, 0))",visualization,901742411544546e8,480
"boxplot(df.gc.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion NG Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.ct.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion CT Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion Syph Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion STI Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"title(""20% HR Cov (6 months), 10% Ann Cov"", outer = TRUE)",visualization,901742411544546e8,480
dev.off(),visualization,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
"suppressMessages(library(""EpiModelHIV""))",import,901742411544546e8,480
"library(""EpiModelHPC"")",import,901742411544546e8,480
"library(""dplyr"")",import,901742411544546e8,480
"source(""analysis/fx.R"")",import,901742411544546e8,480
"library(""wesanderson"")",import,901742411544546e8,480
"par(mfrow = c(1, 2), mar = c(3, 3, 2.5, 1), mgp = c(2, 1, 0))",visualization,901742411544546e8,480
"pal <- wesanderson::wes_palette(""Moonrise1"", n = 9, type = ""continuous"")",visualization,901742411544546e8,480
"load(""data/followup/sim.n3003.rda"")",import,901742411544546e8,480
sim.base <- sim,not sure,901742411544546e8,480
mn.base <- as.data.frame(sim.base),data cleaning,901742411544546e8,480
ir.base <- (sum(mn.base$incid)/sum((1 - mn.base$i.prev) * mn.base$num)) *      52 * 1e+05,data cleaning,901742411544546e8,480
ir.gc.base <- (sum(mn.base$incid.gc)/sum((1 - mn.base$prev.gc) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.ct.base <- (sum(mn.base$incid.ct)/sum((1 - mn.base$prev.ct) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.syph.base <- (sum(mn.base$incid.syph)/sum((1 - mn.base$prev.syph) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
ir.sti.base <- (sum(mn.base$incid.sti)/sum((1 - mn.base$prev.sti) *      mn.base$num)) * 52 * 1e+05,data cleaning,901742411544546e8,480
incid.base <- sum(mn.base$incid),data cleaning,901742411544546e8,480
incid.gc.base <- sum(mn.base$incid.gc),data cleaning,901742411544546e8,480
incid.ct.base <- sum(mn.base$incid.ct),data cleaning,901742411544546e8,480
incid.syph.base <- sum(mn.base$incid.syph),data cleaning,901742411544546e8,480
incid.sti.base <- sum(mn.base$incid.sti),data cleaning,901742411544546e8,480
"sims <- c(3442, 3443, 3003, 3444, 3445)",data cleaning,901742411544546e8,480
"df.hiv.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.hivonly.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.hiv.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.gc.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.gc.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.ct.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.ct.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.syph.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.syph.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.sti.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.sti.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"for (i in seq_along(sims)) {     load(list.files(""data/followup/"", pattern = as.character(sims[i]),          full.names = TRUE))     mn <- as.data.frame(sim)     ir <- (colSums(sim$epi$incid, na.rm = TRUE))/sum((1 - mn$i.prev) *          mn$num) * 52 * 1e+05     ir.gc <- (colSums(sim$epi$incid.gc, na.rm = TRUE))/sum((1 -          mn$prev.gc) * mn$num) * 52 * 1e+05     ir.ct <- (colSums(sim$epi$incid.ct, na.rm = TRUE))/sum((1 -          mn$prev.ct) * mn$num) * 52 * 1e+05     ir.syph <- (colSums(sim$epi$incid.syph, na.rm = TRUE))/sum((1 -          mn$prev.syph) * mn$num) * 52 * 1e+05     ir.sti <- (colSums(sim$epi$incid.sti, na.rm = TRUE))/sum((1 -          mn$prev.sti) * mn$num) * 52 * 1e+05     vec.hiv.nia <- round(ir.base - unname(ir), 1)     df.hiv.pia[, i] <- vec.hiv.nia/ir.base     vec.gc.nia <- round(ir.gc.base - unname(ir.gc), 1)     df.gc.pia[, i] <- vec.gc.nia/ir.gc.base     vec.ct.nia <- round(ir.ct.base - unname(ir.ct), 1)     df.ct.pia[, i] <- vec.ct.nia/ir.ct.base     vec.syph.nia <- round(ir.syph.base - unname(ir.syph), 1)     df.syph.pia[, i] <- vec.syph.nia/ir.syph.base     vec.sti.nia <- round(ir.sti.base - unname(ir.sti), 1)     df.sti.pia[, i] <- vec.sti.nia/ir.sti.base     hiv.tests <- unname(colSums(tail(sim$epi$hivtests.nprep)))     gc.asympt.tests <- unname(colSums(tail(sim$epi$GCasympttests)))     ct.asympt.tests <- unname(colSums(tail(sim$epi$CTasympttests)))     syph.asympt.tests <- unname(colSums(tail(sim$epi$syphasympttests)))     df.hivonly.nnt[, i] <- (hiv.tests)/(incid.base - unname(colSums(sim$epi$incid)))     df.hiv.nnt[, i] <- (gc.asympt.tests + gc.asympt.tests + syph.asympt.tests)/(incid.base -          unname(colSums(sim$epi$incid)))     df.gc.nnt[, i] <- gc.asympt.tests/(incid.gc.base - unname(colSums(sim$epi$incid.gc)))     df.ct.nnt[, i] <- ct.asympt.tests/(incid.ct.base - unname(colSums(sim$epi$incid.ct)))     df.syph.nnt[, i] <- syph.asympt.tests/(incid.syph.base -          unname(colSums(sim$epi$incid.syph)))     df.sti.nnt[, i] <- syph.asympt.tests/(incid.syph.base - unname(colSums(sim$epi$incid.syph))) }",modeling,901742411544546e8,480
"names(df.hiv.pia) <- names(df.gc.pia) <- names(df.gc.nnt) <- names(df.ct.pia) <- names(df.sti.pia) <- names(df.hivonly.nnt) <- names(df.hiv.nnt) <- names(df.ct.nnt) <- names(df.syph.pia) <- names(df.syph.nnt) <- names(df.sti.nnt) <- c(""1"",      ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"")",data cleaning,901742411544546e8,480
head(df.hiv.pia),exploratory,901742411544546e8,480
head(df.gc.pia),exploratory,901742411544546e8,480
head(df.ct.pia),exploratory,901742411544546e8,480
head(df.syph.pia),exploratory,901742411544546e8,480
head(df.sti.pia),exploratory,901742411544546e8,480
head(df.hiv.nnt),exploratory,901742411544546e8,480
head(df.gc.nnt),exploratory,901742411544546e8,480
head(df.ct.nnt),exploratory,901742411544546e8,480
head(df.syph.nnt),exploratory,901742411544546e8,480
head(df.sti.nnt),exploratory,901742411544546e8,480
"pal <- wes_palette(""Zissou"")[c(1, 5)]",visualization,901742411544546e8,480
"par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1), oma = c(0, 0, 2,      0), mgp = c(3, 0.75, 0))",visualization,901742411544546e8,480
"boxplot(df.gc.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion NG Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.ct.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion CT Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion Syph Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion STI Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"title(""20% HR Cov (6 months), 10% Ann Cov"", outer = TRUE)",visualization,901742411544546e8,480
dev.off(),visualization,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
"suppressMessages(library(""EpiModelHIV""))",import,901742411544546e8,480
"library(""EpiModelHPC"")",import,901742411544546e8,480
"library(""dplyr"")",import,901742411544546e8,480
"source(""analysis/fx.R"")",import,901742411544546e8,480
"library(""wesanderson"")",import,901742411544546e8,480
"par(mfrow = c(1, 2), mar = c(3, 3, 2.5, 1), mgp = c(2, 1, 0))",visualization,901742411544546e8,480
"pal <- wesanderson::wes_palette(""Moonrise1"", n = 9, type = ""continuous"")",visualization,901742411544546e8,480
"load(""data/followup/sim.n3003.rda"")",data cleaning,901742411544546e8,480
sim.base <- sim,not sure,901742411544546e8,480
mn.base <- as.data.frame(sim.base),data cleaning,901742411544546e8,480
ir.base <- (sum(mn.base$incid)/sum((1 - mn.base$i.prev) * mn.base$num)) *      52 * 1e+05,modeling,901742411544546e8,480
ir.gc.base <- (sum(mn.base$incid.gc)/sum((1 - mn.base$prev.gc) *      mn.base$num)) * 52 * 1e+05,modeling,901742411544546e8,480
ir.ct.base <- (sum(mn.base$incid.ct)/sum((1 - mn.base$prev.ct) *      mn.base$num)) * 52 * 1e+05,modeling,901742411544546e8,480
ir.syph.base <- (sum(mn.base$incid.syph)/sum((1 - mn.base$prev.syph) *      mn.base$num)) * 52 * 1e+05,modeling,901742411544546e8,480
ir.sti.base <- (sum(mn.base$incid.sti)/sum((1 - mn.base$prev.sti) *      mn.base$num)) * 52 * 1e+05,modeling,901742411544546e8,480
incid.base <- sum(mn.base$incid),modeling,901742411544546e8,480
incid.gc.base <- sum(mn.base$incid.gc),modeling,901742411544546e8,480
incid.ct.base <- sum(mn.base$incid.ct),modeling,901742411544546e8,480
incid.syph.base <- sum(mn.base$incid.syph),modeling,901742411544546e8,480
incid.sti.base <- sum(mn.base$incid.sti),modeling,901742411544546e8,480
"sims <- c(3446, 3447, 3003, 3448, 3449)",visualization,901742411544546e8,480
"df.hiv.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.hivonly.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.hiv.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.gc.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.gc.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.ct.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.ct.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.syph.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.syph.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.sti.pia <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"df.sti.nnt <- data.frame(rep(NA, 256))",setup,901742411544546e8,480
"for (i in seq_along(sims)) {     load(list.files(""data/followup/"", pattern = as.character(sims[i]),          full.names = TRUE))     mn <- as.data.frame(sim)     ir <- (colSums(sim$epi$incid, na.rm = TRUE))/sum((1 - mn$i.prev) *          mn$num) * 52 * 1e+05     ir.gc <- (colSums(sim$epi$incid.gc, na.rm = TRUE))/sum((1 -          mn$prev.gc) * mn$num) * 52 * 1e+05     ir.ct <- (colSums(sim$epi$incid.ct, na.rm = TRUE))/sum((1 -          mn$prev.ct) * mn$num) * 52 * 1e+05     ir.syph <- (colSums(sim$epi$incid.syph, na.rm = TRUE))/sum((1 -          mn$prev.syph) * mn$num) * 52 * 1e+05     ir.sti <- (colSums(sim$epi$incid.sti, na.rm = TRUE))/sum((1 -          mn$prev.sti) * mn$num) * 52 * 1e+05     vec.hiv.nia <- round(ir.base - unname(ir), 1)     df.hiv.pia[, i] <- vec.hiv.nia/ir.base     vec.gc.nia <- round(ir.gc.base - unname(ir.gc), 1)     df.gc.pia[, i] <- vec.gc.nia/ir.gc.base     vec.ct.nia <- round(ir.ct.base - unname(ir.ct), 1)     df.ct.pia[, i] <- vec.ct.nia/ir.ct.base     vec.syph.nia <- round(ir.syph.base - unname(ir.syph), 1)     df.syph.pia[, i] <- vec.syph.nia/ir.syph.base     vec.sti.nia <- round(ir.sti.base - unname(ir.sti), 1)     df.sti.pia[, i] <- vec.sti.nia/ir.sti.base     hiv.tests <- unname(colSums(tail(sim$epi$hivtests.nprep)))     gc.asympt.tests <- unname(colSums(tail(sim$epi$GCasympttests)))     ct.asympt.tests <- unname(colSums(tail(sim$epi$CTasympttests)))     syph.asympt.tests <- unname(colSums(tail(sim$epi$syphasympttests)))     df.hivonly.nnt[, i] <- (hiv.tests)/(incid.base - unname(colSums(sim$epi$incid)))     df.hiv.nnt[, i] <- (gc.asympt.tests + gc.asympt.tests + syph.asympt.tests)/(incid.base -          unname(colSums(sim$epi$incid)))     df.gc.nnt[, i] <- gc.asympt.tests/(incid.gc.base - unname(colSums(sim$epi$incid.gc)))     df.ct.nnt[, i] <- ct.asympt.tests/(incid.ct.base - unname(colSums(sim$epi$incid.ct)))     df.syph.nnt[, i] <- syph.asympt.tests/(incid.syph.base -          unname(colSums(sim$epi$incid.syph)))     df.sti.nnt[, i] <- syph.asympt.tests/(incid.syph.base - unname(colSums(sim$epi$incid.syph))) }",modeling,901742411544546e8,480
"names(df.hiv.pia) <- names(df.gc.pia) <- names(df.gc.nnt) <- names(df.ct.pia) <- names(df.sti.pia) <- names(df.hivonly.nnt) <- names(df.hiv.nnt) <- names(df.ct.nnt) <- names(df.syph.pia) <- names(df.syph.nnt) <- names(df.sti.nnt) <- c(""1"",      ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"")",data cleaning,901742411544546e8,480
head(df.hiv.pia),communication,901742411544546e8,480
head(df.gc.pia),communication,901742411544546e8,480
head(df.ct.pia),communication,901742411544546e8,480
head(df.syph.pia),communication,901742411544546e8,480
head(df.sti.pia),communication,901742411544546e8,480
head(df.hiv.nnt),communication,901742411544546e8,480
head(df.gc.nnt),communication,901742411544546e8,480
head(df.ct.nnt),communication,901742411544546e8,480
head(df.syph.nnt),communication,901742411544546e8,480
head(df.sti.nnt),communication,901742411544546e8,480
"pal <- wes_palette(""Zissou"")[c(1, 5)]",visualization,901742411544546e8,480
"par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1), oma = c(0, 0, 2,      0), mgp = c(3, 0.75, 0))",visualization,901742411544546e8,480
"boxplot(df.gc.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion NG Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.ct.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion CT Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion Syph Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"boxplot(df.syph.pia, outline = FALSE, medlwd = 1.1, col = c(rep(pal[1],      8), rep(pal[2], 4)), ylim = c(0, 1), main = ""PIA by Partner Cutoff"",      las = 2, xlab = ""Partner Cutoff"", ylab = ""Proportion STI Infections Averted"",      cex.axis = 0.7)",visualization,901742411544546e8,480
"title(""20% HR Cov (6 months), 10% Ann Cov"", outer = TRUE)",visualization,901742411544546e8,480
dev.off(),visualization,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
library(rgeos),import,901742411544546e8,480
library(raster),import,901742411544546e8,480
library(rgdal),import,901742411544546e8,480
"if (file.exists(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_coastline.Rdata"")) {     message(""nice, nothing to do here"") } else {     polys <- readShapePoly(""/Users/efuller/1/CNH/Data/WCspatial/GSHHS_shp/h/GSHHS_h_L1.shp"",          force_ring = T)     cut <- as.data.frame(list(x = c(-130, -116, -116, -130, -130),          y = c(50, 50, 32, 32, 50)))     B1 <- Polygon(cut)     Bs1 <- Polygons(list(B1), ID = ""west_coast"")     BSP <- SpatialPolygons(list(Bs1))     WC <- gIntersection(BSP, polys)     save(WC, file = ""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_coastline.Rdata"") }",data cleaning,901742411544546e8,480
"load(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_coastline.Rdata"")",import,901742411544546e8,480
"proj4string(WC) <- CRS(""+proj=longlat +datum=WGS84"")",visualization,901742411544546e8,480
"VMS <- readRDS(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/1_VMS_basic_clean.RDS"")",import,901742411544546e8,480
"coordinates(VMS) <- c(""Longitude"", ""Latitude"")",visualization,901742411544546e8,480
proj4string(VMS) <- proj4string(WC),visualization,901742411544546e8,480
"VMS@data$onland <- as.vector(gContains(WC, VMS, byid = TRUE))",data cleaning,901742411544546e8,480
"saveRDS(VMS, file = ""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_VMS_masked.RDS"")",export,901742411544546e8,480
library(knitr),import,901742411544546e8,480
"setwd(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/"")",setup,901742411544546e8,480
"setwd(""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/diffs"")",setup,901742411544546e8,480
"for (i in seq(1, (dim(mastersheet)[1]))) {     strain <- mastersheet[i, 1]     dir <- mastersheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"), quiet = TRUE)     print(dir)     print(strain) }",communication,901742411544546e8,480
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",not sure,901742411544546e8,480
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",not sure,901742411544546e8,480
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",not sure,901742411544546e8,480
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,901742411544546e8,480
"for (i in seq(1, (dim(test_master_sheet)[1]))) {     strain <- test_master_sheet[i, 1]     dir <- test_master_sheet[i, 2]     print(dir)     print(strain)     knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,          "".md"", sep = """"))     print(dir)     print(strain) }",communication,901742411544546e8,480
library(dplyr),import,901742411544546e8,480
library(tidyr),import,901742411544546e8,480
library(ggplot2),import,901742411544546e8,480
library(scatterplot3d),import,901742411544546e8,480
library(lme4),import,901742411544546e8,480
library(psych),import,901742411544546e8,480
library(scales),import,901742411544546e8,480
library(smacof),import,901742411544546e8,480
library(eba),import,901742411544546e8,480
rm(list = ls()),setup,901742411544546e8,480
dev.off(),visualization,901742411544546e8,480
"dd_adults = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-08-17_data_anonymized.csv"")[-1]",data cleaning,901742411544546e8,480
"dd_adults <- dd_adults %>% mutate(ageGroup = ""adults"")",modeling,901742411544546e8,480
glimpse(dd_adults),exploratory,901742411544546e8,480
"dd_children = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/children/kid-run-02_2016-03-11_data_anonymized.csv"")[-1]",data cleaning,901742411544546e8,480
"dd_children <- dd_children %>% mutate(ageGroup = ""children"")",data cleaning,901742411544546e8,480
glimpse(dd_children),exploratory,901742411544546e8,480
"dd_adults_us = dd_adults %>% filter(country == ""us"")",data cleaning,901742411544546e8,480
"dd_adults_india = dd_adults %>% filter(country == ""india"")",data cleaning,901742411544546e8,480
lowerLim <- 4.45,modeling,901742411544546e8,480
upperLim <- 5.55,modeling,901742411544546e8,480
dd_children_exact = dd_children %>% filter(ageCalc >= lowerLim &      ageCalc <= upperLim),data cleaning,901742411544546e8,480
dd_children_older = dd_children %>% filter(ageCalc >= upperLim &      ageCalc <= 8.5),data cleaning,901742411544546e8,480
dd_children = dd_children_exact,data cleaning,901742411544546e8,480
"dd <- full_join(dd_adults, dd_children) %>% mutate(ageGroup = factor(ageGroup))",data cleaning,901742411544546e8,480
glimpse(dd),exploratory,901742411544546e8,480
"dd_nostapler <- dd %>% filter(leftCharacter != ""stapler"" & rightCharacter !=      ""stapler"") %>% mutate(leftCharacter = factor(leftCharacter),      rightCharacter = factor(rightCharacter))",data cleaning,901742411544546e8,480
"dd_nobaby <- dd %>% filter(leftCharacter != ""baby"" & rightCharacter !=      ""baby"") %>% mutate(leftCharacter = factor(leftCharacter),      rightCharacter = factor(rightCharacter))",data cleaning,901742411544546e8,480
demo = dd %>% distinct(subid),data cleaning,901742411544546e8,480
demo %>% group_by(ageGroup) %>% summarise(n = length(subid)),exploratory,901742411544546e8,480
"dd %>% group_by(ageGroup, sequence) %>% distinct(subid) %>% summarise(n = length(subid))",exploratory,901742411544546e8,480
demo %>% group_by(ageGroup) %>% count(gender),exploratory,901742411544546e8,480
demo %>% group_by(ageGroup) %>% count(ethnicity),exploratory,901742411544546e8,480
"demo %>% group_by(ageGroup) %>% summarise(mean_age = mean(ageCalc,      na.rm = T), sd_age = sd(ageCalc, na.rm = T))",exploratory,901742411544546e8,480
"qplot(subset(demo, ageGroup == ""children"")$ageCalc, binwidth = 1/12,      xlab = ""\nAge (years)"", ylab = ""Count\n"") + scale_x_continuous(breaks = seq(4,      6, 0.25)) + theme(text = element_text(size = 20))",visualization,901742411544546e8,480
"demo %>% group_by(ageGroup, sequence) %>% summarise(mean_age = round(mean(ageCalc,      na.rm = T), 2), sd_age = round(sd(ageCalc, na.rm = T), 2))",exploratory,901742411544546e8,480
"makeDissimByPredicate <- function(selectPredicate, selectAgeGroup) {     tempDissim <- NULL     tempDissim <- dd %>% filter(predicate %in% selectPredicate &          ageGroup %in% selectAgeGroup) %>% mutate(character1 = array(),          character2 = array())     charsort = sort(levels(tempDissim$leftCharacter), decreasing = TRUE)     for (i in 1:length(charsort)) {         tempDissim <- tempDissim %>% mutate(character1 = ifelse(leftCharacter ==              charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),              as.character(character1)), character2 = ifelse(character1 ==              leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%              mutate(character1 = factor(character1), character2 = factor(character2))     }     tempDissim <- tempDissim %>% select(predicate, subid, character1,          character2, responseNum) %>% group_by(character1, character2) %>%          mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,          na.rm = TRUE)) %>% spread(character2, mean)     checkNoStapler <- count(dd) == count(dd_nostapler)     if (FALSE %in% checkNoStapler) {         tempDissim <- tempDissim %>% mutate(baby = NA, character1 = as.character(character1)) %>%              rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))     }     else {         tempDissim <- tempDissim %>% mutate(baby = NA, character1 = as.character(character1)) %>%              rbind(c(""robot"", rep(NA, 12))) %>% mutate(character1 = factor(character1))     }     tempDissim = tempDissim[, c(1, length(tempDissim), 2:(length(tempDissim) -          1))]     names = tempDissim[[1]]     tempDissim = tempDissim[-1]     rownames(tempDissim) = names     colnames(tempDissim) = names     if (FALSE %in% checkNoStapler) {         for (i in 1:9) {             for (j in (i + 1):10) {                 tempDissim[j, i] = tempDissim[i, j]             }         }     }     else {         for (i in 1:8) {             for (j in (i + 1):9) {                 tempDissim[j, i] = tempDissim[i, j]             }         }     }     tempDissim = as.dist(tempDissim)     return(tempDissim) }",data cleaning,901742411544546e8,480
"dissim_adults <- makeDissimByPredicate(selectPredicate = c(""thinking"",      ""feelings"", ""hunger""), selectAgeGroup = ""adults"")",data cleaning,901742411544546e8,480
hcb_adults = hclust(dissim_adults),visualization,901742411544546e8,480
hcb_adults,communication,901742411544546e8,480
"plot(hcb_adults, font.main = 1, main = ""Adults: All predicates (HCA)"",      sub = """", xlab = """", ylab = ""Height"", edgePar = list(col = 1:2,          lty = 2:3))",visualization,901742411544546e8,480
"dissim_adults_thinking <- makeDissimByPredicate(selectPredicate = ""thinking"",      selectAgeGroup = ""adults"")",data cleaning,901742411544546e8,480
hcb_adults_thinking = hclust(dissim_adults_thinking),visualization,901742411544546e8,480
hcb_adults_thinking,exploratory,901742411544546e8,480
"plot(hcb_adults_thinking, font.main = 1, main = ""Adults: Thinking (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_adults_feelings <- makeDissimByPredicate(selectPredicate = ""feelings"",      selectAgeGroup = ""adults"")",data cleaning,901742411544546e8,480
hcb_adults_feelings = hclust(dissim_adults_feelings),visualization,901742411544546e8,480
hcb_adults_feelings,exploratory,901742411544546e8,480
"plot(hcb_adults_feelings, font.main = 1, main = ""Adults: Feelings (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_adults_hunger <- makeDissimByPredicate(selectPredicate = ""hunger"",      selectAgeGroup = ""adults"")",data cleaning,901742411544546e8,480
hcb_adults_hunger = hclust(dissim_adults_hunger),visualization,901742411544546e8,480
hcb_adults_hunger,exploratory,901742411544546e8,480
"plot(hcb_adults_hunger, font.main = 1, main = ""Adults: Hunger (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_children <- makeDissimByPredicate(selectPredicate = c(""thinking"",      ""feelings"", ""hunger""), selectAgeGroup = ""children"")",data cleaning,901742411544546e8,480
hcb_children = hclust(dissim_children),visualization,901742411544546e8,480
hcb_children,visualization,901742411544546e8,480
"plot(hcb_children, font.main = 1, main = ""Children: All predicates (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_children_thinking <- makeDissimByPredicate(selectPredicate = ""thinking"",      selectAgeGroup = ""children"")",data cleaning,901742411544546e8,480
hcb_children_thinking = hclust(dissim_children_thinking),visualization,901742411544546e8,480
hcb_children_thinking,visualization,901742411544546e8,480
"plot(hcb_children_thinking, font.main = 1, main = ""Children: Thinking (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_children_feelings <- makeDissimByPredicate(selectPredicate = ""feelings"",      selectAgeGroup = ""children"")",data cleaning,901742411544546e8,480
hcb_children_feelings = hclust(dissim_children_feelings),visualization,901742411544546e8,480
hcb_children_feelings,visualization,901742411544546e8,480
"plot(hcb_children_feelings, font.main = 1, main = ""Children: Feelings (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"dissim_children_hunger <- makeDissimByPredicate(selectPredicate = ""hunger"",      selectAgeGroup = ""children"")",data cleaning,901742411544546e8,480
hcb_children_hunger = hclust(dissim_children_hunger),visualization,901742411544546e8,480
hcb_children_hunger,visualization,901742411544546e8,480
"plot(hcb_children_hunger, font.main = 1, main = ""Children: Hunger (HCA)"",      sub = """", xlab = """", ylab = ""Height"")",visualization,901742411544546e8,480
"library(""dplyr"")",setup,739760007942095e8,481
"library(""readr"")",modeling,739760007942095e8,481
"library(""devtools"")",setup,739760007942095e8,481
"library(""SummarizedExperiment"")",setup,739760007942095e8,481
"load_all(""../seqUtils/"")",import,739760007942095e8,481
"load_all(""analysis/housekeeping/"")",import,739760007942095e8,481
"sample_names = read.table(""analysis/data/sample_lists/SL1344_names_all.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = FALSE)[,      1]",import,739760007942095e8,481
"design_matrix = constructDesignMatrix_SL1344(sample_names) %>%      dplyr::filter(!(donor == ""fpdj"")) %>% tbl_df() %>% dplyr::filter(!(donor ==      ""fpdl"" & replicate == 2)) %>% dplyr::filter(!(donor == ""ougl"" &      replicate == 2)) %>% dplyr::filter(!(donor == ""mijn"")) %>%      dplyr::filter(!(donor == ""qaqx"")) %>% dplyr::mutate(replicate = ifelse(donor ==      ""babk"", 2, replicate)) %>% dplyr::arrange(donor, condition) %>%      as.data.frame()",data cleaning,739760007942095e8,481
"count_matrix = loadCounts(""processed/salmonella/featureCounts/"",      design_matrix$sample_id, sub_dir = FALSE, counts_suffix = "".featureCounts.txt"")",import,739760007942095e8,481
"transcript_data = tbl_df(readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.transcript_data.rds"")) %>%      dplyr::rename(gene_id = ensembl_gene_id, transcript_id = ensembl_transcript_id,          gene_name = external_gene_name, chr = chromosome_name)",import,739760007942095e8,481
"valid_chromosomes = c(""1"", ""10"", ""11"", ""12"", ""13"", ""14"", ""15"",      ""16"", ""17"", ""18"", ""19"", ""2"", ""20"", ""21"", ""22"", ""3"", ""4"",      ""5"", ""6"", ""7"", ""8"", ""9"", ""MT"", ""X"", ""Y"")",import,739760007942095e8,481
"valid_gene_biotypes = c(""lincRNA"", ""protein_coding"", ""IG_C_gene"",      ""IG_D_gene"", ""IG_J_gene"", ""IG_V_gene"", ""TR_C_gene"", ""TR_D_gene"",      ""TR_J_gene"", ""TR_V_gene"", ""3prime_overlapping_ncrna"", ""known_ncrna"",      ""processed_transcript"", ""antisense"", ""sense_intronic"", ""sense_overlapping"")",import,739760007942095e8,481
"filtered_tx_data = dplyr::filter(transcript_data, gene_biotype %in%      valid_gene_biotypes, chr %in% valid_chromosomes)",data cleaning,739760007942095e8,481
"length_df = dplyr::select(count_matrix, gene_id, length)",exploratory,739760007942095e8,481
library(plyr),data cleaning,828434385592118e8,482
"data <- read.table(""Analysis/Data/ZillowDataSetX"", sep = "","",      stringsAsFactors = FALSE)",import,828434385592118e8,482
"source(""Analysis/Data/ZillowAPICalls.R"")",setup,828434385592118e8,482
library(quickpsy),exploratory,135420956183225e8,483
library(circular),not sure,135420956183225e8,483
library(cowplot),not sure,135420956183225e8,483
library(Hmisc),modeling,135420956183225e8,483
library(synapser),import,135365942725912e8,484
synLogin(),setup,135365942725912e8,484
"source(""../../bin/nf1TumorHarmonization.R"")",import,135365942725912e8,484
"prefix = paste(lubridate::today(), ""bioBank_glioma_cNF_pnf"",      sep = ""-"")",communication,135365942725912e8,484
"biobank = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study,diagnosis  FROM syn13363852 WHERE ( ( \""assay\"" = 'rnaSeq' ) AND ( \""fileFormat\"" = 'sf' ) )"")$asDataFrame()",import,135365942725912e8,484
"cnf = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study,diagnosis FROM syn9702734 WHERE ( ( \""parentId\"" = 'syn5493036' ) AND ( \""assay\"" = 'rnaSeq' ) AND ( \""individualID\"" IS NOT NULL ) )"")$asDataFrame()",import,135365942725912e8,484
"pnf = synTableQuery(""SELECT id,specimenID,species,sex,age,tumorType,isCellLine,study,diagnosis FROM syn8518944 WHERE ( ( \""assay\"" = 'rnaSeq' ) ) and fileFormat='tsv' and isMultiSpecimen is NULL and name like '%gencode%'"")$asDataFrame()",import,135365942725912e8,484
"full.metadata <- rbind(dplyr::select(biobank, c(id, age, sex,      tumorType, isCellLine, study, diagnosis)), dplyr::select(gliomanf1,      c(id, age, sex, tumorType, isCellLine, study, diagnosis)),      dplyr::select(cnf, c(id, age, sex, tumorType, isCellLine,          study, diagnosis)), dplyr::select(pnf, c(id, age, sex,          tumorType, isCellLine, study, diagnosis))) %>% mutate(Sex = tolower(sex))",import,135365942725912e8,484
rownames(full.metadata) <- full.metadata$id,data cleaning,135365942725912e8,484
"fv.tab <- rbind(biobank, gliomanf1, cnf, pnf)",data cleaning,135365942725912e8,484
"tab.with.metadata <- plotMetadata(fv.tab, prefix)",data cleaning,135365942725912e8,484
library(biomaRt),visualization,135365942725912e8,484
"mart = useMart(""ensembl"", dataset = ""hsapiens_gene_ensembl"")",import,135365942725912e8,484
"my_chr <- c(1:22, ""X"", ""Y"")",not sure,135365942725912e8,484
"map <- getBM(attributes = c(""ensembl_transcript_id"", ""hgnc_symbol""),      mart = mart, filters = ""chromosome_name"", values = my_chr)",not sure,135365942725912e8,484
"bio.genes = do.call(""rbind"", lapply(biobank$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T, sep = ""\t"") %>% separate(Name,          into = c(""ensembl_transcript_id"", NA)) %>% inner_join(map,          by = ""ensembl_transcript_id"") %>% group_by(hgnc_symbol) %>%          summarize(totalCounts = sum(NumReads))     data.frame(dplyr::select(tab, ""totalCounts"", Symbol = ""hgnc_symbol""),          synId = rep(x, nrow(tab))) }))",not sure,135365942725912e8,484
Npermutation = 200,setup,91087490785867e9,485
"gli.genes = do.call(""rbind"", lapply(gliomanf1$id, function(x) {     f = synGet(x)$path     tab <- read.table(gzfile(f), header = F)     colnames(tab) <- c(""ensembl"", ""Symbol"", ""Counts"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,135365942725912e8,484
library(glmpath),import,91087490785867e9,485
"cnf.genes = do.call(""rbind"", lapply(cnf$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T)     names(tab) <- c(""Counts"", ""Symbol"")     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,135365942725912e8,484
b = Sys.time(),setup,91087490785867e9,485
"pnf.genes <- do.call(""rbind"", lapply(pnf$id, function(x) {     f = synGet(x)$path     tab <- read.table(f, header = T) %>% dplyr::select(Symbol = ""HugoSymbol"",          Counts = ""est_counts"", tpm)     tab <- tab %>% group_by(Symbol) %>% summarize(totalCounts = sum(Counts))     data.frame(tab, synId = rep(x, nrow(tab))) }))",data cleaning,135365942725912e8,484
"full.tab <- rbind(cnf.genes, gli.genes, bio.genes, pnf.genes)",data cleaning,135365942725912e8,484
"with.z = full.tab %>% group_by(synId) %>% mutate(zScore = (totalCounts -      mean(totalCounts + 0.001, na.rm = T))/sd(totalCounts, na.rm = T))",data cleaning,135365942725912e8,484
"this.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/analysis/2019-02-01/addInCellCulture.R""",data cleaning,135365942725912e8,484
"for (i in 1:Npermutation) {     print(i)     Multi_datainput_m$groupingvar = as.numeric(sample(Multi_datainput_m$groupingvar))     RF_selec = Multi_datainput_m     RF_selec = RF_selec[order(RF_selec$groupingvar), ]     xx = as.matrix(RF_selec %>% select(-groupingvar))     yy = as.numeric(RF_selec$groupingvar) - 1     pp <- rep(NA, length(yy))     num_per_class <- nrow(RF_selec)/2     for (k in 1:num_per_class) {         hold_out = c(k, k + num_per_class)         fit <- glmpath(x = xx[-hold_out, ], y = yy[-hold_out],              family = binomial, max.arclength = 1)         bestdex <- which.min(fit$bic)         if (bestdex == 1) {             bestdex <- 2         }         bestlambda <- fit$lambda[bestdex]         pred <- predict(fit, newx = xx[hold_out, ], s = bestlambda,              type = ""link"", mode = ""lambda"")         pp[hold_out] = pred     }     true_class <- sign(yy - 0.5)     pred_class <- sign(pp)     prediction_res = table(true_class, pred_class)     temp = classAgreement(prediction_res)     Acc_sampled = c(Acc_sampled, temp$diag) }",data cleaning,91087490785867e9,485
"analysis.script = ""https://raw.githubusercontent.com/sgosline/NEXUS/master/bin/nf1TumorHarmonization.R""",not sure,135365942725912e8,484
"print(""time to perform the analysis:"")",communication,91087490785867e9,485
"genes.with.meta = analyzeMetdataWithGenes(with.z, tab.with.metadata,      prefix)",not sure,135365942725912e8,484
print(Sys.time() - b),communication,91087490785867e9,485
"hist(Acc_sampled, breaks = c(0:20)/20)",visualization,91087490785867e9,485
"met.file = paste(prefix, ""metadataSummary.png"", sep = ""\\"")",modeling,135365942725912e8,484
"abline(v = 17/22, col = ""Red"")",visualization,91087490785867e9,485
"abline(v = 0.5, col = ""blue"")",visualization,91087490785867e9,485
Accuracyreal = 17/22,setup,91087490785867e9,485
"dataset.dir = ""syn18134640""",export,135365942725912e8,484
k <- sum(abs(Acc_sampled - 0.5) >= abs(Accuracyreal - 0.5)),evaluation,91087490785867e9,485
"gz1 = gzfile(paste(prefix, ""tidiedData.csv.gz"", sep = """"))",export,135365942725912e8,484
k <- sum(Acc_sampled >= Accuracyreal),evaluation,91087490785867e9,485
"print(zapsmall(binconf(k, length(Acc_sampled), method = ""exact"")))",communication,91087490785867e9,485
"print(zapsmall(binconf(k, length(Acc_sampled), method = ""all"")))",communication,91087490785867e9,485
"write.csv(genes.with.meta, gz1)",import,135365942725912e8,484
"save.image(file = ""thisisatest.rdata"")",export,91087490785867e9,485
"sid = synStore(File(paste(prefix, ""tidiedData.csv.gz"", sep = """"),      parent = dataset.dir), used = unique(genes.with.meta$id),      executed = c(this.script, analysis.script))",export,135365942725912e8,484
"source(""Rcode/testscode/multidimensional_analysis_prep_oneTW.R"")",setup,91087490785867e9,485
set.seed(66),setup,91087490785867e9,485
"sapply(paste(prefix, c(""genesByStudyTumor.png"", ""metadataSummary.png""),      sep = """"), function(x) synStore(File(x, parent = dataset.dir),      used = sid$properties$id, executed = c(this.script, analysis.script)))",not sure,135365942725912e8,484
"pc.files = doPcaPlots(with.z, tab.with.metadata, prefix)",not sure,135365942725912e8,484
RF_selec = Multi_datainput_m,not sure,91087490785867e9,485
"pca.dir = ""syn18134641""",visualization,135365942725912e8,484
xx = as.matrix(RF_selec %>% select(-groupingvar)),data cleaning,91087490785867e9,485
yy = as.numeric(RF_selec$groupingvar) - 1,data cleaning,91087490785867e9,485
"sapply(pc.files, function(x) synStore(File(x, parent = pca.dir),      used = sid$properties$id, executed = c(this.script, analysis.script)))",setup,135365942725912e8,484
"pp <- rep(NA, length(yy))",not sure,91087490785867e9,485
"ppsvm <- rep(NA, length(yy))",not sure,91087490785867e9,485
"sapply(pc.files, function(x) synStore(File(x, parent = pca.dir),      used = sid$properties$id, executed = c(this.script, analysis.script)))",not sure,135365942725912e8,484
"ppsvm_L <- rep(NA, length(yy))",not sure,91087490785867e9,485
"setwd(""~/Documents/CNH_to_github/cnh/Analysis/ses_network/FCM/input"")",setup,135365942725912e8,484
"temp <- read.csv(""Correlations between metiers based on revenues (symmetric matrix), adjusted years.csv"",      header = TRUE)",import,135365942725912e8,484
num <- 10,setup,135365942725912e8,484
"temp.new <- temp[1:num, -1]",data cleaning,135365942725912e8,484
"temp.new[1:3, 1:3]",data cleaning,135365942725912e8,484
"temp.new2 <- apply(temp.new, 2, as.numeric)",data cleaning,135365942725912e8,484
num_per_class <- nrow(RF_selec)/2,setup,91087490785867e9,485
before <- Sys.time(),setup,91087490785867e9,485
my.headers <- names(temp.new),data cleaning,135365942725912e8,484
"for (k in 1:num_per_class) {     hold_out = c(k, k + num_per_class)     fit <- glmpath::glmpath(x = xx[-hold_out, ], y = yy[-hold_out],          family = binomial, max.arclength = 1)     bestdex <- which.min(fit$bic)     if (bestdex == 1) {         bestdex <- 2     }     bestlambda <- fit$lambda[bestdex]     pred <- predict(fit, newx = xx[hold_out, ], s = bestlambda,          type = ""link"", mode = ""lambda"")     pp[hold_out] = pred     bestk = tune.svm3(RF_selec[-hold_out, ], as.data.frame(yy[-hold_out]))     best.parameters = bestk[[2]]     best.parameters_L = bestk[[11]]     svm.model <- svm(yy[-hold_out] ~ ., data = xx[-hold_out,          ], cost = best.parameters$cost, gamma = best.parameters$gamma,          kernel = bestk[[1]])     svm.model_L <- svm(yy[-hold_out] ~ ., data = xx[-hold_out,          ], cost = best.parameters_L$cost, gamma = best.parameters_L$gamma,          kernel = ""linear"")     ppsvm[hold_out] = predict(svm.model, xx[hold_out, ])     ppsvm_L[hold_out] = predict(svm.model_L, xx[hold_out, ]) }",modeling,91087490785867e9,485
print(Sys.getpid()),not sure,135365942725912e8,484
duration = Sys.time() - before,communication,91087490785867e9,485
library(dplyr),setup,135365942725912e8,484
library(cmapQuery),setup,135365942725912e8,484
library(magrittr),setup,135365942725912e8,484
library(glue),setup,135365942725912e8,484
library(homologene),setup,135365942725912e8,484
library(ggplot2),setup,52022566460073e9,486
"dir.create(""analysis/01.L1000Analysis/fwdWebRun/similar"", showWarnings = FALSE,      recursive = TRUE)",export,135365942725912e8,484
true_class <- sign(yy - 0.5),exploratory,91087490785867e9,485
library(grid),setup,52022566460073e9,486
"dir.create(""analysis/01.L1000Analysis/fwdWebRun/opposite"", showWarnings = FALSE,      recursive = TRUE)",export,135365942725912e8,484
library(gridExtra),setup,52022566460073e9,486
pred_class <- sign(pp),exploratory,91087490785867e9,485
"print(""loading data"")",communication,135365942725912e8,484
pred_classsvm <- sign(ppsvm),exploratory,91087490785867e9,485
library(RcppCNPy),setup,52022566460073e9,486
"load(""data/genesEdgerNoOutlier.rda"")",import,135365942725912e8,484
dataset = genesEdgerNoOutlier,data cleaning,135365942725912e8,484
"source(""powerAnalysis/lib.R"")",import,52022566460073e9,486
"groups = c(""E12_1_week_IP_vs_naive_adult_3_IP"", ""E12_2_week_IP_vs_naive_adult_3_IP"",      ""E12_3_day_IP_vs_naive_adult_3_IP"", ""naive_1_week_IP_vs_naive_adult_3_IP"",      ""naive_2_weeks_IP_vs_naive_adult_3_IP"", ""naive_3_days_IP_vs_naive_adult_3_IP"")",not sure,135365942725912e8,484
"groupShorthands = c(E12_1_week_IP_vs_naive_adult_3_IP = ""regen 1 week"",      E12_2_week_IP_vs_naive_adult_3_IP = ""regen 2 week"", E12_3_day_IP_vs_naive_adult_3_IP = ""regen 3 days"",      naive_1_week_IP_vs_naive_adult_3_IP = ""naive 1 week"", naive_2_weeks_IP_vs_naive_adult_3_IP = ""naive 2 weeks"",      naive_3_days_IP_vs_naive_adult_3_IP = ""naive 3 days"")",not sure,135365942725912e8,484
"kDesignPath <- ""powerAnalysis/data/simChrom_design.txt""",import,52022566460073e9,486
FDRLimit = 0.05,setup,135365942725912e8,484
"kRepGenePath <- ""powerAnalysis/data/representative_gene.txt""",import,52022566460073e9,486
"kSimYPath <- ""powerAnalysis/data/simChrom_y.txt""",import,52022566460073e9,486
"kSimBetaPath <- ""powerAnalysis/data/simChrom_b.npy""",import,52022566460073e9,486
"kGeneSpec <- c(coverage_quantile = 0.55, alt_pos_spacing = 25,      alt_pos_magnitude = 0.5, rep = 1)",exploratory,52022566460073e9,486
kGeneLength <- 3501,exploratory,52022566460073e9,486
kPromoterLength <- 1000,exploratory,52022566460073e9,486
"kGeneStructurePlotPath <- ""powerAnalysis/plot_repGene.pdf""",exploratory,52022566460073e9,486
rm(list = ls()),setup,755768664646894e8,487
"setwd(""/Users/ereznik/pancanmet_analysis/analysis/"")",setup,755768664646894e8,487
"source(""../analysis/plottingconventions.R"")",import,755768664646894e8,487
"source(""../import/useful_metimport.R"")",import,755768664646894e8,487
library(ggplot2),import,755768664646894e8,487
library(reshape2),import,755768664646894e8,487
"d = read.csv(""../results/diffabundance/DifferentialAbundanceSummary.csv"",      header = TRUE, row.names = 1)",import,755768664646894e8,487
"dsign = read.csv(""../results/diffabundance/DifferentialAbundance_SignedChanges.csv"",      header = TRUE, row.names = 1)",import,755768664646894e8,487
d$FracDiff = d$TotalDiff/d$notNA,data cleaning,755768664646894e8,487
numSites = 578,import,621893884381279e8,488
"path.alt = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/""",export,621893884381279e8,488
"path.null = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/""",export,621893884381279e8,488
"case.name = c(""4fullread.70ind.over"", ""4fullread.30ind.over"")",import,621893884381279e8,488
"done_list_alt = vector(""list"", length(case.name))",modeling,621893884381279e8,488
"done_list_null = vector(""list"", length(case.name))",modeling,621893884381279e8,488
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.alt, case.name[cc], "".output/pval."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[4])) {                   pval_list[IX] = as.numeric(dat[4])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_alt[[cc]] = done_res     save(""pval_list"", ""done_res"", file = paste0(path.alt, ""sum/pval."",          case.name[cc], "".Robj"")) }",evaluation,621893884381279e8,488
"for (cc in 1:length(case.name)) {     pval_list = rep(NA, numSites)     done_res = rep(NA, numSites)     IX = 1     for (i in 1:numSites) {         num_path = paste0(path.null, case.name[cc], "".output/pval."",              i, "".out"")         if (file.exists(num_path) == FALSE) {             done_res[IX] = FALSE         }         else {             if (file.info(num_path)$size == 0) {                 done_res[IX] = FALSE             }             else {                 dat = scan(num_path, what = """")                 if (!is.na(dat[4])) {                   pval_list[IX] = as.numeric(dat[4])                   done_res[IX] = TRUE                 }                 else {                   done_res[IX] = FALSE                 }             }         }         IX = IX + 1     }     done_list_null[[cc]] = done_res     save(""pval_list"", ""done_res"", file = paste0(path.null, ""sum/pval."",          case.name[cc], "".Robj"")) }",evaluation,621893884381279e8,488
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,283872447907925e7,489
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,283872447907925e7,489
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,283872447907925e7,489
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,283872447907925e7,489
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,283872447907925e7,489
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,283872447907925e7,489
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,283872447907925e7,489
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,283872447907925e7,489
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,283872447907925e7,489
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,283872447907925e7,489
rm(list = ls()),not sure,283872447907925e7,489
gc(),not sure,283872447907925e7,489
set.seed(231),communication,283872447907925e7,489
ncores = 40,setup,283872447907925e7,489
"source(""butler_nickerson_analysis.R"")",import,283872447907925e7,489
"source(""butler_tables.R"")",import,283872447907925e7,489
"source(""~/selection/code/lib/readlib.R"")",import,283872447907925e7,489
version = NA,import,283872447907925e7,489
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,760680266888812e8,490
siteSize = 2048,setup,760680266888812e8,490
"treatment = ""Copper""",setup,760680266888812e8,490
null = FALSE,setup,760680266888812e8,490
"strand = ""both""",setup,760680266888812e8,490
window.size = 300,setup,760680266888812e8,490
numSam = 6,setup,760680266888812e8,490
"library(""DESeq"")",import,760680266888812e8,490
"library(""DESeq2"")",import,760680266888812e8,490
setwd(wd.path),setup,760680266888812e8,490
"if (!null) {     dir.name = paste0(treatment, ""."", siteSize, ""."", strand,          ""."", window.size, "".alt"") } else {     dir.name = paste0(treatment, ""."", siteSize, ""."", strand,          ""."", window.size, "".null"") }",setup,760680266888812e8,490
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",setup,760680266888812e8,490
numSites.list = scan(path),import,760680266888812e8,490
"input.dir.path = paste0(wd.path, dir.name, "".run/"")",setup,760680266888812e8,490
numC = siteSize%/%window.size,setup,760680266888812e8,490
"deseq.data = matrix(data = NA, nc = numSam, nr = sum(numSites.list) *      numC)",import,760680266888812e8,490
st.chr.ix = NULL,import,760680266888812e8,490
en.chr.ix = NULL,not sure,760680266888812e8,490
st.chr.ix[1] = 1,not sure,760680266888812e8,490
"err.check = rep(NA, 22)",not sure,760680266888812e8,490
"for (chr in 1:22) {     numSites = numSites.list[chr]     numRow = numSites * numC     en.chr.ix[chr] = st.chr.ix[chr] + numRow - 1     deseq.data.each = read.table(paste0(input.dir.path, ""data."",          chr, "".txt""))     if (dim(deseq.data.each)[1] == numRow) {         err.check[chr] = FALSE         deseq.data[st.chr.ix[chr]:en.chr.ix[chr], ] = as.matrix(deseq.data.each)     }     st.chr.ix[chr + 1] = en.chr.ix[chr] + 1 }",data cleaning,760680266888812e8,490
"condition = factor(c(rep(""treated"", numSam/2), rep(""untreated"",      numSam/2)))",modeling,760680266888812e8,490
"deseq.full.data = newCountDataSet(deseq.data, condition)",modeling,760680266888812e8,490
"cut.val = c(60, 30, 20, 10, 0)",visualization,760680266888812e8,490
"for (cc in 1:length(cut.val)) {     countData = counts(deseq.full.data)     colData <- data.frame(row.names = c(""T1"", ""T2"", ""T3"", ""C1"",          ""C2"", ""C3""), t = c(""T"", ""T"", ""T"", ""C"", ""C"", ""C""), r = as.factor(c(1,          2, 3, 1, 2, 3)))     rsum = rowSums(countData)     filter.cut = cut.val[cc]     use = (rsum > filter.cut)     countData.filtered = countData[use, ]     ddsTvC <- DESeqDataSetFromMatrix(countData = countData.filtered,          colData = colData, design = ~t)     dds <- DESeq(ddsTvC)     res <- results(dds)     pval.vec = rep(NA, length(use))     pval.vec[use == TRUE] = res$pvalue     pval.filtered = matrix(pval.vec, ncol = numC, byrow = T)     min.pval = apply(pval.filtered, 1, min, na.rm = TRUE)     min.pval[is.infinite(min.pval)] = NA     output.dir.path = paste0(input.dir.path, ""output/"")     if (!file.exists(output.dir.path)) {         dir.create(output.dir.path)     }     write.table(min.pval, file = paste0(output.dir.path, ""/DESeq2.noC.min.pval."",          filter.cut, "".txt""), quote = FALSE, row.names = FALSE,          col.names = FALSE)     write.table(pval.filtered, file = paste0(output.dir.path,          ""/DESeq2.noC.all.pval."", filter.cut, "".txt""), quote = FALSE,          row.names = FALSE, col.names = FALSE) }",evaluation,760680266888812e8,490
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,760680266888812e8,490
siteSize = 2048,setup,760680266888812e8,490
"treatment = ""Copper""",setup,760680266888812e8,490
null = TRUE,setup,760680266888812e8,490
"strand = ""both""",setup,760680266888812e8,490
window.size = 300,setup,760680266888812e8,490
numSam = 6,setup,760680266888812e8,490
setwd(wd.path),setup,760680266888812e8,490
"if (!null) {     dir.name = paste0(treatment, ""."", siteSize, ""."", strand,          ""."", window.size, "".alt"") } else {     dir.name = paste0(treatment, ""."", siteSize, ""."", strand,          ""."", window.size, "".null"") }",setup,760680266888812e8,490
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",setup,760680266888812e8,490
numSites.list = scan(path),import,760680266888812e8,490
"input.dir.path = paste0(wd.path, dir.name, "".run/"")",import,760680266888812e8,490
numC = siteSize%/%window.size,setup,760680266888812e8,490
"deseq.data = matrix(data = NA, nc = numSam, nr = sum(numSites.list) *      numC)",import,760680266888812e8,490
st.chr.ix = NULL,not sure,760680266888812e8,490
en.chr.ix = NULL,not sure,760680266888812e8,490
st.chr.ix[1] = 1,not sure,760680266888812e8,490
"err.check = rep(NA, 22)",not sure,760680266888812e8,490
"for (chr in 1:22) {     numSites = numSites.list[chr]     numRow = numSites * numC     en.chr.ix[chr] = st.chr.ix[chr] + numRow - 1     deseq.data.each = read.table(paste0(input.dir.path, ""data."",          chr, "".txt""))     if (dim(deseq.data.each)[1] == numRow) {         err.check[chr] = FALSE         deseq.data[st.chr.ix[chr]:en.chr.ix[chr], ] = as.matrix(deseq.data.each)     }     st.chr.ix[chr + 1] = en.chr.ix[chr] + 1 }",data cleaning,760680266888812e8,490
"condition = factor(c(rep(""treated"", numSam/2), rep(""untreated"",      numSam/2)))",data cleaning,760680266888812e8,490
"deseq.full.data = newCountDataSet(deseq.data, condition)",data cleaning,760680266888812e8,490
"cut.val = c(60, 30, 20, 10, 0)",visualization,760680266888812e8,490
"for (cc in 1:length(cut.val)) {     countData = counts(deseq.full.data)     colData <- data.frame(row.names = c(""T1"", ""T2"", ""T3"", ""C1"",          ""C2"", ""C3""), t = c(""T"", ""T"", ""T"", ""C"", ""C"", ""C""), r = as.factor(c(1,          2, 3, 1, 2, 3)))     rsum = rowSums(countData)     filter.cut = cut.val[cc]     use = (rsum > filter.cut)     countData.filtered = countData[use, ]     ddsTvC <- DESeqDataSetFromMatrix(countData = countData.filtered,          colData = colData, design = ~t)     dds <- DESeq(ddsTvC)     res <- results(dds)     pval.vec = rep(NA, length(use))     pval.vec[use == TRUE] = res$pvalue     pval.filtered = matrix(pval.vec, ncol = numC, byrow = T)     min.pval = apply(pval.filtered, 1, min, na.rm = TRUE)     min.pval[is.infinite(min.pval)] = NA     output.dir.path = paste0(input.dir.path, ""output/"")     if (!file.exists(output.dir.path)) {         dir.create(output.dir.path)     }     write.table(min.pval, file = paste0(output.dir.path, ""/DESeq2.noC.min.pval."",          filter.cut, "".txt""), quote = FALSE, row.names = FALSE,          col.names = FALSE)     write.table(pval.filtered, file = paste0(output.dir.path,          ""/DESeq2.noC.all.pval."", filter.cut, "".txt""), quote = FALSE,          row.names = FALSE, col.names = FALSE) }",evaluation,760680266888812e8,490
search(),setup,760680266888812e8,490
library(igraph),import,760680266888812e8,490
library(rgexf),import,760680266888812e8,490
"writing.dir <- c(""/home/morr9/analysis"")",setup,760680266888812e8,490
"wd <- c(""/home/morr9/sdal/projects/mann/git/book_2/multidisciplinary-diffusion-model-experiments/results/simulations"")",setup,760680266888812e8,490
setwd(wd),setup,760680266888812e8,490
"batch.dir.list <- c(""02-lens_batch_2016-02-16_00-30-30"", ""02-lens_batch_2016-02-16_08-22-22"",      ""02-lens_batch_2016-02-17_21-20-02"", ""02-lens_batch_2016-02-18_21-01-43"",      ""02-lens_batch_2016-02-19_11-51-15"", ""02-lens_batch_2016-02-19_19-37-18"",      ""02-lens_batch_2016-02-22_00-21-05"", ""02-lens_batch_2016-02-22_08-01-36"",      ""02-lens_batch_2016-02-23_09-16-38"", ""02-lens_batch_2016-02-23_19-25-08"",      ""02-lens_batch_2016-02-24_09-36-21"", ""02-lens_batch_2016-02-24_20-44-42"",      ""02-lens_batch_2016-02-25_14-44-10"", ""02-lens_batch_2016-02-26_14-16-36"",      ""02-lens_batch_2016-02-28_12-46-18"", ""02-lens_batch_2016-02-28_23-26-30"",      ""02-lens_batch_2016-02-29_12-18-15"", ""02-lens_batch_2016-03-01_06-48-37"",      ""02-lens_batch_2016-03-01_06-48-44"", ""02-lens_batch_2016-03-02_11-35-21"",      ""02-lens_batch_2016-03-02_11-36-09"", ""02-lens_batch_2016-03-03_11-05-15"")",setup,760680266888812e8,490
"wn.list <- c(5, 51:59, 6, 61:69, 7, 71:79, 8)",setup,760680266888812e8,490
"master.matrix <- matrix(rep(NA, (length(btwn.list) * length(wn.list))),      nrow = length(btwn.list), ncol = length(wn.list))",setup,760680266888812e8,490
"for (i in 1:length(btwn.list)) {     for (j in 1:length(wn.list)) {         rm(catch.across.runs)         catch.across.runs <- rep(NA, length(batch.dir.list))         for (k in 1:length(batch.dir.list)) {             setwd(wd)             if (file.exists(paste(batch.dir.list[k], ""/a250_bm-0."",                  btwn.list[i], ""_bs0.1_wm0."", wn.list[j], ""_ws0.2_c0.25_r000/output"",                  sep = """"))) {                 setwd(paste(batch.dir.list[k], ""/a250_bm-0."",                    btwn.list[i], ""_bs0.1_wm0."", wn.list[j], ""_ws0.2_c0.25_r000/output"",                    sep = """"))                 if (file.exists(""network_of_agents.pout"")) {                   d <- read.csv(""./network_of_agents.pout"", header = F)                   if (tail(d$V1, n = 1) == 99 & tail(d$V2, n = 1) ==                      249) {                     mean.for.d <- apply(d[, 4:13], 1, mean)                     sd.for.d <- apply(d[, 4:13], 1, sd)                     min.for.d <- apply(d[, 4:13], 1, min)                     max.for.d <- apply(d[, 4:13], 1, max)                     mean.for.d.neg <- apply(d[, 4:8], 1, mean)                     mean.for.d.pos <- apply(d[, 9:13], 1, mean)                     d <- cbind(d, mean.for.d, mean.for.d.neg,                        mean.for.d.pos, sd.for.d, min.for.d, max.for.d)                     d$diff.means.pos.neg <- d$mean.for.d.pos -                        d$mean.for.d.neg                     d$node.name <- NA                     d$node.name <- paste(""A"", d$V2, sep = """")                     for (v in 99:99) {                       assign(paste(""d.t."", v, sep = """"), d[d$V1 ==                          v, ])                       e.list.in <- read.table(gzfile(""edge_list.gz""))                       e.list.use <- e.list.in[, 1:2]                       gg <- graph.data.frame(e.list.use, directed = FALSE)                       V(gg)$state <- get(paste(""d.t."", v, sep = """"))$diff.means.pos.neg[match(V(gg)$name,                          get(paste(""d.t."", v, sep = """"))$node.name)]                       write(c(date(), """", c(i, """", j, """", k),                          ""ERR: NONE""), file = paste(writing.dir,                          ""AnalysisTracker.txt"", sep = """"), ncolumns = 8,                          append = TRUE)                       catch.across.runs[k] <- assortativity(gg,                          V(gg)$state, directed = FALSE)                     }                   }                   else {                     write(c(date(), """", c(i, """", j, """", k), ""ERR: NO 3""),                        file = paste(writing.dir, ""AnalysisTracker.txt"",                          sep = """"), ncolumns = 8, append = TRUE)                   }                 }                 else {                   write(c(date(), """", c(i, """", j, """", k), ""ERR: NO 2""),                      file = paste(writing.dir, ""AnalysisTracker.txt"",                        sep = """"), ncolumns = 8, append = TRUE)                 }             }             else {                 write(c(date(), """", c(i, """", j, """", k), ""ERR: NO 1""),                    file = paste(writing.dir, ""AnalysisTracker.txt"",                      sep = """"), ncolumns = 8, append = TRUE)             }         }         master.matrix[i, j] <- mean(catch.across.runs, na.rm = TRUE)     } }",import,760680266888812e8,490
setwd(writing.dir),import,760680266888812e8,490
save.image(),setup,760680266888812e8,490
save.image(),visualization,760680266888812e8,490
search(),setup,760680266888812e8,490
"source(""./R/FunctionsForRWLAnalysis.R"")",setup,760680266888812e8,490
"analysis_opts <- yaml.load_file(""./analysis_options.yaml"")",setup,760680266888812e8,490
bin_width <- analysis_opts$bin_width,setup,760680266888812e8,490
good_phon <- analysis_opts$targets_s1$phono,setup,760680266888812e8,490
good_semy <- analysis_opts$targets_s1$semantic,setup,760680266888812e8,490
"s1_looks <- read_csv(""./data/study1/02_looking_data.csv"")",import,760680266888812e8,490
"s1_infos <- read_csv(""./data/study1/01_test_scores.csv"") %>%      rename(Subj = ParticipantID) %>% select(-Income, -medu)",import,760680266888812e8,490
s1_looks %>% select(Target) %>% distinct %>% unlist(use.names = FALSE) %>%      sort,data cleaning,760680266888812e8,490
s1_looks %>% select(Target) %>% distinct %>% nrow,data cleaning,760680266888812e8,490
length(good_phon),exploratory,760680266888812e8,490
length(good_semy),exploratory,760680266888812e8,490
"s1_infos %>% mutate(EVTThirds = cut_by_thirds(EVT_GSV)) %>% select(-contains(""PPVT"",      -EVT_raw)) %>% gather(Variable, value, -Subj, -AAE, -female,      -EVTThirds) %>% group_by(EVTThirds, Variable) %>% summarise(n = n(),      mean = mean(value), min = min(value), max = max(value))",data cleaning,760680266888812e8,490
"AggregateLooks(s1_looks, 1 ~ GazeByImageAOI)",data cleaning,760680266888812e8,490
"n_trials <- s1_looks %>% select(Subj, Block, TrialNo) %>% distinct %>%      nrow",data cleaning,760680266888812e8,490
"bad_trials <- find_mistracked_trials(s1_looks, analysis_opts$excessive_na)",data cleaning,760680266888812e8,490
nrow(bad_trials)/n_trials,exploratory,760680266888812e8,490
n_blank <- bad_trials %>% filter(PropNA == 1) %>% nrow,data cleaning,760680266888812e8,490
n_blank/n_trials,data cleaning,760680266888812e8,490
"missing_by_kid <- AggregateLooks(s1_looks, Subj ~ GazeByImageAOI)",data cleaning,760680266888812e8,490
"d_missing <- inner_join(missing_by_kid, s1_infos)",data cleaning,760680266888812e8,490
"summary(lm(PropNA ~ Age, d_missing))",exploratory,760680266888812e8,490
"summary(lm(PropNA ~ EVT_GSV, d_missing))",exploratory,760680266888812e8,490
"trial_outcomes <- s1_looks %>% AggregateLooks(Subj + Block +      TrialNo ~ GazeByImageAOI) %>% mutate(Keeper = PropNA < analysis_opts$excessive_na) %>%      group_by(Subj) %>% summarise(nKeeper = sum(Keeper), nDropper = sum(!Keeper))",data cleaning,760680266888812e8,490
"d_outcomes <- inner_join(trial_outcomes, s1_infos)",data cleaning,760680266888812e8,490
"summary(glm(cbind(nKeeper, nDropper) ~ Age, family = binomial,      d_outcomes))",modeling,760680266888812e8,490
"summary(glm(cbind(nKeeper, nDropper) ~ EVT_GSV, family = binomial,      d_outcomes))",modeling,760680266888812e8,490
"s1_binned <- s1_looks %>% standard_model_pipeline(bins = bin_width,      draw_ot = TRUE) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
s1_trimmed_looks <- s1_looks %>% anti_join(bad_trials),data cleaning,760680266888812e8,490
"s1_trimmed <- s1_trimmed_looks %>% standard_model_pipeline(bins = bin_width,      draw_ot = TRUE) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
"write_csv(s1_trimmed, ""./data/study1/modelling/01_gca.csv"")",export,760680266888812e8,490
"s1_compared <- bind_rows(mutate(s1_trimmed, Dataset = ""Trimmed""),      mutate(s1_binned, Dataset = ""Not Trimmed""))",data cleaning,760680266888812e8,490
"p <- ggplot(s1_compared) + aes(x = Time, y = Proportion, color = Dataset) +      stat_summary(fun.data = mean_se, geom = ""pointrange"") + facet_grid(. ~      EVTBreakThirds) + labs(title = ""Trimming trials with 50%+ missing looks does nothing (S1, by EVT)"")",visualization,760680266888812e8,490
p,visualization,760680266888812e8,490
"ggsave(""./figs/s1_props_with_trial_trimming.png"", p, width = 7,      height = 6)",export,760680266888812e8,490
"s1_biases <- compute_bias_growth_curves(looks = s1_looks, infos = s1_infos,      bins = bin_width, phon_set = good_phon, semy_set = good_semy)",visualization,760680266888812e8,490
"s1_biases_trimmed <- compute_bias_growth_curves(looks = s1_trimmed_looks,      infos = s1_infos, bins = bin_width, phon_set = good_phon,      semy_set = good_semy)",visualization,760680266888812e8,490
"s1_compare_bias <- bind_rows(mutate(s1_biases_trimmed$fourway_bias,      Trim = TRUE), mutate(s1_biases_trimmed$binary_bias, Trim = TRUE),      mutate(s1_biases$fourway_bias, Trim = FALSE), mutate(s1_biases$binary_bias,          Trim = FALSE))",visualization,760680266888812e8,490
"s1_compare_bias %>% group_by(BiasSet, Trim, Bias) %>% summarise(min(Trials),      mean(Trials), max(Trials))",visualization,760680266888812e8,490
"s1_compare_bias %>% group_by(BiasSet, Trim, Bias) %>% summarise(mean(Trials),      min(Trials), max(Trials)) %>% ungroup",visualization,760680266888812e8,490
"s1_biases_trimmed$binary_bias %>% write_csv(""./data/study1/modelling/02_binary_bias.csv"")",export,760680266888812e8,490
"s1_biases_trimmed$fourway_bias %>% write_csv(""./data/study1/modelling/02_fourway_bias.csv"")",export,760680266888812e8,490
max_phon_time <- analysis_opts$convergence$s1$phono,evaluation,760680266888812e8,490
"count_targets <- . %>% select(Block, Target) %>% distinct %>%      count(Block)",evaluation,760680266888812e8,490
"s1_not_to_target <- s1_looks %>% filter(Bias %in% c(""SemanticFoil"",      ""PhonologicalFoil"", NA, ""Unrelated""))",evaluation,760680266888812e8,490
s1_phon_looks <- s1_not_to_target %>% filter(Target %in% good_phon),evaluation,760680266888812e8,490
trial_counts <- count_targets(s1_phon_looks),evaluation,760680266888812e8,490
trial_counts,evaluation,760680266888812e8,490
"stopifnot(trial_counts$n == c(21, 21))",not sure,760680266888812e8,490
s1_semy_looks <- s1_not_to_target %>% filter(Target %in% good_semy),data cleaning,760680266888812e8,490
trial_counts <- count_targets(s1_semy_looks),data cleaning,760680266888812e8,490
trial_counts,communication,760680266888812e8,490
"stopifnot(trial_counts$n == c(16, 16))",not sure,760680266888812e8,490
"s1_semy <- s1_semy_looks %>% standard_model_pipeline(bins = bin_width,      flip = TRUE) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
"s1_phon <- s1_phon_looks %>% standard_model_pipeline(bins = bin_width,      flip = TRUE, max_bin_time = max_phon_time) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
"s1_semy_trimmed <- s1_semy_looks %>% anti_join(bad_trials) %>%      standard_model_pipeline(bins = bin_width, flip = TRUE) %>%      make_model_data(s1_infos)",modeling,760680266888812e8,490
library(dplyr),import,242292492650449e8,491
"s1_phon_trimmed <- s1_phon_looks %>% anti_join(bad_trials) %>%      standard_model_pipeline(bins = bin_width, flip = TRUE, max_bin_time = max_phon_time,          draw = TRUE) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
"s1_phon_for_plotting <- s1_phon_looks %>% standard_model_pipeline(bins = bin_width,      flip = TRUE) %>% make_model_data(s1_infos)",modeling,760680266888812e8,490
"s1_phon_for_plotting_trimmed <- s1_phon_looks %>% anti_join(bad_trials) %>%      standard_model_pipeline(bins = bin_width, flip = TRUE) %>%      make_model_data(s1_infos)",modeling,760680266888812e8,490
"write_csv(s1_phon_trimmed, ""./data/study1/modelling/03_logistic_phon.csv"")",export,760680266888812e8,490
"write_csv(s1_semy_trimmed, ""./data/study1/modelling/03_logistic_semy.csv"")",export,760680266888812e8,490
library(ggplot2),setup,242292492650449e8,491
"write_csv(s1_phon_for_plotting_trimmed, ""./data/study1/modelling/03_logistic_phon_whole_window.csv"")",export,760680266888812e8,490
library(tidyr),setup,242292492650449e8,491
"s1_phon_to_phon <- s1_phon %>% mutate(elog = empirical_logit(ToTarget,      ToPhonological), Comparison = ""Target vs Phon"")",modeling,760680266888812e8,490
"s1_phon_to_unre <- s1_phon %>% mutate(elog = empirical_logit(ToTarget,      ToUnrelated), Comparison = ""Target vs Unre"")",modeling,760680266888812e8,490
"tickets <- readRDS(""processedData/catch/1_cleaningData/tickets.RDS"")",import,242292492650449e8,491
"dscrp <- read.csv(""processedData/catch/3_exploreBuildwebs/ref_tables/metier_descrp.csv"",      stringsAsFactors = FALSE)",import,242292492650449e8,491
"phon_compare_curves <- bind_rows(s1_phon_to_phon, s1_phon_to_unre) %>%      mutate(Trials = ""All"")",data cleaning,760680266888812e8,490
"s1_semy_to_semy <- s1_semy %>% mutate(elog = empirical_logit(ToTarget,      ToSemantic), Comparison = ""Target vs Semy"")",modeling,760680266888812e8,490
"s1_semy_to_unre <- s1_semy %>% mutate(elog = empirical_logit(ToTarget,      ToUnrelated), Comparison = ""Target vs Unre"")",modeling,760680266888812e8,490
"semy_compare_curves <- bind_rows(s1_semy_to_semy, s1_semy_to_unre) %>%      mutate(Trials = ""All"")",data cleaning,760680266888812e8,490
"ggplot(phon_compare_curves) + aes(x = Time, y = elog, color = Comparison) +      stat_summary(fun.data = mean_se, geom = ""pointrange"")",visualization,760680266888812e8,490
last_plot() %+% semy_compare_curves,visualization,760680266888812e8,490
"dscrp$name <- paste(dscrp$Major_species, dscrp$Major_gear)",data cleaning,242292492650449e8,491
"s1_phon_to_phon <- s1_phon_trimmed %>% mutate(elog = empirical_logit(ToTarget,      ToPhonological), Comparison = ""Target vs Phon"")",visualization,760680266888812e8,490
"dscrp <- rename(dscrp, metier.2010 = Metier)",data cleaning,242292492650449e8,491
"s1_phon_to_unre <- s1_phon_trimmed %>% mutate(elog = empirical_logit(ToTarget,      ToUnrelated), Comparison = ""Target vs Unre"")",modeling,760680266888812e8,490
"phon_compare_curves2 <- bind_rows(s1_phon_to_phon, s1_phon_to_unre) %>%      mutate(Trials = ""Trimmed"")",data cleaning,760680266888812e8,490
"s1_semy_to_semy <- s1_semy_trimmed %>% mutate(elog = empirical_logit(ToTarget,      ToSemantic), Comparison = ""Target vs Semy"")",modeling,760680266888812e8,490
"tickets <- left_join(tickets, dscrp[, c(""metier.2010"", ""name"")])",data cleaning,242292492650449e8,491
"s1_semy_to_unre <- s1_semy_trimmed %>% mutate(elog = empirical_logit(ToTarget,      ToUnrelated), Comparison = ""Target vs Unre"")",modeling,760680266888812e8,490
"tickets$tdate <- as.Date(tickets$tdate, format = ""%d-%b-%y"")",data cleaning,242292492650449e8,491
"tickets$doy <- as.numeric(format(tickets$tdate, ""%j""))",data cleaning,242292492650449e8,491
"semy_compare_curves2 <- bind_rows(s1_semy_to_semy, s1_semy_to_unre) %>%      mutate(Trials = ""Trimmed"")",data cleaning,760680266888812e8,490
"ggplot(phon_compare_curves2) + aes(x = Time, y = elog, color = Comparison) +      stat_summary(fun.data = mean_se, geom = ""pointrange"")",visualization,760680266888812e8,490
last_plot() %+% semy_compare_curves2,visualization,760680266888812e8,490
"trimmed_compare <- bind_rows(phon_compare_curves, phon_compare_curves2)",visualization,760680266888812e8,490
"ggplot(trimmed_compare) + aes(x = Time, y = elog, color = Comparison,      linetype = Trials) + stat_summary(fun.data = mean_se, geom = ""pointrange"") +      stat_summary(fun.y = mean, geom = ""line"")",visualization,760680266888812e8,490
"filepath2 <- ""/Data/spotprices.csv""",setup,760680266888812e8,490
"path <- c(getwd(), filepath2)",setup,760680266888812e8,490
"path <- paste(path, collapse = """")",setup,760680266888812e8,490
"spotprices <- read.csv(path, header = TRUE, sep = "","", stringsAsFactors = FALSE)",import,760680266888812e8,490
"spotprices <- spotprices[, -1]",import,760680266888812e8,490
"colnames(spotprices) <- c(""Date"", ""WTISpotPriceBBL"", ""BrentSpotPriceBBL"")",import,760680266888812e8,490
oldwd <- getwd(),setup,760680266888812e8,490
"filepath2 <- ""/Data/""",setup,760680266888812e8,490
"path <- c(getwd(), filepath2)",setup,760680266888812e8,490
"path <- paste(path, collapse = """")",setup,760680266888812e8,490
setwd(path),setup,760680266888812e8,490
"write.csv(spotprices, file = ""CleanSpotPrices.csv"")",import,760680266888812e8,490
setwd(oldwd),setup,760680266888812e8,490
"source(""./analysis/data/GDPdata.R"")",setup,760680266888812e8,490
"source(""./analysis/data/Edudata.R"")",setup,760680266888812e8,490
"source(""./analysis/data/Merge.R"")",setup,760680266888812e8,490
library(ROntoTools),import,760680266888812e8,490
"kpg <- keggPathwayGraphs(""eco"", relPercThresh = 0, updateCache = TRUE,      verbose = TRUE)",exploratory,760680266888812e8,490
"kpg <- setEdgeWeights(kpg, edgeTypeAttr = ""subtype"", edgeWeightByType = list(activation = 1,      inhibition = -1, expression = 1, repression = -1), defaultWeight = 0)",visualization,760680266888812e8,490
"core <- read.csv(""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/best_strains_DEseq.csv"",      header = TRUE)",import,760680266888812e8,490
"colnames(core)[1] <- ""bnum""",import,760680266888812e8,490
"core <- core[complete.cases(core), ]",import,760680266888812e8,490
"kpn <- keggPathwayNames(""eco"")",exploratory,760680266888812e8,490
fc <- core$log2FoldChange[core$padj <= 0.01],evaluation,760680266888812e8,490
"names(fc) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",evaluation,760680266888812e8,490
pv <- core$padj[core$padj <= 0.01],evaluation,760680266888812e8,490
"names(pv) <- paste0(""eco:"", core$bnum[core$padj <= 0.01])",evaluation,760680266888812e8,490
"kpg <- setNodeWeights(kpg, weights = alphaMLG(pv), defaultWeight = 1)",visualization,760680266888812e8,490
"ref <- paste0(""eco:"", core$bnum)",not sure,760680266888812e8,490
"peRes <- pe(x = fc, graphs = kpg, ref = ref, nboot = 200, verbose = TRUE)",modeling,760680266888812e8,490
"s <- Summary(peRes, pathNames = kpn, totalAcc = FALSE, totalPert = FALSE,      pAcc = FALSE, order.by = ""pPert"")",modeling,760680266888812e8,490
"p <- peRes@pathways[[""path:eco00650""]]",evaluation,760680266888812e8,490
"g <- layoutGraph(p@map, layoutType = ""dot"")",visualization,760680266888812e8,490
graphRenderInfo(g) <- list(fixedsize = FALSE),visualization,760680266888812e8,490
edgeRenderInfo(g) <- peEdgeRenderInfo(p),visualization,760680266888812e8,490
nodeRenderInfo(g) <- peNodeRenderInfo(p),visualization,760680266888812e8,490
renderGraph(g),visualization,760680266888812e8,490
"library(""topGO"")",import,760680266888812e8,490
"library(""org.EcK12.eg.db"")",import,760680266888812e8,490
"results <- ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/""",export,760680266888812e8,490
"goDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/gene_association.ecocyc.csv"",      row.names = 1, stringsAsFactors = F)",export,760680266888812e8,490
"myDat <- read.csv(file = ""/Users/annasintsova/git_repos/HUTI-RNAseq/results/differential_expression_analysis/media_all_genes_edited.csv"",      row.names = 1, stringsAsFactors = F)",export,760680266888812e8,490
FCok <- which(abs(myDat$log2FoldChange) > 2),communication,760680266888812e8,490
FDRok <- which(myDat$padj < 0.05),evaluation,760680266888812e8,490
"DE <- intersect(FDRok, FCok)",evaluation,760680266888812e8,490
geneNam <- as.vector(myDat$Name),evaluation,760680266888812e8,490
DEgeneNam <- as.vector(myDat$Name[DE]),evaluation,760680266888812e8,490
geneNam2 <- geneNam[which(geneNam %in% goDat$Symbol)],evaluation,760680266888812e8,490
DEgeneNam2 <- DEgeneNam[which(DEgeneNam %in% goDat$Symbol)],evaluation,760680266888812e8,490
"goDat2 <- goDat[which(goDat$Symbol %in% geneNam2), ]",evaluation,760680266888812e8,490
"EcoliGenes <- rep(0, length(geneNam2))",evaluation,760680266888812e8,490
EcoliGenes[which(geneNam2 %in% DEgeneNam2)] <- 1,evaluation,760680266888812e8,490
names(EcoliGenes) <- geneNam2,evaluation,760680266888812e8,490
DEcoli <- names(EcoliGenes)[which(EcoliGenes == 1)],evaluation,760680266888812e8,490
FacGenes <- as.factor(EcoliGenes),evaluation,760680266888812e8,490
"goBP <- goDat2[which(goDat2$category == ""P""), ]",evaluation,760680266888812e8,490
"goMF <- goDat2[which(goDat2$category == ""F""), ]",evaluation,760680266888812e8,490
"goCC <- goDat2[which(goDat2$category == ""C""), ]",evaluation,760680266888812e8,490
BPterms <- unique(goBP$GO),evaluation,760680266888812e8,490
MFterms <- unique(goMF$GO),evaluation,760680266888812e8,490
CCterms <- unique(goCC$GO),evaluation,760680266888812e8,490
BPlist <- list(),evaluation,760680266888812e8,490
for (ii in 1:length(BPterms)) {     term <- BPterms[ii]     genes <- unique(goBP$Symbol[which(goBP$GO == term)])     BPlist[[ii]] <- genes },evaluation,760680266888812e8,490
names(BPlist) <- BPterms,evaluation,760680266888812e8,490
MFlist <- list(),evaluation,760680266888812e8,490
for (ii in 1:length(MFterms)) {     term <- MFterms[ii]     genes <- unique(goMF$Symbol[which(goMF$GO == term)])     MFlist[[ii]] <- genes },evaluation,760680266888812e8,490
names(MFlist) <- MFterms,evaluation,760680266888812e8,490
CClist <- list(),evaluation,760680266888812e8,490
for (ii in 1:length(CCterms)) {     term <- CCterms[ii]     genes <- unique(goCC$Symbol[which(goCC$GO == term)])     CClist[[ii]] <- genes },evaluation,760680266888812e8,490
names(CClist) <- CCterms,evaluation,760680266888812e8,490
"topBP <- new(""topGOdata"", description = ""Ecoli BP"", ontology = ""BP"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = BPlist)",evaluation,760680266888812e8,490
"topMF <- new(""topGOdata"", description = ""Ecoli MF"", ontology = ""MF"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = MFlist)",evaluation,760680266888812e8,490
"topCC <- new(""topGOdata"", description = ""Ecoli CC"", ontology = ""CC"",      allGenes = FacGenes, nodeSize = 1, annot = annFUN.GO2genes,      GO2genes = CClist)",evaluation,760680266888812e8,490
BP.genes <- genesInTerm(topBP),evaluation,760680266888812e8,490
MF.genes <- genesInTerm(topMF),evaluation,760680266888812e8,490
CC.genes <- genesInTerm(topCC),evaluation,760680266888812e8,490
"BP.Fisher.elim <- runTest(topBP, algorithm = ""elim"", statistic = ""fisher"")",evaluation,760680266888812e8,490
"BP.Fisher.elim.Table <- GenTable(topBP, elimFisher = BP.Fisher.elim,      topNodes = 1000)",evaluation,760680266888812e8,490
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[which(BP.Fisher.elim.Table$elimFisher <      0.05), ]",evaluation,760680266888812e8,490
"BP.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(BP.Fisher.elim.Table) %in%      c(""Term""))]",evaluation,760680266888812e8,490
"if (nrow(BP.Fisher.elim.Table) > 0) {     goIDs <- BP.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(BP.genes[[which(names(BP.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(BP.genes[[which(names(BP.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(BP.Fisher.elim.Table, aDF)     write.csv(bDF, file = paste0(results, ""media_pathway_analysis_BP.csv"")) }",evaluation,760680266888812e8,490
"MF.Fisher.elim <- runTest(topMF, algorithm = ""elim"", statistic = ""fisher"")",modeling,760680266888812e8,490
"MF.Fisher.elim.Table <- GenTable(topMF, elimFisher = MF.Fisher.elim,      topNodes = 1000)",modeling,760680266888812e8,490
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[which(MF.Fisher.elim.Table$elimFisher <      0.05), ]",modeling,760680266888812e8,490
"MF.Fisher.elim.Table <- MF.Fisher.elim.Table[, !(names(MF.Fisher.elim.Table) %in%      c(""Term""))]",modeling,760680266888812e8,490
"if (nrow(MF.Fisher.elim.Table) > 0) {     goIDs <- MF.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(MF.genes[[which(names(MF.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(MF.genes[[which(names(MF.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(MF.Fisher.elim.Table, aDF)     write.csv(bDF, paste0(results, ""media_pathway_analysis_MF.csv"")) }",modeling,760680266888812e8,490
"CC.Fisher.elim <- runTest(topCC, algorithm = ""elim"", statistic = ""fisher"")",modeling,760680266888812e8,490
"CC.Fisher.elim.Table <- GenTable(topCC, elimFisher = CC.Fisher.elim,      topNodes = 200)",modeling,760680266888812e8,490
"CC.Fisher.elim.Table <- CC.Fisher.elim.Table[which(CC.Fisher.elim.Table$elimFisher <      0.05), ]",modeling,760680266888812e8,490
"CC.Fisher.elim.Table <- BP.Fisher.elim.Table[, !(names(CC.Fisher.elim.Table) %in%      c(""Term""))]",modeling,760680266888812e8,490
"if (nrow(CC.Fisher.elim.Table) > 0) {     goIDs <- CC.Fisher.elim.Table$GO.ID     Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))     genesInTerm <- sapply(goIDs, function(x) paste(CC.genes[[which(names(CC.genes) ==          x)]], collapse = "",""))     DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(CC.genes[[which(names(CC.genes) ==          x)]], DEgeneNam1), collapse = "",""))     aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)     bDF <- cbind(CC.Fisher.elim.Table, aDF)     write.csv(bDF, paste0(results, ""media_pathway_analysis_CC.csv"")) }",modeling,760680266888812e8,490
library(shiny),import,760680266888812e8,490
library(plotly),import,760680266888812e8,490
"request_types = c(""Bulky Items"", ""Dead Animal Removal"", ""Graffiti Removal"",      ""Electronic Waste"", ""Illegal Dumping Pickup"", ""Other"", ""Metal/Household Appliances"",      ""Homeless Encampment"", ""Single Streetlight Issue"", ""Multiple Streetlight Issue"",      ""Feedback"", ""Report Water Waste"")",import,760680266888812e8,490
"CD_lists = c(as.character(1:15), ""city of LA"")",import,760680266888812e8,490
"social_types = c(""Median_Age"", ""Median_Household_Income"")",import,760680266888812e8,490
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Regional Requests Analysis"",      sidebarLayout(sidebarPanel(selectInput(inputId = ""CD"", label = ""Council Districts: "",          choices = CD_lists, multiple = TRUE, selectize = TRUE,          selected = ""city of LA""), actionButton(inputId = ""button_cd"",          label = ""Submit"", style = ""padding:3px""), width = 3),          mainPanel(fluidRow(tableOutput(""cd_summary"")))), hr(),      fluidRow(column(6, plotlyOutput(outputId = ""plot_income"")),          column(6, plotlyOutput(outputId = ""plot_unemployment"")))),      tabPanel(""Requests Type Analysis"", sidebarPanel(selectInput(inputId = ""request_type"",          label = ""Request Type: "", choices = request_types, multiple = FALSE,          selectize = TRUE, selected = ""Metal/Household Appliances""),          selectInput(inputId = ""social_type"", label = ""Social Characteristics: "",              choices = social_types, multiple = FALSE, selectize = TRUE,              selected = ""Median_Household_Income""), actionButton(inputId = ""button_req"",              label = ""Submit""), width = 4), mainPanel(fluidRow(plotOutput(outputId = ""req_summary"")))),      tabPanel(""Requests Efficiency Analysis"", fluidRow(column(6,          tableOutput(outputId = ""type_summary"")), column(4, plotOutput(outputId = ""wc"")))),      tabPanel(""Department Efficiency Analysis"", column(3, actionButton(inputId = ""dep_source"",          label = ""Department and request source"")), column(3,          actionButton(inputId = ""dep_type"", label = ""Department and request type"")),          column(3, actionButton(inputId = ""dep_cd"", label = ""Department and Council Districts"")),          plotOutput(""dep_plot"")))",import,760680266888812e8,490
"postscript(file = ""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Presentation\\Article\\figure\\Figure5.ps"",      horizontal = F, onefile = F, width = 3.27, height = 9.19,      family = ""Arial"", pointsize = 12)",export,784627460641786e8,492
"par(mfrow = c(2, 1))",setup,784627460641786e8,492
"plot(nspm.2mo.tow.count.la, select = 1, shade = T, all.terms = T,      scale = 0, xlab = expression(paste(""Dissolved Oxygen"" ~ (mg ~          L^{             2         }))), ylab = ""Effect of Dissolved Oxygen"", ylim = c(-1.2,          0.22))",visualization,784627460641786e8,492
rm(list = ls()),setup,279080009553581e8,493
require(ggplot2),setup,279080009553581e8,493
require(lme4),setup,279080009553581e8,493
require(merTools),setup,279080009553581e8,493
require(lmerTest),setup,279080009553581e8,493
"source(system.file(""utils"", ""allFit.R"", package = ""lme4""))",import,279080009553581e8,493
"source(""./functions/newbinplot.R"")",import,279080009553581e8,493
require(arm),setup,279080009553581e8,493
"source(""./functions/ranNorm.R"")",import,279080009553581e8,493
"source(""./functions/booter.R"")",import,279080009553581e8,493
"survival_data <- read.table(""./analysis/nursery_experiment_inundation/data/nursery_experiment_data.txt"",      header = TRUE)",import,279080009553581e8,493
str(survival_data),exploratory,279080009553581e8,493
"ggplot(survival_data, aes(x = treat, y = surv)) + geom_point() +      stat_smooth()",exploratory,279080009553581e8,493
"library(""ggplot2"")",setup,845243861200288e8,494
rm(list = ls()),setup,728365555405617e8,495
"prototypes <- read.table(""../prototypes_0.txt"")",import,728365555405617e8,495
"uber.proto <- prototypes[1, 2:length(prototypes[1, ])]",data cleaning,728365555405617e8,495
no.features <- length(uber.proto),exploratory,728365555405617e8,495
"no.agents <- length(prototypes[, 1]) - 1",exploratory,728365555405617e8,495
"d.0 <- read.table(""../history_0.txt"", skip = 2)",import,728365555405617e8,495
siteSize = 2048,setup,285188475623727e8,496
"treatment = ""Copper""",setup,285188475623727e8,496
"strand = ""both""",setup,285188475623727e8,496
window.size = 300,setup,285188475623727e8,496
numSam = 6,setup,285188475623727e8,496
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",setup,285188475623727e8,496
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.pval.discrete.Robj"")",export,285188475623727e8,496
load(out.path),import,285188475623727e8,496
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_02.R"",      echo = FALSE)",setup,538775347173214e8,497
"plot(mn.sale$gross.sqft, mn.sale$sale.price.n)",visualization,538775347173214e8,497
"plot(log10(mn.sale$gross.sqft), log10(mn.sale$sale.price.n))",visualization,538775347173214e8,497
hist(log10(mn.sale$sale.price.n)),visualization,538775347173214e8,497
"qqplot(log10(mn.sale$gross.sqft), log10(mn.sale$sale.price.n))",visualization,538775347173214e8,497
"mn.homes <- mn.sale[which(grepl(""FAMILY"", mn.sale$building.class.category)),      ]",data cleaning,538775347173214e8,497
mn.homes$Price.per.gross.sqft <- mn.homes$sale.price.n/mn.homes$gross.sqft,data cleaning,538775347173214e8,497
mn.homes$Price.per.land.sqft <- mn.homes$sale.price.n/mn.homes$land.sqft,data cleaning,538775347173214e8,497
"mn.homes$Price.per.gross.sqft <- replace(mn.homes$Price.per.gross.sqft,      which(is.na(mn.homes$Price.per.gross.sqft)), 0)",data cleaning,538775347173214e8,497
"mn.homes$Price.per.land.sqft <- replace(mn.homes$Price.per.land.sqft,      which(is.na(mn.homes$Price.per.land.sqft)), 0)",data cleaning,538775347173214e8,497
dim(mn.homes),exploratory,538775347173214e8,497
"plot(log10(mn.homes$gross.sqft), log10(mn.homes$sale.price.n))",visualization,538775347173214e8,497
hist(log10(mn.homes$sale.price.n)),visualization,538775347173214e8,497
"summary(mn.homes[which(mn.homes$sale.price.n < 1e+05), ])",exploratory,538775347173214e8,497
rm(list = ls()),setup,656463908962905e7,498
seed <- 627,setup,656463908962905e7,498
set.seed(seed),setup,656463908962905e7,498
"raw_path <- ""analysis/data/raw_data/""",data cleaning,656463908962905e7,498
"derived_path <- ""analysis/data/derived_data/""",export,656463908962905e7,498
"source(""http://svn.research-infrastructures.eu/public/d4science/gcube/trunk/data-analysis/RConfiguration/RD4SFunctions/workspace_interaction.r"")",setup,656463908962905e7,498
"if (file.exists(paste0(raw_path, ""keys.csv""))) {     keys <- read.csv(""analysis/data/raw_data/keys.csv"", stringsAsFactors = FALSE)     username <<- keys$username     token <<- keys$token     rm(keys) }",import,656463908962905e7,498
"if (!file.exists(paste0(raw_path, ""keys.csv""))) {     cat(""To use the vsurf_bb functionality, go to: https://i-marine.d4science.org/group/stockassessment \nand enter your username and personal token"")     set_keys(save_key = TRUE) }",import,656463908962905e7,498
"svspp_dat <- read.csv(paste0(raw_path, ""SVSPP.csv""), stringsAsFactors = FALSE)",import,656463908962905e7,498
"svspp_dat <- svspp_dat %>% dplyr::mutate(COMNAME = tolower(COMNAME)) %>%      dplyr::select(COMNAME, SVSPP) %>% dplyr::mutate(COMNAME = gsub(""atlantic"",      ""Atlantic"", COMNAME), COMNAME = gsub(""american"", ""American"",      COMNAME), COMNAME = gsub(""acadian"", ""Acadian"", COMNAME)) %>%      dplyr::distinct(.keep_all = TRUE)",data cleaning,656463908962905e7,498
"species_list <- c(101, 102, 103, 104, 105, 106, 107, 108, 109,      112, 121, 13, 131, 135, 139, 14, 141, 143, 145, 15, 151,      155, 156, 163, 164, 168, 171, 172, 176, 177, 22, 23, 24,      25, 26, 27, 28, 32, 33, 34, 35, 36, 69, 72, 73, 74, 75, 76,      77, 78, 84)",exploratory,656463908962905e7,498
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,620725276647136e8,499
"join_names <- c(""CRUISE6"", ""STRATUM"", ""STATION"", ""SVVESSEL"",      ""YEAR"", ""SEASON"", ""LAT"", ""LON"", ""EST_TOWDATE"", ""DEPTH"", ""DOY"",      ""SVSPP"")",data cleaning,656463908962905e7,498
"bad_dat <- c(""rast_necrm_bpi"", ""rast_necrm_vrm"", ""rast_bpi_3_25_layer"",      ""rast_bpi_30_250_layer"", ""rast_mab_sed"", ""rast_gdepth"", ""rast_gravel_fraction"",      ""rast_mud_fraction"", ""rast_phi_fraction"", ""rast_sand_fraction"",      ""rast_plcurv20km"", ""rast_plcurv2km"", ""rast_plcurv10km"", ""SURFTEMP"",      ""BOTTEMP"")",data cleaning,656463908962905e7,498
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,620725276647136e8,499
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,620725276647136e8,499
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,620725276647136e8,499
"if (!require(""gplots"")) {     install.packages(""gplots"", dependencies = TRUE)     library(gplots) }",setup,620725276647136e8,499
"if (!require(""RColorBrewer"")) {     install.packages(""RColorBrewer"", dependencies = TRUE)     library(RColorBrewer) }",setup,620725276647136e8,499
"if (!require(""cluster"")) {     install.packages(""cluster"", dependencies = TRUE)     library(cluster) }",setup,620725276647136e8,499
"if (!require(""tidyverse"")) {     install.packages(""tidyverse"", dependencies = TRUE)     library(tidyverse) }",setup,620725276647136e8,499
"if (!require(""reshape2"")) {     install.packages(""reshape2"", dependencies = TRUE)     library(reshape2) }",setup,620725276647136e8,499
"d897 <- read.csv(""analysis/clustering/kmeans/data/897_motor_nms.csv"",      comment.char = ""#"")",import,620725276647136e8,499
d897_nms_domains9 = d897[68:76],not sure,620725276647136e8,499
"kmeans_nms_domains_models = vector(""list"", 11)",modeling,620725276647136e8,499
"for (i in 1:length(kmeans_nms_domains_models)) {     kmeans_nms_domains_models[[i]] = kmeans(x = d897_nms_domains9,          centers = i + 1, iter.max = 30, nstart = 20) }",modeling,620725276647136e8,499
"filtered_d897_nms_domains = d897[c(68:76, 3:7, 82, 33, 81)]",data cleaning,620725276647136e8,499
"filtered_d897_nms_domains_withClusters = vector(""list"", 11)",data cleaning,620725276647136e8,499
for (i in 1:length(filtered_d897_nms_domains_withClusters)) {     filtered_d897_nms_domains_withClusters[[i]] = kmeans_nms_domains_models[[i]]$cluster },not sure,620725276647136e8,499
"path2read = ""~/Desktop/gitHub/protracted_sp/analysis/R/""",setup,367870704969391e8,500
"path2data = ""~/Desktop/gitHub/protracted_sp/analysis/data/""",setup,367870704969391e8,500
"path2plot = ""~/Desktop/gitHub/protracted_sp/analysis/output/""",setup,367870704969391e8,500
"source(paste0(path2read, ""plot_functions.R""))",import,367870704969391e8,500
"par = get_param(output = path2read, out_post = ""posterior/"",      initial.patt = ""Bayes_simulation_study_"")",import,367870704969391e8,500
"setwd(""/Volumes/NOAA_Data/CNH/"")",setup,693021356128156e7,1
require(cluster),setup,693021356128156e7,1
require(ggplot2),setup,693021356128156e7,1
require(dplyr),setup,693021356128156e7,1
library(reshape2),import,362109979148954e8,501
library(plyr),import,362109979148954e8,501
library(dplyr),import,362109979148954e8,501
library(scales),import,362109979148954e8,501
"ftl <- read.csv(""/Users/efuller/1/CNH/Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",      stringsAsFactors = F)",setup,362109979148954e8,501
"ftl$trip_id <- paste0(ftl$ftid, ftl$year)",data cleaning,362109979148954e8,501
"melt_ftl <- melt(ftl, id.vars = c(""veid"", ""trip_id"", ""spid"",      ""tdate"", ""grid""), measure.vars = ""landed_wt"")",data cleaning,362109979148954e8,501
"cast_ftl <- dcast(melt_ftl, trip_id ~ spid, fun.aggregate = sum)",exploratory,362109979148954e8,501
cast_ftl[cast_ftl == 0] <- NA,data cleaning,362109979148954e8,501
"bymedian <- with(melt_ftl, reorder(spid, -value, median))",exploratory,362109979148954e8,501
"boxplot(value ~ bymedian, data = melt_ftl, cex = 0.15, pch = 19,      las = 2, col = alpha(""black"", 0.25))",exploratory,362109979148954e8,501
"num_trips <- sort(table(melt_ftl$spid), decreasing = T)",data cleaning,362109979148954e8,501
"medians <- rep(NA, length(num_trips))",data cleaning,362109979148954e8,501
"sd <- rep(NA, length(num_trips))",data cleaning,362109979148954e8,501
library(synapseClient),setup,70057935314253e8,502
synapseLogin(),setup,70057935314253e8,502
"diffexScriptlist = list(list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/analysis/2016-05-04/encodeSkinAnalysis_ExprOnly.R""),      list(url = ""https://raw.githubusercontent.com/sgosline/dNFLandscape/master/bin/encodeSkinRNASeq.R""),      list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/bin/dermalNFData.R""))",setup,70057935314253e8,502
"txtfiles = list.files(""."")",setup,70057935314253e8,502
"txtfiles = txtfiles[grep(""txt"", txtfiles)]",setup,70057935314253e8,502
"for (file in txtfiles) {     synStore(File(file, parentId = ""syn7518454""), executed = diffexScriptlist,          used = list(list(entity = ""syn6035999""), list(entity = ""syn5579598""))) }",setup,70057935314253e8,502
library(synapseClient),setup,70057935314253e8,502
library(ggplot2),setup,70057935314253e8,502
library(stringr),setup,70057935314253e8,502
library(reshape2),setup,70057935314253e8,502
library(yaml),setup,70057935314253e8,502
"source(""powerAnalysis/lib.R"")",setup,70057935314253e8,502
"kConfigPath <- ""powerAnalysis/powerAnalysis.yml""",setup,70057935314253e8,502
"kSep <- "" """,setup,70057935314253e8,502
kNRows <- -1,setup,70057935314253e8,502
"kVariableRegexp <- ""p_local_concentration.*""",setup,70057935314253e8,502
"kQuantiles <- c(0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99,      0.995, 0.999)",setup,70057935314253e8,502
"kThresholds <- seq(0.5, 0.95, 0.05)",setup,70057935314253e8,502
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,836943379836157e8,503
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,836943379836157e8,503
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,836943379836157e8,503
"source(""./analysis/wood_density_distribution/organisation.R"")",import,836943379836157e8,503
"source(""./packages.R"")",exploratory,836943379836157e8,503
"source(""./analysis/wood_density_distribution/function_index.R"")",data cleaning,836943379836157e8,503
"ggplot(wood_density_data_178ha, aes(x = d, y = e)) + geom_point(aes(color = fd)) +      stat_smooth(method = lm) + theme_bw()",visualization,836943379836157e8,503
"model1 <- lm(e ~ d, data = wood_density_data_178ha)",modeling,836943379836157e8,503
"plot(model1, which = 1)",visualization,836943379836157e8,503
"save(model2, file = ""./analysis/wood_density_distribution/models/lm_models/model1.R"")",export,836943379836157e8,503
"model2 <- gls(e ~ d, data = wood_density_data_178ha, weights = varIdent(form = ~1 |      fd))",modeling,836943379836157e8,503
summary(model2),exploratory,836943379836157e8,503
plot(model2),visualization,836943379836157e8,503
"save(model2, file = ""./analysis/wood_density_distribution/models/gls_models/model2.R"")",export,836943379836157e8,503
"load(""./analysis/wood_density_distribution/bootstrapped/coef_CI_gls_wooddensity_VS_elevation.R"")",import,836943379836157e8,503
coef_CI,not sure,836943379836157e8,503
"booter(model2, data = wood_density_data_178ha, )",not sure,836943379836157e8,503
rm(list = ls()),setup,382392690051347e8,504
library(plyr),import,382392690051347e8,504
library(dplyr),import,382392690051347e8,504
library(reshape2),import,382392690051347e8,504
"codedir <- ""code""",setup,382392690051347e8,504
"outputdir <- ""analysis/ramldb/output""",export,382392690051347e8,504
"tabledir <- ""analysis/ramldb/tables""",setup,382392690051347e8,504
"sapply(list.files(codedir, "".R""), function(x) source(file.path(codedir,      x)))",import,382392690051347e8,504
"load(file.path(outputdir, ""RAMLDB_ricker.Rdata""))",import,382392690051347e8,504
ricker <- srfit,exploratory,382392690051347e8,504
"load(file.path(outputdir, ""RAMLDB_ricker_sst.Rdata""))",import,382392690051347e8,504
ricker_sst <- srfit,not sure,382392690051347e8,504
"load(file.path(outputdir, ""RAMLDB_ricker_sst_lme.Rdata""))",import,382392690051347e8,504
ricker_sst_lme <- srfit,not sure,382392690051347e8,504
"models <- list(ricker, ricker_sst, ricker_sst_lme)",modeling,382392690051347e8,504
"names <- c(""Ricker"", ""SST-Ricker"", ""SST-LME-Ricker"")",data cleaning,382392690051347e8,504
"results <- compare_models(models, names)",evaluation,382392690051347e8,504
"write.csv(results, file.path(tabledir, ""Table1_model_comparison_aic.csv""),      row.names = F)",export,382392690051347e8,504
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,921547267585993e8,505
"spe.dbln <- subset(data3, select = c(age_class, ACA:ARO, LCA:LTR,      OCY, OLA))",data cleaning,921547267585993e8,505
"spe.dbln <- aggregate(. ~ age_class, spe.dbln, mean)",data cleaning,921547267585993e8,505
"spe.dbln <- data.frame(spe.dbln[, -1], row.names = c(""Cm"", ""Sp_Y"",      ""Sp_I1"", ""Sp_I2"", ""Sp_O""))",import,921547267585993e8,505
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,617324977414682e8,506
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,660123304929584e8,507
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",exploratory,660123304929584e8,507
"WaveQTL.repodir <- scan("".WaveQTL.repodir.txt"", what = character())",exploratory,660123304929584e8,507
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,152026990894228e8,508
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,275776730850339e8,509
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
"library(""readstata13"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,275776730850339e8,509
library(RColorBrewer),setup,275776730850339e8,509
library(classInt),setup,275776730850339e8,509
"epr_poly <- readOGR(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/GeoEPR-2014/GeoEPR-2014.shp"")",import,275776730850339e8,509
"epr <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/GeoEPR-2014/EPR-2014.csv"")",import,275776730850339e8,509
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,275776730850339e8,509
library(ggplot2),setup,635929333744571e8,510
library(plyr),setup,635929333744571e8,510
library(stringr),setup,635929333744571e8,510
library(reshape2),setup,635929333744571e8,510
library(xtable),setup,635929333744571e8,510
"source(""powerAnalysis/lib.R"")",setup,635929333744571e8,510
"kInputPath <- ""powerAnalysis/results_design_regressions.RData""",import,635929333744571e8,510
"kLmTablePath <- ""powerAnalysis/tables_design_lm.tex""",import,635929333744571e8,510
"kGlmTablePath <- ""powerAnalysis/tables_design_glm.tex""",import,635929333744571e8,510
library(pwr),setup,262716291239485e8,511
t = sqrt(F),setup,262716291239485e8,511
d = t/sqrt(21),data cleaning,262716291239485e8,511
mdiff = 0.8,data cleaning,262716291239485e8,511
"sediff = -mdiff/qt(0.001, 20)",data cleaning,262716291239485e8,511
"load(""../Data/R2GIS/CleanData/TimeLag12months/Sales20052010LWRmodelAirMean3-2014-03-19.RData"")",data cleaning,170831584837288e7,512
"MCMaster = read.csv(""~/NoiseHedonicProject/Noise-Hedonic/analysis/04MonteCarloSim/Revision/Model3/LWRMonteCarloStats2014-07-02.csv"")",data cleaning,170831584837288e7,512
"MCMaster = MCMaster[1:94, ]",data cleaning,170831584837288e7,512
"MCplotter = function(outputcoefficient, statcoefficient, meanORsd = ""mean"") {     if (meanORsd == ""mean"")          actual = mean(output[[outputcoefficient]][, ""k2000""],              na.rm = T)     if (meanORsd == ""sd"")          actual = sd(output[[outputcoefficient]][, ""k2000""], na.rm = T)     temp = density(MCMaster[, statcoefficient])     plot(temp, xlim = c(min(c(range(temp$x), actual), na.rm = T),          max(c(range(temp$x), actual), na.rm = T)), main = paste(meanORsd,          sub(""beta."", """", outputcoefficient)), axes = F, ylab = """",          xlab = """")     axis(1)     mtext(""relative frequency"", 2, 1, cex = 0.7)     abline(v = actual, col = ""red"") }",data cleaning,170831584837288e7,512
"outputCOEFS = rep(names(output)[c(1:5, 16, 19, 20, 21, 22, 23,      24, 17, 18)], 2)",data cleaning,170831584837288e7,512
statCOEFS = names(MCMaster)[3:30],data cleaning,170831584837288e7,512
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",not sure,870849539060146e7,513
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",not sure,870849539060146e7,513
library(randomForest),setup,368914872407913e8,514
library(caret),setup,368914872407913e8,514
library(doMC),setup,368914872407913e8,514
library(mmadsenr),setup,368914872407913e8,514
library(futile.logger),setup,368914872407913e8,514
library(dplyr),setup,368914872407913e8,514
library(ggthemes),setup,368914872407913e8,514
"get_tassize_subset_ssize_tadur <- function(df, ssize, tadur) {     df_tassize_subset <- dplyr::filter(df, sample_size == ssize,          ta_duration == tadur)     df_tassize_subset }",data cleaning,368914872407913e8,514
"get.pval.from.empirical.null.dist.discrete <- function(statistic.null,      statistic.alt, big.sig = TRUE) {     numNulltests = length(statistic.null)     if (big.sig) {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null > x))         }, statistic.null = statistic.null)     }     else {         numSig = sapply(statistic.alt, function(x, statistic.null) {             return(sum(statistic.null < x))         }, statistic.null = statistic.null)     }     numEqual = sapply(statistic.alt, function(x, statistic.null) {         return(sum(statistic.null == x))     }, statistic.null = statistic.null)     Uval = runif(length(statistic.alt))     pval.list = (numSig + Uval * (numEqual + 1))/(numNulltests +          1)     return(pval.list) }",evaluation,40895869070664e9,515
"wd.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,40895869070664e9,515
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,588933380786329e7,516
rm(list = ls()),data cleaning,588933380786329e7,516
"setwd(""~/Dropbox/Albert Xue/Research/Deployment/SHAPE-Seq_event_detector/"")",modeling,588933380786329e7,516
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,83972056559287e9,517
rm(list = ls()),data cleaning,83972056559287e9,517
require(plyr),data cleaning,83972056559287e9,517
require(dplyr),data cleaning,83972056559287e9,517
require(data.table),data cleaning,83972056559287e9,517
library(igraph),setup,730644206749275e8,518
library(dplyr),setup,730644206749275e8,518
library(parallel),setup,730644206749275e8,518
library(purrr),setup,730644206749275e8,518
library(stringr),setup,730644206749275e8,518
"source(""Analysis/remove_self_node.R"")",import,730644206749275e8,518
"source(""Analysis/compute_triplets.R"")",import,730644206749275e8,518
"source(""Analysis/compute_all_triplets.R"")",import,730644206749275e8,518
"source(""Analysis/categorize_all_triplets.R"")",import,730644206749275e8,518
"source(""Analysis/categorize_triplet1.R"")",import,730644206749275e8,518
"coffeeG05 = read_graph(""Data/iGraphs/coffeeG05.gml"", format = ""gml"")",import,730644206749275e8,518
"gasG05 = read_graph(""Data/iGraphs/gasG05.gml"", format = ""gml"")",import,730644206749275e8,518
print(Sys.getpid()),not sure,480970240430906e8,519
"L1000geneAnnots = readRDS(""analysis/00.cmapRanks/L1000geneAnnots.rds"")",communication,480970240430906e8,519
"inst = readRDS(""analysis/00.cmapRanks/NatInstances.rds"")",import,480970240430906e8,519
library(cmapQuery),import,480970240430906e8,519
library(dplyr),setup,480970240430906e8,519
library(magrittr),setup,480970240430906e8,519
calculateKs = TRUE,setup,480970240430906e8,519
calculateSpecificity = FALSE,setup,480970240430906e8,519
"if (calculateKs) {     print(""pre-calcing random Ks"")     L1000PreCalc = preCalcRandomKs(inst$chem)     saveRDS(L1000PreCalc, ""analysis/00.cmapRanks/NatPreCalc.rds"") }",setup,480970240430906e8,519
r = 1000,setup,522619566880166e8,520
"growth_pars <- mvrnorm(r, mu = rep$par.fixed[1:5], rep$cov.fixed[1:5,      1:5])",setup,522619566880166e8,520
"mat_pars <- mvrnorm(r, mu = coef(am_both$model), summary(am_both$model)$cov.unscaled)",setup,522619566880166e8,520
"source(""analysis/utils.R"")",setup,864049889612943e8,521
"source(""analysis/analysis.R"")",not sure,864049889612943e8,521
setEPS(),setup,48856930877082e9,51
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/partFunctions.eps"",      width = 5, height = 2.1)",export,48856930877082e9,51
"par(mar = c(1, 4, 1, 1), cex = 0.97)",visualization,48856930877082e9,51
"M_partFunctions = matrix(c(31054, 7116, 5788, 1084, 1825, 124,      6826, 77), ncol = 1, byrow = T)",import,48856930877082e9,51
"rownames(M_partFunctions) = c(""re.compile 31,054 (57.6%)"", ""re.search 7,116 (13.2%)"",      ""re.match 5,788 (10.7%)"", ""re.split 1,084 (2%)"", ""re.findall 1,825 (3.4%)"",      ""re.finditer 124 (0.2%)"", ""re.sub 6,826 (12.7%)"", ""re.subn 77 (0.1%)"")",data cleaning,48856930877082e9,51
"barplot(M_partFunctions, legend = rownames(M_partFunctions),      col = c(""gray50"", ""gray30"", ""gray75"", ""gray12"", ""gray87"",          ""gray20"", ""gray67"", ""gray8""), xlim = c(0, 9), width = 0.6,      ylim = range(pretty(c(0, 53894))), las = 1)",visualization,48856930877082e9,51
dev.off(),visualization,48856930877082e9,51
setEPS(),setup,48856930877082e9,51
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/partFlags.eps"",      width = 5, height = 2.1)",export,48856930877082e9,51
"par(mar = c(1, 4, 1, 1), cex = 0.97)",visualization,48856930877082e9,51
"M_partFlags = matrix(c(2996, 24, 1764, 711, 397, 943, 0), ncol = 1,      byrow = T)",import,48856930877082e9,51
"rownames(M_partFlags) = c(""IGNORECASE 2,996 (43.8%)"", ""LOCALE 24 (0.4%)"",      ""MULTILINE 1,764 (25.8%)"", ""DOTALL 711 (10.4%)"", ""UNICODE 397 (5.8%)"",      ""VERBOSE 943 (13.8%)"", ""multiple flags 0 (0%)"")",data cleaning,48856930877082e9,51
"barplot(M_partFlags, legend = rownames(M_partFlags), col = c(""gray80"",      ""gray32"", ""gray67"", ""gray8"", ""gray50"", ""gray92"", ""grey20""),      xlim = c(0, 9), width = 0.6, ylim = range(pretty(c(0, 6835))),      las = 1)",visualization,48856930877082e9,51
dev.off(),visualization,48856930877082e9,51
setEPS(),setup,48856930877082e9,51
"postscript(""/Users/carlchapman/Documents/SoftwareProjects/tour_de_source/analysis/analysis_output/patternFiltering.eps"",      width = 3.5, height = 2)",export,48856930877082e9,51
"par(mar = c(1, 4, 1, 1), cex = 0.97)",visualization,48856930877082e9,51
"M_patternFiltering = matrix(c(25, 97, 13597), ncol = 1, byrow = T)",import,48856930877082e9,51
"rownames(M_patternFiltering) = c(""alien feature 25 (0.2%)"", ""pcre error 97 (0.7%)"",      ""included patterns 13,597 (99.1%)"")",data cleaning,48856930877082e9,51
"barplot(M_patternFiltering, legend = rownames(M_patternFiltering),      col = c(""mediumblue"", ""lightskyblue1"", ""seagreen2""), xlim = c(0,          9), width = 0.6, ylim = range(pretty(c(0, 13719))), las = 1)",visualization,48856930877082e9,51
dev.off(),visualization,48856930877082e9,51
rm(list = ls()),setup,808636595960706e8,522
"setwd(""/Users/efuller/1/CNH/Analysis/VMS/results/2014-10-29/"")",setup,808636595960706e8,522
library(scales),setup,808636595960706e8,522
library(maps),setup,808636595960706e8,522
library(data.table),setup,808636595960706e8,522
"VMS <- readRDS(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_VMS_masked.RDS"")",setup,808636595960706e8,522
VMSdf <- data.table(VMS@data),setup,808636595960706e8,522
"VMSdf[, `:=`(c(""Longitude"", ""Latitude""), list(coordinates(VMS)[,      1], coordinates(VMS)[, 2])), with = FALSE]",setup,808636595960706e8,522
rm(VMS),setup,808636595960706e8,522
"setkey(VMSdf, NULL)",setup,808636595960706e8,522
VMSdf <- unique(VMSdf),setup,808636595960706e8,522
"VMSdf[, `:=`(""alldups"", duplicated(VMSdf, by = c(""Ship_Number"",      ""Date_Time"")) | duplicated(VMSdf, by = c(""Ship_Number"", ""Date_Time""),      fromLast = TRUE)), with = FALSE]",setup,808636595960706e8,522
"VMSdf <- subset(VMSdf, alldups == FALSE)",setup,808636595960706e8,522
"save(VMSdf, file = ""3_VMSdf.Rdata"")",setup,808636595960706e8,522
"load(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_coastline.Rdata"")",setup,808636595960706e8,522
library(ggplot2),setup,808636595960706e8,522
"WC.points <- fortify(WC, region = ""id"")",setup,808636595960706e8,522
"ggplot(WC.points) + aes(long, lat, group = group) + geom_polygon() +      geom_path(color = ""white"") + coord_equal()",setup,808636595960706e8,522
"ggplot(WC.points) + aes(long, lat, group = group) + geom_polygon() +      geom_path(color = ""white"") + coord_equal()",setup,808636595960706e8,522
rm(list = ls()),setup,808636595960706e8,522
"setwd(""/Users/efuller/1/CNH/Analysis/VMS/results/2014-10-29/"")",setup,808636595960706e8,522
library(scales),setup,808636595960706e8,522
library(maps),setup,808636595960706e8,522
library(data.table),setup,808636595960706e8,522
"VMS <- readRDS(""/Users/efuller/1/CNH/Analysis/VMS/writing/code/2_VMS_masked.RDS"")",setup,808636595960706e8,522
VMSdf <- data.table(VMS@data),setup,808636595960706e8,522
"VMSdf[, `:=`(c(""Longitude"", ""Latitude""), list(coordinates(VMS)[,      1], coordinates(VMS)[, 2])), with = FALSE]",setup,808636595960706e8,522
rm(VMS),setup,808636595960706e8,522
rm(list = ls()),setup,214496732922271e8,523
require(lmerTest),setup,214496732922271e8,523
require(lme4),setup,214496732922271e8,523
require(MuMIn),setup,214496732922271e8,523
require(remef),setup,214496732922271e8,523
require(ggplot2),setup,214496732922271e8,523
"data <- read.table(""./analysis/nursery_experiment_inundation/data/biomass_data.txt"",      header = T)",import,214496732922271e8,523
"Ndata <- read.table(""./analysis/nursery_experiment_inundation/data/carbon_intake_data.txt"",      header = T)",import,214496732922271e8,523
str(Ndata),evaluation,214496732922271e8,523
str(data),evaluation,214496732922271e8,523
"Ndata$index <- with(Ndata, paste(sp, mother, block, treat, sep = """"))",data cleaning,214496732922271e8,523
"data$index <- with(data, paste(sp, mother, block, treat, sep = """"))",data cleaning,214496732922271e8,523
"newdata <- merge(Ndata, data, by = ""index"")",data cleaning,214496732922271e8,523
str(newdata),evaluation,214496732922271e8,523
leafArea <- newdata$lBio.y/(newdata$slm.y * 10000),data cleaning,214496732922271e8,523
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,795811287360266e8,524
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,795811287360266e8,524
library(dplyr),exploratory,795811287360266e8,524
"setwd(""/mnt/lustre/home/shim/multiscale_analysis"")",setup,167236282723024e8,525
"library(""multiseq"")",setup,167236282723024e8,525
"library(""ashr"")",setup,167236282723024e8,525
"if (!require(""pacman"")) install.packages(""pacman"")",setup,685696625849232e8,526
"pacman::p_install_gh(""kahaaga/tstools"")",setup,685696625849232e8,526
"pacman::p_load(dplyr, data.table, pracma)",setup,685696625849232e8,526
"summer.energy.data <- readRDS(""analysis/compiled_data.RData"")",import,685696625849232e8,526
"fraction.of.zeros <- readRDS(""analysis/fraction_of_zeros.RData"") %>%      as.data.frame",import,685696625849232e8,526
lags <- -8:8,import,685696625849232e8,526
E <- NULL,import,685696625849232e8,526
tau <- NULL,import,685696625849232e8,526
library.sizes <- 50,import,685696625849232e8,526
"lib <- c(1, dim(data)[1])",import,685696625849232e8,526
pred <- lib,import,685696625849232e8,526
samples.original <- 20,import,685696625849232e8,526
samples.surrogates <- 20,import,685696625849232e8,526
n.surrogates <- 20,import,685696625849232e8,526
"surrogate.methods <- c(""aaft"")",import,685696625849232e8,526
time.unit <- NULL,import,685696625849232e8,526
time.bin.size <- NULL,import,685696625849232e8,526
num.neighbours <- E + 1,import,685696625849232e8,526
random.libs <- TRUE,import,685696625849232e8,526
with.replacement <- TRUE,import,685696625849232e8,526
exclusion.radius <- 30,import,685696625849232e8,526
epsilon <- NULL,import,685696625849232e8,526
RNGseed <- 1111,import,685696625849232e8,526
silent <- TRUE,import,685696625849232e8,526
time.run <- F,import,685696625849232e8,526
print.to.console <- T,import,685696625849232e8,526
time.series.length.threshold <- 100,import,685696625849232e8,526
library_column <- 1,import,685696625849232e8,526
target_column <- 2,import,685696625849232e8,526
surrogate_column <- target_column,import,685696625849232e8,526
convergence.test <- TRUE,import,685696625849232e8,526
parallel <- TRUE,import,685696625849232e8,526
parallelize.on.each.lag <- F,import,685696625849232e8,526
num.cores <- parallel::detectCores() - 1,import,685696625849232e8,526
regression.convergence.plots <- F,import,685696625849232e8,526
always.run.surrogates <- F,import,685696625849232e8,526
n.libsizes.convergence.check <- 20,import,685696625849232e8,526
optimise.FNNdim <- T,import,685696625849232e8,526
optimise.boxcountdim <- T,import,685696625849232e8,526
min.E <- 2,import,685696625849232e8,526
max.E <- 10,import,685696625849232e8,526
min.tau <- 1,import,685696625849232e8,526
max.tau <- 1,import,685696625849232e8,526
plot.simplex.projection <- F,import,685696625849232e8,526
ccm <- list(),import,685696625849232e8,526
"thresholds <- seq(0, 500, 25)",import,685696625849232e8,526
"latitudes <- seq(-90, -90, 1)",import,685696625849232e8,526
bin.sizes <- c(1),import,685696625849232e8,526
"for (l in latitudes) {     for (b in bin.sizes) {         for (t in thresholds) {             cat(""latitude: "", l, ""\tbin.size: "", b, ""\tthreshold: "",                  t, ""\n"")             frac.zeros <- subset(x = fraction.of.zeros, subset = latitude ==                  l & threshold == t)$value[1]             if (frac.zeros > 0.02) {                 too.many.zeros <- TRUE                 cat(""Too many zeros for latitude = "", l, "" and threshold = "",                    t, "".\n\n"")             }             else {                 pracma::tic(gcFirst = T)                 df <- subset(x = summer.energy.data, subset = (threshold ==                    t & latitude == l), select = c(""SummerEnergy"",                    ""GSL"")) %>% as.data.frame                 ccm.gslspel <- tstools::ccm_lagged(data = df,                    lags = lags, library.sizes = library.sizes,                    samples.original = samples.original, samples.surrogates = samples.surrogates,                    surrogate.methods = surrogate.methods, n.surrogates = n.surrogates,                    exclusion.radius = exclusion.radius, library.column = ""GSL"",                    target.column = ""SummerEnergy"", surrogate.column = ""SummerEnergy"",                    optimise.FNNdim = optimise.FNNdim, optimise.boxcountdim = optimise.boxcountdim,                    parallel = parallel)                 ccm.gslspel$latitude <- rep(l)                 ccm.gslspel$bin.size <- rep(b)                 ccm.gslspel$threshold <- rep(t)                 df$threshold <- rep(t)                 filename <- paste(""SummerEnergyDrivesGSL_LR04_"",                    toString(t), ""_"", toString(l), "".RData"", sep = """")                 path <- paste(""results/crossmap_summerenergy_GSL_LR04/"",                    filename, sep = """")                 saveRDS(ccm.gslspel, path)                 print(Sys.time())                 print(head(ccm.gslspel))                 cat(""\n"")                 pracma::toc(echo = T)                 cat(""\n\n"")             }         }     } }",exploratory,685696625849232e8,526
rm(list = ls()),not sure,494452088838443e8,527
"setwd(""/extraspace/yye1/analysis/Hypoxia/PSM"")",setup,494452088838443e8,527
"folder <- ""mRNA""",setup,494452088838443e8,527
if (!file.exists(folder)) {     dir.create(folder) },setup,494452088838443e8,527
"library(""lme4"")",import,192209870088845e8,528
"(mm0 <- glmer(against ~ (1 | projetx) + (1 | id), data = d, family = binomial))",modeling,192209870088845e8,528
"(mmPtyp <- glmer(against ~ (1 | projetx) + (1 | id) + typex,      data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmPtop <- glmer(against ~ (1 | projetx) + (1 | id) + topicr,      data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmPpcf <- glmer(against ~ (1 | projetx) + (1 | id) + motpcf,      data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmP <- glmer(against ~ (1 | projetx) + (1 | id) + typex + motpcf,      data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmIsoc <- glmer(against ~ (1 | projetx) + (1 | id) + agez +      sexe + uni, data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmIcul <- glmer(against ~ (1 | projetx) + (1 | id) + regiling,      data = d, family = binomial()))",modeling,192209870088845e8,528
"(mmIpro <- glmer(against ~ (1 | projetx) + (1 | id) + conx, data = d,      family = binomial()))",modeling,192209870088845e8,528
"(mmI <- glmer(against ~ (1 | projetx) + (1 | id) + agez + sexe +      uni + regiling + conx, data = d, family = binomial()))",modeling,192209870088845e8,528
start.time <- Sys.time(),evaluation,192209870088845e8,528
"(mmF <- glmer(against ~ (1 | projetx) + (1 | id) + agez + sexe +      uni + regiling + conx + typex + motpcf, data = d, family = binomial(),      control = glmerControl(optimizer = ""bobyqa"")))",modeling,192209870088845e8,528
end.time <- Sys.time(),evaluation,192209870088845e8,528
time.taken <- end.time - start.time,evaluation,192209870088845e8,528
time.taken,evaluation,192209870088845e8,528
"modelsPaper <- c(""mmP"", ""mmI"", ""mmF"")",evaluation,192209870088845e8,528
"models <- c(""mm0"", ""mmPtyp"", ""mmPtop"", ""mmPpcf"", ""mmP"", ""mmIsoc"",      ""mmIcul"", ""mmIpro"")",modeling,192209870088845e8,528
"save(list = modelsPaper, file = ""analysis/modelsPaper.RData"")",modeling,192209870088845e8,528
"save(list = models, file = ""analysis/models.RData"")",modeling,192209870088845e8,528
"setwd(""/Volumes/NOAA_Data/CNH/"")",setup,192209870088845e8,528
require(cluster),import,192209870088845e8,528
require(ggplot2),import,192209870088845e8,528
require(dplyr),import,192209870088845e8,528
require(reshape2),import,192209870088845e8,528
require(plyr),import,192209870088845e8,528
require(scales),import,192209870088845e8,528
require(qgraph),import,192209870088845e8,528
require(data.table),import,192209870088845e8,528
"source(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-04-20/FTL_tripTable.R"")",import,192209870088845e8,528
"FTL <- data.table(read.csv(""Data/Catch/FTL_2009-2013_2014-03-21.csv"",      as.is = TRUE))",import,192209870088845e8,528
"price_tripTable <- FTL_tripTable(FTL, type = ""price"", times = 200)",import,192209870088845e8,528
"lb_tripTable <- FTL_tripTable(FTL, type = ""lbs"", times = 200)",import,192209870088845e8,528
"log_tripTable <- FTL_tripTable(FTL, type = ""log"", times = 200)",import,192209870088845e8,528
"proportion_tripTable <- FTL_tripTable(FTL, type = ""proportion"",      times = 200)",import,192209870088845e8,528
"save(price_tripTable, file = ""Analysis/Metiers/results/2014-04-20/price_tripTable.Rdata"")",import,192209870088845e8,528
"save(lb_tripTable, file = ""Analysis/Metiers/results/2014-04-20/lb_tripTable.Rdata"")",import,192209870088845e8,528
"save(log_tripTable, file = ""Analysis/Metiers/results/2014-04-20/log_tripTable.Rdata"")",export,192209870088845e8,528
"save(proportion_tripTable, file = ""Analysis/Metiers/results/2014-04-20/proportion_tripTable.Rdata"")",export,192209870088845e8,528
"FTL <- data.table(read.csv(""Data/Catch/FTL_2009-2013_2014-03-21.csv"",      as.is = TRUE))",import,192209870088845e8,528
"setnames(FTL, names(FTL), tolower(names(FTL)))",data cleaning,192209870088845e8,528
"dates <- paste(FTL$year, FTL$month, FTL$day, sep = ""-"")",data cleaning,192209870088845e8,528
"FTL$tripID <- paste(dates, FTL$veid, sep = ""_"")",data cleaning,192209870088845e8,528
"FTL_df <- select(FTL, tripID, spid, landed_wt)",data cleaning,192209870088845e8,528
"totals <- FTL_df[, sum(landed_wt), by = tripID]",data cleaning,192209870088845e8,528
"catch <- FTL_df[, sum(landed_wt), by = c(""tripID"", ""spid"")]",data cleaning,192209870088845e8,528
"total_catch <- dcast.data.table(catch, tripID ~ spid, fun = sum)",data cleaning,192209870088845e8,528
"setkey(total_catch, tripID)",data cleaning,192209870088845e8,528
"unspecified <- unique(FTL$spid)[grep(""^U"", unique(FTL$spid))]",data cleaning,192209870088845e8,528
"other <- unique(FTL$spid)[grep(""^O"", unique(FTL$spid))]",data cleaning,192209870088845e8,528
"other <- other[-which(other == ""OLVE"" | other == ""OLV1"" | other ==      ""OTCR"" | other == ""OWFS"")]",data cleaning,192209870088845e8,528
"to_remove <- c(unspecified, other)",data cleaning,192209870088845e8,528
"cluster_pre <- total_catch[, !(names(total_catch) %in% to_remove),      with = FALSE]",data cleaning,192209870088845e8,528
"cluster_new <- subset(cluster_pre, rowSums(cluster_pre[, !""tripID"",      with = FALSE]) != 0)",data cleaning,192209870088845e8,528
dim(total_catch) - dim(cluster_new),data cleaning,192209870088845e8,528
"freq <- apply(cluster_new[, !""tripID"", with = FALSE], 2, function(x) length(which(x >      0)))",data cleaning,192209870088845e8,528
"cluster_int <- cluster_new[, !(names(cluster_new) %in% names(freq)[which(freq <      200)]), with = FALSE]",data cleaning,192209870088845e8,528
"cluster_sub <- subset(cluster_int, rowSums(cluster_int[, !""tripID"",      with = FALSE]) != 0)",data cleaning,192209870088845e8,528
dim(total_catch) - dim(cluster_sub),data cleaning,192209870088845e8,528
pca_data <- cluster_sub,data cleaning,192209870088845e8,528
"prop_cluster <- sweep(pca_data[, !""tripID"", with = FALSE], 1,      rowSums(pca_data[, !""tripID"", with = FALSE]), ""/"")",data cleaning,192209870088845e8,528
prop_cluster <- as.data.table(prop_cluster),data cleaning,192209870088845e8,528
prop_cluster$tripID <- pca_data$tripID,data cleaning,192209870088845e8,528
"setkey(prop_cluster, tripID)",data cleaning,192209870088845e8,528
"save(pca_data, file = ""Analysis/Metiers/results/2014-04-20/pca_data.Rdata"")",export,192209870088845e8,528
prop.pca_data <- prop_cluster,not sure,192209870088845e8,528
"save(prop.pca_data, file = ""Analysis/Metiers/results/2014-04-20/prop_pca_data.Rdata"")",export,192209870088845e8,528
"FTL_df <- select(FTL, tripID, spid, landed_wt, ppp)",data cleaning,192209870088845e8,528
FTL_df$value = FTL_df$ppp * FTL_df$landed_wt,data cleaning,192209870088845e8,528
"catch <- select(FTL_df, tripID, spid, value)",data cleaning,192209870088845e8,528
"catch <- filter(catch, value > 0)",data cleaning,192209870088845e8,528
catch <- as.data.table(catch),data cleaning,192209870088845e8,528
"total_catch <- dcast.data.table(catch, tripID ~ spid, fun = sum)",data cleaning,192209870088845e8,528
"setkey(total_catch, tripID)",data cleaning,192209870088845e8,528
"unspecified <- unique(FTL$spid)[grep(""^U"", unique(FTL$spid))]",data cleaning,192209870088845e8,528
"other <- unique(FTL$spid)[grep(""^O"", unique(FTL$spid))]",data cleaning,192209870088845e8,528
"other <- other[-which(other == ""OLVE"" | other == ""OLV1"" | other ==      ""OTCR"" | other == ""OWFS"")]",data cleaning,192209870088845e8,528
"to_remove <- c(unspecified, other)",data cleaning,192209870088845e8,528
"cluster_pre <- total_catch[, !(names(total_catch) %in% to_remove),      with = FALSE]",data cleaning,192209870088845e8,528
"cluster_new <- subset(cluster_pre, rowSums(cluster_pre[, !""tripID"",      with = FALSE]) != 0)",data cleaning,192209870088845e8,528
dim(total_catch) - dim(cluster_new),data cleaning,192209870088845e8,528
"freq <- apply(cluster_new[, !""tripID"", with = FALSE], 2, function(x) length(which(x >      0)))",data cleaning,192209870088845e8,528
"cluster_int <- cluster_new[, !(names(cluster_new) %in% names(freq)[which(freq <      200)]), with = FALSE]",data cleaning,192209870088845e8,528
"cluster_sub <- subset(cluster_int, rowSums(cluster_int[, !""tripID"",      with = FALSE]) != 0)",data cleaning,192209870088845e8,528
dim(total_catch) - dim(cluster_sub),data cleaning,192209870088845e8,528
price.pca_data <- cluster_sub,data cleaning,192209870088845e8,528
"save(price.pca_data, file = ""Analysis/Metiers/results/2014-04-20/price_pca_data.Rdata"")",export,192209870088845e8,528
library(dplyr),setup,501299866009504e7,529
library(ggplot2),setup,501299866009504e7,529
library(scales),setup,501299866009504e7,529
library(stringr),setup,501299866009504e7,529
library(tidyr),setup,501299866009504e7,529
"flavors = sort(c(""c4.large"", ""m4.large"", ""r3.large"", ""c3.large"",      ""m3.medium""))",setup,501299866009504e7,529
"f_str = str_sub(flavors, 1, 2)",data cleaning,501299866009504e7,529
"ref = data.frame(cpuRef = c(32, 32, 32, 32), memRef = c(32, 64,      128, 256), cpuP = rep(1, 4), memP = c(1, 2, 4, 8)) %>% group_by(memRef) %>%      mutate(scenario = paste(cpuRef, memRef, sep = ""_""), scP = paste(cpuP,          memP, sep = "":""))",setup,501299866009504e7,529
"df_analysis = read.table(file = ""../data/google/scaling-analysis-SM-SF.dat"",      header = T)",import,501299866009504e7,529
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,613133576698601e7,530
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,613133576698601e7,530
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,613133576698601e7,530
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,613133576698601e7,530
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,211303872754797e8,531
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,319315182045102e8,532
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,319315182045102e8,532
args <- commandArgs(trailingOnly = TRUE),not sure,319315182045102e8,532
idx <- as.numeric(args[1]),not sure,319315182045102e8,532
print(idx),not sure,319315182045102e8,532
"req <- c(""rstan"")",not sure,319315182045102e8,532
rm(req),not sure,319315182045102e8,532
set.seed(3749),not sure,319315182045102e8,532
sessionInfo(),not sure,319315182045102e8,532
"load(""./data/d00_ci5.Rdta"")",not sure,319315182045102e8,532
"load(""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",not sure,319315182045102e8,532
library(tidyverse),import,537187237059697e8,533
"setwd(""/Users/angelD/Downloads/git_repo/SDE2"")",setup,537187237059697e8,533
"RF14.ctrl <- read_tsv(""analysis/03_ASprofile/data/whippetResult/RF14_vs_cntrl_output.diff"") %>%      mutate(absDeltaPsi = abs(DeltaPsi)) %>% mutate(Gene = str_replace_all(string = Gene,      pattern = ""\\..+$"", replacement = """")) %>% mutate(Group = ""RF14.ctrl"")",data cleaning,537187237059697e8,533
"RF89.ctrl <- read_tsv(""analysis/03_ASprofile/data/whippetResult/RF89_vs_cntrl_output.diff"") %>%      mutate(absDeltaPsi = abs(DeltaPsi)) %>% mutate(Gene = str_replace_all(string = Gene,      pattern = ""\\..+$"", replacement = """")) %>% mutate(Group = ""RF89.ctrl"")",data cleaning,537187237059697e8,533
"ALL <- bind_rows(RF14.ctrl, RF89.ctrl) %>% mutate(Group = factor(Group))",data cleaning,537187237059697e8,533
ALL.sig <- ALL %>% filter(absDeltaPsi > 0.1 & Probability > 0.8 &      Psi_A > 0.1),data cleaning,537187237059697e8,533
sig_genes_whippet <- ALL.sig %>% filter(!duplicated(Gene)) %>%      pull(Gene),data cleaning,537187237059697e8,533
length(sig_genes_whippet),exploratory,537187237059697e8,533
"data_path <- ""analysis/05_IRfinder/data/rawIRfinderResult""",setup,537187237059697e8,533
"fns <- file.path(data_path, list.files(data_path, pattern = ""txt""))",setup,537187237059697e8,533
"setwd(""C:/Users/mcolvin/Documents/projects/Collaborations/Noxubee-Bats/analysis"")",setup,214935748372227e7,534
"source(""./src/1_global.R"")",import,214935748372227e7,534
"source(""./src/2_functions.R"")",setup,214935748372227e7,534
"source(""./src/3_load.R"")",import,214935748372227e7,534
"source(""./src/4_clean.R"")",data cleaning,214935748372227e7,534
"source(""./src/5_tables.R"")",data cleaning,214935748372227e7,534
"source(""./src/6_figures.R"")",visualization,214935748372227e7,534
"source(""./src/7_analysis.R"")",evaluation,214935748372227e7,534
"knit2html(""./src/build.Rmd"", fragment.only = TRUE)",not sure,214935748372227e7,534
"setwd(""C:/Users/mcolvin/Documents/projects/Collaborations/Noxubee-Bats/analysis"")",setup,214935748372227e7,534
"source(""~/selection/code/lib/mh_plot_lib.R"")",setup,214935748372227e7,534
"results.tag <- """"",setup,214935748372227e7,534
"version <- """"",setup,214935748372227e7,534
degf <- NA,setup,214935748372227e7,534
"what <- ""gscan""",setup,214935748372227e7,534
cA <- commandArgs(TRUE),setup,214935748372227e7,534
cutoff <- 0,setup,214935748372227e7,534
extra.plots <- c(),setup,214935748372227e7,534
"if (length(cA)) {     results.tag <- cA[1]     version <- cA[2]     degf <- as.numeric(cA[3])     if (length(cA) > 3) {         extra.plots <- strsplit(cA[4], "","", fixed = TRUE)[[1]]     } } else {     stop(""Must specify results tag as first argument"") }",data cleaning,214935748372227e7,534
"if (version == """") {     stop(""Must specify version as second argument"") }",not sure,214935748372227e7,534
"if (is.na(degf)) {     stop(""Must specify degrees of freedom as third argument"") }",not sure,214935748372227e7,534
library(tidyverse),setup,479510501725599e8,535
library(fst),setup,479510501725599e8,535
"ed_in <- read_fst(""analysis/data/derived-data/ed-ensemble-out.fst"") %>%      as_tibble()",not sure,479510501725599e8,535
"setwd(""analysis"")",setup,99490048061125e9,536
library(randomForest),setup,99490048061125e9,536
library(ica),setup,99490048061125e9,536
library(e1071),setup,99490048061125e9,536
require(Hmisc),setup,99490048061125e9,536
library(osfr),setup,99490048061125e9,536
library(tidyverse),setup,99490048061125e9,536
library(stringr),setup,99490048061125e9,536
library(gridExtra),setup,99490048061125e9,536
library(RGraphics),setup,99490048061125e9,536
"source(""Rcode/functions.r"")",import,99490048061125e9,536
"convert.factors.to.strings <- function(dataframe) {     class.data <- sapply(dataframe, class)     factor.vars <- class.data[class.data == ""factor""]     for (colname in names(factor.vars)) {         dataframe[, colname] <- as.character(dataframe[, colname])     }     return(dataframe) }",setup,99490048061125e9,536
"versions = try(system(""git tag"", intern = TRUE))",setup,99490048061125e9,536
"if (class(versions) == ""try-error"") {     versions = list.files(""../.git/refs/tags"") }",setup,99490048061125e9,536
version = versions[length(versions)],setup,99490048061125e9,536
"PMeta = osfr::path_file(""myxcv"")",setup,99490048061125e9,536
"PMeta = ""../data/Projects_metadata.csv""",not sure,99490048061125e9,536
RECREATEMINFILE = TRUE,not sure,99490048061125e9,536
NO_svm = TRUE,not sure,99490048061125e9,536
"groupingby = ""Berlin""",data cleaning,99490048061125e9,536
Npermutation = 1,modeling,99490048061125e9,536
"STICK = ""~/Desktop/HCSdata_2/Sharable""",export,99490048061125e9,536
library(stats),modeling,5240067190025e10,537
library(rcompanion),exploratory,5240067190025e10,537
"Normal <- read.csv(file = ""Analysis/Data/kc_house_data.csv"",      sep = "","", header = TRUE)",import,5240067190025e10,537
"Enriched <- read.table(file = ""Analysis/Data/MainData"", sep = "","",      header = TRUE)",import,5240067190025e10,537
"PCAData2 <- Enriched[, c(""price"", ""NumberOfBedrooms"", ""NumberOfBathrooms"",      ""LivingSpace"", ""TotalArea"", ""NumberOfFloors"", ""WaterfrontView"",      ""View"", ""YearBuilt"", condition)]",data cleaning,5240067190025e10,537
"PComp <- prcomp(PCADataAll, center = TRUE, scale = TRUE)",modeling,5240067190025e10,537
"PCADataAll2 <- predict(PComp, PCADataAll)",modeling,5240067190025e10,537
S <- cov(PCADataAll2),modeling,5240067190025e10,537
Sinv <- solve(S),modeling,5240067190025e10,537
"d <- rep(0, times = 21436)",modeling,5240067190025e10,537
"pseu <- read.csv(""analysis/data/pseudopassives-old.csv"")",import,67505003279075e9,538
pseu$isPas <- factor(pseu$selected),data cleaning,67505003279075e9,538
rm(list = ls()),setup,213598045986146e8,539
require(ggplot2),import,213598045986146e8,539
require(lme4),import,213598045986146e8,539
require(merTools),import,213598045986146e8,539
require(lmerTest),import,213598045986146e8,539
"source(system.file(""utils"", ""allFit.R"", package = ""lme4""))",setup,213598045986146e8,539
"source(""./functions/newbinplot.R"")",setup,213598045986146e8,539
require(arm),import,213598045986146e8,539
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,298019106965512e8,540
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/Data/Cleanup_05.R"",      echo = FALSE)",setup,298019106965512e8,540
dim(mn.rentals),setup,298019106965512e8,540
"source(""../../bin/sigSurvAnalysis.R"", chdir = T)",modeling,919755324721336e7,541
"gene = ""NF1""",modeling,919755324721336e7,541
"for (dis in tcga.cancer.types) {     sapply(list(c(""CDC27"", ""CREBBP""), ""CREBBP"", ""CDC27""), function(g) {         mut.sig <- survivalAnalysisByMutationAndExpression(dis,              mutGene = c(g), exprGene = c(gene))     }) }",data cleaning,919755324721336e7,541
"reports = drake_plan(benchmark_evaluation_report = knitr::knit(knitr_in(""analysis/rmd/benchmark-eval.Rmd""),      output = file_out(""analysis/rmd/output-benchmarks.md""), quiet = TRUE),      strings_in_dots = ""literals"")",communication,675319425063208e8,1
"vignat <- read.table(""/home/rishabh/Analysis/hand_analysis/prefstats/pref/_home_necto_vnds_nf_vignat-mg-existing-flows-latency.results"")",import,675319425063208e8,1
"vignat[""middlebox""] <- ""Prefetching""",data cleaning,675319425063208e8,1
"all_data <- rbind(all_data, netfilter)",data cleaning,675319425063208e8,1
"all_data <- rbind(all_data, vignat)",data cleaning,675319425063208e8,1
"all_data <- all_data[rep(row.names(all_data), all_data$V3), 1:5]",data cleaning,675319425063208e8,1
"data_summary <- summarySE(all_data, measurevar = ""V4"", groupvars = c(""V1"",      ""middlebox""))",modeling,675319425063208e8,1
"cbbPalette <- c(""#000000"", ""#E69F00"", ""#56B4E9"", ""#009E73"", ""#F0E442"",      ""#0072B2"", ""#D55E00"", ""#CC79A7"")",visualization,675319425063208e8,1
pd <- position_dodge(2),visualization,675319425063208e8,1
"p <- ggplot(data_summary, aes(x = V1/1000, y = V4/1000, group = middlebox,      color = middlebox, shape = middlebox)) + geom_point(size = 3,      position = pd) + geom_line() + geom_errorbar(aes(ymin = (V4 -      ci)/1000, ymax = (V4 + ci)/1000), width = 0.01, position = pd) +      labs(title = ""Latency for ~100Kpkt/s. 500 existing probe flows/s"") +      xlab(""# concurrent flows (K)"") + ylab(bquote(""1-way latency, only existing flows, "" *      mu * ""s"")) + theme_bw() + scale_x_continuous(breaks = c(1,      10, 20, 30, 40, 50, 60, 64)) + theme(plot.margin = unit(c(0,      0, 0, 0), ""in""))",visualization,675319425063208e8,1
"ggsave(filename = ""latency-existing-flows.png"", width = 8, height = 4)",export,675319425063208e8,1
print(p),visualization,675319425063208e8,1
"vignat <- read.table(""/home/rishabh/Analysis/hand_analysis/prefstats/pref/_home_necto_vnds_nf_vignat-mg-existing-flows-latency.results"")",import,675319425063208e8,1
"gbm <- build.tcga.ds(geneExprId = ""syn1911168"", rppaId = NULL,      gisticId = ""syn1687604"", cbioPrefix = ""gbm"", isRNASeq = TRUE,      missenseFilter = cosmicProteinPositions)",modeling,675319425063208e8,1
"kirc <- build.tcga.ds(geneExprId = ""syn1911237"", rppaId = NULL,      gisticId = ""syn1687602"", cbioPrefix = ""kirc"", isRNASeq = TRUE,      missenseFilter = cosmicProteinPositions)",modeling,675319425063208e8,1
"prad <- build.tcga.ds(geneExprId = ""syn1917323"", rppaId = NULL,      gisticId = ""syn1687640"", cbioPrefix = ""prad"", isRNASeq = TRUE,      missenseFilter = cosmicProteinPositions)",modeling,675319425063208e8,1
"idxs1 <- groupMatch(rownames(coad$geneExpr), rownames(read$geneExpr))",data cleaning,675319425063208e8,1
"idxs2 <- groupMatch(rownames(coad$rppa), rownames(read$rppa))",data cleaning,675319425063208e8,1
"idxs3 <- groupMatch(rownames(coad$gistic), rownames(read$gistic))",data cleaning,675319425063208e8,1
"crc <- list(geneExpr = cbind(coad$geneExpr[idxs1[[1]], ], read$geneExpr[idxs1[[2]],      ]), rppa = cbind(coad$rppa[idxs2[[1]], ], read$rppa[idxs2[[2]],      ]), gistic = cbind(coad$gistic[idxs3[[1]], ], read$gistic[idxs3[[2]],      ]), mut = coad$mut)",data cleaning,675319425063208e8,1
"save(brca, crc, blca, luad, skcm, lusc, laml, ucec, ov, gbm,      kirc, prad, file = ""~/data/TCGA_ds_ver4.rda"")",export,675319425063208e8,1
"replotFeatures(""./results//all_2013_08_03"")",visualization,675319425063208e8,1
"sangerNoLymph <- sanger[, !(getTissueType(sampleNames(sanger)) %in%      c(""HAEMATOPOIETIC_AND_LYMPHOID_TISSUE""))]",data cleaning,675319425063208e8,1
"ccleNoLymph <- ccle[, !(getTissueType(sampleNames(ccle)) %in%      c(""HAEMATOPOIETIC_AND_LYMPHOID_TISSUE""))]",data cleaning,675319425063208e8,1
env <- new.env(),visualization,675319425063208e8,1
"load(""~/data/TCGA_ds_ver4.rda"", envir = env)",import,675319425063208e8,1
tcgaList <- as.list(env),exploratory,675319425063208e8,1
"for (tt in names(tcgaList)) {     tcgaList[[tt]]$fmat <- build_feature_matrix(tcgaList[[tt]],          with.rppa = FALSE) }",exploratory,675319425063208e8,1
"dir.prefix <- ""./results/all_2013_08_03/""",import,675319425063208e8,1
"for (drug in colnames(pData(ccleNoLymph))) {     runDrugAnalysis(drug, ""ccle"", dir.prefix, ccleNoLymph, tcgaList) }",import,675319425063208e8,1
"for (drug in colnames(pData(sangerNoLymph))) {     runDrugAnalysis(drug, ""sanger"", dir.prefix, sangerNoLymph,          tcgaList) }",import,675319425063208e8,1
"dir.prefix <- ""results/brca/jul_12_2013/""",import,675319425063208e8,1
dir.create(dir.prefix),import,675319425063208e8,1
"prefix = ""ccle""",import,675319425063208e8,1
drugEset <- ccle,import,675319425063208e8,1
"path.chr.len = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/""",setup,63050681585446e9,1
"chr.len.list = scan(file = paste0(path.chr.len, ""chr.len.txt""))",setup,63050681585446e9,1
case.two = NA,setup,63050681585446e9,1
"try(setwd(""~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis""))",setup,219569200417027e8,1
"detect.d = read.csv(""../Results/SimplifiedPhonology/Detectability/RandomConcepts/detectability_randomConcepts_firstSegments.csv"",      stringsAsFactors = F)",import,219569200417027e8,1
mean(detect.d$z),modeling,219569200417027e8,1
sum(detect.d$z < 0),modeling,219569200417027e8,1
sum(detect.d$z < 0)/nrow(detect.d),modeling,219569200417027e8,1
mean(detect.d$z),modeling,219569200417027e8,1
sum(detect.d$p > 0.95 & detect.d$z < 0),modeling,219569200417027e8,1
sum(detect.d$p > 0.95 & detect.d$z < 0)/nrow(detect.d),exploratory,219569200417027e8,1
"write.table(dfp, file = ""../data/google/3a_colateral_violations-google-data.dat"",      row.names = F)",export,219569200417027e8,1
names(old_tbl),exploratory,219569200417027e8,1
"old_and_new <- rbind(new_tbl, old_tbl)",data cleaning,219569200417027e8,1
"old_and_new_ranked <- add_rmse_rankings(old_and_new) %>% mutate(short_name = map2_chr(variables,      lags, ~make_model_name(variables = .x, lags = .y)), lags = unlist(lags),      size = map_dbl(variables, length)) %>% dplyr::select(short_name,      origin, everything()) %>% dplyr::select(-variables) %>% arrange(rmse_1,      rmse_2, rmse_3, rmse_4, rmse_5, rmse_6, rmse_7)",data cleaning,219569200417027e8,1
names(old_and_new_ranked),data cleaning,219569200417027e8,1
"print(old_and_new_ranked, n = 30)",exploratory,219569200417027e8,1
"country_name <- ""Brasil""",data cleaning,219569200417027e8,1
forecast_exercise_year <- 2018,data cleaning,219569200417027e8,1
forecast_exercise_number <- 2,data cleaning,219569200417027e8,1
"output_path <- paste0(""./analysis/VAR_output/edd_exercises/"",      forecast_exercise_year, ""_exercise_"", forecast_exercise_number,      ""/"")",export,219569200417027e8,1
"saveRDS(old_and_new_ranked, paste0(output_path, country_name,      ""_old_and_new.rds""))",export,219569200417027e8,1
"levels(brit.act$isAdj) <- c(1, 0, 1, 0)",data cleaning,219569200417027e8,1
brit.act$isAdj <- as.numeric(as.character(brit.act$isAdj)),data cleaning,219569200417027e8,1
brit.act$NAdj <- factor(brit.act$isAdj),data cleaning,219569200417027e8,1
"levels(brit.act$NAdj) <- c(""Not Adjacent"", ""Adjacent"")",data cleaning,219569200417027e8,1
"brit.act <- subset(brit.act, (year <= 1100 & isTo == 0) | year >      1100)",data cleaning,219569200417027e8,1
"parameters <- as.data.frame(cbind(read.csv(""analysis/parameters/parameters.csv""),      read.csv(""analysis/parameters/rise_parameters.csv"")))",data cleaning,219569200417027e8,1
"brit.act <- subset(brit.act, year <= parameters$end_data)",data cleaning,219569200417027e8,1
"fit1 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit1.RDS"")",import,219569200417027e8,1
"fit2 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit2.RDS"")",import,219569200417027e8,1
"fit3 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit3-resample.RDS"")",import,219569200417027e8,1
"fit4 <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit4-resample.RDS"")",import,219569200417027e8,1
a1 <- as.data.frame(extract(fit1)),data cleaning,219569200417027e8,1
a2 <- as.data.frame(extract(fit2)),data cleaning,219569200417027e8,1
a3 <- fit3,data cleaning,219569200417027e8,1
a4 <- fit4,data cleaning,219569200417027e8,1
"load(""analysis/rdata-tmp/RoT-dat3.RData"")",import,219569200417027e8,1
"load(""analysis/rdata-tmp/RoT-dat4.RData"")",import,219569200417027e8,1
a3$s.year <- stan.dat3$t[a3$s],data cleaning,219569200417027e8,1
a3$re.year <- a3$s.year * sd(brit.act$year) + mean(brit.act$year),data cleaning,219569200417027e8,1
a4$s.year <- stan.dat4$t[a4$s],data cleaning,219569200417027e8,1
a4$re.year <- a4$s.year * sd(brit.act$year) + mean(brit.act$year),data cleaning,219569200417027e8,1
library(tidyverse),setup,261795501224697e8,1
mtcars %>% select(mpg),exploratory,261795501224697e8,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,261795501224697e8,1
f <- function() test <- 1,not sure,261795501224697e8,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,261795501224697e8,1
if (TRUE) dothing <- TRUE,not sure,261795501224697e8,1
for (i in 1:10) print(i),not sure,261795501224697e8,1
"ifly <- ""test""",not sure,261795501224697e8,1
"new_tbl <- new_tbl %>% dplyr::select(-c(lag_sel_method, t_treshold,      var_size, short_name)) %>% mutate(origin = ""new_code"") %>%      dplyr::select(vars_select(names(.), -starts_with(""rank"")))",data cleaning,399227908346802e7,1
names(new_tbl),data cleaning,399227908346802e7,1
"old_tbl <- readRDS(""./analysis/VAR_output/edd_exercises/2018_exercise_2/from_older_version_code/Brasil_by_step_12345_to_comp.rds"")",import,399227908346802e7,1
"old_tbl <- old_tbl %>% dplyr::select(variables, lags, everything()) %>%      dplyr::select(-c(rank_8, rmse_8)) %>% mutate(origin = ""old_code"") %>%      dplyr::select(vars_select(names(.), -starts_with(""rank"")))",data cleaning,399227908346802e7,1
names(old_tbl),data cleaning,399227908346802e7,1
"old_and_new <- rbind(new_tbl, old_tbl)",data cleaning,399227908346802e7,1
"old_and_new_ranked <- add_rmse_rankings(old_and_new) %>% mutate(short_name = map2_chr(variables,      lags, ~make_model_name(variables = .x, lags = .y)), lags = unlist(lags),      size = map_dbl(variables, length)) %>% dplyr::select(short_name,      origin, everything()) %>% dplyr::select(-variables) %>% arrange(rmse_1,      rmse_2, rmse_3, rmse_4, rmse_5, rmse_6, rmse_7)",data cleaning,399227908346802e7,1
names(old_and_new_ranked),data cleaning,399227908346802e7,1
"print(old_and_new_ranked, n = 30)",exploratory,399227908346802e7,1
"country_name <- ""Brasil""",data cleaning,399227908346802e7,1
forecast_exercise_year <- 2018,data cleaning,399227908346802e7,1
forecast_exercise_number <- 2,data cleaning,399227908346802e7,1
"output_path <- paste0(""./analysis/VAR_output/edd_exercises/"",      forecast_exercise_year, ""_exercise_"", forecast_exercise_number,      ""/"")",export,399227908346802e7,1
"saveRDS(old_and_new_ranked, paste0(output_path, country_name,      ""_old_and_new.rds""))",export,399227908346802e7,1
"new_tbl <- new_tbl %>% dplyr::select(-c(lag_sel_method, t_treshold,      var_size, short_name)) %>% mutate(origin = ""new_code"") %>%      dplyr::select(vars_select(names(.), -starts_with(""rank"")))",data cleaning,399227908346802e7,1
oldwd <- getwd(),setup,399227908346802e7,1
"filepath2 <- ""/Data/""",setup,399227908346802e7,1
"path <- c(getwd(), filepath2)",setup,399227908346802e7,1
"path <- paste(path, collapse = """")",setup,399227908346802e7,1
setwd(path),setup,399227908346802e7,1
"write.csv(RigCountByTrajectory, file = ""CleanRigCountByTrajectory.csv"")",export,399227908346802e7,1
setwd(oldwd),setup,399227908346802e7,1
"lines(arid2.x, two.kernel.s, type = ""l"", col = ""blue"")",visualization,399227908346802e7,1
"fit.plot.clust <- function(wp.group, scale.factor, image.metric,      clust.method, k) stat.val <- compute.image.metric(group = wp.group,      sf = scale.factor, duplicates = TRUE, frame = FALSE, FUN = image.metric,      analysis.dir = ""analysis/"")",not sure,399227908346802e7,1
d <- dist(1 - stat.val),data cleaning,399227908346802e7,1
"fit <- fit.clust(d, cluster.method, dim = k)",modeling,399227908346802e7,1
"plot.clust(fit, cluster.method)",visualization,399227908346802e7,1
"png(filename = ""/Users/chrisnavarro/Desktop/MQP/analysis/results/bartest.png"")",visualization,399227908346802e7,1
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",data cleaning,399227908346802e7,1
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,399227908346802e7,1
"for (i in seq(1, (dim(test_master_sheet)[1]))) strain <- test_master_sheet[i,      1]",not sure,399227908346802e7,1
"dir <- test_master_sheet[i, 2]",data cleaning,399227908346802e7,1
print(dir),exploratory,399227908346802e7,1
print(strain),exploratory,399227908346802e7,1
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,      "".md"", sep = """"))",communication,399227908346802e7,1
print(dir),exploratory,399227908346802e7,1
print(strain),exploratory,399227908346802e7,1
"pathVarP_hot = pathVarP[pathVarP$colocalized_somatic_mutation_count >      2 | pathVarP$PCGP, ]",not sure,399227908346802e7,1
"write.table(file = ""out/colocalize_var.tsv"", pathVarP_hot, quote = F,      sep = ""\t"", row.names = F)",export,399227908346802e7,1
"pathVarPOT_hot = pathVarPOT[pathVarPOT$colocalized_somatic_mutation_count >      2 | pathVarPOT$PCGP, ]",not sure,399227908346802e7,1
table(pathVarPOT_hot$HUGO_Symbol),exploratory,399227908346802e7,1
pathVarPOT_hot$somatic_count_plot = pathVarPOT_hot$colocalized_somatic_mutation_count,not sure,399227908346802e7,1
"pathVarPOT_hot$HGVSp_short_plot = gsub(""p."", """", pathVarPOT_hot$HGVSp_short)",not sure,399227908346802e7,1
"p = ggplot(pathVarPOT_hot, aes(y = HUGO_Symbol, x = somatic_count_plot,      color = PCGP))",visualization,399227908346802e7,1
"p = p + facet_grid(Gene_Classification ~ ., drop = T, scale = ""free_y"",      space = ""free_y"")",visualization,399227908346802e7,1
p = p + geom_point(stroke = 0) + theme_bw(),visualization,399227908346802e7,1
"p = p + geom_text_repel(aes(label = ifelse(duplicated(HGVSp_short),      NA, HGVSp_short_plot)))",visualization,399227908346802e7,1
"p = p + theme(axis.title = element_text(size = 16), axis.text.x = element_text(colour = ""black"",      size = 14, angle = 90, vjust = 0.5), axis.text.y = element_text(colour = ""black"",      size = 14))",visualization,399227908346802e7,1
p = p + scale_x_log10(),visualization,399227908346802e7,1
p = p + expand_limits(x = 0),visualization,399227908346802e7,1
"p = p + labs(x = ""Co-localizing somatic mutation count"", y = ""Gene"")",visualization,399227908346802e7,1
p,visualization,399227908346802e7,1
"fn = ""out/pathVarP_spotlight.pdf""",not sure,399227908346802e7,1
"ggsave(file = fn, width = 7, h = 5, useDingbats = FALSE)",visualization,399227908346802e7,1
"source(""./src/4_clean.R"")",setup,563516114605591e8,542
"source(""./src/5_tables.R"")",setup,563516114605591e8,542
"source(""./src/6_figures.R"")",setup,563516114605591e8,542
"source(""./src/7_analysis.R"")",setup,563516114605591e8,542
"knit2html(""./src/build.Rmd"", fragment.only = TRUE)",communication,563516114605591e8,542
x11(),setup,207452423172072e8,543
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,207452423172072e8,543
module = 1,not sure,207452423172072e8,543
me = net$MEs[[module]],not sure,207452423172072e8,543
order = order(sampleInfo$order),data cleaning,207452423172072e8,543
color = sampleInfo$color,visualization,207452423172072e8,543
x11(),not sure,207452423172072e8,543
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,207452423172072e8,543
"pdf(""9861.pdf"", width = 6, height = 3, pointsize = 8)",visualization,207452423172072e8,543
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,207452423172072e8,543
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,207452423172072e8,543
dev.off(),visualization,207452423172072e8,543
"event_locations2[20:30, 13]",exploratory,661344232270494e8,544
summary(mod2),exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""expression""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""domain""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""transcripts""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
pops <- read.table(infile_pops),import,689763019792736e8,546
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,361209801863879e8,545
"infile_probs <- paste(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/outSupportMix_chr"",      i, "".Probs.tped"", sep = """")",import,689763019792736e8,546
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,361209801863879e8,545
probs <- read.table(infile_probs),import,689763019792736e8,546
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""exons""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"probs[, 1:10]",exploratory,689763019792736e8,546
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""expression""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"GOOD <- matrix(ncol = (dim(pops)[2]), nrow = (dim(pops)[1]))",exploratory,689763019792736e8,546
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"for (j in 5:(dim(pops)[2])) for (s in 1:(dim(pops)[1])) if ((probs[s,      j]) < 0.95) GOOD[s, j] <- ""6"" else GOOD[s, j] <- pops[s,      j]",data cleaning,689763019792736e8,546
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,361209801863879e8,545
"Good <- GOOD[, -c(1:4)]",data cleaning,689763019792736e8,546
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"Good <- as.data.frame(t(cbind(pops[, 1:4], Good)))",data cleaning,689763019792736e8,546
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,361209801863879e8,545
"output <- paste(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr"",      i, ""_good"", sep = """")",data cleaning,689763019792736e8,546
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"write.table(Good, output, sep = ""\t"", quote = F, row.names = F,      col.names = F)",export,689763019792736e8,546
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"chr1_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr1_good"")",export,689763019792736e8,546
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
"chr2_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr2_good"")",import,689763019792736e8,546
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,361209801863879e8,545
"chr3_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr3_good"")",import,689763019792736e8,546
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,361209801863879e8,545
"chr4_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr4_good"")",import,689763019792736e8,546
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""domain""]])",modeling,361209801863879e8,545
"chr5_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr5_good"")",import,689763019792736e8,546
"chr6_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr6_good"")",import,689763019792736e8,546
summary(mod2),modeling,361209801863879e8,545
"chr7_good <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/Analysis/75_windows/pop_prob/chr7_good"")",import,689763019792736e8,546
"samples_n <- read.table(""~/Documents/SupporMix/Supportmix_barley_phased_1896/tpedData/land_admixed_k5.tfam.gz"",      header = F)",import,689763019792736e8,546
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"Index_odd <- seq(1, 2 * (dim(samples_n)[1]), 2)",import,689763019792736e8,546
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
head(Index_odd),data cleaning,689763019792736e8,546
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"names_odd <- as.data.frame(cbind(as.data.frame(samples_n[, 1]),      Index_odd))",exploratory,689763019792736e8,546
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""domain""]] + data[[""mcomplexity""]])",modeling,361209801863879e8,545
summary(mod2),modeling,361209801863879e8,545
head(names_odd),data cleaning,689763019792736e8,546
"Anova(mod2, type = ""2"")",exploratory,361209801863879e8,545
"colnames(names_odd) <- c(""Samples"", ""Index"")",exploratory,689763019792736e8,546
"boxplot(data[[""Ka_pos""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka_pos"", outline = F)",modeling,361209801863879e8,545
"samples_even <- as.data.frame(paste(samples_n[, 1], ""_2"", sep = """"))",data cleaning,689763019792736e8,546
"boxplot(data[[""Ka""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_neg""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"Index_even <- seq(2, 2 * (dim(samples_n)[1]), 2)",data cleaning,689763019792736e8,546
"names_even <- as.data.frame(cbind(as.data.frame(samples_even[,      1]), Index_even))",data cleaning,689763019792736e8,546
head(names_even),data cleaning,689763019792736e8,546
"boxplot(data[[""alpha""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""transcripts""]], main = ""Transcripts"",      ylab = ""Ks"", outline = F)",visualization,361209801863879e8,545
"colnames(names_even) <- c(""Samples"", ""Index"")",exploratory,689763019792736e8,546
"boxplot(data[[""Ka_pos""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_neg""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"col_names <- as.data.frame(rbind(names_even, names_odd))",data cleaning,689763019792736e8,546
"boxplot(data[[""omega_A""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""alpha""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""exons""]], main = ""Number of exons"",      ylab = ""Ks"", outline = F)",visualization,361209801863879e8,545
head(col_names),data cleaning,689763019792736e8,546
"boxplot(data[[""Ka_pos""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka_pos"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka"",      outline = F)",visualization,361209801863879e8,545
"col_names_or <- col_names[order(col_names$Index), ]",exploratory,689763019792736e8,546
"boxplot(data[[""Ka_neg""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ka_neg"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""size""]], main = ""Size"", ylab = ""omega_A"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""alpha""]] ~ data[[""size""]], main = ""Size"", ylab = ""alpha"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""size""]], main = ""Size"", ylab = ""Ks"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_pos""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""breadth""]], main = ""Breadth"", ylab = ""Ka"",      outline = F)",visualization,361209801863879e8,545
head(col_names_or),data cleaning,689763019792736e8,546
"boxplot(data[[""Ka_neg""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"col_names_or_samples <- as.data.frame(col_names_or[, 1])",exploratory,689763019792736e8,546
"boxplot(data[[""alpha""]] ~ data[[""breadth""]], main = ""Breadth"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""breadth""]], main = ""Breadth"", ylab = ""Ks"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_pos""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_neg""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""alpha""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""distance""]], main = ""Distance"",      ylab = ""Ks"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_pos""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"colnames(col_names_or_samples) <- c(""Info"")",data cleaning,689763019792736e8,546
"boxplot(data[[""Ka""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""Ka"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_neg""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"Support_results_all <- cbind(as.data.frame(chr1_good), as.data.frame(chr2_good),      as.data.frame(chr3_good), as.data.frame(chr4_good), as.data.frame(chr5_good),      as.data.frame(chr6_good), as.data.frame(chr7_good))",data cleaning,689763019792736e8,546
"boxplot(data[[""alpha""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""mcomplexity""]], main = ""Messenger complexity"",      ylab = ""Ks"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_pos""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""Ka"", outline = F)",visualization,361209801863879e8,545
dim(Support_results_all),data cleaning,689763019792736e8,546
"boxplot(data[[""Ka_neg""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
Support_results <- as.data.frame(t(Support_results_all)),exploratory,689763019792736e8,546
"boxplot(data[[""alpha""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""expression""]], main = ""Expression"",      ylab = ""Ks"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_pos""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""Ka_pos"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka""]] ~ data[[""domain""]], main = ""Domain"", ylab = ""Ka"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ka_neg""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""Ka_neg"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""omega_A""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""omega_A"", outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""alpha""]] ~ data[[""domain""]], main = ""Domain"",      ylab = ""alpha"", outline = F)",visualization,361209801863879e8,545
dim(Support_results),data cleaning,689763019792736e8,546
"boxplot(data[[""Ks""]] ~ data[[""domain""]], main = ""Domain"", ylab = ""Ks"",      outline = F)",visualization,361209801863879e8,545
"boxplot(data[[""Ks""]] ~ data[[""domain""]], main = ""Domain"", ylab = ""Ks"",      outline = F)",visualization,361209801863879e8,545
"SNP_infoNAMES <- as.data.frame(c(""Chro"", ""SNP"", ""Cumulative"",      ""Extra""))",exploratory,689763019792736e8,546
"colnames(SNP_infoNAMES) <- c(""Info"")",data cleaning,689763019792736e8,546
"col_names_all <- rbind(SNP_infoNAMES, col_names_or_samples)",data cleaning,689763019792736e8,546
"colnames(Support_results) <- col_names_all[, 1]",data cleaning,689763019792736e8,546
"Support_results[1:10, 1:10]",data cleaning,689763019792736e8,546
Index <- c(1:dim(Support_results)[1]),exploratory,689763019792736e8,546
"support_indexed <- cbind(as.data.frame(Index), as.data.frame(Support_results))",data cleaning,689763019792736e8,546
"head(support_indexed[1:10, 1:10])",data cleaning,689763019792736e8,546
summary(mod2),exploratory,361209801863879e8,545
"genetic_map <- read.table(""~/Documents/github/BarleyLandraces/Datasets/GeneticMap_iSelect_9k.txt"",      header = T)",exploratory,689763019792736e8,546
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",modeling,361209801863879e8,545
head(genetic_map),import,689763019792736e8,546
"AuROC.wave[ind.ix, 4] = auc(status, logLR)[1]",modeling,361209801863879e8,545
"genetic_map_support <- genetic_map[(genetic_map[, 1] %in% support_indexed$SNP),      ]",exploratory,689763019792736e8,546
head(genetic_map_support),data cleaning,689763019792736e8,546
ind.ix = 5,modeling,361209801863879e8,545
"gmap_and_support <- cbind(as.data.frame(genetic_map_support),      as.data.frame(support_indexed))",exploratory,689763019792736e8,546
"gmap_and_support[1:10, 1:15]",exploratory,689763019792736e8,546
"case.name = c(""fullread.4ind.over"", ""2fullread.4ind.over"", ""4fullread.4ind.over"")",data cleaning,361209801863879e8,545
"ms.null = vector(""list"", length(case.name))",data cleaning,361209801863879e8,545
"ms.alt = vector(""list"", length(case.name))",data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,361209801863879e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
ov$feature_id <- NULL,not sure,859508078312501e8,13
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,361209801863879e8,545
names(ov) <- sample_names,not sure,859508078312501e8,13
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.null = done_res,data cleaning,361209801863879e8,545
"id_split <- strsplit(rownames(ov), ""|"", fixed = TRUE)",data cleaning,859508078312501e8,13
sum(done.alt),exploratory,361209801863879e8,545
"install.packages(""doParallel"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,377887798007578e8,547
"feature_names <- sapply(id_split, function(x) paste0(x[1], ""_"",      x[6]))",data cleaning,859508078312501e8,13
sum(done.null),exploratory,361209801863879e8,545
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,377887798007578e8,547
min(logLR.alt),exploratory,361209801863879e8,545
max(logLR.alt),exploratory,361209801863879e8,545
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
ms.null[[1]] = logLR.null,data cleaning,361209801863879e8,545
ms.alt[[1]] = logLR.alt,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,361209801863879e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,361209801863879e8,545
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.null = done_res,data cleaning,361209801863879e8,545
sum(done.alt),exploratory,361209801863879e8,545
sum(done.null),exploratory,361209801863879e8,545
min(logLR.alt),exploratory,361209801863879e8,545
max(logLR.alt),exploratory,361209801863879e8,545
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
ms.null[[2]] = logLR.null,data cleaning,361209801863879e8,545
ms.alt[[2]] = logLR.alt,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,361209801863879e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,361209801863879e8,545
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.null = done_res,data cleaning,361209801863879e8,545
sum(done.alt),exploratory,361209801863879e8,545
sum(done.null),exploratory,361209801863879e8,545
min(logLR.alt),exploratory,361209801863879e8,545
max(logLR.alt),exploratory,361209801863879e8,545
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
K562_hg19_H3k9ac <- readPeakFile(K562_hg19_H3k9ac),import,801482078852132e8,548
ms.null[[3]] = logLR.null,data cleaning,361209801863879e8,545
"downloadGSMbedFiles(""GSM1003574"", destDir = ""hg19"")",import,801482078852132e8,548
ms.alt[[3]] = logLR.alt,data cleaning,361209801863879e8,545
"K562_hg19_Cbp <- ""GSM1003574_hg19_wgEncodeBroadHistoneK562Cbpsc369Pk.broadPeak""",not sure,801482078852132e8,548
"wave.null = vector(""list"", length(case.name))",data cleaning,361209801863879e8,545
"wave.alt = vector(""list"", length(case.name))",data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[1], "".Robj""))",import,361209801863879e8,545
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,801482078852132e8,548
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[1], "".Robj""))",import,361209801863879e8,545
"downloadGSMbedFiles(""GSM1003583"", destDir = ""hg19"")",import,801482078852132e8,548
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.null = done_res,data cleaning,361209801863879e8,545
sum(done.alt),exploratory,361209801863879e8,545
sum(done.null),exploratory,361209801863879e8,545
min(logLR.alt),exploratory,361209801863879e8,545
max(logLR.alt),exploratory,361209801863879e8,545
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
"K562_hg19_P300 <- ""GSM1003583_hg19_wgEncodeBroadHistoneK562P300StdPk.broadPeak""",setup,801482078852132e8,548
K562_hg19_P300 <- readPeakFile(K562_hg19_P300),import,801482078852132e8,548
wave.null[[1]] = logLR.null,data cleaning,361209801863879e8,545
wave.alt[[1]] = logLR.alt,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[2], "".Robj""))",import,361209801863879e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
"downloadGSMbedFiles(""GSM1003578"", destDir = ""hg19"")",import,801482078852132e8,548
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[2], "".Robj""))",import,361209801863879e8,545
"A549_hg19_H3k27ac <- ""GSM1003578_hg19_wgEncodeBroadHistoneA549H3k27acEtoh02Pk.broadPeak""",setup,801482078852132e8,548
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.null = done_res,data cleaning,361209801863879e8,545
A549_hg19_H3k27ac <- readPeakFile(A549_hg19_H3k27ac),import,801482078852132e8,548
sum(done.alt),exploratory,361209801863879e8,545
GSM1003578,not sure,801482078852132e8,548
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",import,723629177315161e8,145
sum(done.null),exploratory,361209801863879e8,545
min(logLR.alt),exploratory,361209801863879e8,545
max(logLR.alt),exploratory,361209801863879e8,545
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",import,723629177315161e8,145
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
wave.null[[2]] = logLR.null,data cleaning,361209801863879e8,545
wave.alt[[2]] = logLR.alt,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[3], "".Robj""))",import,361209801863879e8,545
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,723629177315161e8,145
logLR.alt = as.numeric(logLR_list),data cleaning,361209801863879e8,545
done.alt = done_res,data cleaning,361209801863879e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[3], "".Robj""))",import,361209801863879e8,545
"Cbp & P300 <- enrichPeakOverlap(hg19_Cbp, hg19_P300, TxDb = NULL,      pAdjustMethod = ""BH"", nShuffle = 1000, chainFile = NULL,      pool = TRUE, mc.cores = detectCores() - 1, verbose = TRUE)",evaluation,801482078852132e8,548
logLR.null = as.numeric(logLR_list),data cleaning,361209801863879e8,545
"K562_hg19_Cbp <- ""GSM1003574_hg19_wgEncodeBroadHistoneK562Cbpsc369Pk.broadPeak""",import,801482078852132e8,548
"for (i in seq(1, (dim(test_master_sheet)[1]))) strain <- test_master_sheet[i,      1]",data cleaning,723629177315161e8,145
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,801482078852132e8,548
done.null = done_res,data cleaning,361209801863879e8,545
"dir <- test_master_sheet[i, 2]",data cleaning,723629177315161e8,145
sum(done.alt),exploratory,361209801863879e8,545
sum(done.null),exploratory,361209801863879e8,545
min(logLR.alt),exploratory,361209801863879e8,545
print(dir),exploratory,723629177315161e8,145
max(logLR.alt),exploratory,361209801863879e8,545
print(strain),exploratory,723629177315161e8,145
min(logLR.null),exploratory,361209801863879e8,545
max(logLR.null),exploratory,361209801863879e8,545
"K562_hg19_Cbp.tagMatrix <- getTagMatrix(K562_hg19_Cbp, windows = promoter)",data cleaning,801482078852132e8,548
wave.null[[3]] = logLR.null,data cleaning,361209801863879e8,545
wave.alt[[3]] = logLR.alt,data cleaning,361209801863879e8,545
ix = 1,data cleaning,361209801863879e8,545
"tagHeatmap(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), color = ""red"")",visualization,801482078852132e8,548
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,      "".md"", sep = """"))",communication,723629177315161e8,145
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,361209801863879e8,545
print(dir),exploratory,723629177315161e8,145
print(strain),exploratory,723629177315161e8,145
peak <- K562_hg19_Cbp,setup,801482078852132e8,548
"AuROC.ms[ind.ix, 2] = auc(status, logLR)[1]",modeling,361209801863879e8,545
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,361209801863879e8,545
peak,not sure,801482078852132e8,548
"AuROC.wave[ind.ix, 2] = auc(status, logLR)[1]",modeling,361209801863879e8,545
"peakHeatmap(K562_hg19_Cbp, TxDb = txdb, upstream = 3000, downstream = 3000,      color = ""red"")",visualization,801482078852132e8,548
ix = 2,data cleaning,361209801863879e8,545
"locus.path = ""/mnt/lustre/home/shim/wavelets/data/DNase/region_01_sel_step1/""",setup,723629177315161e8,145
"output.path = paste0(multiscale.analysis.repodir, ""/analysis/simulation/sample_size/simulation_manydsQTL_v1/data/"")",export,723629177315161e8,145
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,361209801863879e8,545
"AuROC.ms[ind.ix, 3] = auc(status, logLR)[1]",modeling,361209801863879e8,545
"plotAvgProf(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), xlab = ""Genomic Region (5'->3')"",      ylab = ""Read Count Frequency"")",visualization,801482078852132e8,548
"inds.IDs = scan(paste0(WaveQTL.repodir, ""/data/Shim_2014_etc/DNaseI.individuals.oneline.txt""),      what = """")",import,723629177315161e8,145
"plotAvgProf(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), conf = 0.95,      resample = 1000)",visualization,801482078852132e8,548
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,361209801863879e8,545
"AuROC.wave[ind.ix, 3] = auc(status, logLR)[1]",modeling,361209801863879e8,545
"source(paste0(multiscale.analysis.repodir, ""/src/R/prepare.DNase.funcs.R""))",setup,723629177315161e8,145
"source(paste0(multiscale.analysis.repodir, ""/src/R/utils.R""))",setup,723629177315161e8,145
ix = 3,data cleaning,361209801863879e8,545
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,361209801863879e8,545
"data = read.table(""/mnt/lustre/home/shim/wavelets/revision/etc/simu.578.sites.txt"",      header = T)",import,723629177315161e8,145
"AuROC.ms[ind.ix, 4] = auc(status, logLR)[1]",modeling,361209801863879e8,545
chr.list = data$chr,data cleaning,723629177315161e8,145
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,361209801863879e8,545
site.list = data$site,data cleaning,723629177315161e8,145
genoIX.list = data$genoIX,data cleaning,723629177315161e8,145
"AuROC.wave[ind.ix, 4] = auc(status, logLR)[1]",modeling,361209801863879e8,545
chr = chr.list[ss],data cleaning,723629177315161e8,145
"peakAnno <- annotatePeak(K562_hg19_Cbp, tssRegion = c(-3000,      3000), TxDb = txdb, annoDb = ""org.Hs.eg.db"")",evaluation,801482078852132e8,548
site = site.list[ss],data cleaning,723629177315161e8,145
genoIX = genoIX.list[ss],data cleaning,723629177315161e8,145
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.wave""",export,361209801863879e8,545
plotAnnoPie(peakAnno),visualization,801482078852132e8,548
"write.table(AuROC.wave, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",export,361209801863879e8,545
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.ms""",export,361209801863879e8,545
vennpie(peakAnno),visualization,801482078852132e8,548
"write.table(AuROC.ms, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",export,361209801863879e8,545
"path = paste0(locus.path, ""chr"", chr, "".loc"")",export,723629177315161e8,145
upsetplot(peakAnno),visualization,801482078852132e8,548
"upsetplot(peakAnno, vennpie = TRUE)",visualization,801482078852132e8,548
"loc_dat = read.table(path, as.is = TRUE)",import,723629177315161e8,145
"plotDistToTSS(peakAnno, title = ""Distribution of transcription factor-binding loci\nrelative to TSS"")",visualization,801482078852132e8,548
"chrIX = loc_dat[site, 1]",exploratory,723629177315161e8,145
"locus.start = loc_dat[site, 2]",exploratory,723629177315161e8,145
"locus.end = loc_dat[site, 3] - 1",exploratory,723629177315161e8,145
"geno.info.path = paste0(geno.info.dir.path, ""maf_chr"", chr, ""."",      site, "".geno"")",import,723629177315161e8,145
"res = read.DNase.data(hdf5.data.path = hdf5.data.path, hdf5.mapp.path = hdf5.mapp.path,      geno.info.path = geno.info.path, inds.IDs = inds.IDs, chrIX = chrIX,      locus.start = locus.start, locus.end = locus.end)",import,723629177315161e8,145
pathway1 <- enrichPathway(as.data.frame(peakAnno)$geneId),setup,801482078852132e8,548
phenoD = ceiling(res$DNase.dat),import,723629177315161e8,145
"geno.path = paste0(geno.dir.path, ""chr"", chr, ""."", site, "".geno"")",import,723629177315161e8,145
"genoF = read.table(geno.path, as.is = TRUE)",import,723629177315161e8,145
"head(pathway1, 2)",evaluation,801482078852132e8,548
"genoD = as.numeric(genoF[genoIX, 4:73])",data cleaning,723629177315161e8,145
"climate <- climate_sim(ncdc_file_path = paste0(wd, ""inputs/ncdc_Jamestown.csv""),      lat_degrees = 46.9, elevation = 1400)",import,361209801863879e8,545
"path.output = paste0(output.path, ""pheno.dat."", ss)",communication,723629177315161e8,145
pet.VAR <- climate$pet.VAR,data cleaning,361209801863879e8,545
"write.table(phenoD, path.output, row.names = FALSE, col.names = FALSE,      quote = FALSE)",communication,723629177315161e8,145
precip.VAR <- climate$precip.VAR,data cleaning,361209801863879e8,545
"path.output = paste0(output.path, ""orig.geno.dat."", ss)",export,723629177315161e8,145
remove(climate),data cleaning,361209801863879e8,545
"cat(genoD, file = path.output)",export,723629177315161e8,145
"locus.path = ""/mnt/lustre/home/shim/wavelets/data/DNase/region_01_sel_step1/""",import,723629177315161e8,145
"cat(""Saving plot...\n"")",communication,361209801863879e8,545
"names(dapc.df) <- c(""A1"", ""A2"", ""pop"")",setup,32866217661649e7,145
"dapc.plot <- ggplot(dapc.df, aes(x = A1, y = A2, color = pop)) +      geom_point() + ylab(""LD 2"") + xlab(""LD 1"") + labs(color = ""Population"") +      theme_classic(base_size = 18) + theme(legend.position = c(0.88,      0.85)) + theme(legend.background = element_rect(colour = ""black"",      fill = ""white"", linetype = ""solid"")) + NULL",visualization,32866217661649e7,145
dapc.plot,visualization,32866217661649e7,145
"names(dapc.df) <- c(""A1"", ""A2"", ""pop"")",visualization,32866217661649e7,145
"prop_tripTable <- FTL_cp(FTL, type = ""proportion"", times = 300,      spid_remove, cmplx_remove, mgmt_remove)",modeling,32866217661649e7,145
"save(prop_tripTable, file = paste(""/Volumes/NOAA_Data/CNH/Analysis/Metiers/results/2014-05-17/prop_tripTable_"",      Sys.Date(), "".Rdata"", sep = """"))",export,32866217661649e7,145
library(ggplot2),setup,32866217661649e7,145
library(RMark),setup,32866217661649e7,145
"source(""./Analysis/ImportFormat.R"")",setup,32866217661649e7,145
"source(""./Analysis/KnownFateModels.R"")",setup,32866217661649e7,145
"p <- ggplot(TopModel.real, aes(x = Year, y = estimate))",visualization,32866217661649e7,145
"p <- p + geom_pointrange(data = TopModel.real, aes(x = Year,      y = estimate, ymin = lcl, ymax = ucl), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Daily Survival Rate"")",visualization,32866217661649e7,145
p,visualization,32866217661649e7,145
"ggsave(""./Figures/DailySurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",export,32866217661649e7,145
library(ggplot2),setup,32866217661649e7,145
"p <- ggplot(TopModel.derived, aes(x = Year, y = Estimate))",visualization,32866217661649e7,145
"p <- p + geom_pointrange(data = TopModel.derived, aes(x = Year,      y = Estimate, ymin = LCL, ymax = UCL), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Annual Survival Rate"")",visualization,32866217661649e7,145
p,visualization,32866217661649e7,145
"ggsave(""./Figures/AnnualSurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",export,32866217661649e7,145
"merged_catches <- merge(catches, total_catch, by = c(""drvid"",      ""year""), all.x = TRUE, all.y = FALSE)",exploratory,970600308617577e8,545
"e$wh.pos = l.details[match(e$glotto, l.details$glotto), ]$possiblegrammars",data cleaning,32866217661649e7,145
"yrdf <- readRDS(""/Users/efuller/1/CNH/Analysis/Metiers/results/2015-01-13/yrdf.RDS"")",data cleaning,970600308617577e8,545
"e$wh.init = e$wh.pos == ""1 Initial interrogative phrase""",data cleaning,32866217661649e7,145
"merged_df <- merge(merged_catches, yrdf[[1]][, c(""drvid"", ""year"",      ""yr_revenue"", ""simpsons"")], by = c(""drvid"", ""year""), all.x = TRUE)",import,970600308617577e8,545
"e = e[!is.na(e$wh.pos), ]",data cleaning,32866217661649e7,145
merged_df$prop_lb = merged_df$lbs/merged_df$total_lbs,data cleaning,970600308617577e8,545
"e = e[e$wh.E > 0.2, ]",data cleaning,32866217661649e7,145
"m0 = lmer(wh.E ~ 1 + (1 | fam) + (1 | area), data = e)",modeling,32866217661649e7,145
"m1 = lmer(wh.E ~ wh.init + (1 | fam) + (1 | area), data = e)",modeling,32866217661649e7,145
"anova(m0, m1)",modeling,32866217661649e7,145
"m2 = lmer(wh.E ~ 1 + all.E + (1 | fam) + (1 | area), data = e)",modeling,32866217661649e7,145
"m3 = lmer(wh.E ~ 1 + wh.init + all.E + (1 | fam) + (1 | area),      data = e)",modeling,32866217661649e7,145
"m4 = lmer(wh.E ~ 1 + wh.init * all.E + (1 | fam) + (1 | area),      data = e)",modeling,32866217661649e7,145
"anova(m2, m3, m4)",modeling,32866217661649e7,145
"interaction.plot(e$wh.init, cut(e$all.E, quantile(e$all.E, seq(0,      1, length.out = 5))), e$wh.E)",visualization,32866217661649e7,145
library(lattice),setup,32866217661649e7,145
"names(results0302) <- c(""gens"", ""xs"", ""ys"", ""cstrats"", ""pstrats"",      ""contTag"")",setup,371500995708629e8,549
merged_df$prop_dollars = merged_df$dollars/merged_df$yr_revenue,data cleaning,970600308617577e8,545
"xyplot(e$wh.E ~ e$all.E, groups = e$wh.init, type = c(""p"", ""r""),      auto.key = T)",visualization,32866217661649e7,145
"write.csv(merged_df, ""/Users/efuller/1/CNH/Analysis/forage_landings/forage_boats.csv"")",data cleaning,970600308617577e8,545
"FileThreat03Trial02 <- list(results0302, 5, 5, 0, 0.1, 0.1)",import,371500995708629e8,549
"write.csv(forage_table, ""/Users/efuller/1/CNH/Analysis/forage_landings/spid_interest.csv"")",export,970600308617577e8,545
"write.csv(forage_table, ""/Users/efuller/1/CNH/Analysis/forage_landings/spid_interest.csv"")",export,970600308617577e8,545
"m2008.tx <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = tx.2008)",modeling,32866217661649e7,145
"m2009.la <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = la.2009)",modeling,32866217661649e7,145
"m2009.tx <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = tx.2009)",modeling,32866217661649e7,145
"names(FileThreat03Trial02) <- c(""results"", ""size"", ""reps"", ""egt.version"",      ""mutation.rate"", ""death.rate"")",setup,371500995708629e8,549
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure1.R"")",setup,32866217661649e7,145
"total_catch <- ddply(all_trips, .(drvid, year), summarize, total_lbs = sum(round_wt))",exploratory,970600308617577e8,545
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure2.R"")",setup,32866217661649e7,145
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure3.R"")",setup,32866217661649e7,145
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure4.R"")",setup,32866217661649e7,145
"gens2501 <- c(1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,      4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,      5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)",import,371500995708629e8,549
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure5.R"")",setup,32866217661649e7,145
rownames(ECs) = 1:nrow(ECs),data cleaning,970600308617577e8,545
"xs2501 <- c(5, 5, 1, 2, 4, 5, 5, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1,      1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 5, 5, 5, 1, 1, 1, 1, 2, 2,      2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5)",import,371500995708629e8,549
sessionInfo(),communication,32866217661649e7,145
dim(ECs),exploratory,970600308617577e8,545
"ys2501 <- c(4, 5, 2, 2, 5, 4, 5, 2, 1, 2, 4, 5, 4, 5, 4, 5, 1,      2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 3, 4, 5, 3, 4, 5, 2, 3, 4,      5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5)",import,371500995708629e8,549
"save.image(file = paste(Sys.Date(), "".RData"", sep = """"))",export,32866217661649e7,145
"for (i in 1:nrow(ECs)) ECs[i, ] = c(MRI_list[[i]]$EC)",data cleaning,970600308617577e8,545
"cstrats2501 <- as.factor(c(2, 3, 3, 1, 3, 1, 1, 1, 2, 3, 2, 2,      2, 2, 3, 1, 2, 2, 3, 3, 2, 1, 2, 3, 3, 2, 2, 1, 1, 2, 1,      3, 2, 3, 3, 2, 3, 2, 2, 1, 3, 2, 1, 2, 2, 3, 2, 3, 1, 1,      1))",setup,371500995708629e8,549
rownames(ECs)[i] = MRI_list[[i]]$name,data cleaning,970600308617577e8,545
"pstrats2501 <- as.factor(c(4, 2, 2, 3, 4, 1, 1, 2, 3, 4, 2, 2,      3, 4, 1, 2, 1, 3, 2, 4, 3, 2, 2, 2, 2, 1, 4, 3, 3, 3, 1,      2, 2, 1, 1, 1, 3, 4, 3, 4, 3, 4, 3, 2, 1, 3, 1, 1, 1, 2,      2))",setup,371500995708629e8,549
"Bayesian_contrees <- NTS(tmp, Random51)",modeling,32866217661649e7,145
"setwd(""../../../../Analysis"")",setup,32866217661649e7,145
"contTag2501 <- c(0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,      1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,      1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0)",import,371500995708629e8,549
"save(Bayesian_contrees, file = ""../Data/R_data/TreeCmp-Bayesian_contrees.Rda"")",export,32866217661649e7,145
"ECs = ECs[, -seq(101, ncol(ECs), by = 101)]",data cleaning,970600308617577e8,545
"setwd(""../Data/Tree_Comparisons/Bayesian/treesets"")",setup,32866217661649e7,145
"results2501 <- data.frame(gens2501, xs2501, ys2501, cstrats2501,      pstrats2501, contTag2501)",setup,371500995708629e8,549
"load(""~/Dropbox/Columbia Radiogenomics/Data/TCGA_GBM_Expression.RData"")",import,970600308617577e8,545
"tmp <- TreeCmp.Read(""Chain"", verbose = TRUE)",import,32866217661649e7,145
"Bayesian_treesets <- NTS(tmp, Random51)",modeling,32866217661649e7,145
"names(results2501) <- c(""gens"", ""xs"", ""ys"", ""cstrats"", ""pstrats"",      ""contTag"")",setup,371500995708629e8,549
"setwd(""../../../../Analysis"")",setup,32866217661649e7,145
"G = t(X_TCGA[, which(colnames(X_TCGA) %in% rownames(ECs))])",data cleaning,970600308617577e8,545
"save(Bayesian_treesets, file = ""../Data/R_data/TreeCmp-Bayesian_treesets.Rda"")",export,32866217661649e7,145
"FileThreat25Trial01 <- list(results2501, 5, 5, 0, 0.1, 0.1)",import,371500995708629e8,549
"ECs = ECs[which(rownames(ECs) %in% rownames(G)), ]",data cleaning,970600308617577e8,545
"G = G[match(rownames(ECs), rownames(G)), ]",data cleaning,970600308617577e8,545
summary(veg_data),exploratory,233186006080359e7,550
"names(FileThreat25Trial01) <- c(""results"", ""size"", ""reps"", ""egt.version"",      ""mutation.rate"", ""death.rate"")",setup,371500995708629e8,549
"par_ML <- c(1, 26, 51, 76, 101)",exploratory,32866217661649e7,145
"par_MF <- c(1, 6, 11, 16, 21)",exploratory,32866217661649e7,145
"gens2502 <- c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,      4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,      5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)",import,371500995708629e8,549
"Morph = read.table(""~/Dropbox/Columbia Radiogenomics/Data/TCIA_Morphometrics.txt"",      header = TRUE)",import,970600308617577e8,545
par_MC <- c(1:5),exploratory,32866217661649e7,145
"xs2502 <- c(5, 5, 1, 2, 4, 5, 5, 1, 2, 2, 3, 3, 4, 4, 1, 1, 1,      2, 2, 2, 3, 3, 3, 3, 4, 5, 5, 5, 1, 1, 1, 1, 2, 2, 2, 2,      2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5)",import,371500995708629e8,549
"ys2502 <- c(4, 5, 2, 2, 5, 4, 5, 2, 1, 2, 4, 5, 4, 5, 4, 5, 1,      2, 3, 1, 2, 5, 1, 2, 3, 3, 4, 5, 3, 4, 5, 2, 3, 4, 5, 1,      2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5)",import,371500995708629e8,549
"par_MLMF <- c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61,      66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121)",exploratory,32866217661649e7,145
"rownames(Morph) = paste(Morph$Feature, Morph$Statistics, sep = ""_"")",data cleaning,970600308617577e8,545
"cstrats2502 <- as.factor(c(2, 3, 3, 1, 3, 1, 1, 1, 2, 3, 2, 2,      2, 2, 3, 1, 2, 2, 3, 3, 2, 1, 2, 3, 3, 2, 2, 1, 1, 2, 1,      3, 2, 3, 3, 2, 3, 2, 2, 1, 3, 2, 1, 2, 2, 3, 2, 3, 1))",setup,371500995708629e8,549
"par_MLMC <- c(1:5, 26:30, 51:55, 76:80, 101:105)",exploratory,32866217661649e7,145
"colnames(Morph) = gsub(""[.]"", ""-"", as.character(colnames(Morph)))",data cleaning,970600308617577e8,545
"cstrats2502 <- as.factor(c(2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2,      1, 2, 3, 3, 2, 1, 2, 1, 2, 2, 3, 3, 2, 1, 2, 3, 3, 2, 2,      2, 1, 1, 2, 3, 2, 1, 3, 2, 1, 2, 2, 2, 2, 1, 1, 2, 3))",setup,371500995708629e8,549
par_MFMC <- c(1:25),setup,32866217661649e7,145
"Morph = t(Morph[, -c(1:2)])",data cleaning,970600308617577e8,545
"pstrats2502 <- as.factor(c(2, 3, 4, 4, 4, 3, 2, 1, 2, 1, 3, 4,      1, 3, 1, 2, 3, 4, 3, 2, 3, 4, 3, 2, 1, 2, 3, 4, 4, 4, 3,      4, 3, 2, 1, 1, 3, 2, 4, 1, 3, 2, 1, 2, 3, 4, 3, 2, 2))",setup,371500995708629e8,549
par_MLMFMC <- c(1:125),setup,32866217661649e7,145
"Morph = Morph[which(rownames(Morph) %in% rownames(ECs)), ]",data cleaning,970600308617577e8,545
"cat(""Four different datasets have been loaded:\n\n    ML_besttrees\n    ML_bootstraps\n    Bayesian_contrees\n    Bayesian_treesets\n\nAnd 7 parameters combination sets:\n\n    par_ML ; par_MF ; par_MC ;\n    par_MLMF ; par_MLMC ; par_MFMC ;\n    par_MLMFMC ;"")",communication,32866217661649e7,145
"ECs = ECs[which(rownames(ECs) %in% rownames(Morph)), ]",data cleaning,970600308617577e8,545
"contTag2502 <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,      1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,      1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0)",import,371500995708629e8,549
"G = G[which(rownames(G) %in% rownames(Morph)), ]",data cleaning,970600308617577e8,545
"results2502 <- data.frame(gens2502, xs2502, ys2502, cstrats2502,      pstrats2502, contTag2502)",setup,371500995708629e8,549
"Geo = read.xls(""~/Dropbox/Columbia Radiogenomics/Data/TCIA_Geometrics.xls"")",import,970600308617577e8,545
"Bayesian_contrees <- NTS(tmp, Random51)",modeling,32866217661649e7,145
"names(results2502) <- c(""gens"", ""xs"", ""ys"", ""cstrats"", ""pstrats"",      ""contTag"")",import,371500995708629e8,549
rownames(Geo) = Geo$Patient.ID,data cleaning,970600308617577e8,545
"Geo = as.matrix(Geo[, -c(1, 6:11)])",data cleaning,970600308617577e8,545
"FileThreat25Trial02 <- list(results2502, 5, 5, 0, 0.1, 0.1)",setup,371500995708629e8,549
sqrt(RMS(vals)^2 - mean(vals)^2),modeling,32866217661649e7,145
"names(FileThreat25Trial02) <- c(""results"", ""size"", ""reps"", ""egt.version"",      ""mutation.rate"", ""death.rate"")",setup,371500995708629e8,549
"Geo = Geo[which(rownames(Geo) %in% rownames(ECs)), ]",data cleaning,970600308617577e8,545
SumQuad <- function(vals) clean <- na.omit(vals),data cleaning,32866217661649e7,145
"ECs = ECs[which(rownames(ECs) %in% rownames(Geo)), ]",data cleaning,970600308617577e8,545
"G = G[which(rownames(G) %in% rownames(Geo)), ]",data cleaning,970600308617577e8,545
"DatasetsListThreat03 <- list(FileThreat03Trial01$results, FileThreat03Trial02$results)",import,371500995708629e8,549
"Morph = Morph[which(rownames(Morph) %in% rownames(Geo)), ]",data cleaning,970600308617577e8,545
"DatasetsListThreat25 <- list(FileThreat25Trial01$results, FileThreat25Trial02$results)",import,371500995708629e8,549
"G = G[match(rownames(ECs), rownames(G)), ]",data cleaning,970600308617577e8,545
sqrt(sum(vals^2)),modeling,32866217661649e7,145
"ListOfThreats <- list(DatasetsListThreat03, DatasetsListThreat25)",import,371500995708629e8,549
"Geo = Geo[match(rownames(ECs), rownames(Geo)), ]",data cleaning,970600308617577e8,545
"genomeAvgData <- melt(genomeAvg, id = c(""id""))",data cleaning,233186006080359e7,550
"Morph = Morph[match(rownames(ECs), rownames(Morph)), ]",data cleaning,970600308617577e8,545
"errColIndices <- grepl(""Err"", colnames(sysData))",communication,32866217661649e7,145
dim(ECs),exploratory,970600308617577e8,545
"ThreatLevelVector <- c(3, 25)",import,371500995708629e8,549
dim(G),exploratory,970600308617577e8,545
dim(Geo),exploratory,970600308617577e8,545
dim(Morph),exploratory,970600308617577e8,545
LengthThreatLevelVector <- length(ThreatLevelVector),exploratory,371500995708629e8,549
"Phenos = read.csv(""~/Dropbox/Columbia Radiogenomics/Data/TCGA_Clinical_Traits.csv"")",import,970600308617577e8,545
errors <- sysData[errColIndices],import,32866217661649e7,145
values <- sysData[!errColIndices],import,32866217661649e7,145
ThreatLevelIndex <- c(1:LengthThreatLevelVector),setup,371500995708629e8,549
Y = Phenos,data cleaning,970600308617577e8,545
rownames(Y) = as.character(Y$Patient.ID),data cleaning,970600308617577e8,545
"rmsDiffByStudy <- with(values, aggregate(values, by = list(StudyType,      VarIndex), RMSDiff))",modeling,32866217661649e7,145
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
"Y = Y[, -1]",data cleaning,970600308617577e8,545
"maxRMSDiff <- sapply(rmsDiffByStudy[, !colnames(rmsDiffByStudy) %in%      c(""StudyType"", ""Group.1"", ""Group.2"")], max)",modeling,32866217661649e7,145
"rmsDiffAll <- sapply(values[!colnames(values) %in% c(""StudyType"")],      RMSDiff)",modeling,32866217661649e7,145
"Y = Y[which(rownames(Y) %in% rownames(ECs)), 17:18]",data cleaning,970600308617577e8,545
"rmsStdDev <- sapply(rmsDiffByStudy[, c(3:29)], RMS)",modeling,32866217661649e7,145
done.null = done_res,evaluation,300273010740057e8,551
"quadStdDev <- sapply(rmsDiffByStudy[, c(3:29)], SumQuad)",modeling,32866217661649e7,145
"ECs = ECs[which(rownames(ECs) %in% rownames(Y)), ]",data cleaning,970600308617577e8,545
"G = G[which(rownames(G) %in% rownames(Y)), ]",data cleaning,970600308617577e8,545
"Morph = Morph[which(rownames(Morph) %in% rownames(Y)), ]",data cleaning,970600308617577e8,545
sum(done.alt),evaluation,300273010740057e8,551
"Geo = Geo[which(rownames(Geo) %in% rownames(Y)), ]",data cleaning,970600308617577e8,545
"rmsStdDevOutput <- data.frame(Parameter = names(rmsStdDev), SigmaCut = rmsStdDev)",export,32866217661649e7,145
sum(done.null),evaluation,300273010740057e8,551
dim(ECs),exploratory,970600308617577e8,545
"SummaryFunction <- function(DF) Summary <- c(Proportion = mean(DF[[2]]),      sd = sd(DF[[2]]))",setup,371500995708629e8,549
"rmsStdDevOutput$Parameter <- gsub(""LamALam"", ""LA"", rmsStdDevOutput$Parameter)",modeling,32866217661649e7,145
dim(G),exploratory,970600308617577e8,545
min(pval.alt),evaluation,300273010740057e8,551
"write.csv(rmsStdDevOutput, ""SystematicsCutVariationErrors.csv"",      row.names = FALSE)",modeling,32866217661649e7,145
dim(Geo),exploratory,970600308617577e8,545
max(pval.alt),evaluation,300273010740057e8,551
dim(Y),exploratory,970600308617577e8,545
"genomeAvgData$segment <- ""genomeAvg""",not sure,233186006080359e7,550
min(pval.null),evaluation,300273010740057e8,551
dim(Morph),exploratory,970600308617577e8,545
return(Summary),visualization,371500995708629e8,549
max(pval.null),evaluation,300273010740057e8,551
"bg <- read.csv(""files/speciesCopyNumberAnalysis/BG.txt"", sep = ""\t"",      header = FALSE, row.names = NULL)",import,233186006080359e7,550
ms.null[[1]] = pval.null,evaluation,300273010740057e8,551
library(tidyverse),setup,32866217661649e7,145
"set.seed(11151990, kind = ""L'Ecuyer-CMRG"")",modeling,970600308617577e8,545
library(fst),setup,32866217661649e7,145
ms.alt[[1]] = pval.alt,evaluation,300273010740057e8,551
"ed_in <- read_fst(""analysis/data/derived-data/ed-ensemble-out.fst"") %>%      as_tibble()",import,32866217661649e7,145
"params <- read_fst(""analysis/data/derived-data/ed-params.fst"") %>%      as_tibble()",import,32866217661649e7,145
nsplit = 0.8,modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,300273010740057e8,551
"colnames(bg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,233186006080359e7,550
ndatasets = 1000,modeling,970600308617577e8,545
pval.alt = as.numeric(pval_list),evaluation,300273010740057e8,551
"params_sub <- params %>% semi_join(params %>% group_by(pft, variable) %>%      filter(sd(value) > 0) %>% ungroup() %>% distinct(variable)) %>%      rename(parameter = variable, parameter_value = value)",data cleaning,32866217661649e7,145
iter = 20000,modeling,970600308617577e8,545
done.alt = done_res,evaluation,300273010740057e8,551
burn = 10000,modeling,970600308617577e8,545
"params_wide <- spread(params_sub, variable, value)",data cleaning,32866217661649e7,145
thin = 10,modeling,970600308617577e8,545
sigma = 1,modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,300273010740057e8,551
"ed_summary <- ed_in %>% filter(lubridate::month(time) >= 6, lubridate::month(time) <=      8) %>% group_by(run_id, variable, yyear = lubridate::year(time)) %>%      summarize(value_mean = mean(value, na.rm = TRUE)) %>% ungroup(ed_summary)",data cleaning,32866217661649e7,145
"load(""~/Dropbox/Columbia Radiogenomics/Analysis/Cross_Validation_Results/GaussCV_Results.RData"")",import,970600308617577e8,545
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
done.null = done_res,evaluation,300273010740057e8,551
"time_average <- ed_summary %>% filter(yyear > 1912) %>% group_by(variable,      run_id) %>% summarize(value_mean = mean(value_mean)) %>%      left_join(params_sub)",exploratory,32866217661649e7,145
"theta = seq(from = 0.1, to = 10, by = 0.1)",modeling,970600308617577e8,545
sum(done.alt),evaluation,300273010740057e8,551
sum(done.null),evaluation,300273010740057e8,551
"bgData <- melt(bg, id = c(""id""))",data cleaning,233186006080359e7,550
registerDoParallel(cores = detectCores()),modeling,970600308617577e8,545
min(pval.alt),evaluation,300273010740057e8,551
max(pval.alt),evaluation,300273010740057e8,551
min(pval.null),evaluation,300273010740057e8,551
Res = list(),modeling,970600308617577e8,545
max(pval.null),evaluation,300273010740057e8,551
"linmod <- time_average %>% group_by(variable, pft, parameter) %>%      nest() %>% mutate(fit = map(data, possibly(lm, NULL), formula = value_mean ~      parameter_value), failed_fit = map_lgl(fit, is.null), ) %>%      filter(!failed_fit) %>% mutate(r2 = map2_dbl(fit, data, modelr::rsquare),      slope = map_dbl(fit, ~coefficients(.x)[[2]]))",modeling,32866217661649e7,145
ms.null[[2]] = pval.null,evaluation,300273010740057e8,551
ms.alt[[2]] = pval.alt,evaluation,300273010740057e8,551
"for (j in 1:ncol(Y)) y = scale(Y[!is.na(Y[, j]), j])",modeling,970600308617577e8,545
linmod %>% arrange(desc(r2)),evaluation,32866217661649e7,145
"Results = foreach(i = 1:ndatasets) %dopar% ind = sample(1:length(y),      size = nsplit * length(y), replace = FALSE)",modeling,970600308617577e8,545
"time_average %>% filter(pft == ""Early hardwood"", parameter ==      ""nonlocal_dispersal"") %>% ggplot() + aes(x = parameter_value,      y = value_mean) + geom_smooth(method = ""lm"") + geom_point() +      facet_wrap(~variable, scales = ""free_y"")",visualization,32866217661649e7,145
"bgData$segment <- ""bg""",not sure,233186006080359e7,550
"ed_summary %>% left_join(params_wide %>% filter(pft == ""Early hardwood"")) %>%      ggplot() + aes(x = yyear, y = value_mean, group = run_id,      color = nonlocal_dispersal) + geom_line(alpha = 0.5) + facet_wrap(~variable,      scales = ""free_y"") + scale_color_viridis_c()",visualization,32866217661649e7,145
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,300273010740057e8,551
"X = Geo[!is.na(Y[, j]), ]",data cleaning,970600308617577e8,545
"ggsave(""analysis/figures/prelim-ed-ensemble-out.png"", width = 8,      height = 8)",export,32866217661649e7,145
"bl <- read.csv(""files/speciesCopyNumberAnalysis/BL.txt"", sep = ""\t"",      header = FALSE, row.names = NULL)",import,233186006080359e7,550
pval.alt = as.numeric(pval_list),evaluation,300273010740057e8,551
X = scale(X),data cleaning,970600308617577e8,545
done.alt = done_res,evaluation,300273010740057e8,551
"X = cbind(rep(1, nrow(X)), X)",data cleaning,970600308617577e8,545
theta_hat = theta[cvs[[j]][2]],modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,300273010740057e8,551
"K = GaussKernel(t(X), theta_hat)",modeling,970600308617577e8,545
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
"colnames(bl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,233186006080359e7,550
"rel_f = ""plink_out/all.normal.merge.indep_50_5_2.vcf.ibd.genome.PI_HAT0.05.tsv""",import,857048418140039e8,552
done.null = done_res,evaluation,300273010740057e8,551
"rel = read.table(header = T, quote = """", sep = ""\t"", row.names = NULL,      file = rel_f, stringsAsFactors = FALSE)",import,857048418140039e8,552
sum(done.alt),evaluation,300273010740057e8,551
sum(done.null),evaluation,300273010740057e8,551
diag(K) = 1,modeling,970600308617577e8,545
min(pval.alt),evaluation,300273010740057e8,551
minmonth = min(dat$Month[dat$Year == minyear]),data cleaning,32866217661649e7,145
max(pval.alt),evaluation,300273010740057e8,551
"blData <- melt(bl, id = c(""id""))",data cleaning,233186006080359e7,550
maxyear = max(dat$Year),data cleaning,32866217661649e7,145
maxmonth = max(dat$Month[dat$Year == maxyear]),data cleaning,32866217661649e7,145
"rel_short = rel[rel$Z1 + rel$Z2 > 0.2, ]",exploratory,857048418140039e8,552
min(pval.null),evaluation,300273010740057e8,551
nmonths = length(unique(dat$year_month)),data cleaning,32866217661649e7,145
max(pval.null),evaluation,300273010740057e8,551
ms.null[[3]] = pval.null,evaluation,300273010740057e8,551
n = nrow(K),data cleaning,970600308617577e8,545
ms.alt[[3]] = pval.alt,evaluation,300273010740057e8,551
"rel_short$Sample1 = gsub(""(.12).*"", ""\\1"", as.character(rel_short$FID1))",data cleaning,857048418140039e8,552
"v = matrix(1, n, 1)",data cleaning,970600308617577e8,545
"rel_short$Sample2 = gsub(""(.12).*"", ""\\1"", as.character(rel_short$FID2))",data cleaning,857048418140039e8,552
"dat[, `:=`(Tx, S_n_CR > 0)]",data cleaning,32866217661649e7,145
"wave.null = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
"dat[, `:=`(Outcome, NOx..tons.)]",data cleaning,32866217661649e7,145
"wave.alt = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
M = diag(n) - v %*% t(v)/n,modeling,970600308617577e8,545
"colnames(ethni_short) = c(""Sample1"", ""cancer1"", ""assigned_ethnicity1"")",data cleaning,857048418140039e8,552
years = 2002:2014,data cleaning,32866217661649e7,145
"blData$segment <- ""bl""",not sure,233186006080359e7,550
K = M %*% K %*% M,modeling,970600308617577e8,545
"results = array(NA, c(5, 3, length(years)))",data cleaning,32866217661649e7,145
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/sum/pval."",      case.name[1], "".Robj""))",import,300273010740057e8,551
K = K/mean(diag(K)),modeling,970600308617577e8,545
"pg <- read.csv(""files/speciesCopyNumberAnalysis/PG.txt"", sep = ""\t"",      header = FALSE, row.names = NULL)",import,233186006080359e7,550
"rel_short_m1 = merge(rel_short, ethni_short, by = ""Sample1"",      all.x = T)",data cleaning,857048418140039e8,552
"dimnames(results) = list(c(""IPTW"", ""IPTWt50"", ""Crump"", ""OverlapWeight"",      ""PPTA""), c(""Est"", ""2.5%"", ""97.5%""), years)",data cleaning,32866217661649e7,145
pval.alt = as.numeric(pval_list),evaluation,300273010740057e8,551
"Kn = K[ind, ind]",modeling,970600308617577e8,545
done.alt = done_res,evaluation,300273010740057e8,551
"colnames(ethni_short) = c(""Sample2"", ""cancer2"", ""assigned_ethnicity2"")",data cleaning,857048418140039e8,552
"sample_sizes = matrix(NA, length(years), 3)",data cleaning,32866217661649e7,145
"dimnames(sample_sizes) = list(years, c(""Untreated"", ""Treated"",      ""Total""))",data cleaning,32866217661649e7,145
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,970600308617577e8,545
"rel_short_m2 = merge(rel_short_m1, ethni_short, by = ""Sample2"",      all.x = T)",data cleaning,857048418140039e8,552
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/sum/pval."",      case.name[1], "".Robj""))",import,300273010740057e8,551
"colnames(pg) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",data cleaning,233186006080359e7,550
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
MAE.Geo = mean(abs(y[-ind] - fhat[-ind])),modeling,970600308617577e8,545
done.null = done_res,evaluation,300273010740057e8,551
"pgData <- melt(pg, id = c(""id""))",data cleaning,233186006080359e7,550
"pgData$segment <- ""pg""",data cleaning,233186006080359e7,550
rel_short_m2$same_sample = (rel_short_m2$Sample1 == rel_short_m2$Sample2),data cleaning,857048418140039e8,552
sum(done.alt),evaluation,300273010740057e8,551
"R2_Geo = cor(y[-ind], fhat[-ind])^2",modeling,970600308617577e8,545
sum(done.null),evaluation,300273010740057e8,551
min(pval.alt),evaluation,300273010740057e8,551
max(pval.alt),evaluation,300273010740057e8,551
"for (i in 1:length(years)) dat_annual = dat[Year == years[i],      list(Outcome = sum(Outcome, na.rm = TRUE), months_with_outcome = sum(!is.na(Outcome)),          Txmonths = sum(Tx == TRUE), isCoal = Fuel.Type..Primary..x[1] ==              ""Coal"", initialYear = Initial.Year.of.Operation[1],          S_n_CR = (sum(S_n_CR) >= 6), avgNOxControls = mean(NumNOxControls -              (Tx == 1), na.rm = TRUE), scrubber = (sum(AnySO2control) >=              6), totOpTime = sum(Operating.Time), NOxemissions = sum(NOx..tons.),          SO2emissions = sum(SO2..tons.), CO2emissions = sum(CO2..short.tons.),          GrossLoad = sum(Gross.Load..MW.h.), HeatInput = sum(Heat.Input..MMBtu.),          pctCapacity = mean(Heat.Input..MMBtu./Capacity), Phase2 = Is.Phase2[1],          EPA.Region = EPA.Region[1], Latitude = Facility.Latitude.x[1],          Longitude = Facility.Longitude.x[1]), by = c(""uID"")]",exploratory,32866217661649e7,145
min(pval.null),evaluation,300273010740057e8,551
max(pval.null),evaluation,300273010740057e8,551
"rel_short_m2_same = rel_short_m2[rel_short_m2$assigned_ethnicity2 ==      rel_short_m2$assigned_ethnicity1, ]",data cleaning,857048418140039e8,552
"X = Morph[!is.na(Y[, j]), ]",data cleaning,970600308617577e8,545
wave.null[[1]] = pval.null,evaluation,300273010740057e8,551
dim(dat_annual),exploratory,32866217661649e7,145
wave.alt[[1]] = pval.alt,evaluation,300273010740057e8,551
"rel_short_m2_same_withethni = rel_short_m2_same[rel_short_m2_same$assigned_ethnicity1 !=      ""unknown"", ]",data cleaning,857048418140039e8,552
"X = scale(X, scale = FALSE)",modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/sum/pval."",      case.name[2], "".Robj""))",import,300273010740057e8,551
"pl <- read.csv(""files/speciesCopyNumberAnalysis/PL.txt"", sep = ""\t"",      header = FALSE, row.names = NULL)",import,233186006080359e7,550
"dat_annual = dat_annual[Outcome != 0, ]",data cleaning,32866217661649e7,145
"X = cbind(rep(1, nrow(X)), X)",data cleaning,970600308617577e8,545
rel_short_m2_same_withethni$assigned_ethnicity1 = as.character(rel_short_m2_same_withethni$assigned_ethnicity1),data cleaning,857048418140039e8,552
"with(dat_annual, table(months_with_outcome))",data cleaning,32866217661649e7,145
"colnames(pl) <- c(""id"", ""onetoone"", ""dup"", ""noortho"")",import,233186006080359e7,550
"p = ggplot(data = rel_short_m2_same_withethni, aes(x = Z1, y = Z2,      color = same_sample))",visualization,857048418140039e8,552
theta_hat = theta[cvs[[j]][3]],modeling,970600308617577e8,545
"dat_annual = dat_annual[months_with_outcome == 12, ]",exploratory,32866217661649e7,145
"K = GaussKernel(t(X), theta_hat)",modeling,970600308617577e8,545
"plData <- melt(pl, id = c(""id""))",data cleaning,233186006080359e7,550
"p = p + facet_grid(. ~ assigned_ethnicity1, drop = T, scales = ""free"",      space = ""free"")",visualization,857048418140039e8,552
dim(dat_annual),exploratory,32866217661649e7,145
p = p + geom_point(alpha = 0.2),visualization,857048418140039e8,552
diag(K) = 1,modeling,970600308617577e8,545
p = p + theme_bw(),visualization,857048418140039e8,552
"with(dat_annual, table(Txmonths))",exploratory,32866217661649e7,145
"p = p + xlim(0, 1) + ylim(0, 1)",visualization,857048418140039e8,552
"dat_annual = dat_annual[Txmonths %in% c(0, 12)]",exploratory,32866217661649e7,145
n = nrow(K),exploratory,970600308617577e8,545
pval.alt = as.numeric(pval_list),evaluation,300273010740057e8,551
done.alt = done_res,evaluation,300273010740057e8,551
dim(dat_annual),exploratory,32866217661649e7,145
colMeans(is.na(dat_annual)),exploratory,32866217661649e7,145
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/sum/pval."",      case.name[2], "".Robj""))",import,300273010740057e8,551
"v = matrix(1, n, 1)",data cleaning,970600308617577e8,545
p,communication,857048418140039e8,552
"fn = paste(pd, ""PanCanAtlas_rel_z1.z2_withinEthni.pdf"", sep = ""_"")",communication,857048418140039e8,552
"ggsave(file = fn, height = 5, width = 12, useDingbats = FALSE)",communication,857048418140039e8,552
M = diag(n) - v %*% t(v)/n,modeling,970600308617577e8,545
"dat_annual = dat_annual[!is.na(HeatInput) & !is.na(pctCapacity),      ]",data cleaning,32866217661649e7,145
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
K = M %*% K %*% M,modeling,970600308617577e8,545
done.null = done_res,evaluation,300273010740057e8,551
sum(done.alt),evaluation,300273010740057e8,551
K = K/mean(diag(K)),modeling,970600308617577e8,545
sum(done.null),evaluation,300273010740057e8,551
"dat_annual[, `:=`(Tx, (Txmonths == 12))]",data cleaning,32866217661649e7,145
min(pval.alt),evaluation,300273010740057e8,551
max(pval.alt),evaluation,300273010740057e8,551
"Kn = K[ind, ind]",modeling,970600308617577e8,545
min(pval.null),evaluation,300273010740057e8,551
max(pval.null),evaluation,300273010740057e8,551
"with(dat_annual, table(Tx))",exploratory,32866217661649e7,145
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,970600308617577e8,545
wave.null[[2]] = pval.null,evaluation,300273010740057e8,551
dim(dat_annual),exploratory,32866217661649e7,145
wave.alt[[2]] = pval.alt,evaluation,300273010740057e8,551
MAE.Morph = mean(abs(y[-ind] - fhat[-ind])),modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/wave/sum/pval."",      case.name[3], "".Robj""))",import,300273010740057e8,551
"dat_annual[, `:=`(Outcome, log(Outcome))]",data cleaning,32866217661649e7,145
"R2_Morph = cor(y[-ind], fhat[-ind])^2",modeling,970600308617577e8,545
"n_grp = with(dat_annual, table(Tx))",data cleaning,32866217661649e7,145
"X = G[!is.na(Y[, j]), ]",modeling,970600308617577e8,545
pval.alt = as.numeric(pval_list),evaluation,300273010740057e8,551
X = log2(X + 1),modeling,970600308617577e8,545
done.alt = done_res,evaluation,300273010740057e8,551
"sample_sizes[i, c(""Untreated"", ""Treated"")] = n_grp",data cleaning,32866217661649e7,145
"X = cbind(rep(1, nrow(X)), X)",data cleaning,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/wave/sum/pval."",      case.name[3], "".Robj""))",import,300273010740057e8,551
"rel_short_m2_same_withethni_ofinterest = rel_short_m2_same_withethni[!rel_short_m2_same_withethni$same_sample,      ]",data cleaning,857048418140039e8,552
"sample_sizes[i, ""Total""] = dim(dat_annual)[[1]]",data cleaning,32866217661649e7,145
theta_hat = theta[cvs[[j]][1]],modeling,970600308617577e8,545
"rel_short_m2_same_withethni_ofinterest = rel_short_m2_same_withethni_ofinterest[(rel_short_m2_same_withethni_ofinterest$Z2 >      0.125 & rel_short_m2_same_withethni_ofinterest$Z1 > 0.25) |      (rel_short_m2_same_withethni_ofinterest$Z1 > 0.2), ]",data cleaning,857048418140039e8,552
"with(dat_annual, t.test(Outcome ~ Tx))",modeling,32866217661649e7,145
"K = GaussKernel(t(X), theta_hat)",modeling,970600308617577e8,545
pval.null = as.numeric(pval_list),evaluation,300273010740057e8,551
diag(K) = 1,modeling,970600308617577e8,545
done.null = done_res,evaluation,300273010740057e8,551
sum(done.alt),evaluation,300273010740057e8,551
"dat_annual[, `:=`(coal_no_scrubber, (isCoal == TRUE & scrubber ==      FALSE))]",data cleaning,32866217661649e7,145
sum(done.null),evaluation,300273010740057e8,551
min(pval.alt),evaluation,300273010740057e8,551
"dat_annual[, `:=`(coal_with_scrubber, (isCoal == TRUE & scrubber ==      TRUE))]",data cleaning,32866217661649e7,145
n = nrow(K),exploratory,970600308617577e8,545
max(pval.alt),evaluation,300273010740057e8,551
min(pval.null),evaluation,300273010740057e8,551
max(pval.null),evaluation,300273010740057e8,551
"psmod = glm(Tx ~ totOpTime + HeatInput + pctCapacity + Phase2 +      avgNOxControls + coal_no_scrubber + coal_with_scrubber +      as.factor(EPA.Region), family = binomial, data = dat_annual)",modeling,32866217661649e7,145
"v = matrix(1, n, 1)",data cleaning,970600308617577e8,545
wave.null[[3]] = pval.null,evaluation,300273010740057e8,551
wave.alt[[3]] = pval.alt,evaluation,300273010740057e8,551
summary(psmod),evaluation,32866217661649e7,145
M = diag(n) - v %*% t(v)/n,modeling,970600308617577e8,545
K = M %*% K %*% M,modeling,970600308617577e8,545
pdf(hist.file.name),export,300273010740057e8,551
K = K/mean(diag(K)),modeling,970600308617577e8,545
"dat_annual[, `:=`(ps, psmod$fitted)]",evaluation,32866217661649e7,145
"Kn = K[ind, ind]",modeling,970600308617577e8,545
"tn = paste(""out/TCGA_z1_z2_relatives.tsv"", sep = ""_"")",export,857048418140039e8,552
"par(mfrow = c(4, 1))",visualization,300273010740057e8,551
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,970600308617577e8,545
"write.table(rel_short_m2_same_withethni_ofinterest, quote = F,      sep = ""\t"", row.names = FALSE, file = tn)",export,857048418140039e8,552
"hist(wave.null[[1]], main = ""null Wavelet (70)"", breaks = 47)",visualization,300273010740057e8,551
MAE.G = mean(abs(y[-ind] - fhat[-ind])),modeling,970600308617577e8,545
"hist(ms.null[[1]], main = ""null multiscale (70)"", breaks = 47)",visualization,300273010740057e8,551
"colors = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5))",visualization,32866217661649e7,145
"hist(wave.alt[[1]], main = ""alt Wavelet (70)"", breaks = 47)",visualization,300273010740057e8,551
"par(mfrow = c(1, 1))",visualization,32866217661649e7,145
"R2_G = cor(y[-ind], fhat[-ind])^2",modeling,970600308617577e8,545
"hist(ms.alt[[1]], main = ""alt multiscale (70)"", breaks = 47)",visualization,300273010740057e8,551
"X = ECs[!is.na(Y[, j]), ]",modeling,970600308617577e8,545
"rel_short_m2_same_withethni_ofinterest2 = rel_short_m2_same_withethni_ofinterest[(rel_short_m2_same_withethni_ofinterest$Z2 >      0.125 & rel_short_m2_same_withethni_ofinterest$Z1 > 0.25) |      (rel_short_m2_same_withethni_ofinterest$Z1 > 0.625), ]",data cleaning,857048418140039e8,552
"par(mfrow = c(4, 1))",visualization,300273010740057e8,551
X = scale(X),modeling,970600308617577e8,545
"with(subset(dat_annual, Tx == FALSE), hist(ps, breaks = 100,      col = colors[1], main = """", xlab = ""Estimated Propensity Scores"",      xlim = c(0, 1)))",visualization,32866217661649e7,145
"hist(wave.null[[2]], main = ""null Wavelet (30)"", breaks = 47)",visualization,300273010740057e8,551
"with(subset(dat_annual, Tx == TRUE), hist(ps, breaks = 100, col = colors[2],      add = TRUE))",visualization,32866217661649e7,145
"hist(ms.null[[2]], main = ""null multiscale (30)"", breaks = 47)",visualization,300273010740057e8,551
"X = cbind(rep(1, nrow(X)), X)",data cleaning,970600308617577e8,545
"legend(""top"", c(""Untreated"", ""Treated""), fill = colors, bty = ""n"")",visualization,32866217661649e7,145
"tn = paste(""out/TCGA_z1_z2_relatives_strict.tsv"", sep = ""_"")",not sure,857048418140039e8,552
"hist(wave.alt[[2]], main = ""alt Wavelet (30)"", breaks = 47)",visualization,300273010740057e8,551
"par(mfrow = c(2, 1))",visualization,32866217661649e7,145
"hist(ms.alt[[2]], main = ""alt multiscale (30)"", breaks = 47)",visualization,300273010740057e8,551
theta_hat = theta[cvs[[j]][4]],modeling,970600308617577e8,545
"with(subset(dat_annual, Tx == FALSE), hist(ps, xlim = c(0, 1),      breaks = 50, main = paste(n_grp[1], ""Untreated"")))",visualization,32866217661649e7,145
"write.table(rel_short_m2_same_withethni_ofinterest2, quote = F,      sep = ""\t"", row.names = FALSE, file = tn)",export,857048418140039e8,552
"K = GaussKernel(t(X), theta_hat)",modeling,970600308617577e8,545
"par(mfrow = c(4, 1))",visualization,300273010740057e8,551
"with(subset(dat_annual, Tx == TRUE), hist(ps, xlim = c(0, 1),      breaks = 50, main = paste(n_grp[2], ""Treated"")))",visualization,32866217661649e7,145
"hist(wave.null[[3]], main = ""null Wavelet (10)"", breaks = 47)",visualization,300273010740057e8,551
diag(K) = 1,modeling,970600308617577e8,545
dev.off(),visualization,32866217661649e7,145
"hist(ms.null[[3]], main = ""null multiscale (10)"", breaks = 47)",visualization,300273010740057e8,551
"hist(wave.alt[[3]], main = ""alt Wavelet (10)"", breaks = 47)",visualization,300273010740057e8,551
n = nrow(K),exploratory,970600308617577e8,545
"hist(ms.alt[[3]], main = ""alt multiscale (10)"", breaks = 47)",visualization,300273010740057e8,551
"v = matrix(1, n, 1)",data cleaning,970600308617577e8,545
"dat_annual[, `:=`(W, Tx/ps + (1 - Tx)/(1 - ps))]",evaluation,32866217661649e7,145
"with(dat_annual, hist(W, breaks = 50))",evaluation,32866217661649e7,145
dev.off(),visualization,300273010740057e8,551
M = diag(n) - v %*% t(v)/n,modeling,970600308617577e8,545
K = M %*% K %*% M,modeling,970600308617577e8,545
summary(dat_annual$W),communication,32866217661649e7,145
K = K/mean(diag(K)),modeling,970600308617577e8,545
"Kn = K[ind, ind]",modeling,970600308617577e8,545
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,970600308617577e8,545
"msm = svyglm(Outcome ~ Tx, family = ""gaussian"", design = svydesign(~1,      weights = ~W, data = dat_annual))",modeling,32866217661649e7,145
MAE.ECs = mean(abs(y[-ind] - fhat[-ind])),modeling,970600308617577e8,545
"R2_ECs = cor(y[-ind], fhat[-ind])^2",modeling,970600308617577e8,545
"fpr.wave.list = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
"tpr.wave.list = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
"IPW = c(coef(msm)[2], confint(msm)[2, ])",evaluation,32866217661649e7,145
"c(MAE.G, MAE.Morph, MAE.Geo, MAE.ECs, R2_G, R2_Morph, R2_Geo,      R2_ECs)",data cleaning,970600308617577e8,545
"fpr.ms.list = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
"tpr.ms.list = vector(""list"", length(case.name))",evaluation,300273010740057e8,551
IPW,evaluation,32866217661649e7,145
"Final = matrix(unlist(Results), nrow = ndatasets, ncol = 8, byrow = TRUE)",data cleaning,970600308617577e8,545
"mod.names = c(""Expression"", ""Morph"", ""Geo"", ""ECs"")",data cleaning,970600308617577e8,545
"for (cc in 1:length(case.name)) pval = as.numeric(c(wave.null[[cc]],      wave.alt[[cc]]))",evaluation,300273010740057e8,551
"disc = c(rep(0, 578), rep(1, 578))",evaluation,300273010740057e8,551
"colnames(Final) = c(paste(""MAE"", mod.names, sep = ""_""), paste(""R2"",      mod.names, sep = ""_""))",data cleaning,970600308617577e8,545
"bal.ipw = bal.table(dx.wts(dat_annual$ps, dat_annual, treat.var = ""Tx"",      vars = c(""totOpTime"", ""HeatInput"", ""pctCapacity"", ""Phase2"",          ""avgNOxControls"", ""coal_no_scrubber"", ""coal_with_scrubber""),      estimand = ""ATE"", x.as.weights = F))",evaluation,32866217661649e7,145
Res[[j]] = Final,data cleaning,970600308617577e8,545
if (i == 1) balance = numeric(length(years) * 6 * 9),evaluation,32866217661649e7,145
"cat(""Completed Phenotype"", j, ""\n"")",data cleaning,970600308617577e8,545
"colMeans(Res[[1]][, 1:4])",exploratory,970600308617577e8,545
"dim(balance) = c(length(years), 9, 6)",evaluation,32866217661649e7,145
"colMeans(Res[[1]][, 5:8])",exploratory,970600308617577e8,545
rnk = order(pval),evaluation,300273010740057e8,551
"colMeans(Res[[2]][, 1:4])",exploratory,970600308617577e8,545
dimnames(balance)[[2]] <- rownames(bal.ipw[[1]]),evaluation,32866217661649e7,145
"colMeans(Res[[2]][, 5:8])",exploratory,970600308617577e8,545
p.wave = pval[rnk],evaluation,300273010740057e8,551
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Gauss_SECT.RData"")",export,970600308617577e8,545
d.wave = disc[rnk],evaluation,300273010740057e8,551
fdp.wave = NULL,evaluation,300273010740057e8,551
"dimnames(balance)[[3]] <- c(""Unweighted"", ""IPTW"", ""IPTWt50"",      ""PPTA"", ""OverlapWeight"", ""Crump"")",data cleaning,32866217661649e7,145
sig.wave = NULL,evaluation,300273010740057e8,551
tpr.wave = NULL,evaluation,300273010740057e8,551
fpr.wave = NULL,evaluation,300273010740057e8,551
"balance[i, , ""Unweighted""] = bal.ipw[[1]][, ""std.eff.sz""]",evaluation,32866217661649e7,145
"balance[i, , ""IPTW""] = bal.ipw[[2]][, ""std.eff.sz""]",evaluation,32866217661649e7,145
uni.p.wave = unique(p.wave),evaluation,300273010740057e8,551
"dat_annual[, `:=`(Wt50, ifelse(W > 50, 50, W))]",evaluation,32866217661649e7,145
"print(sprintf(""SD ND difference is %f, standard error estimate: %f"",      ndsd$meandiff, ndsd$stderr))",communication,970600308617577e8,545
"with(dat_annual, table(Wt50 == 50))",communication,32866217661649e7,145
for (i in 1:length(uni.p.wave)) wh = which(p.wave <= uni.p.wave[i]),evaluation,300273010740057e8,551
sig.wave[i] = length(wh),evaluation,300273010740057e8,551
"ndad <- b.diffste(adall, ndall, 1024)",modeling,970600308617577e8,545
"msmt50 = svyglm(Outcome ~ Tx, family = ""gaussian"", design = svydesign(~1,      weights = ~Wt50, data = dat_annual))",modeling,32866217661649e7,145
fdp.wave[i] = 1 - (sum(d.wave[wh])/length(wh)),evaluation,300273010740057e8,551
"print(sprintf(""AD ND difference is %f, standard error estimate: %f"",      ndad$meandiff, ndad$stderr))",communication,970600308617577e8,545
"IPWt50 = c(coef(msmt50)[2], confint(msmt50)[2, ])",evaluation,32866217661649e7,145
tpr.wave[i] = sum(d.wave[wh])/578,evaluation,300273010740057e8,551
IPWt50,evaluation,32866217661649e7,145
fpr.wave[i] = (length(wh) - sum(d.wave[wh]))/578,evaluation,300273010740057e8,551
"sdad <- b.diffste(adall, sdall, 1024)",modeling,970600308617577e8,545
fpr.wave.list[[cc]] = fpr.wave,evaluation,300273010740057e8,551
tpr.wave.list[[cc]] = tpr.wave,evaluation,300273010740057e8,551
"balance[i, , ""IPTWt50""] = bal.table(dx.wts(dat_annual$Wt50, dat_annual,      treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"", ""pctCapacity"",          ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"", ""coal_with_scrubber""),      estimand = ""ATE"", x.as.weights = T))[[2]][, ""std.eff.sz""]",evaluation,32866217661649e7,145
"print(sprintf(""AD SD difference is %f, standard error estimate: %f"",      sdad$meandiff, sdad$stderr))",communication,970600308617577e8,545
"for (cc in 1:length(case.name)) pval = as.numeric(c(ms.null[[cc]],      ms.alt[[cc]]))",evaluation,300273010740057e8,551
"crum = crump(Y = dat_annual$Outcome, A = dat_annual$Tx, PS = dat_annual$ps)",modeling,32866217661649e7,145
"disc = c(rep(0, 578), rep(1, 578))",evaluation,300273010740057e8,551
rnk = order(pval),evaluation,300273010740057e8,551
"crum[c(""est"", ""CI"")]",evaluation,32866217661649e7,145
p.ms = pval[rnk],evaluation,300273010740057e8,551
"print(""-----------------------------------------"")",not sure,970600308617577e8,545
d.ms = disc[rnk],evaluation,300273010740057e8,551
fdp.ms = NULL,evaluation,300273010740057e8,551
"balance[i, , ""Crump""] = bal.table(dx.wts(crum$w, dat_annual,      treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"", ""pctCapacity"",          ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"", ""coal_with_scrubber""),      estimand = ""ATE"", x.as.weights = T))[[2]][, ""std.eff.sz""]",evaluation,32866217661649e7,145
sig.ms = NULL,evaluation,300273010740057e8,551
tpr.ms = NULL,evaluation,300273010740057e8,551
fpr.ms = NULL,evaluation,300273010740057e8,551
uni.p.ms = unique(p.ms),evaluation,300273010740057e8,551
"print(""Studentized bootstrapped hypothesis test (Algo 16.2)"")",communication,970600308617577e8,545
"overlap_wt = ato(Y = dat_annual$Outcome, A = dat_annual$Tx, PS = dat_annual$ps)",modeling,32866217661649e7,145
for (i in 1:length(uni.p.ms)) wh = which(p.ms <= uni.p.ms[i]),evaluation,300273010740057e8,551
sig.ms[i] = length(wh),evaluation,300273010740057e8,551
"ndsd_tst <- b.studentized_ttest(sdall, ndall, 1000)",modeling,970600308617577e8,545
"overlap_wt[c(""ato"", ""CI"")]",evaluation,32866217661649e7,145
fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh)),evaluation,300273010740057e8,551
"b.showsiglev(ndsd_tst, ""SD vs ND"")",modeling,970600308617577e8,545
tpr.ms[i] = sum(d.ms[wh])/578,evaluation,300273010740057e8,551
"ndad_tst <- b.studentized_ttest(adall, ndall, 1000)",modeling,970600308617577e8,545
fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/578,evaluation,300273010740057e8,551
"balance[i, , ""OverlapWeight""] = bal.table(dx.wts(overlap_wt$w,      dat_annual, treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"",          ""pctCapacity"", ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"",          ""coal_with_scrubber""), estimand = ""ATE"", x.as.weights = T))[[2]][,      ""std.eff.sz""]",evaluation,32866217661649e7,145
"b.showsiglev(ndad_tst, ""AD vs ND"")",modeling,970600308617577e8,545
fpr.ms.list[[cc]] = fpr.ms,evaluation,300273010740057e8,551
"sdad_tst <- b.studentized_ttest(adall, sdall, 1000)",modeling,970600308617577e8,545
"X = model.matrix(psmod)[, -1]",modeling,32866217661649e7,145
tpr.ms.list[[cc]] = tpr.ms,evaluation,300273010740057e8,551
"b.showsiglev(sdad_tst, ""AD vs SD"")",modeling,970600308617577e8,545
"out.design = PPTA.design(A = dat_annual$Tx, X = X, M = 1000)",modeling,32866217661649e7,145
"save(""fpr.wave.list"", ""tpr.wave.list"", ""fpr.ms.list"", ""tpr.ms.list"",      file = output.path)",export,300273010740057e8,551
"out.analysis = PPTA.analysis(Y = dat_annual$Outcome, out = out.design,      Qburn = 100, Q = 1000, outcome.dist = ""gaussian"")",modeling,32866217661649e7,145
pdf(ROC.file.name),export,300273010740057e8,551
"print(""-----------------------------------------"")",not sure,970600308617577e8,545
xmax = 1,evaluation,300273010740057e8,551
"cond.means = apply(out.analysis$mcmc[, 2, ], 2, mean)",evaluation,32866217661649e7,145
"out.ppta = c(mean(cond.means), quantile(out.analysis$mcmc[, 2,      ], c(0.025, 0.975)))",evaluation,32866217661649e7,145
if (T) S = out.design$S,evaluation,32866217661649e7,145
S[is.na(S)] = 0,evaluation,32866217661649e7,145
"data_mat = load_data(""example_data/other_data/F_subtract.txt"")",import,970600308617577e8,545
"temp2 = apply(S, 2, function(x) bal.table(dx.wts(1 * x, dat_annual,      treat.var = ""Tx"", vars = c(""totOpTime"", ""HeatInput"", ""pctCapacity"",          ""Phase2"", ""avgNOxControls"", ""coal_no_scrubber"", ""coal_with_scrubber""),      estimand = ""ATE"", x.as.weights = T))[[2]][, ""std.eff.sz""])",evaluation,32866217661649e7,145
"event_locations1 = read.csv(""analysis/F_subtract/replicates/F_subtract_1.csv"")",import,970600308617577e8,545
"event_locations2 = read.csv(""analysis/F_subtract/replicates/F_subtract_2.csv"")",import,970600308617577e8,545
ymax = 1,visualization,300273010740057e8,551
"event_locations3 = read.csv(""analysis/F_subtract/replicates/F_subtract_3.csv"")",import,970600308617577e8,545
"balance[i, , ""PPTA""] = rowMeans(temp2, na.rm = T)",evaluation,32866217661649e7,145
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",visualization,300273010740057e8,551
"results[""IPTW"", , i] = IPW",evaluation,32866217661649e7,145
"results[""IPTWt50"", , i] = IPWt50",evaluation,32866217661649e7,145
"results[""Crump"", , i] = c(crum$est, crum$CI)",evaluation,32866217661649e7,145
"get_event_group <- function(event_locations_temp, event_group) return(sapply(1:ncol(event_locations_temp),      function(i) event_locations_temp[, i] %in% event_group))",data cleaning,970600308617577e8,545
"results[""OverlapWeight"", , i] = c(overlap_wt$ato, overlap_wt$CI)",evaluation,32866217661649e7,145
"results[""PPTA"", , i] = out.ppta",evaluation,32866217661649e7,145
"get_shared_all <- function(event_group) return((get_event_group(event_locations1,      event_group) & get_event_group(event_locations2, event_group)) &      get_event_group(event_locations3, event_group))",data cleaning,970600308617577e8,545
"get_shared_2 <- function(event_group) return((get_event_group(event_locations1,      event_group) + get_event_group(event_locations2, event_group) +      get_event_group(event_locations3, event_group)) >= 2)",data cleaning,970600308617577e8,545
"print(paste(""Year"", years[i], ""completed.""))",communication,32866217661649e7,145
"shared_all = lapply(list(c(2, 3, 1.5), -c(2, 3, 1.5), c(1, 3,      -1.5), -c(1, 3, -1.5)), function(i) get_shared_all(i))",data cleaning,970600308617577e8,545
"shared_2 = lapply(list(c(2, 3, 1.5), -c(2, 3, 1.5), c(1, 3, -1.5),      -c(1, 3, -1.5)), function(i) get_shared_2(i))",data cleaning,970600308617577e8,545
"points(c(0, fpr.ms.list[[1]]), c(0, tpr.ms.list[[1]]), type = ""l"",      col = ""blue"")",visualization,300273010740057e8,551
"points(c(0, fpr.wave.list[[1]]), c(0, tpr.wave.list[[1]]), type = ""l"",      col = ""skyblue"")",visualization,300273010740057e8,551
create_event_locations_shared <- function(shared_list) event_locations_shared = event_locations1 *      0,data cleaning,970600308617577e8,545
"balance[, , ""Unweighted""]",communication,32866217661649e7,145
"points(c(0, fpr.ms.list[[2]]), c(0, tpr.ms.list[[2]]), type = ""l"",      col = ""darkgreen"")",visualization,300273010740057e8,551
"event_locations_shared[which(shared_list[[1]], arr.ind = T)] = 2",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[2]], arr.ind = T)] = -2",data cleaning,970600308617577e8,545
bal = data.frame(),not sure,32866217661649e7,145
"event_locations_shared[which(shared_list[[3]], arr.ind = T)] = 1",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[4]], arr.ind = T)] = -1",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[1]] & shared_list[[3]],      arr.ind = T)] = 3",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[1]] & shared_list[[4]],      arr.ind = T)] = 1.5",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[2]] & shared_list[[4]],      arr.ind = T)] = -3",data cleaning,970600308617577e8,545
"event_locations_shared[which(shared_list[[2]] & shared_list[[3]],      arr.ind = T)] = -1.5",data cleaning,970600308617577e8,545
return(event_locations_shared),data cleaning,970600308617577e8,545
event_locations_shared_all = create_event_locations_shared(shared_all),data cleaning,970600308617577e8,545
"for (i in 1:dim(balance)[1]) for (j in 1:dim(balance)[2]) for (k in 1:dim(balance)[3]) bal = rbind(bal,      data.frame(Year = years[i], Balance = balance[i, j, k], Estimator = dimnames(balance)[[3]][k],          Covariate = dimnames(balance)[[2]][j]))",evaluation,32866217661649e7,145
event_locations_shared_2 = create_event_locations_shared(shared_2),data cleaning,970600308617577e8,545
"concurrent_events_all = find_concurrent_events(event_locations_shared_all,      2, event_types = c(-1, 1))",data cleaning,970600308617577e8,545
"concurrent_events_2 = find_concurrent_events(event_locations_shared_2,      2, event_types = c(-1, 1))",data cleaning,970600308617577e8,545
setDT(bal),evaluation,32866217661649e7,145
"ggplot(bal[, list(Balance = mean(abs(Balance))), by = .(Estimator,      Year)]) + geom_line(aes(y = Balance, x = Year, color = Estimator,      group = interaction(Estimator)))",visualization,32866217661649e7,145
"ggplot(bal[, list(Balance = max(abs(Balance))), by = .(Estimator,      Year)]) + geom_line(aes(y = Balance, x = Year, color = Estimator,      group = interaction(Estimator)))",visualization,32866217661649e7,145
"pdf(""analysis/F_subtract/replicates/replicate_shared_events.pdf"",      width = 14, height = 14)",export,970600308617577e8,545
"make_visual(data_mat, event_locations_shared_all, concurrent_events_all,      log_colors = T, diverging = T)",visualization,970600308617577e8,545
sample_sizes,communication,32866217661649e7,145
"make_visual(data_mat, event_locations_shared_2, concurrent_events_2,      log_colors = T, diverging = T)",visualization,970600308617577e8,545
"range(sample_sizes[, ""Total""])",communication,32866217661649e7,145
dev.off(),visualization,970600308617577e8,545
"tx_prev = sample_sizes[, ""Treated""]/sample_sizes[, ""Total""]",communication,32866217661649e7,145
tx_prev,communication,32866217661649e7,145
range(tx_prev),communication,32866217661649e7,145
"points(c(0, fpr.wave.list[[2]]), c(0, tpr.wave.list[[2]]), type = ""l"",      col = ""green"")",visualization,300273010740057e8,551
"event_locations1[20:30, 13]",data cleaning,970600308617577e8,545
"event_locations2[20:30, 13]",data cleaning,970600308617577e8,545
"points(c(0, fpr.ms.list[[3]]), c(0, tpr.ms.list[[3]]), type = ""l"",      col = ""red"")",visualization,300273010740057e8,551
"event_locations3[20:30, 13]",data cleaning,970600308617577e8,545
"points(c(0, fpr.wave.list[[3]]), c(0, tpr.wave.list[[3]]), type = ""l"",      col = ""orange"")",visualization,300273010740057e8,551
"source(""Rcode/Timewindows_utilisation.r"")",setup,970600308617577e8,545
"alldata = left_join(Multi_datainput, metadata)",data cleaning,970600308617577e8,545
alldata = convert.factors.to.strings(alldata),data cleaning,970600308617577e8,545
"alldata_conc = rbind(alldata_conc, alldata)",data cleaning,970600308617577e8,545
"alldata_conc = rbind(alldata, alldata_conc)",data cleaning,970600308617577e8,545
unique(alldata_conc$genotype),exploratory,970600308617577e8,545
"results_dat = adply(results, c(1, 3))",communication,32866217661649e7,145
unique(alldata_conc$treatment),exploratory,970600308617577e8,545
unique(alldata_conc$Title),exploratory,970600308617577e8,545
"names(results_dat) = c(""Method"", ""year"", ""Est"", ""Lower"", ""Upper"")",communication,32866217661649e7,145
"p = ggplot(data = results_dat, aes(x = year, y = Est, group = Method,      color = Method)) + geom_point() + geom_line()",visualization,32866217661649e7,145
"p = p + geom_ribbon(aes(ymin = results_dat$Lower, ymax = results_dat$Upper,      group = results_dat$Method), linetype = 2, alpha = 0.1)",visualization,32866217661649e7,145
"Meta_analysis_data = alldata_conc %>% filter(genotype %in% c(""WT"",      ""C57BL/6J"", ""C57bl/6J"", ""129/C57BL6J"", ""C57BL/6N"")) %>% filter(treatment %in%      c(""CTL"", ""0"", ""none""))",data cleaning,970600308617577e8,545
p,visualization,32866217661649e7,145
"Meta_analysis_data$age = -difftime(Meta_analysis_data$animal_birthdate,      Meta_analysis_data$date, units = ""weeks"")",data cleaning,970600308617577e8,545
"PCAdat = Meta_analysis_data[, 2:163]",data cleaning,970600308617577e8,545
"metadata = Meta_analysis_data[, c(1, 164:ncol(Meta_analysis_data))]",data cleaning,970600308617577e8,545
"out <- lapply(PCAdat, function(x) length(unique(x)))",data cleaning,970600308617577e8,545
"NAC = lapply(PCAdat, function(x) length(unique(x)))",data cleaning,970600308617577e8,545
"legend(0.7, 0.3, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10""), col = c(""blue"", ""skyblue"",      ""darkgreen"", ""green"", ""red"", ""orange""), lty = c(1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,300273010740057e8,551
"sapply(PCAdat, function(x) !any(is.na(x)))",data cleaning,970600308617577e8,545
want <- which(!out < 2),data cleaning,970600308617577e8,545
"PCAdat[, want]",data cleaning,970600308617577e8,545
"input.pca <- prcomp(PCAdat[, want], center = TRUE, scale. = TRUE)",modeling,970600308617577e8,545
Moddata = as.data.frame(input.pca$x),data cleaning,970600308617577e8,545
Moddata$age = as.numeric(Meta_analysis_data$age),data cleaning,970600308617577e8,545
Moddata$genotype = as.factor(Meta_analysis_data$genotype),data cleaning,970600308617577e8,545
"p = ggplot(aes(y = PC1, x = age, color = genotype), data = Moddata)",visualization,970600308617577e8,545
p = p + geom_point(),visualization,970600308617577e8,545
"ggsave(""materialforpaper/metaanalysis.pdf"")",visualization,970600308617577e8,545
"quantilesN <- quantile(RawNData$SampleSize, c(0.25, 0.5, 0.75))",modeling,970600308617577e8,545
meanN <- mean(RawNData$SampleSize),exploratory,970600308617577e8,545
sdN <- sd(RawNData$SampleSize),modeling,970600308617577e8,545
"dsHeight1 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst"", ""age_ht""))",data cleaning,970600308617577e8,545
"dsHeight2 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst"", ""age_ht""))",data cleaning,970600308617577e8,545
"colnames(dsHeight1) <- c(""CID"", ""CRace1"", ""CGender1"", ""HtSt1"",      ""AgeHt1"")",data cleaning,970600308617577e8,545
"colnames(dsHeight2) <- c(""CID"", ""CRace2"", ""CGender2"", ""HtSt2"",      ""AgeHt2"")",data cleaning,970600308617577e8,545
rm(dsHeight),data cleaning,970600308617577e8,545
"dsLeftHand <- merge(x = dsLinksLeftHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",data cleaning,970600308617577e8,545
"dsLeftHand <- merge(x = dsLeftHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",data cleaning,970600308617577e8,545
"dsRightHand <- merge(x = dsLinksRightHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",data cleaning,970600308617577e8,545
"dsRightHand <- merge(x = dsRightHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",data cleaning,970600308617577e8,545
"rm(dsLinksLeftHand, dsLinksRightHand, dsHeight1, dsHeight2)",data cleaning,970600308617577e8,545
"ds <- rbind(dsLeftHand, dsRightHand)",data cleaning,970600308617577e8,545
"rm(dsLeftHand, dsRightHand)",data cleaning,970600308617577e8,545
"write.csv(ds, pathOutput)",export,970600308617577e8,545
ageFloor <- 19,data cleaning,970600308617577e8,545
"ds <- subset(ds, AgeHt1 >= ageFloor & AgeHt2 >= ageFloor)",data cleaning,970600308617577e8,545
"ds[is.na(ds$R), ""R""] <- 0.375",data cleaning,970600308617577e8,545
library(e1071),setup,970600308617577e8,545
"brief <- summary(lm(HtSt1 ~ 1 + HtSt2 + R + HtSt2 * R, data = ds))",modeling,970600308617577e8,545
coeficients <- coef(brief),modeling,970600308617577e8,545
count <- length(brief$residuals),modeling,970600308617577e8,545
"hSquared <- coeficients[""HtSt2:R"", ""Estimate""]",modeling,970600308617577e8,545
"cSquared <- coeficients[""HtSt2"", ""Estimate""]",modeling,970600308617577e8,545
eSquared <- 1 - hSquared - cSquared,modeling,970600308617577e8,545
mean(ds$HtSt1),exploratory,970600308617577e8,545
sd(ds$HtSt1),exploratory,970600308617577e8,545
skewness(ds$HtSt1),modeling,970600308617577e8,545
"dsResult <- data.frame(N = count, H2 = hSquared, C2 = cSquared,      E2 = eSquared, Mean = mean(ds$HtSt1), SD = sd(ds$HtSt1),      Skew = skewness(ds$HtSt1))",data cleaning,970600308617577e8,545
if (length(wh) > 0) if (length(wh) > 1) case.two = TRUE,exploratory,970600308617577e8,545
res$st.posi[wh] = 5,data cleaning,970600308617577e8,545
res$en.posi[wh] = 5 + size - 1,data cleaning,970600308617577e8,545
"res = data.frame(chr = res$chr, st.posi = res$st.posi, en.posi = res$en.posi)",data cleaning,970600308617577e8,545
"write.table(res, file = paste0(path, Treatment, ""."", size, "".chr"",      chr, "".locus""), col.names = TRUE, row.names = FALSE, quote = FALSE)",export,970600308617577e8,545
case.two,exploratory,970600308617577e8,545
problem.site,exploratory,970600308617577e8,545
"fwdCMAP = cmapR::parse.gctx(""data-raw/CD_signatures_full_42809x22268.gctx"")",import,970600308617577e8,545
gc(),not sure,970600308617577e8,545
"instances = readr::read_csv(""data-raw/Drugs_metadata.csv"")",import,970600308617577e8,545
"fwdMetadata = readr::read_csv(""data-raw/CD_signature_metadata.csv"")",import,970600308617577e8,545
"fwdMetadata %<>% mutate(pert_iname = instances$pert_iname[match(pert_id,      instances$pert_id)])",data cleaning,970600308617577e8,545
"fwdGeneAnnots = readr::read_csv(""data-raw/Probes_full_metadata.csv"")",data cleaning,970600308617577e8,545
fwdMatrix = fwdCMAP@mat,data cleaning,970600308617577e8,545
"L1000geneAnnots = readr::read_tsv(""/space/scratch/nlim/LINCS/GSE92742-Level5/Gene_Info.txt"")",import,970600308617577e8,545
L1000geneAnnots %<>% filter(pr_is_bing == 1),data cleaning,970600308617577e8,545
goodGenes = fwdGeneAnnots$pr_gene_symbol %in% L1000geneAnnots$pr_gene_symbol,data cleaning,970600308617577e8,545
"fwdGeneAnnots = fwdGeneAnnots[goodGenes, ]",data cleaning,970600308617577e8,545
"fwdMatrix = fwdMatrix[, goodGenes]",data cleaning,970600308617577e8,545
all(colnames(fwdMatrix) == fwdGeneAnnots$pr_id),data cleaning,970600308617577e8,545
all(rownames(fwdMatrix) == fwdMetadata$sig_id),data cleaning,970600308617577e8,545
"fwdRanks = fwdMatrix %>% apply(1, frankv, order = -1)",data cleaning,970600308617577e8,545
rownames(fwdRanks) = colnames(fwdMatrix),data cleaning,970600308617577e8,545
all(colnames(fwdRanks) == fwdMetadata$sig_id),data cleaning,970600308617577e8,545
"saveRDS(fwdRanks, ""analysis/00.cmapRanks/FWDranks.rds"")",export,970600308617577e8,545
"saveRDS(fwdGeneAnnots, ""analysis/00.cmapRanks/FWDgeneAnnots.rds"")",export,970600308617577e8,545
"saveRDS(fwdMetadata, ""analysis/00.cmapRanks/FWDinstances.rds"")",export,970600308617577e8,545
return(c),exploratory,970600308617577e8,545
"d.sim <- apply(outputs, 1, csim)",modeling,970600308617577e8,545
"pdf(""test_2.pdf"")",export,970600308617577e8,545
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"",      main = paste(""A="", no.agents, "" F="", no.features, sep = """"))",visualization,970600308617577e8,545
dev.off(),visualization,970600308617577e8,545
"other <- other[-which(other == ""OLVE"" | other == ""OLV1"" | other ==      ""OTCR"" | other == ""OWFS"")]",data cleaning,970600308617577e8,545
"to_remove <- c(unspecified, other)",data cleaning,970600308617577e8,545
"cluster_pre <- total_catch[, !(names(total_catch) %in% to_remove),      with = FALSE]",data cleaning,970600308617577e8,545
"cluster_new <- subset(cluster_pre, rowSums(cluster_pre[, !""tripID"",      with = FALSE]) != 0)",data cleaning,970600308617577e8,545
dim(total_catch) - dim(cluster_new),data cleaning,970600308617577e8,545
"freq <- apply(cluster_new[, !""tripID"", with = FALSE], 2, function(x) length(which(x >      0)))",data cleaning,970600308617577e8,545
"cluster_int <- cluster_new[, !(names(cluster_new) %in% names(freq)[which(freq <      200)]), with = FALSE]",data cleaning,970600308617577e8,545
"cluster_sub <- subset(cluster_int, rowSums(cluster_int[, !""tripID"",      with = FALSE]) != 0)",data cleaning,970600308617577e8,545
dim(total_catch) - dim(cluster_sub),exploratory,970600308617577e8,545
pca_data <- cluster_sub,exploratory,970600308617577e8,545
"prop_cluster <- sweep(pca_data[, !""tripID"", with = FALSE], 1,      rowSums(pca_data[, !""tripID"", with = FALSE]), ""/"")",modeling,970600308617577e8,545
prop_cluster <- as.data.table(prop_cluster),data cleaning,970600308617577e8,545
prop_cluster$tripID <- pca_data$tripID,data cleaning,970600308617577e8,545
"setkey(prop_cluster, tripID)",data cleaning,970600308617577e8,545
"save(pca_data, file = ""Analysis/Metiers/results/2014-04-20/pca_data.Rdata"")",export,970600308617577e8,545
prop.pca_data <- prop_cluster,data cleaning,970600308617577e8,545
"save(prop.pca_data, file = ""Analysis/Metiers/results/2014-04-20/prop_pca_data.Rdata"")",export,970600308617577e8,545
"FTL_df <- select(FTL, tripID, spid, landed_wt, ppp)",data cleaning,970600308617577e8,545
FTL_df$value = FTL_df$ppp * FTL_df$landed_wt,data cleaning,970600308617577e8,545
"catch <- select(FTL_df, tripID, spid, value)",data cleaning,970600308617577e8,545
"catch <- filter(catch, value > 0)",data cleaning,970600308617577e8,545
catch <- as.data.table(catch),data cleaning,970600308617577e8,545
"total_catch <- dcast.data.table(catch, tripID ~ spid, fun = sum)",data cleaning,970600308617577e8,545
"setkey(total_catch, tripID)",data cleaning,970600308617577e8,545
"unspecified <- unique(FTL$spid)[grep(""^U"", unique(FTL$spid))]",data cleaning,970600308617577e8,545
"other <- unique(FTL$spid)[grep(""^O"", unique(FTL$spid))]",data cleaning,970600308617577e8,545
"other <- other[-which(other == ""OLVE"" | other == ""OLV1"" | other ==      ""OTCR"" | other == ""OWFS"")]",data cleaning,970600308617577e8,545
"to_remove <- c(unspecified, other)",data cleaning,970600308617577e8,545
"cluster_pre <- total_catch[, !(names(total_catch) %in% to_remove),      with = FALSE]",data cleaning,970600308617577e8,545
"cluster_new <- subset(cluster_pre, rowSums(cluster_pre[, !""tripID"",      with = FALSE]) != 0)",data cleaning,970600308617577e8,545
dim(total_catch) - dim(cluster_new),exploratory,970600308617577e8,545
"freq <- apply(cluster_new[, !""tripID"", with = FALSE], 2, function(x) length(which(x >      0)))",exploratory,970600308617577e8,545
"cluster_int <- cluster_new[, !(names(cluster_new) %in% names(freq)[which(freq <      200)]), with = FALSE]",exploratory,970600308617577e8,545
"cluster_sub <- subset(cluster_int, rowSums(cluster_int[, !""tripID"",      with = FALSE]) != 0)",data cleaning,970600308617577e8,545
dim(total_catch) - dim(cluster_sub),data cleaning,970600308617577e8,545
price.pca_data <- cluster_sub,data cleaning,970600308617577e8,545
"save(price.pca_data, file = ""Analysis/Metiers/results/2014-04-20/price_pca_data.Rdata"")",export,970600308617577e8,545
"FTL.ref <- select(FTL, tripID, veid, grid, month)",data cleaning,970600308617577e8,545
FTL.ref <- FTL.ref[!duplicated(FTL.ref)],data cleaning,970600308617577e8,545
"save(FTL.ref, file = ""Analysis/Metiers/results/2014-04-20/FTL_ref.Rdata"")",export,970600308617577e8,545
"source(""./src/4_clean.R"")",setup,970600308617577e8,545
"source(""./src/5_tables.R"")",setup,970600308617577e8,545
"source(""./src/6_figures.R"")",setup,970600308617577e8,545
"source(""./src/7_analysis.R"")",setup,970600308617577e8,545
"knit2html(""./src/build.Rmd"", fragment.only = TRUE)",communication,970600308617577e8,545
"evaluated_promise_type <- evaluated_promise_type %>% mutate(relative_count = count/total_count,      promise_type = ifelse(promise_type == ""ca"", ""Custom argument"",          ifelse(promise_type == ""na"", ""Non argument"", ""Default argument"")))",data cleaning,970600308617577e8,545
list(evaluated_promise_type = evaluated_promise_type),data cleaning,970600308617577e8,545
"visualize_analyses <- function(analyses) promise_type_count_by_value_type <- analyses$evaluated_promise_type %>%      rename(`Promise type` = promise_type) %>% ggplot(aes(promise_value_type,      weight = relative_count, fill = `Promise type`)) + geom_bar() +      scale_y_continuous(labels = relative_labels) + labs(x = ""Value type"",      y = ""Count (%)"", title = ""Evaluated promise value type"") +      guides(title = NULL) + scale_fill_gdocs() + theme(legend.position = ""bottom"",      axis.text.x = element_text(angle = 60, hjust = 1))",visualization,970600308617577e8,545
"value_type_count_by_promise_type <- analyses$evaluated_promise_type %>%      rename(`Promise type` = promise_type) %>% ggplot(aes(`Promise type`,      weight = relative_count, fill = promise_value_type)) + geom_bar(position = ""fill"") +      scale_y_continuous(labels = relative_labels) + labs(x = ""Promise type"",      y = ""Count (%)"", title = ""Evaluated promise value type"") +      guides(title = NULL) + scale_fill_gdocs() + theme(legend.position = ""bottom"")",data cleaning,970600308617577e8,545
"list(promise_type_count_by_value_type = promise_type_count_by_value_type,      value_type_count_by_promise_type = value_type_count_by_promise_type)",data cleaning,970600308617577e8,545
latex_analyses <- function(analyses) list(),data cleaning,970600308617577e8,545
"main <- function() analyzer <- create_analyzer(""Promise Value Type Analysis"",      combine_analyses, summarize_analyses, visualize_analyses,      latex_analyses)",data cleaning,970600308617577e8,545
drive_analysis(analyzer),modeling,970600308617577e8,545
main(),modeling,970600308617577e8,545
warnings(),modeling,970600308617577e8,545
head(gdp_education_data),exploratory,970600308617577e8,545
ls(gdp_education_data),exploratory,970600308617577e8,545
matching_cases <- nrow(gdp_education_data),exploratory,970600308617577e8,545
matching_cases,exploratory,970600308617577e8,545
"gdp_education_data <- gdp_education_data[order(gdp_education_data$GDP_US_dollars),      ]",exploratory,970600308617577e8,545
"thirteenth_ranked_country <- gdp_education_data[13, ]",exploratory,970600308617577e8,545
class(thirteenth_ranked_country),exploratory,970600308617577e8,545
as.vector(thirteenth_ranked_country$economy),data cleaning,970600308617577e8,545
"high_income_groups <- subset(gdp_education_data, Income.Group ==      ""High income: OECD"" | Income.Group == ""High income: nonOECD"")",data cleaning,970600308617577e8,545
str(high_income_groups),exploratory,970600308617577e8,545
as.vector(unique(high_income_groups$Income.Group)),data cleaning,970600308617577e8,545
length(as.vector(unique(high_income_groups$Income.Group))),data cleaning,970600308617577e8,545
"aggregate(high_income_groups$GDP_rank, list(high_income_groups$Income.Group),      FUN = mean)",data cleaning,970600308617577e8,545
"ggplot(data = gdp_education_data, aes(x = economy, y = GDP_US_dollars,      fill = Income.Group)) + geom_bar(stat = ""identity"")",visualization,970600308617577e8,545
"plot(gdp_education_data$GDP_rank, gdp_education_data$GDP_US_dollars)",visualization,970600308617577e8,545
"seq(0, 1, 0.2)",exploratory,970600308617577e8,545
"gdp_education_data$GDP_quantile <- cut(gdp_education_data$GDP_rank,      quantile(gdp_education_data$GDP_rank, probs = c(0, 0.2, 0.4,          0.6, 0.8, 1)))",data cleaning,970600308617577e8,545
"quantile_table <- aggregate(gdp_education_data$GDP_rank, list(gdp_education_data$Income.Group,      gdp_education_data$GDP_quantile), FUN = length)",data cleaning,970600308617577e8,545
quantile_table,exploratory,970600308617577e8,545
"nrow(highest_GDP_lowest_income_data <- subset(gdp_education_data,      Income.Group == ""Lower middle income"" & GDP_rank < 39))",exploratory,970600308617577e8,545
"top_10 <- subset(gdp_education_data, GDP_rank < 11)",exploratory,970600308617577e8,545
"plot(top_10$GDP_US_dollar, top_10$economy, col = top_10$Income.Group)",visualization,970600308617577e8,545
"bottom_10 <- subset(gdp_education_data, GDP_rank > 180)",data cleaning,970600308617577e8,545
"plot(bottom_10$GDP_US_dollar, bottom_10$economy, col = bottom_10$Income.Group)",visualization,970600308617577e8,545
bottom_10,exploratory,970600308617577e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,137501084478572e8,553
left_Q3 <- anlgX < 0 & anlgY < 0,exploratory,970600308617577e8,545
left_Q4 <- anlgX > 0 & anlgY < 0,exploratory,970600308617577e8,545
right_Q1 <- anlgU > 0 & anlgV > 0,exploratory,970600308617577e8,545
right_Q2 <- anlgU < 0 & anlgV > 0,exploratory,970600308617577e8,545
right_Q3 <- anlgU < 0 & anlgV < 0,exploratory,970600308617577e8,545
right_Q4 <- anlgU > 0 & anlgV < 0,exploratory,970600308617577e8,545
done.alt = done_res,data cleaning,137501084478572e8,553
"gpg_quadrants <- data.frame(index = 1:n, left_Q1, left_Q2, left_Q3,      left_Q4, right_Q1, right_Q2, right_Q3, right_Q4)",data cleaning,970600308617577e8,545
"quadrant_transactions <- as(gpg_quadrants[, -1], ""transactions"")",data cleaning,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[1], "".Robj""))",import,137501084478572e8,553
"gpg_values <- data.frame(index = 1:n, red_val = red, green_val = green,      blue_val = blue, opacity_val = opacity, focalPointX_val = x_mean,      focalPointY_val = y_mean, dispersionX_val = dpX, dispersionY_val = dpY,      positionX_val = xpos, positionY_val = ypos, verticalDiameter_val = sX,      horizontalDiameter_val = sY)",data cleaning,970600308617577e8,545
"rm(list = c(""leftJoy"", ""rightJoy"", ""leftJoyX"", ""leftJoyY"", ""rightJoyX"",      ""rightJoyY"", ""left_Q4"", ""left_Q3"", ""left_Q2"", ""left_Q1"",      ""right_Q4"", ""right_Q3"", ""right_Q2"", ""right_Q1""))",data cleaning,970600308617577e8,545
logLR.null = as.numeric(logLR_list),data cleaning,137501084478572e8,553
detach(gpg_data),data cleaning,970600308617577e8,545
done.null = done_res,data cleaning,137501084478572e8,553
library(glmpath),setup,970600308617577e8,545
"source(""Rcode/functions.r"")",setup,970600308617577e8,545
sum(done.alt),evaluation,137501084478572e8,553
"PMeta = ""../data/Projects_metadata.csv""",import,970600308617577e8,545
sum(done.null),evaluation,137501084478572e8,553
Projects_metadata <- read_csv(PMeta),import,970600308617577e8,545
min(logLR.alt),evaluation,137501084478572e8,553
max(logLR.alt),evaluation,137501084478572e8,553
RECREATEMINFILE = FALSE,setup,970600308617577e8,545
min(logLR.null),evaluation,137501084478572e8,553
STICK = NA,setup,970600308617577e8,545
max(logLR.null),evaluation,137501084478572e8,553
"Name_project = ""Ro_testdata""",setup,970600308617577e8,545
"groupingby = ""MITsoft""",setup,970600308617577e8,545
ms.null[[1]] = logLR.null,data cleaning,137501084478572e8,553
"source(""Rcode/get_behav_gp.r"")",setup,970600308617577e8,545
"source(""Rcode/analysis_for_paper1/multidimensional_analysis_prep_diffTW.R"")",setup,970600308617577e8,545
ms.alt[[1]] = logLR.alt,data cleaning,137501084478572e8,553
six_windowMIT = Multi_datainput_m,setup,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,137501084478572e8,553
"input.pca <- prcomp(Multi_datainput_m %>% select(-groupingvar),      center = TRUE, scale. = TRUE)",modeling,970600308617577e8,545
Moddata = as.data.frame(input.pca$x),data cleaning,970600308617577e8,545
logLR.alt = as.numeric(logLR_list),data cleaning,137501084478572e8,553
done.alt = done_res,data cleaning,137501084478572e8,553
Moddata$groupingvar = as.factor(Multi_datainput_m$groupingvar),data cleaning,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[2], "".Robj""))",import,137501084478572e8,553
data = Moddata,data cleaning,970600308617577e8,545
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,970600308617577e8,545
ACURRACY,exploratory,970600308617577e8,545
logLR.null = as.numeric(logLR_list),data cleaning,137501084478572e8,553
"data = Moddata[, 1:10]",exploratory,970600308617577e8,545
done.null = done_res,data cleaning,137501084478572e8,553
data$groupingvar = as.factor(Multi_datainput_m$groupingvar),exploratory,970600308617577e8,545
sum(done.alt),evaluation,137501084478572e8,553
sum(done.null),evaluation,137501084478572e8,553
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,970600308617577e8,545
ACURRACY,setup,970600308617577e8,545
ACURRACY,setup,970600308617577e8,545
library(glmpath),setup,970600308617577e8,545
"source(""Rcode/functions.r"")",setup,970600308617577e8,545
"PMeta = ""../data/Projects_metadata.csv""",setup,970600308617577e8,545
Projects_metadata <- read_csv(PMeta),setup,970600308617577e8,545
min(logLR.alt),evaluation,137501084478572e8,553
max(logLR.alt),evaluation,137501084478572e8,553
RECREATEMINFILE = FALSE,setup,970600308617577e8,545
STICK = NA,setup,970600308617577e8,545
min(logLR.null),evaluation,137501084478572e8,553
"Name_project = ""Ro_testdata""",setup,970600308617577e8,545
max(logLR.null),evaluation,137501084478572e8,553
"groupingby = ""MITsoft""",setup,970600308617577e8,545
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,952822014223784e8,554
"source(""Rcode/get_behav_gp.r"")",setup,970600308617577e8,545
"source(""Rcode/analysis_for_paper1/multidimensional_analysis_prep_diffTW.R"")",setup,970600308617577e8,545
six_windowMIT = Multi_datainput_m,setup,970600308617577e8,545
"input.pca <- prcomp(Multi_datainput_m %>% select(-groupingvar),      center = TRUE, scale. = TRUE)",modeling,970600308617577e8,545
Moddata = as.data.frame(input.pca$x),data cleaning,970600308617577e8,545
Moddata$groupingvar = as.factor(Multi_datainput_m$groupingvar),data cleaning,970600308617577e8,545
data = Moddata,data cleaning,970600308617577e8,545
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",data cleaning,970600308617577e8,545
ACURRACY,data cleaning,970600308617577e8,545
ms.null[[2]] = logLR.null,data cleaning,137501084478572e8,553
"data = Moddata[, 1:10]",data cleaning,970600308617577e8,545
data$groupingvar = as.factor(Multi_datainput_m$groupingvar),data cleaning,970600308617577e8,545
ms.alt[[2]] = logLR.alt,data cleaning,137501084478572e8,553
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,970600308617577e8,545
ACURRACY,setup,970600308617577e8,545
"library(""parallel"")",setup,983183410484344e8,555
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,137501084478572e8,553
"load(""gl_1990_merge_rmNA.Rdata"")",setup,983183410484344e8,555
"load(""gl_2015_merge_rmNA.Rdata"")",import,983183410484344e8,555
"tidy.name.vector <- make.names(colnames(action_types), unique = TRUE)",data cleaning,952822014223784e8,554
logLR.alt = as.numeric(logLR_list),data cleaning,137501084478572e8,553
done.alt = done_res,data cleaning,137501084478572e8,553
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/logLR."",      case.name[3], "".Robj""))",import,137501084478572e8,553
logLR.null = as.numeric(logLR_list),not sure,137501084478572e8,553
colnames(action_types) <- tidy.name.vector,import,952822014223784e8,554
"pca_merge_1990 <- glPca(gl_1990_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",modeling,983183410484344e8,555
done.null = done_res,data cleaning,137501084478572e8,553
sum(done.alt),evaluation,137501084478572e8,553
"save(pca_merge_1990, file = ""pca_merge_1990.Rdata"")",export,983183410484344e8,555
emp_check_action <- action_types %>% filter(emp_id == emp_one),data cleaning,952822014223784e8,554
sum(done.null),evaluation,137501084478572e8,553
min(logLR.alt),evaluation,137501084478572e8,553
max(logLR.alt),evaluation,137501084478572e8,553
min(logLR.null),evaluation,137501084478572e8,553
"pca_merge_2015 <- glPca(gl_2015_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",modeling,983183410484344e8,555
max(logLR.null),evaluation,137501084478572e8,553
weird_vol_terms <- action_types %>% filter(emp_id %in% weird_data$emp_id),data cleaning,952822014223784e8,554
"save(pca_merge_2015, file = ""pca_merge_2015.Rdata"")",export,983183410484344e8,555
ms.null[[3]] = logLR.null,data cleaning,137501084478572e8,553
ms.alt[[3]] = logLR.alt,data cleaning,137501084478572e8,553
"wave.null = vector(""list"", length(case.name))",data cleaning,137501084478572e8,553
weird_vol_terms <- weird_vol_terms %>% group_by(emp_id) %>% mutate(max_record = max(date_of_record)) %>%      ungroup() %>% filter(date_of_record == max_record),data cleaning,952822014223784e8,554
"plot(nspm.2mo.tow.count.tx, select = 1, shade = T, all.terms = T,      scale = 0, xlab = ""Dissolved Oxygen (mg l^-1"", ylab = """")",visualization,970600308617577e8,545
"wave.alt = vector(""list"", length(case.name))",data cleaning,137501084478572e8,553
abline(h = 0),modeling,970600308617577e8,545
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[1], "".Robj""))",import,137501084478572e8,553
"write_csv(weird_vol_terms, path = ""C:/Users/MonticT/Documents/AnalysisProjects/Vol_Terms/Models/ModelExplanation/weird_non_terms.csv"")",export,952822014223784e8,554
"text(3, -2, ""B"", cex = 1.5, font = 2)",visualization,970600308617577e8,545
rm(list = ls()),data cleaning,970600308617577e8,545
library(ggplot2),setup,970600308617577e8,545
library(reshape2),setup,970600308617577e8,545
library(plyr),setup,970600308617577e8,545
"setwd(""/Users/pascaltimshel/git/snpsnap/analysis/validation_summary_stats_inputEQmatched"")",setup,970600308617577e8,545
"path.base = ""/Users/pascaltimshel/snpsnap/validation_07-08-2014""",setup,970600308617577e8,545
"analysis_name = ""SNPsnap_rand100_defaultMatchCrit_n100_excludeInputHLA""",setup,970600308617577e8,545
"path.analysis = file.path(path.base, analysis_name)",setup,970600308617577e8,545
"file.annotation.input = file.path(path.analysis, ""input_snps_annotated.tab"")",setup,970600308617577e8,545
"file.annotation.matched = file.path(path.analysis, ""matched_snps_annotated.tab"")",setup,970600308617577e8,545
df.input = read.delim(file.annotation.input),setup,970600308617577e8,545
df.matched = read.delim(file.annotation.matched),setup,970600308617577e8,545
"df.matched[, ""set""] <- as.factor(df.matched[, ""set""])",setup,970600308617577e8,545
str(df.matched),setup,970600308617577e8,545
"df.stat.input <- summarise(df.input, set = as.factor(""input""),      origin = as.factor(""input""), N = nrow(df.input), mean_freq_bin = mean(freq_bin),      mean_gene_count = mean(gene_count), mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",modeling,970600308617577e8,545
ptm <- proc.time(),modeling,970600308617577e8,545
"df.stat.matched <- ddply(df.matched, c(""set""), summarise, origin = as.factor(""matched""),      N = length(set), mean_freq_bin = mean(freq_bin), mean_gene_count = mean(gene_count),      mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), min_friends_ld05 = min(friends_ld05),      max_friends_ld05 = max(friends_ld05), median_gene_count = median(gene_count))",modeling,970600308617577e8,545
proc.time() - ptm,modeling,970600308617577e8,545
"df.stat <- rbind(df.stat.input, df.stat.matched)",data cleaning,970600308617577e8,545
"csv.filename <- paste(analysis_name, ""_stat.csv"", sep = """")",import,970600308617577e8,545
"write.csv(df.stat, file = csv.filename, row.names = FALSE)",export,970600308617577e8,545
"df.compare <- ddply(df.stat, .(origin), summarise, mean_freq_bin = mean(mean_freq_bin),      mean_gene_count = mean(mean_gene_count), mean_dist_nearest_gene_snpsnap = mean(mean_dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(mean_friends_ld05))",data cleaning,970600308617577e8,545
"df.ratio <- df.compare[1, -1]/df.compare[2, -1] * 100",exploratory,970600308617577e8,545
"df.compare <- rbind.fill(df.compare, df.ratio)",exploratory,970600308617577e8,545
"csv.filename <- paste(analysis_name, ""_compare.csv"", sep = """")",import,970600308617577e8,545
"write.csv(df.compare, file = csv.filename, row.names = FALSE)",export,970600308617577e8,545
"preds <- expand.grid(dden = with(riskratio, seq(min(dden), max(dden),      length = 100)))",modeling,548830410232767e8,556
"preds$rr <- predict(model2, preds, type = ""response"")",modeling,548830410232767e8,556
"preds$CI025 <- preds$rr + predict(model2, preds, type = ""response"",      se.fit = T)$se.fit * -1.96",evaluation,548830410232767e8,556
"preds$CI975 <- preds$rr + predict(model2, preds, type = ""response"",      se.fit = T)$se.fit * 1.96",evaluation,548830410232767e8,556
"p1 <- ggplot(preds, aes(x = log(dden), y = (rr))) + geom_line() +      geom_point(data = riskratio, aes(x = log(dden), y = log(diff_mort))) +      geom_ribbon(aes(ymin = (CI025), ymax = (CI975)), alpha = 0.333) +      theme_bw() + ylab(""log(riskratio (Mortality))"") + xlab(expression(""log(Wood density)"" ~      g ~ cm^3)) + theme(text = element_text(size = 20))",visualization,548830410232767e8,556
p1,visualization,548830410232767e8,556
"ggsave(p1, file = ""./analysis/inundation_wooddensity_relationship/graph_code/graphs/inundation_VS_wooddensity.png"",      width = 6, height = 6)",export,548830410232767e8,556
"pybs <- read.csv(""~/mat336/projects/algorithm-benchmarking-analysis/python_code/search/bsi_python.csv"")",import,548830410232767e8,556
"pyls <- read.csv(""~/mat336/projects/algorithm-benchmarking-analysis/python_code/search/lsi_python.csv"")",import,548830410232767e8,556
"plot(time ~ input, data = pybs)",visualization,548830410232767e8,556
"mats <- as.data.frame(rbind(mats, tmpdat))",data cleaning,970600308617577e8,545
"qs <- group_by(mats, s) %>% summarise(q = logSumExp(lp__) - log(n()))",data cleaning,970600308617577e8,545
"plot(time ~ input, data = pyls)",visualization,548830410232767e8,556
qs$p <- qs$q - logSumExp(qs$q),modeling,970600308617577e8,545
"mats <- merge(mats, qs)",modeling,970600308617577e8,545
abline(pylslm$coefficients),visualization,548830410232767e8,556
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,970600308617577e8,545
"pylslm <- lm(time ~ input, data = pyls)",modeling,548830410232767e8,556
"pyls$mean_times <- sapply(pyls$input, function(x) mean(pyls$time[pyls$input ==      x]))",evaluation,548830410232767e8,556
"plot(mean_times ~ input, data = pyls)",visualization,548830410232767e8,556
"mean_model <- lm(mean_times ~ input, data = pyls)",modeling,548830410232767e8,556
abline(mean_model$coefficients),visualization,548830410232767e8,556
"pyls$max_times <- sapply(pyls$input, function(x) max(pyls$time[pyls$input ==      x]))",exploratory,548830410232767e8,556
"plot(max_times ~ input, data = pyls)",visualization,548830410232767e8,556
"max_model <- lm(max_times ~ input, data = pyls)",modeling,548830410232767e8,556
abline(max_model$coefficients),modeling,548830410232767e8,556
DistrictData$CrimeViolent <- DistrictData$dangerousBodilyHarm +      DistrictData$murderAndManslaughter,data cleaning,548830410232767e8,556
DistrictData$ViolentCrimeRate <- (DistrictData$CrimeViolent/DistrictData$TotalPopulation) *      1e+05,data cleaning,548830410232767e8,556
DistrictData$CrimeNonViolent <- DistrictData$robberyFromOrOutOfCars +      DistrictData$robberyOfCars + DistrictData$vandalism + DistrictData$vandalismGraffiti +      DistrictData$streetCrime + DistrictData$burglaryDaylight +      DistrictData$burglary + DistrictData$robberyIncludingExtortionAndAttackOfCarDrivers,data cleaning,548830410232767e8,556
DistrictData$NonViolentCrimeRate <- (DistrictData$CrimeNonViolent/DistrictData$TotalPopulation) *      1e+05,data cleaning,548830410232767e8,556
DistrictData$CrimeTotal <- DistrictData$bodilyHarm + DistrictData$dangerousBodilyHarm +      DistrictData$violentCrime + DistrictData$murderAndManslaughter +      DistrictData$robberyIncludingExtortionAndAttackOfCarDrivers +      DistrictData$robberyFromOrOutOfCars + DistrictData$robberyOfCars +      DistrictData$vandalism + DistrictData$vandalismGraffiti +      DistrictData$streetCrime + DistrictData$burglaryDaylight +      DistrictData$burglary,data cleaning,548830410232767e8,556
DistrictData$CrimeRate <- (DistrictData$CrimeTotal/DistrictData$TotalPopulation) *      1e+05,data cleaning,548830410232767e8,556
"DistrictData$DistrictName <- iconv(DistrictData$DistrictName,      from = ""latin1"", to = ""UTF-8"")",data cleaning,548830410232767e8,556
set.seed(parameters$seed),modeling,970600308617577e8,545
"write.csv(DistrictData, file = ""Analysis/data/DistrictData2013.csv"")",export,548830410232767e8,556
"newmcmc <- sample_n(mats, 8000, replace = T, weight = exp(mats$p))",modeling,970600308617577e8,545
"saveRDS(newmcmc, ""analysis/mcmc-runs/ToRaising-Stan-Fit4-resample.RDS"")",export,970600308617577e8,545
setMKLthreads(1),setup,970600308617577e8,545
"surveys <- expand_surveys(set_den = c(0.5, 1, 2, 5, 10)/1000,      lengths_cap = c(5, 10, 20, 50, 100, 500, 1000), ages_cap = c(2,          5, 10, 20, 50))",setup,970600308617577e8,545
"surveys[surveys$set_den == 0.002 & surveys$lengths_cap == 500 &      surveys$ages_cap == 10, ]",setup,970600308617577e8,545
"sim <- test_surveys(pop, surveys = surveys, keep_details = 98,      n_sims = 5, n_loops = 200, cores = 7, q = sim_logistic(k = 2,          x0 = 3), export = ""analysis/cod_sim_exports/2018-10-28_no_age_clust_test"")",modeling,970600308617577e8,545
setMKLthreads(),setup,970600308617577e8,545
"source(""./src/3_load.R"")",setup,970600308617577e8,545
"source(""./src/4_clean.R"")",setup,970600308617577e8,545
"source(""./src/5_tables.R"")",setup,970600308617577e8,545
"source(""./src/6_figures.R"")",setup,970600308617577e8,545
"source(""./src/7_analysis.R"")",setup,970600308617577e8,545
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",communication,970600308617577e8,545
"data_4GHA_A = read.csv(""correlation_analysis/combined_data/data_4GHA_A.csv"")",import,970600308617577e8,545
"data_4IRY_A = read.csv(""correlation_analysis/combined_data/data_4IRY_A.csv"")",import,970600308617577e8,545
"ASAP_res_prop = rbind(data_1RD8_AB, data_2FP7_B, data_2Z83_A,      data_2JLY_A, data_3GOL_A, data_3LYF_A, data_4AQF_B, data_4GHA_A,      data_4IRY_A)",data cleaning,970600308617577e8,545
ASAP_res_prop$protein = factor(ASAP_res_prop$protein),data cleaning,970600308617577e8,545
ASAP_pdb_prop = data.frame(),data cleaning,970600308617577e8,545
counter = 0,data cleaning,970600308617577e8,545
for (pdb in levels(ASAP_res_prop$protein)) counter = counter +      1,not sure,970600308617577e8,545
"CD_lists = c(as.character(1:15), ""city of LA"")",import,139807343948632e7,557
"cat(counter[[1]][1], "" "", pdb, ""\n"")",modeling,970600308617577e8,545
"pdb_data = ASAP_res_prop[ASAP_res_prop$protein == pdb, ]",modeling,970600308617577e8,545
"x = cor.test(pdb_data$entropy, pdb_data$rsa_avg_md, method = ""spearman"")",modeling,970600308617577e8,545
"social_types = c(""Median_Age"", ""Median_Household_Income"")",setup,139807343948632e7,557
r.seqent.rsa = x$estimate,modeling,970600308617577e8,545
"x = cor.test(pdb_data$entropy, pdb_data$wcn_avg_md, method = ""spearman"")",modeling,970600308617577e8,545
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Regional Requests Analysis"",      sidebarLayout(sidebarPanel(selectInput(inputId = ""CD"", label = ""Council Districts: "",          choices = CD_lists, multiple = TRUE, selectize = TRUE,          selected = ""city of LA""), actionButton(inputId = ""button_cd"",          label = ""Submit"", style = ""padding:3px""), width = 3),          mainPanel(fluidRow(tableOutput(""cd_summary"")))), hr(),      fluidRow(column(6, plotlyOutput(outputId = ""plot_income"")),          column(6, plotlyOutput(outputId = ""plot_unemployment"")))),      tabPanel(""Requests Type Analysis"", sidebarPanel(selectInput(inputId = ""request_type"",          label = ""Request Type: "", choices = request_types, multiple = FALSE,          selectize = TRUE, selected = ""Metal/Household Appliances""),          selectInput(inputId = ""social_type"", label = ""Social Characteristics: "",              choices = social_types, multiple = FALSE, selectize = TRUE,              selected = ""Median_Household_Income""), actionButton(inputId = ""button_req"",              label = ""Submit""), width = 4), mainPanel(fluidRow(plotOutput(outputId = ""req_summary"")))),      tabPanel(""Requests Efficiency Analysis"", fluidRow(column(6,          tableOutput(outputId = ""type_summary"")), column(4, plotOutput(outputId = ""wc"")))),      tabPanel(""Department Efficiency Analysis"", column(3, actionButton(inputId = ""dep_source"",          label = ""Department and request source"")), column(3,          actionButton(inputId = ""dep_type"", label = ""Department and request type"")),          column(3, actionButton(inputId = ""dep_cd"", label = ""Department and Council Districts"")),          plotOutput(""dep_plot"")))",communication,139807343948632e7,557
r.seqent.wcnCA = x$estimate,data cleaning,970600308617577e8,545
"x = cor.test(pdb_data$entropy, pdb_data$bfca, method = ""spearman"")",modeling,970600308617577e8,545
r.seqent.bfCA = x$estimate,modeling,970600308617577e8,545
"row = data.frame(pdb = pdb, nres = length(pdb_data$entropy),      r.seqent.rsa = r.seqent.rsa, r.seqent.wcnCA = r.seqent.wcnCA,      r.seqent.bfCA = r.seqent.bfCA, sd.seqent = sd(pdb_data$entropy),      mean.seqent = mean(pdb_data$entropy), median.seqent = median(pdb_data$entropy),      sd.wcnCA = sd(pdb_data$wcn_avg_md), mean.wcnCA = mean(pdb_data$wcn_avg_md),      median.wcnCA = median(pdb_data$wcn_avg_md), sd.rsa = sd(pdb_data$rsa_avg_md),      mean.rsa = mean(pdb_data$rsa_avg_md), median.rsa = median(pdb_data$rsa_avg_md))",data cleaning,970600308617577e8,545
"ASAP_pdb_prop = rbind(ASAP_pdb_prop, row)",data cleaning,970600308617577e8,545
"setwd(""C:/Users/Amir/Documents/GitHub/cordiv/analysis/src"")",setup,970600308617577e8,545
"write.csv(ASAP_pdb_prop, ""../tables/ASAP_pdb_prop.csv"", row.names = F)",export,970600308617577e8,545
"MainData3 <- data.frame(MainData2, AddressData)",import,139807343948632e7,557
my.headers <- names(temp.new),data cleaning,970600308617577e8,545
"MainData4 <- data.frame(MainData3, ZillowDataSet6)",setup,139807343948632e7,557
"req <- c(""foreign"", ""Hmisc"", ""tables"")",data cleaning,970600308617577e8,545
"lapply(req, library, character.only = TRUE)",data cleaning,970600308617577e8,545
"write.table(MainData4, file = ""Analysis/Data/EnrichedData"", sep = "","")",export,139807343948632e7,557
"analysis <- read.dta(""./data/d00_analysis.dta"")",import,970600308617577e8,545
"tabdat <- with(analysis, data.frame(Sex = factor(sex, labels = c(""Male"",      ""Female"")), Country = factor(country, labels = c(""Czech Republic"",      ""Russia"", ""Romania"")), Diabetes = factor(diabete, labels = c(""Yes"",      ""No"")), Hypertension = factor(hypertension, labels = c(""Yes"",      ""No"")), Stage = factor(stage_imputed, labels = c(""I"", ""II"",      ""III"", ""IV"")), Grade = factor(grade), Histology = histo_grp,      Smoking = factor(smoke_status, labels = c(""Never smoker"",          ""Former smoker"", ""Current smoker"")), `Age at recruitment (years)` = cut(age_recruitment,          breaks = c(min(age_recruitment, na.rm = TRUE), 55, 65,              max(age_recruitment, na.rm = TRUE)), right = FALSE,          include.lowest = TRUE), `BMI (kg/m$^2$)` = cut(bmi_current,          breaks = c(min(bmi_current, na.rm = TRUE), 25, 30, max(bmi_current,              na.rm = TRUE)), right = FALSE, include.lowest = TRUE),      `Season-adjusted circulating 25(OH)D$_3$ category` = factor(d3_q4,          labels = c(""1 (lowest)"", ""2"", ""3"", ""4 (highest)"")), `Vital status` = factor(vitalstatus,          labels = c(""alive"", ""dead"")), Total = ""Total"", check.names = FALSE))",data cleaning,970600308617577e8,545
"addlevel <- function(x) factor(x, levels = c(levels(x), ""missing""))",data cleaning,970600308617577e8,545
"model2 <- lm(elev ~ diff_mort + dden, riskratio)",modeling,518880921648815e8,558
"tabdat <- data.frame(lapply(tabdat, addlevel), stringsAsFactors = FALSE,      check.names = FALSE)",data cleaning,970600308617577e8,545
"tabdat[is.na(tabdat)] <- ""missing""",data cleaning,970600308617577e8,545
tabdat <- droplevels(tabdat),data cleaning,970600308617577e8,545
"t1 <- tabular(Total + Literal(""\\\\ %"") + Sex + Literal(""\\\\  %"") +      `Age at recruitment (years)` + Literal(""\\\\ %"") + Country +      Literal(""\\\\ %"") + `BMI (kg/m$^2$)` + Literal(""\\\\ %"") +      Smoking + Literal(""\\\\ %"") + Diabetes + Literal(""\\\\ %"") +      Hypertension + Literal(""\\\\ %"") + Stage + Literal(""\\\\ %"") +      Grade + Literal(""\\\\ %"") + Histology + Literal(""\\\\ %"") +      `Season-adjusted circulating 25(OH)D$_3$ category` ~ (`Vital status` *      ((n = 1) + Paste(Percent(""col""), digits = 0, prefix = ""("",          postfix = "")"", head = ""(\\%)"", justify = ""r"")) + (Total = (n = 1))),      data = tabdat)",data cleaning,970600308617577e8,545
"test <- booktabs(latex(t1, booktabs = TRUE, file = ""./analysis/output/o08_descriptive_by_vitstat.tex"",      caption = ""Demographic characteristics and covariates by vital status""))",data cleaning,970600308617577e8,545
"latex(tabular(Factor(Smoking) + Literal(""\\newline %"") + Factor(Sex) ~      Factor(`Vital status`) * ((n = 1) + Paste(Percent(""col""),          digits = 0, prefix = ""("", postfix = "")"", head = ""(\\%)"",          justify = ""r"")), data = tabdat, suppressLabels = 0))",data cleaning,970600308617577e8,545
su_vitd <- summary(analysis$vd3_h),exploratory,970600308617577e8,545
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,23583795921877e9,559
summary(model2),exploratory,518880921648815e8,558
"pctiles_vitd <- quantile(analysis$vd3_h, probs = c(0.05, 0.25,      0.5, 0.75, 0.95), na.rm = TRUE)",modeling,970600308617577e8,545
"model3 <- lm(elev ~ dden, riskratio)",modeling,518880921648815e8,558
"model4 <- lm(elev ~ diff_mort, riskratio)",modeling,518880921648815e8,558
"sink(""./analysis/output/l08_vitd_summary.txt"")",setup,970600308617577e8,545
su_vitd,exploratory,970600308617577e8,545
pctiles_vitd,exploratory,970600308617577e8,545
sink(),exploratory,970600308617577e8,545
summary(model3),exploratory,518880921648815e8,558
"anolis = read.csv(""analysis/data/anolis.convergence.csv"")",import,23583795921877e9,559
summary(model4),exploratory,518880921648815e8,558
"points(c(0, fpr.ms.overS[[1]]), c(0, tpr.ms.overS[[1]]), type = ""l"",      col = ""blue"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overS[[1]]), c(0, tpr.wave.overS[[1]]),      type = ""l"", col = ""skyblue"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overS[[2]]), c(0, tpr.ms.overS[[2]]), type = ""l"",      col = ""darkgreen"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overS[[2]]), c(0, tpr.wave.overS[[2]]),      type = ""l"", col = ""green"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overS[[3]]), c(0, tpr.ms.overS[[3]]), type = ""l"",      col = ""red"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overS[[3]]), c(0, tpr.wave.overS[[3]]),      type = ""l"", col = ""orange"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overB[[1]]), c(0, tpr.ms.overB[[1]]), type = ""l"",      col = ""blue"", lty = ""dashed"")",visualization,970600308617577e8,545
head(anolis),exploratory,23583795921877e9,559
"points(c(0, fpr.wave.overB[[1]]), c(0, tpr.wave.overB[[1]]),      type = ""l"", col = ""skyblue"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overB[[2]]), c(0, tpr.ms.overB[[2]]), type = ""l"",      col = ""darkgreen"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overB[[2]]), c(0, tpr.wave.overB[[2]]),      type = ""l"", col = ""green"", lty = ""dashed"")",visualization,970600308617577e8,545
"par(mfrow = c(2, 2))",visualization,518880921648815e8,558
"points(c(0, fpr.ms.overB[[3]]), c(0, tpr.ms.overB[[3]]), type = ""l"",      col = ""red"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overB[[3]]), c(0, tpr.wave.overB[[3]]),      type = ""l"", col = ""orange"", lty = ""dashed"")",visualization,970600308617577e8,545
library(ggplot2),visualization,23583795921877e9,559
plot(model2),visualization,518880921648815e8,558
"legend(0.6, 0.4, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10"", ""binomial"", ""beta-binomial (small)"",      ""beta-binomial (big)""), col = c(""blue"", ""skyblue"", ""darkgreen"",      ""green"", ""red"", ""orange"", ""black"", ""black"", ""black""), lty = c(rep(""solid"",      7), ""twodash"", ""dashed""), text.col = ""black"", merge = FALSE,      bg = ""white"")",visualization,970600308617577e8,545
"save(model2, file = ""./analysis/inundation_predicts_species_distributions/models/elevation_Vs_wooddensityN_diff_mortality.R"")",export,518880921648815e8,558
dev.off(),visualization,970600308617577e8,545
"pdf(""logLR_ROC_withoverS.pdf"")",export,970600308617577e8,545
library(ggforce),not sure,23583795921877e9,559
xmax = 1,exploratory,970600308617577e8,545
"model2_glm <- glm(elev ~ dden + diff_mort, riskratio, family = ""gaussian"")",modeling,518880921648815e8,558
"gg0 = ggplot(anolis, aes(SVLength, FemurLength, colour = Island)) +      geom_point() + facet_zoom(xy = Ecomorph == ""Crown-Giant"")",visualization,23583795921877e9,559
ymax = 1,exploratory,970600308617577e8,545
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",visualization,970600308617577e8,545
summary(model2_glm),exploratory,518880921648815e8,558
gg0,visualization,23583795921877e9,559
"points(c(0, fpr.ms[[1]]), c(0, tpr.ms[[1]]), type = ""l"", col = ""blue"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[1]]), c(0, tpr.wave[[1]]), type = ""l"",      col = ""skyblue"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms[[2]]), c(0, tpr.ms[[2]]), type = ""l"", col = ""darkgreen"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[2]]), c(0, tpr.wave[[2]]), type = ""l"",      col = ""green"")",visualization,970600308617577e8,545
"save(model2_glm, file = ""./analysis/inundation_predicts_species_distributions/models/elevation_Vs_wooddensityN_diff_mortality_GLM.R"")",export,518880921648815e8,558
"ggsave(""analysis/output/anolis_zoom.pdf"", plot = gg0)",visualization,23583795921877e9,559
"points(c(0, fpr.ms[[3]]), c(0, tpr.ms[[3]]), type = ""l"", col = ""red"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[3]]), c(0, tpr.wave[[3]]), type = ""l"",      col = ""orange"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overS[[1]]), c(0, tpr.ms.overS[[1]]), type = ""l"",      col = ""blue"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overS[[1]]), c(0, tpr.wave.overS[[1]]),      type = ""l"", col = ""skyblue"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overS[[2]]), c(0, tpr.ms.overS[[2]]), type = ""l"",      col = ""darkgreen"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overS[[2]]), c(0, tpr.wave.overS[[2]]),      type = ""l"", col = ""green"", lty = ""twodash"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overS[[3]]), c(0, tpr.ms.overS[[3]]), type = ""l"",      col = ""red"", lty = ""twodash"")",visualization,970600308617577e8,545
"source(""./functions/booter.R"")",import,518880921648815e8,558
"points(c(0, fpr.wave.overS[[3]]), c(0, tpr.wave.overS[[3]]),      type = ""l"", col = ""orange"", lty = ""twodash"")",visualization,970600308617577e8,545
"legend(0.6, 0.4, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10"", ""binomial"", ""beta-binomial (small)""),      col = c(""blue"", ""skyblue"", ""darkgreen"", ""green"", ""red"", ""orange"",          ""black"", ""black""), lty = c(rep(""solid"", 7), ""twodash""),      text.col = ""black"", merge = FALSE, bg = ""white"")",visualization,970600308617577e8,545
dev.off(),visualization,970600308617577e8,545
"CI <- booter(model2, data = riskratio, n = 5000, coef = T)",modeling,518880921648815e8,558
library(dplyr),data cleaning,23583795921877e9,559
"pdf(""logLR_ROC_withoverB.pdf"")",export,970600308617577e8,545
xmax = 1,exploratory,970600308617577e8,545
CI,evaluation,518880921648815e8,558
ymax = 1,exploratory,970600308617577e8,545
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",visualization,970600308617577e8,545
coef(model2),modeling,518880921648815e8,558
"points(c(0, fpr.ms[[1]]), c(0, tpr.ms[[1]]), type = ""l"", col = ""blue"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[1]]), c(0, tpr.wave[[1]]), type = ""l"",      col = ""skyblue"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms[[2]]), c(0, tpr.ms[[2]]), type = ""l"", col = ""darkgreen"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[2]]), c(0, tpr.wave[[2]]), type = ""l"",      col = ""green"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms[[3]]), c(0, tpr.ms[[3]]), type = ""l"", col = ""red"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave[[3]]), c(0, tpr.wave[[3]]), type = ""l"",      col = ""orange"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overB[[1]]), c(0, tpr.ms.overB[[1]]), type = ""l"",      col = ""blue"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overB[[1]]), c(0, tpr.wave.overB[[1]]),      type = ""l"", col = ""skyblue"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overB[[2]]), c(0, tpr.ms.overB[[2]]), type = ""l"",      col = ""darkgreen"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overB[[2]]), c(0, tpr.wave.overB[[2]]),      type = ""l"", col = ""green"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.ms.overB[[3]]), c(0, tpr.ms.overB[[3]]), type = ""l"",      col = ""red"", lty = ""dashed"")",visualization,970600308617577e8,545
"points(c(0, fpr.wave.overB[[3]]), c(0, tpr.wave.overB[[3]]),      type = ""l"", col = ""orange"", lty = ""dashed"")",visualization,970600308617577e8,545
"ann = anolis %>% group_by(Ecomorph, Island) %>% summarise(mean = mean(SVLength),      sd = sd(SVLength))",exploratory,23583795921877e9,559
"source(""~/selection/code/lib/readlib.R"")",import,519237346015871e7,560
"legend(0.6, 0.4, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10"", ""binomial"", ""beta-binomial (big)""),      col = c(""blue"", ""skyblue"", ""darkgreen"", ""green"", ""red"", ""orange"",          ""black"", ""black""), lty = c(rep(""solid"", 7), ""dashed""),      text.col = ""black"", merge = FALSE, bg = ""white"")",visualization,970600308617577e8,545
dev.off(),visualization,970600308617577e8,545
ann,exploratory,23583795921877e9,559
version = NA,not sure,519237346015871e7,560
library(ape),setup,970600308617577e8,545
"gg1 = ggplot(ann, aes(Ecomorph, mean, colour = Island)) + geom_point(stat = ""identity"") +      geom_pointrange(aes(ymax = mean + sd, ymin = mean - sd))",visualization,23583795921877e9,559
result_phylo <- as.phylo(result$hclust),import,970600308617577e8,545
if (length(commandArgs(TRUE))) version = commandArgs(TRUE)[1],not sure,519237346015871e7,560
gg1,visualization,23583795921877e9,559
"write(write.tree(result_phylo), file = ""/home/stesee/DotAligner/analysis/dotaligner3/seed_10_55.new.dotaligner3.clusters.newick"")",export,970600308617577e8,545
"ggsave(""analysis/output/anolis_mean.pdf"", plot = gg1)",visualization,23583795921877e9,559
dev.off(),visualization,970600308617577e8,545
"list2ascii <- function(x, file = paste(deparse(substitute(x)),      "".txt"", sep = """")) tmp.wid = getOption(""width"")",setup,970600308617577e8,545
library(ggplot2),visualization,23583795921877e9,559
options(width = 10000),setup,970600308617577e8,545
sink(file),setup,970600308617577e8,545
"root <- paste0(""~/selection/counts/"", version, ""/all"")",not sure,519237346015871e7,560
print(x),setup,970600308617577e8,545
sink(),setup,970600308617577e8,545
library(RMark),communication,23583795921877e9,559
options(width = tmp.wid),setup,970600308617577e8,545
return(invisible(NULL)),setup,970600308617577e8,545
"read.totals <- paste0(""~/selection/analysis/"", version, ""/effsize/effsize_reads.txt.gz"")",not sure,519237346015871e7,560
"list2ascii(pvpick(result, alpha = 0.98, pv = ""au"", type = ""geq"",      max.only = TRUE)$clusters, file = ""/home/stesee/DotAligner/analysis/nw/seed_10_55.new.nw.clusters"")",data cleaning,970600308617577e8,545
"source(""./Analysis/ImportFormat.R"")",import,23583795921877e9,559
rd <- read.counts.and.data(root),import,519237346015871e7,560
"source(""./Analysis/KnownFateModels.R"")",import,23583795921877e9,559
counts <- rd$counts,exploratory,519237346015871e7,560
"p <- ggplot(TopModel.real, aes(x = Year, y = estimate))",visualization,23583795921877e9,559
totals <- rd$totals,exploratory,519237346015871e7,560
"p <- p + geom_pointrange(data = TopModel.real, aes(x = Year,      y = estimate, ymin = lcl, ymax = ucl), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Daily Survival Rate"")",visualization,23583795921877e9,559
p,visualization,23583795921877e9,559
data <- rd$data,exploratory,519237346015871e7,560
"ggsave(""./Figures/DailySurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",visualization,23583795921877e9,559
"read.totals <- read.table(read.totals, as.is = TRUE, header = TRUE)",import,519237346015871e7,560
library(ggplot2),visualization,23583795921877e9,559
"p <- ggplot(TopModel.derived, aes(x = Year, y = Estimate))",visualization,23583795921877e9,559
"p <- p + geom_pointrange(data = TopModel.derived, aes(x = Year,      y = Estimate, ymin = LCL, ymax = UCL), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Annual Survival Rate"")",visualization,23583795921877e9,559
dim(sig2),exploratory,970600308617577e8,545
p,visualization,23583795921877e9,559
head(sig2),exploratory,970600308617577e8,545
subset(sig2),exploratory,970600308617577e8,545
"ucas_acceptance_chart <- ggplot(data = hostEntrants, aes(x = `Cycle Year`,      y = `Number of Acceptances`, fill = `Subject Group (Detailed Level)`)) +      geom_area(colour = ""black"", size = 0.2, alpha = 0.4) + labs(title = paste0(""All NI University acceptances by all "",      filters$applicationRoute, "" applicants (2007--2018)"")) +      ylab(""Number of acceptances"") + xlab(""Year"") + scale_fill_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,192475151270628e8,34
sig2$type <- getType(sig2),exploratory,970600308617577e8,545
"table(sig2$type, sig2$probegene)",exploratory,970600308617577e8,545
"ggsave(""./Figures/AnnualSurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",visualization,23583795921877e9,559
"results <- data.frame(pops = colnames(totals), size = apply(totals,      2, max), effective.size = colMeans(totals))",data cleaning,519237346015871e7,560
"write.table(results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,519237346015871e7,560
"library(""rgdal"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""geosphere"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""raster"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""rgeos"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""Imap"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.2/Resources/library"")",setup,23583795921877e9,559
"library(""gepaf"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""vegan"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""scales"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"library(""countrycode"", lib.loc = ""/Library/Frameworks/R.framework/Versions/3.4/Resources/library"")",setup,23583795921877e9,559
"capitals <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/country-capitals.csv"")",import,23583795921877e9,559
"read.results <- data.frame(pops = colnames(read.totals), effective.size = colMeans(read.totals))",data cleaning,519237346015871e7,560
"capitals <- capitals[capitals$ContinentName == ""Africa"", ]",import,23583795921877e9,559
"write.table(read.results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size_reads.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,519237346015871e7,560
capitals$x <- as.numeric(paste(capitals$CapitalLongitude)),data cleaning,23583795921877e9,559
capitals$y <- as.numeric(paste(capitals$CapitalLatitude)),data cleaning,23583795921877e9,559
"opt_loc <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/opt_loc.csv"")",import,23583795921877e9,559
rm(constrainedLoadingsRandom),setup,519237346015871e7,560
"oneword_weird$twin <- oneword_weird$Answer.choice == ""\""twin\""""",data cleaning,728108570212498e8,561
"tsvs = ga.files$entity.id[grep(""mutations.tsv"", ga.files$entity.name)]",data cleaning,519237346015871e7,560
"oneword_weird$single <- oneword_weird$Answer.choice == ""\""single\""""",data cleaning,728108570212498e8,561
"pdfs = ga.files$entity.id[grep(""PerPatient"", ga.files$entity.name)]",data cleaning,519237346015871e7,560
logNorm <- rna_count_matrix(doLogNorm = TRUE),data cleaning,519237346015871e7,560
voomNorm <- rna_count_matrix(doVoomNorm = TRUE),data cleaning,519237346015871e7,560
"write.table(logNorm, ""featureCountsByGeneLogNormalized.txt"")",export,519237346015871e7,560
"write.table(voomNorm, ""featureCountsByGeneVOOMnormalized.txt"")",export,519237346015871e7,560
"oneword_weird$distractor_position = (oneword_weird$Answer.target_position ==      ""\""left\"""") * -1 + (oneword_weird$Answer.target_position ==      ""\""right\"""") * 1 + (oneword_weird$Answer.logical_position ==      ""\""left\"""") * -1 + (oneword_weird$Answer.logical_position ==      ""\""right\"""") * 1",data cleaning,728108570212498e8,561
"synStore(File(""featureCountsByGeneLogNormalized.txt"", parentId = ""syn4984701""),      used = list(list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/analysis/2016-03-08/somaticMutsRnaProcessing.R"",          wasExecuted = TRUE)))",not sure,519237346015871e7,560
"synStore(File(""featureCountsByGeneVOOMnormalized.txt"", parentId = ""syn4984701""),      used = list(list(url = ""https://raw.githubusercontent.com/Sage-Bionetworks/dermalNF/master/analysis/2016-03-08/somaticMutsRnaProcessing.R"",          wasExecuted = TRUE)))",not sure,519237346015871e7,560
"opt_loc$wbcode <- countrycode(opt_loc$country, origin = ""country.name"",      destination = ""wb"")",data cleaning,23583795921877e9,559
"df <- opt_loc[!is.na(opt_loc$wbcode), ]",data cleaning,23583795921877e9,559
done.null = done_res,setup,605313735548407e8,562
gam.2mo.dur.tx <- na.omit(gam.2mo.dur.tx),data cleaning,519237346015871e7,560
"level_1 <- subset(oneword_weird, oneword_weird$Answer.scale_and_levels_condition ==      6)",data cleaning,728108570212498e8,561
"m.2mo.dur.tx <- gam(log(towhours + 1) ~ factor(yr) + la_fuel_price +      hrs + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), data = gam.2mo.dur.tx)",modeling,519237346015871e7,560
df$capital <- NA,data cleaning,23583795921877e9,559
"level_2 <- subset(oneword_weird, oneword_weird$Answer.scale_and_levels_condition ==      7)",data cleaning,728108570212498e8,561
"nspm.2mo.dur.tx <- gam(log(towhours + 1) ~ factor(yr) + la_fuel_price +      hrs + s(do) + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat),      data = gam.2mo.dur.tx)",modeling,519237346015871e7,560
gam.check(m.2mo.dur.tx),modeling,519237346015871e7,560
"for (i in 1:nrow(capitals)) country <- countrycode(capitals$CountryCode[i],      origin = ""iso2c"", destination = ""wb"")",data cleaning,23583795921877e9,559
sum(done.alt),data cleaning,605313735548407e8,562
"if (!is.na(country)) subset <- df[df$wbcode == country, ]",data cleaning,23583795921877e9,559
"png(""/Users/efuller/Desktop/CNH/Analysis/participation_plots/analysis/fig_2_orf.png"",      width = 4, height = 4, res = 600, units = ""in"")",export,267601606203243e8,563
sum(done.null),data cleaning,605313735548407e8,562
"n = length(du867[du867$status != 0, ]$loss)",not sure,694975318387151e8,564
summary(m.2mo.dur.tx),evaluation,519237346015871e7,560
"m = length(du86[du86$status != 0, ]$loss)",not sure,694975318387151e8,564
"par(bg = ""transparent"")",setup,267601606203243e8,563
min(logLR.alt),data cleaning,605313735548407e8,562
"gam.2mo.tow.count.la <- gam.2mo.tow.count.la[, c(""yr"", ""jd"",      ""hrs"", ""do"", ""depth"", ""ppnd"", ""la_fuel_price"", ""tow.cnt"",      ""areaOB"", ""cent_lon"", ""cent_lat"")]",not sure,519237346015871e7,560
"m = length(du43[du43$status != 0, ]$loss)",not sure,694975318387151e8,564
gam.2mo.tow.count.la <- na.omit(gam.2mo.tow.count.la),data cleaning,519237346015871e7,560
"m = length(du8[du8$status != 0, ]$loss)",not sure,694975318387151e8,564
max(logLR.alt),data cleaning,605313735548407e8,562
min(logLR.null),data cleaning,605313735548407e8,562
"m.2mo.tow.count.la <- gam(tow.cnt ~ factor(yr) + la_fuel_price +      hrs + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), family = poisson, data = gam.2mo.tow.count.la)",modeling,519237346015871e7,560
max(logLR.null),data cleaning,605313735548407e8,562
"summary(du867[du867$status != 0, ]$loss)",exploratory,694975318387151e8,564
"summary(du86[du86$status != 0, ]$loss)",exploratory,694975318387151e8,564
"summary(du43[du43$status != 0, ]$loss)",exploratory,694975318387151e8,564
"nspm.2mo.tow.count.la <- gam(tow.cnt ~ factor(yr) + la_fuel_price +      hrs + s(do) + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat),      family = poisson, data = gam.2mo.tow.count.la)",modeling,519237346015871e7,560
gam.check(m.2mo.tow.count.la),evaluation,519237346015871e7,560
"oneword_weird_randomized <- aggregate(cbind(twin, single) ~ Answer.item +      Answer.scale_and_levels_condition, data = oneword_weird,      sum)",data cleaning,728108570212498e8,561
summary(m.2mo.tow.count.la),evaluation,519237346015871e7,560
wave.null[[2]] = logLR.null,modeling,605313735548407e8,562
"gam.2mo.tow.count.tx <- gam.2mo.tow.count.tx[, c(""yr"", ""jd"",      ""hrs"", ""do"", ""depth"", ""ppnd"", ""la_fuel_price"", ""tow.cnt"",      ""cent_lon"", ""cent_lat"")]",data cleaning,519237346015871e7,560
average_twin_level_1 <- sum(level_1$twin),data cleaning,728108570212498e8,561
gam.2mo.tow.count.tx <- na.omit(gam.2mo.tow.count.tx),data cleaning,519237346015871e7,560
wave.alt[[2]] = logLR.alt,modeling,605313735548407e8,562
"m.2mo.tow.count.tx <- gam(tow.cnt ~ factor(yr) + la_fuel_price +      hrs + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), family = poisson, data = gam.2mo.tow.count.tx)",modeling,519237346015871e7,560
"nspm.2mo.tow.count.tx <- gam(tow.cnt ~ factor(yr) + la_fuel_price +      hrs + s(do) + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat),      family = poisson, data = gam.2mo.tow.count.tx)",modeling,519237346015871e7,560
average_twin_level_1,evaluation,728108570212498e8,561
summary(m.2mo.tow.count.tx),evaluation,519237346015871e7,560
"gam.2mo.avg.dur.la <- gam.2mo.avg.dur.la[, c(""yr"", ""jd"", ""hrs"",      ""do"", ""depth"", ""ppnd"", ""la_fuel_price"", ""avg.dur"", ""cent_lon"",      ""cent_lat"")]",data cleaning,519237346015871e7,560
gam.2mo.avg.dur.la <- na.omit(gam.2mo.avg.dur.la),data cleaning,519237346015871e7,560
average_twin_level_2 <- length(level_2$twin),data cleaning,728108570212498e8,561
"m.2mo.avg.dur.la <- gam(avg.dur ~ factor(yr) + la_fuel_price +      hrs + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), data = gam.2mo.avg.dur.la)",modeling,519237346015871e7,560
"nspm.2mo.avg.dur.la <- gam(avg.dur ~ factor(yr) + la_fuel_price +      hrs + s(do) + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat),      data = gam.2mo.avg.dur.la)",modeling,519237346015871e7,560
average_twin_level_2,evaluation,728108570212498e8,561
summary(m.2mo.avg.dur.la),evaluation,519237346015871e7,560
"gam.2mo.avg.dur.tx <- gam.2mo.avg.dur.tx[, c(""yr"", ""jd"", ""hrs"",      ""do"", ""depth"", ""ppnd"", ""la_fuel_price"", ""avg.dur"", ""cent_lon"",      ""cent_lat"")]",data cleaning,519237346015871e7,560
gam.2mo.avg.dur.tx <- na.omit(gam.2mo.avg.dur.tx),data cleaning,519237346015871e7,560
"m.2mo.avg.dur.tx <- gam(avg.dur ~ factor(yr) + la_fuel_price +      hrs + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), data = gam.2mo.avg.dur.tx)",modeling,519237346015871e7,560
"nspm.2mo.avg.dur.tx <- gam(avg.dur ~ factor(yr) + la_fuel_price +      hrs + s(do) + s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat),      data = gam.2mo.avg.dur.tx)",modeling,519237346015871e7,560
"variance_analysis = aov(twin ~ as.factor(Answer.item) + as.factor(distractor_position),      data = level_2)",data cleaning,728108570212498e8,561
summary(m.2mo.avg.dur.tx),evaluation,519237346015871e7,560
ix = 1,not sure,605313735548407e8,562
summary(variance_analysis),evaluation,728108570212498e8,561
"la.2008 <- subset(gam.2mo.dur.la, gam.2mo.dur.la$yr == 2008)",data cleaning,519237346015871e7,560
"tx.2008 <- subset(gam.2mo.dur.tx, gam.2mo.dur.tx$yr == 2008)",data cleaning,519237346015871e7,560
"la.2009 <- subset(gam.2mo.dur.la, gam.2mo.dur.la$yr == 2009)",data cleaning,519237346015871e7,560
"tx.2009 <- subset(gam.2mo.dur.tx, gam.2mo.dur.tx$yr == 2009)",data cleaning,519237346015871e7,560
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",import,605313735548407e8,562
"m2008.la <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = la.2008)",modeling,519237346015871e7,560
"m2008.tx <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = tx.2008)",modeling,519237346015871e7,560
"m2009.la <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = la.2009)",modeling,519237346015871e7,560
"m2009.tx <- gam(log(towhours + 1) ~ la_fuel_price + hrs + +s(depth) +      s(ppnd) + s(jd) + s(cent_lon, cent_lat) + s(cent_lon, cent_lat,      by = do), data = tx.2009)",modeling,519237346015871e7,560
"logistic_analysis = glm(twin ~ as.factor(Answer.scale_and_levels_condition) +      as.factor(Answer.item) + as.factor(distractor_position),      data = oneword_weird)",modeling,728108570212498e8,561
summary(logistic_analysis),evaluation,728108570212498e8,561
"ucas_gap_chart <- ggplot(data = ucas_data, aes(x = `Cycle Year`)) +      geom_point(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      geom_line(aes(y = demandSupplyDiff, colour = `Subject Group (Detailed Level)`)) +      labs(title = paste0(""Difference between number of University applications and number of acceptances (2007--2018)"")) +      ylab(""Demand / supply difference"") + xlab(""Year"") + scale_colour_discrete(name = ""Subject"",      labels = c(""Electronic & Electrical Engineering"", ""Computer Science"",          ""Software Engineering"")) + theme_minimal()",visualization,955573743907735e8,565
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure1.R"")",setup,519237346015871e7,560
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure2.R"")",setup,519237346015871e7,560
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure3.R"")",setup,519237346015871e7,560
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure4.R"")",setup,519237346015871e7,560
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure5.R"")",setup,519237346015871e7,560
"binom.test(40, 67, 0.75)",evaluation,728108570212498e8,561
level_1$Answer.comment,evaluation,728108570212498e8,561
sessionInfo(),setup,519237346015871e7,560
"ggsave(filename = getwd() %>% paste0(""/analysis/images/ucas-demand-suplus.png""),      plot = ucas_gap_chart, device = ""png"")",export,955573743907735e8,565
ix = 1,not sure,519237346015871e7,560
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,519237346015871e7,560
"AuROC.ms[ind.ix, 2] = auc(status, logLR)[1]",not sure,519237346015871e7,560
graph <- CYmerge,not sure,955573743907735e8,565
fn_iha_7q10(flows),export,728108570212498e8,561
"fn_iha_mlf(flows, 8)",export,728108570212498e8,561
graph$year[graph$year == 1995 | graph$year == 1996] <- 1994,data cleaning,955573743907735e8,565
g2 <- group2(flows),export,728108570212498e8,561
head(yahara),export,728108570212498e8,561
summary(yahara),export,728108570212498e8,561
"graph <- group_by(graph, year)",data cleaning,955573743907735e8,565
"path <- c(getwd(), filepath2)",communication,728108570212498e8,561
"path <- paste(path, collapse = """")",not sure,728108570212498e8,561
setwd(path),not sure,728108570212498e8,561
"write.csv(RigCountByTrajectory, file = ""CleanRigCountByTrajectory.csv"")",not sure,728108570212498e8,561
setwd(oldwd),not sure,728108570212498e8,561
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,357315384084359e8,566
library(stringr),data cleaning,357315384084359e8,566
"source(""Analysis/remove_self_node.R"")",import,357315384084359e8,566
"source(""Analysis/compute_triplets.R"")",setup,357315384084359e8,566
"source(""Analysis/compute_all_triplets.R"")",setup,357315384084359e8,566
"source(""Analysis/categorize_all_triplets.R"")",setup,357315384084359e8,566
"source(""Analysis/categorize_triplet1.R"")",setup,357315384084359e8,566
"coffeeG05 = read_graph(""Data/iGraphs/coffeeG05.gml"", format = ""gml"")",import,357315384084359e8,566
"gasG05 = read_graph(""Data/iGraphs/gasG05.gml"", format = ""gml"")",import,357315384084359e8,566
"all_triplets = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",exploratory,357315384084359e8,566
"all_triplets_test = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",exploratory,357315384084359e8,566
"ids = unique(unlist(all_triplets %>% filter(category == ""ABC"") %>%      select(X, Y, Z)))",data cleaning,357315384084359e8,566
"subG = induced_subgraph(coffeeG05, vids = ids)",exploratory,357315384084359e8,566
lay = layout.circle(subG),not sure,357315384084359e8,566
"par(mfrow = c(1, 1))",visualization,357315384084359e8,566
"plot(subG, layout = lay)",visualization,357315384084359e8,566
r = 14,not sure,357315384084359e8,566
"plot(induced_subgraph(coffeeG05, vids = as.character(unlist(all_triplets[r,      1:3]))), main = all_triplets[r, 5])",visualization,357315384084359e8,566
summary(r_e_2)$QEp,exploratory,357315384084359e8,566
summary(r_er_2)$QEp,exploratory,357315384084359e8,566
summary(r_o_2)$QEp,exploratory,357315384084359e8,566
qqnorm(residuals(r_e_2)),evaluation,357315384084359e8,566
qqline(residuals(r_e_2)),evaluation,357315384084359e8,566
qqnorm(residuals(r_er_2)),evaluation,357315384084359e8,566
qqline(residuals(r_er_2)),evaluation,357315384084359e8,566
qqnorm(residuals(r_o_2)),evaluation,357315384084359e8,566
qqline(residuals(r_o_2)),evaluation,357315384084359e8,566
funnel(r_e_2),evaluation,357315384084359e8,566
funnel(r_er_2),evaluation,357315384084359e8,566
funnel(r_o_2),evaluation,357315384084359e8,566
"m_e_ranef <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~1,      random = ~1 | unique_type, data = metadat_lnrr_noherb_list$experimental)",modeling,357315384084359e8,566
"m_er_ranef <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~1,      random = ~1 | unique_type, data = metadat_lnrr_noherb_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_ranef <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~1,      random = ~1 | unique_type, data = metadat_lnrr_noherb_list$observational)",modeling,357315384084359e8,566
summary(m_e_ranef),evaluation,357315384084359e8,566
summary(m_er_ranef),evaluation,357315384084359e8,566
summary(m_o_ranef),evaluation,357315384084359e8,566
summary(m_ranef),evaluation,357315384084359e8,566
summary(m_fxl_order),evaluation,357315384084359e8,566
"m_e_fxl_order <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp *      order3, random = ~1 | unique_type, data = metadat_lnrr_fxl_order_list$experimental)",modeling,357315384084359e8,566
setwd(oldwd),setup,174626463092864e8,567
"m_er_fxl_order <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp *      order3, random = ~1 | unique_type, data = metadat_lnrr_fxl_order_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_fxl_order <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp *      order3, random = ~1 | unique_type, data = metadat_lnrr_fxl_order_list$observational)",modeling,357315384084359e8,566
summary(m_e_fxl_order),modeling,357315384084359e8,566
summary(m_er_fxl_order),modeling,357315384084359e8,566
summary(m_o_fxl_order),modeling,357315384084359e8,566
anova(m_fxl_fucales),modeling,357315384084359e8,566
"setwd(""/data/mcgaugheyd/projects/nei/hufnagel/ddl_nisc_custom_capture/recalibrated_bams/"")",setup,174626463092864e8,567
"m_e_fxl_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_fxl_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
anova(m_e_fxl_fucales),modeling,357315384084359e8,566
library(BatchJobs),import,174626463092864e8,567
anova(m_er_fxl_fucales),modeling,357315384084359e8,566
library(PopSV),import,174626463092864e8,567
"anova(m_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0), c(0,      1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1, 0)))",modeling,357315384084359e8,566
"anova(m_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",modeling,357315384084359e8,566
"source(""~/git/CNV_analysis/PopSV/automatedPipeline.R"")",import,174626463092864e8,567
"m_e_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"anova(m_e_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",modeling,357315384084359e8,566
"anova(m_e_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",modeling,357315384084359e8,566
"anova(m_er_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",modeling,357315384084359e8,566
"bam.files = read.table(""~/git/CNV_analysis/Analysis/ddl_nisc_eye_panel_PopSV/bams.tsv"",      as.is = TRUE, header = TRUE)",import,174626463092864e8,567
"anova(m_er_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0),      c(0, 0, 1, 0), c(0, 0, 0, 1)))",modeling,357315384084359e8,566
"anova(m_o_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",modeling,357315384084359e8,566
"anova(m_o_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",modeling,357315384084359e8,566
anova(m_depth_fucales),modeling,357315384084359e8,566
"m_e_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$observational)",modeling,357315384084359e8,566
anova(m_e_depth_fucales),modeling,357315384084359e8,566
anova(m_er_depth_fucales),modeling,357315384084359e8,566
anova(m_o_depth_fucales),modeling,357315384084359e8,566
"m_e_depth_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~coralline * depth_m_relative_to_mllw, random = ~1 |          unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~coralline * depth_m_relative_to_mllw, random = ~1 |          unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"m_e_depth_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"files.df = init.filenames(bam.files, code = ""example"")",not sure,174626463092864e8,567
anova(m_depth_kelp),modeling,357315384084359e8,566
"metadat_lnrr_kelp %>% ggplot(aes(x = depth_m_relative_to_mllw,      color = expt_type)) + geom_density(aes(fill = expt_type),      alpha = 0.5)",visualization,357315384084359e8,566
"save(files.df, file = ""files.RData"")",export,174626463092864e8,567
"m_e_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"anova(m_e_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",modeling,357315384084359e8,566
bin.size = 1000,not sure,174626463092864e8,567
"anova(m_er_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",modeling,357315384084359e8,566
"data2 <- data[, c(""AboveGroundFloor"", ""RenovationFlag"", ""grade"",      ""condition"", ""View"", ""WaterfrontView"", ""NumberOfFloors"",      ""NumberOfBedrooms"", ""NumberOfBathrooms"", ""SaleYear"", ""ConstructionYear"",      ""TotalArea"", ""BasementSize"", ""LivingSpace"", ""quantile"")]",setup,440988841932267e8,568
"anova(m_o_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",modeling,357315384084359e8,566
"m_e_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"m_e_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
summary(m_lat_fucales),modeling,357315384084359e8,566
"m_e_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$observational)",modeling,357315384084359e8,566
"test <- manova(cbind(AboveGroundFloor, RenovationFlag, grade,      condition, View, WaterfrontView, NumberOfFloors, NumberOfBedrooms,      NumberOfBathrooms, SaleYear, ConstructionYear, TotalArea,      LivingSpace) ~ quantile, data = data2)",exploratory,440988841932267e8,568
"m_e_lat_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"m_e_lat_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
summary(m_lat_kelp),modeling,357315384084359e8,566
"summary(test, test = ""Wilks"")",exploratory,440988841932267e8,568
"m_e_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"m_e_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"m_e_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
summary(m_lh),modeling,357315384084359e8,566
"m_e_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~kelp_life_stage *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~kelp_life_stage *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"anova(m_er_lh_grp_kelp_cor, L = rbind(c(1, 0, 0, 0, 0, 0), c(0,      1, 0, 0, 0, 0), c(0, 0, 1, 0, 0, 0), c(0, 0, 0, 1, 0, 0),      c(0, 0, 0, 0, 1, 0), c(0, 0, 0, 0, 0, 1)))",modeling,357315384084359e8,566
"m_e_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental)",modeling,357315384084359e8,566
"m_er_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,357315384084359e8,566
"m_o_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$observational)",modeling,357315384084359e8,566
"anova(m_er_lh_grp_kelp_crust, L = rbind(c(1, 0, 0, 0, 0), c(0,      1, 0, 0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0,      0, 0, 1), c(1, 0, 0, 1, 0)))",modeling,357315384084359e8,566
"m_e_lh_grp_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_lh_grp_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"m_e_lh_grp_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,357315384084359e8,566
"m_er_lh_grp_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,357315384084359e8,566
"ASAP_pdb_prop = rbind(ASAP_pdb_prop, row)",data cleaning,77623645728454e9,569
"setwd(""C:/Users/Amir/Documents/GitHub/cordiv/analysis/src"")",setup,77623645728454e9,569
"colnames(rnaMeta) = rnaSeq[1:10, 2]",data cleaning,430237762164325e8,545
"write.csv(ASAP_pdb_prop, ""../tables/ASAP_pdb_prop.csv"", row.names = F)",export,77623645728454e9,569
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",data cleaning,430237762164325e8,545
"rnaExp = apply(rnaExp, 2, as.numeric)",data cleaning,430237762164325e8,545
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",data cleaning,430237762164325e8,545
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",data cleaning,430237762164325e8,545
"rnaCelIDs = as.numeric(as.character(rnaSeq[12:nrow(rnaSeq), 2]))",data cleaning,430237762164325e8,545
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",data cleaning,430237762164325e8,545
"tresh <- rnaSeqTresh(rnaExp, ""analysis/02.Mouse Single Cell/tresholds"",      cores = 16)",data cleaning,430237762164325e8,545
rn(rnaExp),data cleaning,430237762164325e8,545
"tresholds = matrix(rep(1, len(rn(rnaExp))))",data cleaning,430237762164325e8,545
rownames(tresholds) = rn(rnaExp),data cleaning,430237762164325e8,545
"write.table(tresholds, file = ""analysis/02.Mouse Single Cell/noTresh"",      col.names = F, row.names = T, quote = F)",export,430237762164325e8,545
require(org.Hs.eg.db),setup,430237762164325e8,545
all.gn <- unique(unlist(as.list(org.Hs.egSYMBOL))),data cleaning,430237762164325e8,545
samp.tab <- samp.tab %>% filter(Gene %in% all.gn),data cleaning,430237762164325e8,545
"allz <- which(apply(samp.tab %>% dplyr::select(-Gene), 1, function(x) all(x ==      0)))",data cleaning,430237762164325e8,545
"if (length(allz) > 0) samp.tab <- samp.tab[-allz, ]",data cleaning,430237762164325e8,545
samp.mat <- samp.tab %>% dplyr::select(-Gene),data cleaning,430237762164325e8,545
print(dim(samp.mat)),exploratory,430237762164325e8,545
"rownames(samp.mat) <- make.names(samp.tab$Gene, unique = TRUE)",data cleaning,430237762164325e8,545
"cell.annotations <- data.frame(Patient = as.factor(sapply(colnames(samp.tab),      function(x) gsub(""LN"", """", unlist(strsplit(x, split = ""_""))[1]))),      IsPooled = as.factor(sapply(colnames(samp.tab), function(x) unlist(strsplit(x,          split = ""_""))[2] == ""Pooled"")), IsTumor = as.factor(sapply(colnames(samp.tab),          function(x) length(grep(""LN"", x)) == 0)))[-1, ]",data cleaning,430237762164325e8,545
"source(""./src/4_clean.R"")",import,77623645728454e9,569
"rmd <- system.file(""processing_clustering_vis.Rmd"", package = ""singleCellSeq"")",import,430237762164325e8,545
"source(""./src/5_tables.R"")",import,77623645728454e9,569
"source(""./src/6_figures.R"")",import,77623645728454e9,569
"kf <- rmarkdown::render(rmd, rmarkdown::html_document(), output_file = paste(getwd(),      ""/processing_cluster_vis.html"", sep = """"), params = list(samp.mat = samp.mat,      gene.list = ""mcpcounter""))",export,430237762164325e8,545
"source(""./src/7_analysis.R"")",import,77623645728454e9,569
"synapser::synStore(File(kf, parentId = analysis_dir), executed = paste(""https://raw.githubusercontent.com/Sage-Bionetworks/single-cell-seq/master/analysis/"",      syn_file, ""/run_"", syn_file, ""_analysis.R"", sep = """"), used = syn_file)",data cleaning,430237762164325e8,545
library(dplyr),setup,557301021879539e8,570
sink(),export,440988841932267e8,568
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",export,77623645728454e9,569
"rmd <- system.file(""heatmap_vis.Rmd"", package = ""singleCellSeq"")",import,430237762164325e8,545
"kf <- rmarkdown::render(rmd, rmarkdown::html_document(), output_file = paste(getwd(),      ""/heatmap_vis.html"", sep = """"), params = list(samp.mat = samp.mat,      cell.annotations = cell.annotations))",export,430237762164325e8,545
"table_categorisation <- read.csv(""analysis/materialforpaper/table_categorisation.csv"")",import,440988841932267e8,568
"synapser::synStore(File(kf, parentId = analysis_dir), executed = paste(""https://raw.githubusercontent.com/Sage-Bionetworks/single-cell-seq/master/analysis/"",      syn_file, ""/run_"", syn_file, ""_analysis.R"", sep = """"), used = syn_file)",data cleaning,430237762164325e8,545
"sink(""analysis/materialforpaper/tablecat2.tex"")",export,440988841932267e8,568
"cmapData = cmapR::parse.gctx(""/space/scratch/nlim/LINCS/GSE92742-Level5/Level5_Data.gctx"")",import,557301021879539e8,570
"print(xtable::xtable(table_categorisation, align = ""|l|l|l|l|"",      label = ""cat_table"", caption = ""The initial 45 columns were pooled into 18 and 10 categories.""),      include.rownames = FALSE, table.placement = ""!htbp"")",communication,440988841932267e8,568
"print(""read DE data"")",communication,557301021879539e8,570
sink(),export,440988841932267e8,568
gc(),evaluation,557301021879539e8,570
tracks <- unique(VMS$Doc_Number),exploratory,440988841932267e8,568
"print(""garbage collection complete"")",communication,557301021879539e8,570
captured <- length(uniqueShrimps[which(uniqueShrimps %in% tracks)]),exploratory,440988841932267e8,568
"inst = readr::read_tsv(""/space/scratch/nlim/LINCS/GSE92742-Level5/Sig_Info.txt"")",import,557301021879539e8,570
"L1000geneAnnots = readr::read_tsv(""/space/scratch/nlim/LINCS/GSE92742-Level5/Gene_Info.txt"")",import,557301021879539e8,570
"print(""read metadata"")",communication,557301021879539e8,570
summary(quantModel),exploratory,901615852722898e8,571
"pred <- data.frame(d = seq(min(wood_density_data_178ha$d), max(wood_density_data_178ha$d),      length = 100))",setup,901615852722898e8,571
instanceOrder = colnames(cmapData@mat),not sure,557301021879539e8,570
geneOrder = rownames(cmapData@mat),not sure,557301021879539e8,570
"taus <- c(0.025, 0.1, 0.5, 0.9, 0.975)",setup,901615852722898e8,571
"shrimpVMS <- VMS[VMS$Doc_Number %in% uniqueShrimps, ]",exploratory,440988841932267e8,568
"L1000geneAnnots = L1000geneAnnots[match(geneOrder, L1000geneAnnots$pr_gene_id),      ]",not sure,557301021879539e8,570
length(unique(shrimpVMS$Doc_Number)) == captured,exploratory,440988841932267e8,568
"write.csv(shrimpVMS, ""/wrk2/efuller/NOAA/Data_Analysis/VMS/Code/processed_data/shrimpVMS.csv"")",export,440988841932267e8,568
owned <- unique(Owners$VESSEL.DOC..),exploratory,440988841932267e8,568
"preds <- expand.grid(d = pred$d, Quantile = as.factor(taus))",data cleaning,901615852722898e8,571
"preds$e <- as.vector(predict(quantModel, pred, type = ""response""))",data cleaning,901615852722898e8,571
df$Team1_avg_pnt_top_3_players_6 = as.numeric(df$Team1_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
df$Team2_avg_pnt_top_3_players_6 = as.numeric(df$Team2_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
"CIQ <- booter(quantModel, data = wood_density_data_178ha, preds = pred,      quantreg = TRUE, n = 5000)",modeling,901615852722898e8,571
df,setup,20816502859816e8,568
"model.predict <- function(df) p.hats = predict(train.glm, newdata = df)",modeling,20816502859816e8,568
"preds$CI025 <- CIQ[1, ]",data cleaning,901615852722898e8,571
"for (lag in 1:nrow(acf_df)) acf_plot <- acf_plot + geom_segment(aes(xend = lag,      yend = 0))",visualization,248167911078781e8,572
return(data.frame(result = p.hats)),evaluation,20816502859816e8,568
"acf_plot + scale_y_continuous(limits = c(-1, 1))",visualization,248167911078781e8,572
"preds$CI975 <- CIQ[2, ]",data cleaning,901615852722898e8,571
flc_mod <- mod,not sure,248167911078781e8,572
"write.table(preds, file = ""./analysis/wood_density_distribution/data/quantreg_predictions.txt"")",export,901615852722898e8,571
head(preds),exploratory,901615852722898e8,571
"cols <- c(""#8CB369"", ""#F4E285"", ""#4C8577"", ""#F4A259"", ""#BC4B51"")",setup,901615852722898e8,571
"yhat.deploy(""nbaGLM"")",modeling,20816502859816e8,568
"yhat.predict(model_name = ""nbaGLM"", test[1, ])",modeling,20816502859816e8,568
"predict.glm(train.glm, newdata = test[1, ], type = ""response"")",modeling,20816502859816e8,568
model.require <- function() library(e1071),modeling,20816502859816e8,568
"p1 <- ggplot(preds[preds$d < 0.6, ], aes(x = d, y = exp(e), group = Quantile)) +      geom_point(data = wood_density_data_178ha[wood_density_data_178ha$d <          0.6, ], inherit.aes = F, aes(x = d, y = e)) + geom_ribbon(aes(ymin = exp(CI025),      ymax = exp(CI975), group = Quantile, fill = Quantile), alpha = 0.74) +      geom_line() + theme_bw() + ylab(""Elevation (m asl)"") + xlab(bquote(""Wood density g"" ~      cm^-3)) + theme(legend.position = ""top"") + scale_fill_manual(values = cols) +      theme(text = element_text(size = 20))",visualization,901615852722898e8,571
model.transform <- function(df) df$Team1_win_last_6 = as.numeric(df$Team1_win_last_6),modeling,20816502859816e8,568
p1,exploratory,901615852722898e8,571
"ggsave(p1, file = ""./analysis/wood_density_distribution/graph_code/graphs/wooddensity_VS_elevation_quanReg.png"",      width = 7, height = 6)",export,901615852722898e8,571
df$Team2_win_last_6 = as.numeric(df$Team2_win_last_6),data cleaning,20816502859816e8,568
df$Team1_away_win_percentage_10 = as.numeric(df$Team1_away_win_percentage_10),data cleaning,20816502859816e8,568
df$Team2_away_win_percentage_10 = as.numeric(df$Team2_away_win_percentage_10),data cleaning,20816502859816e8,568
df$Team1_avg_pnt_top_3_players_6 = as.numeric(df$Team1_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
df$Team2_avg_pnt_top_3_players_6 = as.numeric(df$Team2_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
prts <- unique(vessel_landings$pcid),exploratory,901615852722898e8,571
"props <- total %>% left_join(fresh, by = ""year"") %>% mutate(prop = n/ntot) %>%      ggplot(aes(x = year, y = prop)) + geom_col() + scale_x_continuous(breaks = yrs,      expand = c(0.01, 0), limits = c(yrs[1], yrs[28])) + xlab(""Year"") +      ylab(""Proportion fresh and eyeless"") + cowplot::theme_cowplot() +      theme(axis.text.x = element_text(angle = 90, vjust = 0.5))",visualization,926322991494089e8,564
df,import,20816502859816e8,568
"model.predict <- function(df) p.hats = predict(train.svm.1, newdata = df)",modeling,20816502859816e8,568
return(data.frame(result = p.hats)),modeling,20816502859816e8,568
"cowplot::ggsave(""analysis/output/proportion_fresh_capelin.png"",      height = 10, width = 10)",export,926322991494089e8,564
"yhat.deploy(""nbaSVM"")",modeling,20816502859816e8,568
"yhat.svm.result = yhat.predict(model_name = ""nbaSVM"", test)",modeling,20816502859816e8,568
yhat.svm.result,modeling,20816502859816e8,568
"mean(yhat.svm.result == test$Result, na.rm = TRUE)",modeling,20816502859816e8,568
yhat.svm.result,modeling,20816502859816e8,568
model.require <- function() library(e1071),modeling,20816502859816e8,568
model.transform <- function(df) df$Team1_win_last_6 = as.numeric(df$Team1_win_last_6),modeling,20816502859816e8,568
df$Team2_win_last_6 = as.numeric(df$Team2_win_last_6),data cleaning,20816502859816e8,568
df$Team1_away_win_percentage_10 = as.numeric(df$Team1_away_win_percentage_10),data cleaning,20816502859816e8,568
df$Team2_away_win_percentage_10 = as.numeric(df$Team2_away_win_percentage_10),data cleaning,20816502859816e8,568
"if (length(which(gvdata$OurName %in% rownames(rezdata))) != dim(gvdata)[1]) stop(""Error in name matching!"")",import,926322991494089e8,564
df$Team1_avg_pnt_top_3_players_6 = as.numeric(df$Team1_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
df$Team2_avg_pnt_top_3_players_6 = as.numeric(df$Team2_avg_pnt_top_3_players_6),data cleaning,20816502859816e8,568
"library(""dplyr"")",setup,198185169603676e8,568
"library(""ggplot2"")",setup,198185169603676e8,568
"library(""tidyr"")",setup,198185169603676e8,568
"library(""tibble"")",setup,198185169603676e8,568
"library(""stringr"")",setup,198185169603676e8,568
"library(""lubridate"")",setup,198185169603676e8,568
"library(""DBI"")",setup,198185169603676e8,568
"library(""tidygraph"")",setup,198185169603676e8,568
"library(""tidytext"")",setup,198185169603676e8,568
"library(""magrittr"")",setup,198185169603676e8,568
"library(""readr"")",setup,198185169603676e8,568
"library(""readxl"")",setup,198185169603676e8,568
"library(""purrr"")",setup,198185169603676e8,568
"library(""visNetwork"")",setup,198185169603676e8,568
"outfile = ""analysis/F/compare_F_and_F_subtract.pdf""",export,38868009718135e9,573
"con <- dbConnect(RMySQL::MySQL(), dbname = ""ba"", host = ""localhost"",      port = 3306, user = ""root"", password = ""1234"")",import,198185169603676e8,568
"data_mat = load_data(""example_data/other_data/F_subtract.txt"")",import,38868009718135e9,573
"event_locations1 = read.csv(file_list[[1]], row.names = 1)",import,38868009718135e9,573
"event_locations2 = read.csv(file_list[[2]], row.names = 1)",import,38868009718135e9,573
event_locations3 = read.csv(file_list[[3]]),import,38868009718135e9,573
"source(""./src/7_analysis.R"")",setup,541811172151938e8,574
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,611179769039154e8,575
"sql_statement <- ""SELECT ba.website.url AS website_url, ba.link.domain AS link_url, ba.link.article_id AS article_id FROM ba.link INNER JOIN ba.article ON ba.link.article_id=ba.article.id INNER JOIN ba.website ON article.website_id=website.id""",import,198185169603676e8,568
"get_event_group <- function(event_locations_temp, event_group) return(sapply(1:ncol(event_locations_temp),      function(i) event_locations_temp[, i] %in% event_group))",setup,38868009718135e9,573
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",communication,541811172151938e8,574
all_links <- con %>% tbl(sql(sql_statement)) %>% collect(),import,198185169603676e8,568
"event_group = c(1, 3, -1.5)",setup,38868009718135e9,573
"sql_statement_website <- ""SELECT id, name, url FROM ba.website""",import,198185169603676e8,568
gtex <- read.gtex.data(gtex.data.file),import,541811172151938e8,574
all_websites <- con %>% tbl(sql(sql_statement_website)) %>% collect(),import,198185169603676e8,568
"sql_all_articles <- ""SELECT id, url, content_text, date_published, website_id FROM ba.article""",import,198185169603676e8,568
all_articles <- con %>% tbl(sql(sql_all_articles)) %>% collect(),exploratory,198185169603676e8,568
"cat(sprintf(""Total number of tissue types: %d\n"", nrow(gtex)))",exploratory,541811172151938e8,574
"sample_articles <- all_articles %>% filter(as.Date(date_published) >=      ""2016-03-01"" & as.Date(date_published) <= ""2018-03-01"")",exploratory,198185169603676e8,568
sample_links <- all_links %>% filter(article_id %in% sample_articles$id) %>%      filter(!(link_url == website_url)),exploratory,198185169603676e8,568
"cat(sprintf(""Total number of genes: %d\n"", ncol(gtex)))",exploratory,541811172151938e8,574
"sample_links_clean <- sample_links %>% mutate(website_url = str_remove(website_url,      ""http.0,1://"")) %>% mutate(website_url = str_remove(website_url,      ""www."")) %>% mutate(website_url = str_remove(website_url,      ""/"")) %>% mutate(link_url = str_remove(link_url, ""http.0,1://"")) %>%      mutate(link_url = str_remove(link_url, ""www."")) %>% mutate(link_url = str_remove(link_url,      ""/""))",data cleaning,198185169603676e8,568
"rows <- !is.element(rownames(gtex), c(""pancreas"", ""whole blood""))",exploratory,541811172151938e8,574
"gtex <- gtex[rows, ]",data cleaning,541811172151938e8,574
"upswings = ((get_event_group(event_locations1, -c(event_group,      2, -2, 0)) & get_event_group(event_locations2, event_group)) &      get_event_group(event_locations3, event_group)) | ((get_event_group(event_locations1,      -event_group) & get_event_group(event_locations2, c(event_group,      2, -2, 0))) & get_event_group(event_locations3, event_group))",setup,38868009718135e9,573
"platforms <- ""linkedin|wikipedia|wikimedia|commons|google|youtube|telegram|whatsapp|facebook|vk.com|mailto|javascript|creativecommons|xing|pinterest|addtoany|amzn.to|twitter|instagram|vkontakte|youtu.be|vimeo|amazon|ebay""",import,198185169603676e8,568
gtex.pca <- prcomp(gtex),modeling,541811172151938e8,574
"downswings = ((get_event_group(event_locations1, c(event_group,      2, -2, 0)) & get_event_group(event_locations2, -event_group)) &      get_event_group(event_locations3, -event_group)) | ((get_event_group(event_locations1,      event_group) & get_event_group(event_locations2, -c(event_group,      2, -2, 0))) & get_event_group(event_locations3, -event_group))",setup,38868009718135e9,573
event_locations = upswings * 0,setup,38868009718135e9,573
event_locations[upswings] = 1,setup,38868009718135e9,573
"print(summary(gtex.pca)$importance[, 1:2])",evaluation,541811172151938e8,574
event_locations[downswings] = -1,setup,38868009718135e9,573
pdf(NULL),communication,541811172151938e8,574
"concurrent_events = find_concurrent_events(event_locations, 2,      event_types = c(-1, 1))",exploratory,38868009718135e9,573
"pdf(outfile, width = 14, height = 14)",export,38868009718135e9,573
"p <- plot.gtex.top2pcs(gtex, gtex.pca)",visualization,541811172151938e8,574
"ggsave(pc.plot.file, p, height = 4, width = 4, dpi = 200)",export,541811172151938e8,574
"make_visual(data_mat, event_locations, concurrent_events, log_colors = T,      diverging = T)",visualization,38868009718135e9,573
dev.off(),export,38868009718135e9,573
"d.0 <- read.table(""../history_0.txt"", skip = 2)",import,38868009718135e9,573
dev.off(),export,541811172151938e8,574
print(sessionInfo()),setup,541811172151938e8,574
"outputs <- d.0[(no.agents + 1):length(d.0[, 1]), (4 + no.features +      1):(4 + no.features + 1 + no.features - 1)]",data cleaning,38868009718135e9,573
csim <- function(x1) x <- as.numeric(x1),setup,38868009718135e9,573
y <- as.numeric(uber.proto),data cleaning,38868009718135e9,573
c <- x %*% y/sqrt(x %*% x * y %*% y),setup,38868009718135e9,573
return(c),setup,38868009718135e9,573
"d.sim <- apply(outputs, 1, csim)",setup,38868009718135e9,573
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"")",visualization,38868009718135e9,573
"probe_and_timing_and_occurance_table <- db %>% tbl(""metadata"") %>%      collect %>% mutate(occurance = grepl(""^OCCURANCE"", key)) %>%      mutate(timing = (grepl(""^TIMING"", key) | grepl(""^PROBE"",          key))) %>% filter(timing | occurance) %>% mutate(segment = sapply(str_split(mapply(trim,      key), ""/"", n = 2), `[`, 2), probe = sapply(str_split(mapply(trim,      key), ""/"", n = 2), `[`, 1)) %>% mutate(segment = ifelse(is.na(segment),      ""TOTAL"", segment)) %>% select(-key)",data cleaning,38868009718135e9,573
list(timing = probe_and_timing_and_occurance_table),setup,38868009718135e9,573
"summarize_analyses <- function(analyses) timing <- analyses$timing %>%      group_by(probe, segment) %>% summarize(time = sum(as.numeric(ifelse(timing,      value, 0))), count = sum(as.numeric(ifelse(occurance, value,      0)))) %>% mutate(count = ifelse(count == 0, 1, count)) %>%      mutate(number = time/count) %>% select(probe, segment, number) %>%      ungroup",setup,38868009718135e9,573
"list(all = timing, total = timing %>% filter(grepl(""TOTAL"", segment)) %>%      select(-segment) %>% mutate(percent = (100 * number/sum(number))) %>%      arrange(desc(percent)), probes_and_segments = timing %>%      filter(!grepl(""TOTAL"", segment)) %>% mutate(percent = (100 *      number/sum(number))) %>% arrange(desc(percent)), segments = timing %>%      filter(!grepl(""TOTAL"", segment)) %>% group_by(segment) %>%      summarize(number = sum(number)) %>% ungroup %>% mutate(percent = (100 *      number/sum(number))) %>% arrange(desc(percent)), probes = timing %>%      filter(!grepl(""TOTAL"", segment)) %>% group_by(probe) %>%      summarize(number = sum(number)) %>% ungroup %>% mutate(percent = (100 *      number/sum(number))) %>% arrange(desc(percent)))",data cleaning,38868009718135e9,573
visualize_analyses <- function(analyses) list(),setup,38868009718135e9,573
latex_analyses <- function(analyses) list(),setup,38868009718135e9,573
"main <- function() analyzer <- create_analyzer(""Timing Information"",      analyze_database, combine_analyses, summarize_analyses, visualize_analyses,      latex_analyses)",setup,38868009718135e9,573
drive_analysis(analyzer),exploratory,38868009718135e9,573
mobileCyc = mobileJsonCyc$Cycle$Data,exploratory,753568042069673e8,568
desktopCyc = desktopJsonCyc$Cycle$Data,exploratory,753568042069673e8,568
siblingCyc = siblingJsonCyc$Cycle$Data,exploratory,753568042069673e8,568
sibMobCyc = sibMobJsonCyc$Cycle$Data,exploratory,753568042069673e8,568
sibDesktCyc = sibDeskJsonCyc$Cycle$Data,exploratory,753568042069673e8,568
main(),exploratory,38868009718135e9,573
siblingCyc = siblingCyc[-which(siblingCyc %in% c(max(siblingCyc)))],exploratory,753568042069673e8,568
warnings(),exploratory,38868009718135e9,573
"RunAnalysis <- function() print(t.test(mobileCyc, desktopCyc,      alternative = ""two.sided"", var.equal = FALSE))",exploratory,753568042069673e8,568
logLR.null = as.numeric(logLR_list),data cleaning,615602674894035e8,568
done.null = done_res,data cleaning,615602674894035e8,568
sum(done.alt),exploratory,615602674894035e8,568
sum(done.null),exploratory,615602674894035e8,568
min(logLR.alt),exploratory,615602674894035e8,568
max(logLR.alt),exploratory,615602674894035e8,568
min(logLR.null),exploratory,615602674894035e8,568
max(logLR.null),exploratory,615602674894035e8,568
wave.null[[3]] = logLR.null,exploratory,615602674894035e8,568
wave.alt[[3]] = logLR.alt,exploratory,615602674894035e8,568
ix = 1,setup,615602674894035e8,568
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",setup,615602674894035e8,568
"AuROC.ms[ind.ix, 2] = auc(status, logLR)[1]",setup,615602674894035e8,568
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",exploratory,615602674894035e8,568
"AuROC.wave[ind.ix, 2] = auc(status, logLR)[1]",exploratory,615602674894035e8,568
ix = 2,setup,615602674894035e8,568
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",exploratory,615602674894035e8,568
"AuROC.ms[ind.ix, 3] = auc(status, logLR)[1]",exploratory,615602674894035e8,568
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",exploratory,615602674894035e8,568
"AuROC.wave[ind.ix, 3] = auc(status, logLR)[1]",exploratory,615602674894035e8,568
ix = 3,exploratory,615602674894035e8,568
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",exploratory,615602674894035e8,568
"AuROC.ms[ind.ix, 4] = auc(status, logLR)[1]",exploratory,615602674894035e8,568
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",exploratory,615602674894035e8,568
"AuROC.wave[ind.ix, 4] = auc(status, logLR)[1]",exploratory,615602674894035e8,568
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.wave""",export,615602674894035e8,568
"write.table(AuROC.wave, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",exploratory,615602674894035e8,568
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.ms""",export,615602674894035e8,568
"write.table(AuROC.ms, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",exploratory,615602674894035e8,568
"hist(ms.alt[[3]], main = paste0(""alt multiscale : "", numIND,      "" "", title.name[3]), breaks = 47)",not sure,615602674894035e8,568
"par(mfrow = c(4, 1))",data cleaning,615602674894035e8,568
"hist(wave.null[[4]], main = paste0(""null Wavelet : "", numIND,      "" "", title.name[4]), breaks = 47)",not sure,615602674894035e8,568
"hist(ms.null[[4]], main = paste0(""null multiscale : "", numIND,      "" "", title.name[4]), breaks = 47)",not sure,615602674894035e8,568
"hist(wave.alt[[4]], main = paste0(""alt Wavelet : "", numIND, "" "",      title.name[4]), breaks = 47)",not sure,615602674894035e8,568
"hist(ms.alt[[4]], main = paste0(""alt multiscale : "", numIND,      "" "", title.name[4]), breaks = 47)",not sure,615602674894035e8,568
dev.off(),not sure,615602674894035e8,568
"tpr.wave.list = vector(""list"", length(case.name))",exploratory,615602674894035e8,568
"fpr.ms.list = vector(""list"", length(case.name))",exploratory,615602674894035e8,568
"tpr.ms.list = vector(""list"", length(case.name))",setup,615602674894035e8,568
"for (cc in 1:length(case.name)) pval = as.numeric(c(wave.null[[cc]],      wave.alt[[cc]]))",exploratory,615602674894035e8,568
"disc = c(rep(0, 578), rep(1, 578))",exploratory,615602674894035e8,568
rnk = order(pval),exploratory,615602674894035e8,568
p.wave = pval[rnk],exploratory,615602674894035e8,568
d.wave = disc[rnk],exploratory,615602674894035e8,568
fdp.wave = NULL,exploratory,615602674894035e8,568
sig.wave = NULL,exploratory,615602674894035e8,568
tpr.wave = NULL,exploratory,615602674894035e8,568
fpr.wave = NULL,exploratory,615602674894035e8,568
uni.p.wave = unique(p.wave),exploratory,615602674894035e8,568
for (i in 1:length(uni.p.wave)) wh = which(p.wave <= uni.p.wave[i]),exploratory,615602674894035e8,568
sig.wave[i] = length(wh),exploratory,615602674894035e8,568
fdp.wave[i] = 1 - (sum(d.wave[wh])/length(wh)),exploratory,615602674894035e8,568
tpr.wave[i] = sum(d.wave[wh])/578,exploratory,615602674894035e8,568
fpr.wave[i] = (length(wh) - sum(d.wave[wh]))/578,exploratory,615602674894035e8,568
fpr.wave.list[[cc]] = fpr.wave,exploratory,615602674894035e8,568
tpr.wave.list[[cc]] = tpr.wave,exploratory,615602674894035e8,568
"for (cc in 1:length(case.name)) pval = as.numeric(c(ms.null[[cc]],      ms.alt[[cc]]))",exploratory,615602674894035e8,568
"disc = c(rep(0, 578), rep(1, 578))",not sure,615602674894035e8,568
rnk = order(pval),not sure,615602674894035e8,568
p.ms = pval[rnk],not sure,615602674894035e8,568
d.ms = disc[rnk],not sure,615602674894035e8,568
fdp.ms = NULL,not sure,615602674894035e8,568
sig.ms = NULL,not sure,615602674894035e8,568
tpr.ms = NULL,not sure,615602674894035e8,568
fpr.ms = NULL,not sure,615602674894035e8,568
uni.p.ms = unique(p.ms),not sure,615602674894035e8,568
for (i in 1:length(uni.p.ms)) wh = which(p.ms <= uni.p.ms[i]),exploratory,615602674894035e8,568
sig.ms[i] = length(wh),exploratory,615602674894035e8,568
fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh)),exploratory,615602674894035e8,568
tpr.ms[i] = sum(d.ms[wh])/578,exploratory,615602674894035e8,568
fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/578,exploratory,615602674894035e8,568
fpr.ms.list[[cc]] = fpr.ms,exploratory,615602674894035e8,568
tpr.ms.list[[cc]] = tpr.ms,exploratory,615602674894035e8,568
pdf(ROC.file.name),exploratory,615602674894035e8,568
xmax = 1,export,615602674894035e8,568
ymax = 1,setup,615602674894035e8,568
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",setup,615602674894035e8,568
"points(c(0, fpr.ms.list[[1]]), c(0, tpr.ms.list[[1]]), type = ""l"",      col = ""red"")",visualization,615602674894035e8,568
"points(c(0, fpr.wave.list[[1]]), c(0, tpr.wave.list[[1]]), type = ""l"",      col = ""blue"")",not sure,615602674894035e8,568
"points(c(0, fpr.ms.list[[2]]), c(0, tpr.ms.list[[2]]), type = ""l"",      col = ""red"", lty = ""dashed"")",not sure,615602674894035e8,568
"points(c(0, fpr.wave.list[[2]]), c(0, tpr.wave.list[[2]]), type = ""l"",      col = ""blue"", lty = ""dashed"")",visualization,615602674894035e8,568
"points(c(0, fpr.ms.list[[3]]), c(0, tpr.ms.list[[3]]), type = ""l"",      col = ""red"", lty = ""dotdash"")",visualization,615602674894035e8,568
"points(c(0, fpr.wave.list[[3]]), c(0, tpr.wave.list[[3]]), type = ""l"",      col = ""blue"", lty = ""dotdash"")",visualization,615602674894035e8,568
"points(c(0, fpr.ms.list[[4]]), c(0, tpr.ms.list[[4]]), type = ""l"",      col = ""red"", lty = ""dotted"")",visualization,615602674894035e8,568
"points(c(0, fpr.wave.list[[4]]), c(0, tpr.wave.list[[4]]), type = ""l"",      col = ""blue"", lty = ""dotted"")",visualization,615602674894035e8,568
"legend(0.7, 0.3, c(paste0(""multiscale "", numIND), paste0(""Wavelets "",      numIND), title.name), col = c(""red"", ""blue"", ""black"", ""black"",      ""black"", ""black""), lty = c(""solid"", ""solid"", ""solid"", ""dashed"",      ""dotdash"", ""dotted""), text.col = ""black"", merge = FALSE,      bg = ""white"")",not sure,615602674894035e8,568
dev.off(),visualization,615602674894035e8,568
dev.off(),not sure,615602674894035e8,568
"hist(ms.alt[[3]], main = paste0(""alt multiscale : "", numIND,      "" "", title.name[3]), breaks = 47)",not sure,615602674894035e8,568
"cell.annotations <- data.frame(Patient = as.factor(sapply(colnames(samp.tab),      function(x) gsub(""LN"", """", unlist(strsplit(x, split = ""_""))[1]))),      IsPooled = as.factor(sapply(colnames(samp.tab), function(x) unlist(strsplit(x,          split = ""_""))[2] == ""Pooled"")), IsTumor = as.factor(sapply(colnames(samp.tab),          function(x) length(grep(""LN"", x)) == 0)))[-1, ]",not sure,615602674894035e8,568
"runMarkdown(samp.mat, cell.annotations = cell.annotations, syn_file,      analysis_dir)",communication,615602674894035e8,568
p1,not sure,615602674894035e8,568
"ggsave(p1, file = ""./analysis/inundation_wooddensity_relationship/graph_code/graphs/inundation_VS_wooddensity.png"",      width = 6, height = 6)",visualization,615602674894035e8,568
library(pheatmap),visualization,515836643986404e8,576
"ptukey(abs(0.341) * sqrt(2), nmeans = 4, df = 8, lower = F)",setup,689617290394381e8,577
hist(shrub_a_analysis$seednum),visualization,689617290394381e8,577
"boxplot(shrub_a_analysis$seednum ~ shrub_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""shrub life form abundance per treatment"")",visualization,689617290394381e8,577
"with(shrub_a_analysis, plot(treatment, seednum))",visualization,689617290394381e8,577
"vif(glm(seednum ~ treatment + block, data = shrub_a_analysis))",modeling,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,689617290394381e8,577
"with(shrub_a_analysis, table(block, treatment))",exploratory,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,689617290394381e8,577
sampsize = 500,data cleaning,218690308509395e8,578
"clust.dat.prop <- vector(""list"", length = max.clusts)",data cleaning,218690308509395e8,578
set.seed(2),data cleaning,218690308509395e8,578
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",visualization,689617290394381e8,577
"shrub_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() + geom_bar(aes(treatment,      fill = as.factor(treatment))) + facet_grid(plot ~ .) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,689617290394381e8,577
"ggplot(shrub_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,689617290394381e8,577
"shrub.abund.glm <- glmer(seednum ~ block + treatment + (1 | plot),      data = shrub_a_analysis, family = poisson)",modeling,689617290394381e8,577
shrub.abund.res <- resid(shrub.abund.glm),modeling,689617290394381e8,577
shrub.abund.pred <- predict(shrub.abund.glm),evaluation,689617290394381e8,577
"plot(shrub.abund.pred, shrub.abund.res, ylab = ""Residuals"", xlab = ""predicted values"",      main = ""resid vs pred"")",evaluation,689617290394381e8,577
"abline(0, 0)",visualization,689617290394381e8,577
qqnorm(shrub.abund.res),evaluation,689617290394381e8,577
"qqline(shrub.abund.res, col = ""red"")",evaluation,689617290394381e8,577
hist(shrub.abund.res),visualization,689617290394381e8,577
K = K/mean(diag(K)),data cleaning,755548062734306e8,126
"anova(shrub.abund.glm, test = ""F"")",modeling,689617290394381e8,577
"Kn = K[ind, ind]",data cleaning,755548062734306e8,126
summary(shrub.abund.glm),modeling,689617290394381e8,577
"pdf(outfile, width = 14, height = 14)",export,426062096608803e8,579
"make_visual(data_mat, event_locations, concurrent_events, log_colors = T,      diverging = T)",visualization,426062096608803e8,579
dev.off(),visualization,426062096608803e8,579
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,755548062734306e8,126
"1 - pf(0.32, 3, 7)",modeling,689617290394381e8,577
MAE.ECs = mean(abs(y[-ind] - fhat[-ind])),modeling,755548062734306e8,126
"addpoly(pred$pred, ci.lb = pred$ci.lb, ci.ub = pred$ci.ub, row = -0.5,      digits = 3, mlab = ""REML Model"", efac = 1.3)",modeling,426062096608803e8,579
abline(h = 0.4),visualization,426062096608803e8,579
"R2_ECs = cor(y[-ind], fhat[-ind])^2",modeling,755548062734306e8,126
"text(-0.8, 28, ""Study"", pos = 4)",visualization,426062096608803e8,579
"c(MAE.G, MAE.Morph, MAE.Geo, MAE.ECs, R2_G, R2_Morph, R2_Geo,      R2_ECs)",data cleaning,755548062734306e8,126
"summary(glht(shrub.abund.glm, mcp(treatment = ""Tukey"")))",modeling,689617290394381e8,577
"text(1.5, 28, ""Proportion [95% CI]"", pos = 2)",visualization,426062096608803e8,579
"res1 <- rma(yi, vi, method = ""REML"", data = dat, mods = medianYear)",modeling,426062096608803e8,579
"Final = matrix(unlist(Results), nrow = ndatasets, ncol = 8, byrow = TRUE)",data cleaning,755548062734306e8,126
"pred1 <- predict(res1, transf = transf.ipft.hm, targs = list(ni = dat$NumberOfArticlesExamined))",modeling,426062096608803e8,579
pred1,modeling,426062096608803e8,579
"mod.names = c(""Expression"", ""Morph"", ""Geo"", ""ECs"")",data cleaning,755548062734306e8,126
"colnames(Final) = c(paste(""MAE"", mod.names, sep = ""_""), paste(""R2"",      mod.names, sep = ""_""))",data cleaning,755548062734306e8,126
"ptukey(abs(-0.226) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
cexs <- 1/dat$vi,not sure,426062096608803e8,579
"ptukey(abs(0.068) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
"ptukey(abs(-1.209) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
"ptukey(abs(0.293) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
cexs <- 1 + (cexs - min(cexs))/(max(cexs) - min(cexs)),exploratory,426062096608803e8,579
"ptukey(abs(-1.005) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
"plot(NA, NA, xlab = ""Year"", ylab = ""Proportion of studies reporting a power analysis"",      xlim = c(min(dat$medianYear), max(dat$medianYear)), ylim = c(0,          1), bty = ""l"")",visualization,426062096608803e8,579
"ptukey(abs(-1.27) * sqrt(2), nmeans = 4, df = 8, lower = F)",modeling,689617290394381e8,577
"lines(dat$medianYear, pred1$ci.lb, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,426062096608803e8,579
"lines(dat$medianYear, pred1$ci.ub, col = ""darkgray"", lty = ""dashed"",      lwd = 2)",visualization,426062096608803e8,579
"lines(dat$medianYear, pred1$pred, col = ""darkgray"", lwd = 2)",visualization,426062096608803e8,579
"points(dat$medianYear, transf.ipft(dat$yi, dat$NumberOfArticlesExamined),      pch = 19, cex = cexs)",visualization,426062096608803e8,579
hist(tree_a_analysis$seednum),visualization,689617290394381e8,577
"boxplot(tree_a_analysis$seednum ~ tree_a_analysis$treatment,      xlab = ""treatment"", ylab = ""seednum"", main = ""tree life form abundance per treatment"")",visualization,689617290394381e8,577
"runAnalysis <- function(dd, scale) my.inits <- function() list()",setup,426062096608803e8,579
"with(tree_a_analysis, plot(treatment, seednum))",visualization,689617290394381e8,577
my.params <- get.params(),not sure,426062096608803e8,579
"vif(glm(seednum ~ treatment + block, data = tree_a_analysis))",modeling,689617290394381e8,577
Res[[j]] = Final,data cleaning,755548062734306e8,126
"cat(""Completed Phenotype"", j, ""\n"")",communication,755548062734306e8,126
"colMeans(Res[[1]][, 1:4])",exploratory,755548062734306e8,126
"colMeans(Res[[1]][, 5:8])",exploratory,755548062734306e8,126
"colMeans(Res[[2]][, 1:4])",exploratory,755548062734306e8,126
"colMeans(Res[[2]][, 5:8])",exploratory,755548062734306e8,126
"ggplot(tree_a_analysis, aes(block, seednum)) + geom_bar(stat = ""identity"",      aes(fill = treatment))",visualization,689617290394381e8,577
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",export,755548062734306e8,126
"ggplot(tree_a_analysis, aes(treatment, seednum)) + geom_bar(stat = ""identity"",      aes(fill = block))",visualization,689617290394381e8,577
"ggplot(tree_a_analysis, aes(treatment, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ block)",visualization,689617290394381e8,577
"ggplot(tree_a_analysis, aes(block, seednum, color = treatment)) +      geom_boxplot() + facet_grid(. ~ treatment)",visualization,689617290394381e8,577
"Acc_sampled = rbind(Acc_sampled, ACURRACY[-1])",modeling,453806722071022e7,126
"with(tree_a_analysis, table(block, treatment))",exploratory,689617290394381e8,577
beepr::beep(),communication,453806722071022e7,126
"print(""time to perform the analysis:"")",communication,453806722071022e7,126
print(Sys.time() - b),communication,453806722071022e7,126
"hist(as.numeric(Acc_sampled[-1, 1]), breaks = (c(-11:10)/21 +      0.5/21) * 2, main = ""Jhuang_6smallwindows_L1regLregression"")",exploratory,453806722071022e7,126
"abline(v = ACURRACYreal[2], col = ""Red"")",visualization,453806722071022e7,126
"abline(v = 0, col = ""blue"")",visualization,453806722071022e7,126
"hist(as.numeric(Acc_sampled[-1, 2]), breaks = (c(-11:10)/21 +      0.5/21) * 2, main = ""Jhuang_6smallwindows_SVMlin"")",visualization,453806722071022e7,126
"abline(v = ACURRACYreal[4], col = ""Red"")",visualization,453806722071022e7,126
"abline(v = 0, col = ""blue"")",visualization,453806722071022e7,126
"ggplot(tree_a_analysis, aes(treatment, seednum)) + geom_point()",visualization,689617290394381e8,577
"k1 <- sum(as.numeric(Acc_sampled[-1, 1]) >= ACURRACYreal[2])",evaluation,453806722071022e7,126
"cbPalette <- c(""#999999"", ""#56B4E9"", ""#F0E442"", ""#CC79A7"")",visualization,689617290394381e8,577
"k2 <- sum(as.numeric(Acc_sampled[-1, 2]) >= ACURRACYreal[4])",evaluation,453806722071022e7,126
"print(zapsmall(binconf(k1, nrow(Acc_sampled) - 1, method = ""all"")))",communication,453806722071022e7,126
"print(zapsmall(binconf(k2, nrow(Acc_sampled) - 1, method = ""all"")))",communication,453806722071022e7,126
"tree_a_analysis %>% filter(!is.na(seednum)) %>% ggplot() + geom_bar(aes(treatment,      fill = as.factor(treatment))) + facet_grid(plot ~ .) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,689617290394381e8,577
"ggplot(tree_a_analysis, aes(block, seednum)) + geom_boxplot(aes(fill = block)) +      facet_grid(. ~ treatment) + scale_fill_manual(values = cbPalette) +      theme(legend.position = ""none"")",visualization,689617290394381e8,577
"tree.abund.glm <- glmer(seednum ~ block + treatment + (1 | plot),      data = tree_a_analysis, family = poisson)",modeling,689617290394381e8,577
tree.abund.res <- resid(tree.abund.glm),evaluation,689617290394381e8,577
sum(done.alt),exploratory,453806722071022e7,126
tree.abund.pred <- predict(tree.abund.glm),evaluation,689617290394381e8,577
sum(done.null),exploratory,453806722071022e7,126
min(logLR.alt),exploratory,453806722071022e7,126
max(logLR.alt),exploratory,453806722071022e7,126
min(logLR.null),exploratory,453806722071022e7,126
max(logLR.null),exploratory,453806722071022e7,126
wave.null[[1]] = logLR.null,data cleaning,453806722071022e7,126
wave.alt[[1]] = logLR.alt,data cleaning,453806722071022e7,126
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[2], "".Robj""))",import,453806722071022e7,126
logLR.alt = as.numeric(logLR_list),data cleaning,453806722071022e7,126
done.alt = done_res,data cleaning,453806722071022e7,126
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[2], "".Robj""))",import,453806722071022e7,126
logLR.null = as.numeric(logLR_list),data cleaning,453806722071022e7,126
done.null = done_res,data cleaning,453806722071022e7,126
sum(done.alt),exploratory,453806722071022e7,126
sum(done.null),exploratory,453806722071022e7,126
min(logLR.alt),exploratory,453806722071022e7,126
max(logLR.alt),exploratory,453806722071022e7,126
min(logLR.null),exploratory,453806722071022e7,126
max(logLR.null),exploratory,453806722071022e7,126
wave.null[[2]] = logLR.null,data cleaning,453806722071022e7,126
wave.alt[[2]] = logLR.alt,data cleaning,453806722071022e7,126
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/logLR."",      case.name[3], "".Robj""))",import,453806722071022e7,126
logLR.alt = as.numeric(logLR_list),data cleaning,453806722071022e7,126
done.alt = done_res,data cleaning,453806722071022e7,126
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/logLR."",      case.name[3], "".Robj""))",import,453806722071022e7,126
logLR.null = as.numeric(logLR_list),data cleaning,453806722071022e7,126
done.null = done_res,data cleaning,453806722071022e7,126
sum(done.alt),exploratory,453806722071022e7,126
sum(done.null),exploratory,453806722071022e7,126
min(logLR.alt),exploratory,453806722071022e7,126
max(logLR.alt),exploratory,453806722071022e7,126
min(logLR.null),exploratory,453806722071022e7,126
max(logLR.null),exploratory,453806722071022e7,126
wave.null[[3]] = logLR.null,data cleaning,453806722071022e7,126
wave.alt[[3]] = logLR.alt,data cleaning,453806722071022e7,126
ix = 1,setup,453806722071022e7,126
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.ms[ind.ix, 2] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.wave[ind.ix, 2] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
ix = 2,setup,453806722071022e7,126
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.ms[ind.ix, 3] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.wave[ind.ix, 3] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
ix = 3,setup,453806722071022e7,126
"logLR = c(ms.null[[ix]], ms.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.ms[ind.ix, 4] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
"logLR = c(wave.null[[ix]], wave.alt[[ix]])",data cleaning,453806722071022e7,126
"AuROC.wave[ind.ix, 4] = auc(status, logLR)[1]",evaluation,453806722071022e7,126
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.wave""",export,453806722071022e7,126
"write.table(AuROC.wave, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",export,453806722071022e7,126
"output.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/res/AuROC.ms""",export,453806722071022e7,126
"write.table(AuROC.ms, file = output.path, quote = FALSE, row.names = c(70,      30, 10, 6, 4), col.names = FALSE)",export,453806722071022e7,126
foo5,not sure,453806722071022e7,126
foo$top_h1_total,exploratory,453806722071022e7,126
foo10$top_h1_total,exploratory,453806722071022e7,126
foo5$top_h1_total,exploratory,453806722071022e7,126
"mn.homes$Price.per.land.sqft <- replace(mn.homes$Price.per.land.sqft,      which(is.na(mn.homes$Price.per.land.sqft)), 0)",data cleaning,453806722071022e7,126
dim(mn.homes),exploratory,453806722071022e7,126
"plot(log10(mn.homes$gross.sqft), log10(mn.homes$sale.price.n))",visualization,453806722071022e7,126
hist(log10(mn.homes$sale.price.n)),visualization,453806722071022e7,126
"summary(mn.homes[which(mn.homes$sale.price.n < 1e+05), ])",exploratory,453806722071022e7,126
mn.homes$outliers <- (log10(mn.homes$sale.price.n) <= 5) + 0,evaluation,453806722071022e7,126
"mn.homes <- mn.homes[which(mn.homes$outliers == 0), ]",data cleaning,453806722071022e7,126
"plot(mn.homes$gross.sqft, mn.homes$sale.price.n)",visualization,453806722071022e7,126
"write.csv(mn.homes, file = ""rollingsales_manhattan_familyhome.csv"")",export,453806722071022e7,126
"xtable(summary(lmList(Tr ~ starting | miss.data, data = best_Tr_test))[[4]][,      , 2])",modeling,453806722071022e7,126
"climatedata$Day <- as.numeric(substr(climate$DATE, 7, 8))",data cleaning,453806722071022e7,126
"Anova(mod2, type = ""2"")",modeling,733790131052956e8,580
climatedata$Tmax <- (climate$TMAX),data cleaning,453806722071022e7,126
climatedata$Tmin <- (climate$TMIN),data cleaning,453806722071022e7,126
climatedata$RHmax <- 0,data cleaning,453806722071022e7,126
climatedata$RHmin <- 0,data cleaning,453806722071022e7,126
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,733790131052956e8,580
climatedata$Rs <- 0,data cleaning,453806722071022e7,126
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""domain""]])",modeling,733790131052956e8,580
"input <- ReadInputs(varnames = colnames(climatedata), climatedata = climatedata,      stopmissing = c(10, 10, 3), timestep = ""daily"", interp_missing_days = F,      interp_missing_entries = F, interp_abnormal = F, missing_method = ""DoY average"",      abnormal_method = ""DoY average"")",import,453806722071022e7,126
"data(""constants"")",import,453806722071022e7,126
summary(mod2),exploratory,733790131052956e8,580
constants$Elev <- 10,data cleaning,453806722071022e7,126
"Anova(mod2, type = ""2"")",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,733790131052956e8,580
constants$lat_rad <- 38.8846 * pi/180,setup,453806722071022e7,126
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""distance""]] + data[[""mcomplexity""]])",modeling,733790131052956e8,580
summary(mod2),exploratory,733790131052956e8,580
"df <- ET.HargreavesSamani(data = input, constants = constants,      ts = ""daily"")",data cleaning,453806722071022e7,126
"Anova(mod2, type = ""2"")",modeling,733790131052956e8,580
pet.VAR <- df$ET.Daily,data cleaning,453806722071022e7,126
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,733790131052956e8,580
pet.VAR[pet.VAR < 0] <- 0,data cleaning,453806722071022e7,126
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,733790131052956e8,580
pet.VAR[is.na(pet.VAR) == T] <- 0,data cleaning,453806722071022e7,126
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""expression""]])",modeling,733790131052956e8,580
"land.INFO <- c(""area"", ""invert"", ""n"", ""s_fc"", ""psi"", ""y_cl"",      ""y_c"", ""s_wilt"", ""k_sat"", ""RD"", ""b"", ""slope"", ""kb"", ""y_wt_0"",      ""s_t_0"", ""GW_bf_0"", ""Sy"", ""wetland_invert"", ""wetland_area"",      ""volume_max"")",setup,453806722071022e7,126
"land.INFO <- matrix(0, nrow = 1, ncol = length(land.INFO), dimnames = list(c(1),      c(land.INFO)))",setup,453806722071022e7,126
summary(mod2),exploratory,733790131052956e8,580
"Anova(mod2, type = ""2"")",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,733790131052956e8,580
"land.INFO[, ""area""] <- gArea(watershed.shp) * (10^6)",setup,453806722071022e7,126
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,733790131052956e8,580
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""exons""]] + data[[""domain""]])",modeling,733790131052956e8,580
"land.INFO[, ""n""] <- soils$n",data cleaning,453806722071022e7,126
"land.INFO[, ""s_fc""] <- soils$s_fc/100",data cleaning,453806722071022e7,126
"land.INFO[, ""psi""] <- -16662 * (soils$n^7.8831)",data cleaning,453806722071022e7,126
"land.INFO[, ""y_cl""] <- -1 * soils$y_cl",data cleaning,453806722071022e7,126
"land.INFO[, ""y_c""] <- -soils$y_rd/2",data cleaning,453806722071022e7,126
"land.INFO[, ""s_wilt""] <- soils$s_w/100",data cleaning,453806722071022e7,126
"land.INFO[, ""k_sat""] <- -soils$ksat * 24",data cleaning,453806722071022e7,126
"land.INFO[, ""RD""] <- -soils$y_rd",data cleaning,453806722071022e7,126
"land.INFO[, ""b""] <- 12.524 * (soils$clay/100) + 3.6907",data cleaning,453806722071022e7,126
"land.INFO[, ""y_wt_0""] <- 0",data cleaning,453806722071022e7,126
"land.INFO[, ""s_t_0""] <- land.INFO[, ""s_fc""]",data cleaning,453806722071022e7,126
"land.INFO[, ""GW_bf_0""] <- 300",data cleaning,453806722071022e7,126
"land.INFO[, ""Sy""] <- soils$Sy",data cleaning,453806722071022e7,126
"land.INFO[, ""wetland_invert""] <- -1000 * 0.05 * (length(rowSums(area)[rowSums(area) !=      max(rowSums(area), na.rm = T)]) + 1)",data cleaning,453806722071022e7,126
"land.INFO[, ""wetland_area""] <- max(rowSums(area)) * (1000^2)",data cleaning,453806722071022e7,126
"land.INFO[, ""volume_max""] <- max(rowSums(volume[, -giw.ID])) *      (1000^3)",data cleaning,453806722071022e7,126
"land.INFO[, ""kb""] <- 0.046",data cleaning,453806722071022e7,126
n.wetlands <- 1,setup,453806722071022e7,126
"giw.INFO <- c(""giw.ID"", ""area_watershed"", ""area_wetland"", ""invert"",      ""vol_ratio"", ""n"", ""s_fc"", ""psi"", ""y_cl"", ""y_c"", ""s_wilt"",      ""k_sat"", ""RD"", ""b"", ""Sy"", ""y_w_0"", ""s_t_0"")",setup,453806722071022e7,126
"giw.INFO <- matrix(0, nrow = n.wetlands, ncol = length(giw.INFO),      dimnames = list(seq(1, n.wetlands, 1), c(giw.INFO)))",setup,453806722071022e7,126
"giw.INFO[, ""giw.ID""] <- giw.ID",data cleaning,453806722071022e7,126
"giw.INFO[, ""area_watershed""] <- (gArea(basin.shp, byid = T)[giw.ID]) *      (1000^2)",data cleaning,453806722071022e7,126
"giw.INFO[, ""area_wetland""] <- max(area[, giw.ID]) * (1000^2)",data cleaning,453806722071022e7,126
"giw.INFO[, ""invert""] <- -1000 * 0.05 * (length(area[, giw.ID][area[,      giw.ID] != max(area[, giw.ID], na.rm = T)]))",data cleaning,453806722071022e7,126
"giw.INFO[, ""n""] <- soils$n",data cleaning,453806722071022e7,126
"giw.INFO[, ""s_fc""] <- soils$s_fc/100",data cleaning,453806722071022e7,126
"giw.INFO[, ""psi""] <- -16662 * (soils$n^7.8831)",data cleaning,453806722071022e7,126
"giw.INFO[, ""y_cl""] <- -1 * soils$y_cl",data cleaning,453806722071022e7,126
"giw.INFO[, ""y_c""] <- -soils$y_rd/2",data cleaning,453806722071022e7,126
"giw.INFO[, ""s_wilt""] <- soils$s_w/100",data cleaning,453806722071022e7,126
"giw.INFO[, ""k_sat""] <- -soils$ksat * 24",data cleaning,453806722071022e7,126
"giw.INFO[, ""RD""] <- -soils$y_rd",data cleaning,453806722071022e7,126
"giw.INFO[, ""b""] <- 12.524 * (soils$clay/100) + 3.6907",data cleaning,453806722071022e7,126
"giw.INFO[, ""Sy""] <- giw.INFO[, ""n""] * (1 - giw.INFO[, ""s_fc""])",data cleaning,453806722071022e7,126
"giw.INFO[, ""y_w_0""] <- 0",data cleaning,453806722071022e7,126
"giw.INFO[, ""s_t_0""] <- giw.INFO[, ""s_fc""]",data cleaning,453806722071022e7,126
"giw.INFO[, ""vol_ratio""] <- 0",data cleaning,453806722071022e7,126
"save.image(paste0(dir3, ""/Backup/model_parameters.RData""))",export,453806722071022e7,126
rm(list = ls(all = TRUE)),setup,453806722071022e7,126
"wd5 <- ""~/Wetland_Hydrologic_Capacitance_Model""",setup,453806722071022e7,126
"dir5 <- ""//nfs/WHC-data/Validation_Modeling/WHC_BaltimoreCorner""",setup,453806722071022e7,126
"source(paste0(wd5, ""/R/WHC_2.R""))",setup,453806722071022e7,126
"load((paste0(dir5, ""/Backup/model_parameters.RData"")))",import,453806722071022e7,126
n.years <- length(pet.VAR)/365,setup,453806722071022e7,126
"date <- strptime(climate$DATE, ""%Y%m%d"")",setup,453806722071022e7,126
"precip.VAR[as.yearmon(date) == ""Sep 2008""] <- 0",data cleaning,453806722071022e7,126
"precip.VAR[as.yearmon(date) == ""Oct 2008""] <- 0",data cleaning,453806722071022e7,126
"precip.VAR[date == paste(as.Date(""2010-08-18""))] <- 0",data cleaning,453806722071022e7,126
"precip.VAR[as.yearmon(date) == ""Oct 2010""] <- 0",data cleaning,453806722071022e7,126
"WHC <- wetland.hydrology(giw.INFO, land.INFO, precip.VAR, pet.VAR,      n.years, area, volume, giw.ID)",data cleaning,453806722071022e7,126
"par(mar = c(3, 3, 0, 0) + 0.25)",visualization,453806722071022e7,126
"par(mgp = c(2, 0.6, 0))",visualization,453806722071022e7,126
par(ps = 12),visualization,453806722071022e7,126
par(cex.lab = 14/12),visualization,453806722071022e7,126
par(cex.axis = 10/12),visualization,453806722071022e7,126
"plot(watershed$y_wt, type = ""n"", xlab = ""Simulation Day"", ylab = ""Relative Elevation [mm]"")",visualization,453806722071022e7,126
"points(watershed$y_wt, type = ""l"", lty = 2, lwd = 2, col = ""darkorange"")",visualization,453806722071022e7,126
"points(watershed$y_w, type = ""l"", lty = 2, lwd = 2, col = ""navyblue"")",visualization,453806722071022e7,126
"legend(""bottomleft"", lty = 2, , lwd = 2, col = c(""navyblue"",      ""darkorange""), c(""Upland Wetland Stage"", ""Upland Water Table""),      bty = ""n"")",visualization,453806722071022e7,126
"datExprR = datExpr[sample(1:nrow(datExpr), numRows, replace = FALSE),      ]",data cleaning,453806722071022e7,126
"net = blockwiseModules(t(datExprR), power = thresholdPower, networkType = ""signed"",      maxBlockSize = numRows)",modeling,453806722071022e7,126
moduleColorsAutomatic = labels2colors(net$colors),visualization,453806722071022e7,126
mColors = moduleColorsAutomatic[net$blockGenes[[1]]],visualization,453806722071022e7,126
x11(),visualization,453806722071022e7,126
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,453806722071022e7,126
module = 1,setup,453806722071022e7,126
me = net$MEs[[module]],setup,453806722071022e7,126
order = order(sampleInfo$order),data cleaning,453806722071022e7,126
color = sampleInfo$color,visualization,453806722071022e7,126
x11(),visualization,453806722071022e7,126
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,453806722071022e7,126
"pdf(""9861.pdf"", width = 6, height = 3, pointsize = 8)",export,453806722071022e7,126
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,453806722071022e7,126
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,453806722071022e7,126
dev.off(),visualization,453806722071022e7,126
q = 8,setup,453806722071022e7,126
Temp.deg <- list.net.deg[[q]],data cleaning,453806722071022e7,126
Temp.numb <- list.net.numb[[q]],data cleaning,453806722071022e7,126
"Temp.numb <- lapply(Temp.numb, log)",data cleaning,453806722071022e7,126
"par(mfrow = c(2, 1), mar = c(3, 4, 2, 2))",visualization,453806722071022e7,126
"boxplot(Temp.deg[[1]], Temp.deg[[2]], Temp.deg[[3]], Temp.deg[[4]],      Temp.deg[[5]], main = ""Degree"", col = ""darkgray"")",visualization,453806722071022e7,126
"boxplot(Temp.numb[[1]], Temp.numb[[2]], Temp.numb[[3]], Temp.numb[[4]],      Temp.numb[[5]], main = ""Number"", col = ""darkgray"")",visualization,453806722071022e7,126
"axis(1, at = 1:5, label = rownames(beta.par))",visualization,453806722071022e7,126
m <- 10,setup,453806722071022e7,126
n <- 5,setup,453806722071022e7,126
"mat <- matrix(rbinom(100, 10, 0.1), m, n)",setup,453806722071022e7,126
"if (min(c(rowSums(mat), colSums(mat))) == 0) stop(""Hey, you have a species in your network that does not interact with any other species. The following functions will get stuck."")",evaluation,453806722071022e7,126
"par(mfrow = c(2, 3))",visualization,453806722071022e7,126
"hist(list.deg[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.deg[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.deg[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.deg[[4]], xlab = ""number"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.deg[[5]], xlab = ""number"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"par(mfrow = c(2, 3))",visualization,453806722071022e7,126
"hist(list.numb[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.numb[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.numb[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.numb[[4]], xlab = ""number"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
"hist(list.numb[[5]], xlab = ""number"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,453806722071022e7,126
tamoxifen <- dba.contrast(tamoxifen),modeling,453806722071022e7,126
plot(tamoxifen),visualization,453806722071022e7,126
tamoxifen <- dba.analyze(tamoxifen),modeling,453806722071022e7,126
"plot(tamoxifen, contrast = 1)",visualization,453806722071022e7,126
tamoxifen.DB <- dba.report(tamoxifen),communication,453806722071022e7,126
corvals <- dba.plotHeatmap(tamoxifen),visualization,453806722071022e7,126
"samples <- read.csv(file.path(system.file(""extra"", package = ""DiffBind""),      ""tamoxifen.csv""))",import,453806722071022e7,126
names(samples),exploratory,453806722071022e7,126
"tamoxifen <- dba(sampleSheet = ""tamoxifen.csv"")",import,453806722071022e7,126
tamoxifen,exploratory,453806722071022e7,126
plot(tamoxifen),visualization,453806722071022e7,126
exprs(sc2) <- exprs_combat,setup,453806722071022e7,126
"plotPCA(sc2, ncomponents = 3, colour_by = ""plate"")",visualization,453806722071022e7,126
"plotPCA(sc2, ncomponents = 3, colour_by = ""censored"")",visualization,453806722071022e7,126
"plotPCA(sc2, ncomponents = 3, colour_by = ""patient.days_to_birth"")",visualization,453806722071022e7,126
"plotPCA(sc2, ncomponents = 3, colour_by = ""patient.days_to_death"")",visualization,453806722071022e7,126
"plotPCA(sc2, colour_by = ""patient.stage_event.clinical_stage"",      ncomponents = 3)",visualization,453806722071022e7,126
"plotQC(sc2, type = ""find"", var = ""plate"")",visualization,453806722071022e7,126
"plotQC(sc2, type = ""find"", var = ""censored"")",visualization,453806722071022e7,126
"plotQC(sc2, type = ""find"", var = ""patient.days_to_birth"")",visualization,453806722071022e7,126
"plotQC(sc2, type = ""find"", var = ""patient.days_to_death"")",visualization,453806722071022e7,126
"plotQC(sc2, type = ""find"", var = ""patient.stage_event.clinical_stage"")",visualization,453806722071022e7,126
library(ggrepel),setup,453806722071022e7,126
"hgnc_symbols <- sapply(strsplit(featureNames(sc2), ""_""), `[`,      2)",data cleaning,453806722071022e7,126
"dvar <- data_frame(mean = rowMeans(exprs(sc2)), var = matrixStats::rowVars(exprs(sc2)),      hgnc_symbols, gene = featureNames(sc2))",data cleaning,453806722071022e7,126
"ggplot(dvar, aes(x = mean, y = var)) + geom_point(color = ""grey"") +      xlab(""Mean"") + ylab(""Variance"") + geom_text_repel(data = filter(dvar,      var > 8.5), aes(label = hgnc_symbols), color = ""blue"")",visualization,453806722071022e7,126
is_exprs(sce) <- exprs(sce) > 0,evaluation,453806722071022e7,126
sce <- calculateQCMetrics(sce),modeling,453806722071022e7,126
"plotHighestExprs(sce, col_by_variable = ""plate"")",visualization,453806722071022e7,126
"plotQC(sc2, type = ""expl"", variables = c(""plate"", ""censored"",      ""patient.age_at_initial_pathologic_diagnosis""))",visualization,453806722071022e7,126
library(rstan),setup,453806722071022e7,126
library(coda),setup,453806722071022e7,126
library(MCMCglmm),setup,453806722071022e7,126
"X <- model.matrix(~censored + patient.age_at_initial_pathologic_diagnosis,      pData(sc2))",modeling,453806722071022e7,126
"X <- t(scale(X[, -1]))",data cleaning,453806722071022e7,126
"Y <- t(scale(t(exprs(sc2)[matrixStats::rowVars(exprs(sc2)) >      5, ])))",data cleaning,453806722071022e7,126
"X <- rbind(X, rnorm(ncol(X)))",data cleaning,453806722071022e7,126
N <- ncol(Y),data cleaning,453806722071022e7,126
G <- nrow(Y),data cleaning,453806722071022e7,126
P = nrow(X),data cleaning,453806722071022e7,126
"dlist <- list(N = N, G = G, P = P, X = X, Y = Y)",setup,453806722071022e7,126
"model <- stan_model(""~/oxford/phenot/synthetic/phenot.stan"",      model_name = ""phenotime"")",modeling,453806722071022e7,126
"fit <- vb(model, dlist, grad_samples = 3)",modeling,453806722071022e7,126
"tmap <- posterior.mode(mcmc(extract(fit, ""pst"")$pst))",evaluation,453806722071022e7,126
pca <- prcomp(t(Y)),modeling,453806722071022e7,126
"df <- data_frame(tmap, pc1 = pca$x[, 1], pc2 = pca$x[, 2], age = sc2$patient.age_at_initial_pathologic_diagnosis,      censored = sc2$censored, death = sc2$patient.days_to_death)",data cleaning,453806722071022e7,126
"ggplot(df, aes(x = pc1, y = tmap, color = age)) + geom_point() +      viridis::scale_color_viridis()",visualization,453806722071022e7,126
"cowplot::plot_grid(ggplot(df, aes(x = pc1, y = tmap, color = age)) +      geom_point() + viridis::scale_color_viridis(), ggplot(df,      aes(x = pc1, y = tmap, color = censored)) + geom_point() +      scale_color_brewer(palette = ""Set1""))",visualization,453806722071022e7,126
"ggplot(df, aes(x = pc1, y = tmap, color = censored)) + geom_point() +      scale_color_brewer(palette = ""Set1"")",visualization,453806722071022e7,126
"ggplot(df, aes(x = pc1, y = tmap, color = age)) + geom_point() +      viridis::scale_color_viridis(name = ""Age"") + theme_classic() +      xlab(""Principal component 1"") + ylab(""MAP covariate latent trajectory"")",visualization,453806722071022e7,126
"ggsave(""~/Dropbox/Oxford/talks/confirmation_of_status/figs/phenotime1.png"",      width = 6, height = 4)",export,453806722071022e7,126
"tidy_beta <- function(beta, n) names(beta) <- rownames(Y)",setup,453806722071022e7,126
"beta_tidy <- gather(beta, gene, value)",data cleaning,453806722071022e7,126
beta_tidy$beta <- n,data cleaning,453806722071022e7,126
return(beta_tidy),evaluation,453806722071022e7,126
"beta_1_tidy <- tidy_beta(as_data_frame(extract(fit, ""beta"")$beta[,      , 1]), ""beta_1"")",data cleaning,453806722071022e7,126
"beta_2_tidy <- tidy_beta(as_data_frame(extract(fit, ""beta"")$beta[,      , 2]), ""beta_2"")",data cleaning,453806722071022e7,126
"beta_3_tidy <- tidy_beta(as_data_frame(extract(fit, ""beta"")$beta[,      , 3]), ""beta_3"")",data cleaning,453806722071022e7,126
"beta <- bind_rows(beta_1_tidy, beta_2_tidy, beta_3_tidy)",data cleaning,453806722071022e7,126
"beta$beta <- plyr::mapvalues(beta$beta, from = c(""beta_1"", ""beta_2"",      ""beta_3""), to = c(""censored"", ""patient_age"", ""random""))",data cleaning,453806722071022e7,126
"filter(beta, gene %in% rownames(Y)[1:20]) %>% ggplot(aes(x = gene,      y = value, color = beta)) + geom_boxplot()",data cleaning,453806722071022e7,126
"beta_sig <- beta %>% group_by(gene, beta) %>% summarise(lower = quantile(value,      0.025), upper = quantile(value, 0.975)) %>% mutate(significant = upper <      0 | lower > 0)",evaluation,453806722071022e7,126
"sig_genes <- beta_sig %>% filter(significant) %>% extract2(""gene"")",evaluation,453806722071022e7,126
"beta_for_plot <- filter(beta, gene %in% sig_genes)",data cleaning,453806722071022e7,126
"beta_for_plot$gene <- sapply(strsplit(beta_for_plot$gene, ""_""),      `[`, 2)",data cleaning,453806722071022e7,126
"ggplot(beta_for_plot, aes(x = beta, y = value, color = beta)) +      geom_boxplot() + facet_wrap(~gene, scales = ""free_y"") + theme(legend.position = ""none"") +      geom_hline(yintercept = 0, linetype = 2)",visualization,453806722071022e7,126
"mean_expr_df <- data_frame(mean = rowMeans(Y), var = matrixStats::rowVars(Y),      gene = rownames(Y), tau = tau_map)",data cleaning,453806722071022e7,126
"beta_sig <- inner_join(beta_sig, mean_expr_df, by = ""gene"")",data cleaning,453806722071022e7,126
"ggplot(beta_sig, aes(x = significant, y = mean)) + geom_boxplot()",visualization,453806722071022e7,126
"ggplot(beta_sig, aes(x = significant, y = var)) + geom_boxplot()",visualization,453806722071022e7,126
"ggplot(beta_sig, aes(x = significant, y = tau)) + geom_boxplot()",visualization,453806722071022e7,126
"View(filter(beta_sig, beta == ""censored"", significant))",exploratory,453806722071022e7,126
"plotPCA(sce, colour_by = ""ENST00000464611.1_ACTB"")",visualization,453806722071022e7,126
"plotExpression(sc2, x = ""plate"", feature = ""ENST00000464611.1_ACTB"")",visualization,453806722071022e7,126
"mean_var_df <- data_frame(gene = featureNames(sce), mean = rowMeans(exprs(sce)),      var = matrixStats::rowVars(exprs(sce)))",data cleaning,453806722071022e7,126
"ggplot(mean_var_df, aes(x = mean, y = var)) + geom_point(color = ""grey"") +      geom_point(data = filter(mean_var_df, grepl(""TP53"", mean_var_df$gene)),          color = ""blue"") + ggtitle(""blue genes all tp53 transcripts"")",visualization,453806722071022e7,126
"mostvar_genes <- arrange(mean_var_df, desc(var)) %>% extract2(""gene"")",data cleaning,453806722071022e7,126
"exprs_df <- data.frame(t(exprs(sce)[mostvar_genes[1:10], ]))",data cleaning,453806722071022e7,126
"names(exprs_df) <- sapply(strsplit(mostvar_genes[1:10], ""_""),      `[`, 2)",data cleaning,453806722071022e7,126
pairs(exprs_df),exploratory,453806722071022e7,126
"points(c(0, fpr.ms.list[[3]]), c(0, tpr.ms.list[[3]]), type = ""l"",      col = ""red"")",visualization,679957729065791e8,581
"points(c(0, fpr.wave.list[[3]]), c(0, tpr.wave.list[[3]]), type = ""l"",      col = ""orange"")",visualization,679957729065791e8,581
"legend(0.7, 0.3, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10""), col = c(""blue"", ""skyblue"",      ""darkgreen"", ""green"", ""red"", ""orange""), lty = c(1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,679957729065791e8,581
dev.off(),visualization,679957729065791e8,581
library(dplyr),setup,679957729065791e8,581
"plot.IO <- read.csv(""./Analysis/Cleaned_data/plot_IO_Y2.csv"")",import,679957729065791e8,581
"maize <- filter(plot.IO, zaocode == ""Maize"")",data cleaning,679957729065791e8,581
maize$y2_hhid <- as.character(maize$y2_hhid),data cleaning,679957729065791e8,581
"hhid.reg.zone <- read.csv(""./Analysis/Cleaned_data/hhid_reg_zone_y2.csv"")",import,679957729065791e8,581
hhid.reg.zone$y2_hhid <- as.character(hhid.reg.zone$y2_hhid),data cleaning,679957729065791e8,581
"coords <- read.csv(""./Analysis/Cleaned_data/lon_lat.csv"")",import,679957729065791e8,581
coords$y2_hhid <- as.character(coords$y2_hhid),data cleaning,679957729065791e8,581
"with(coords, plot(lon, lat))",visualization,679957729065791e8,581
log <- plot.IO$y2_hhid %in% hhid.reg.zone$y2_hhid,not sure,679957729065791e8,581
table(log),evaluation,679957729065791e8,581
log2 <- plot.IO$y2_hhid %in% coords$y2_hhid,visualization,679957729065791e8,581
table(log2),evaluation,679957729065791e8,581
length(unique(plot.IO$y2_hhid)),exploratory,679957729065791e8,581
"maize2 <- left_join(maize[, c(""y2_hhid"", ""plotnum"", ""output.kg"")],      hhid.reg.zone)",data cleaning,679957729065791e8,581
"maize3 <- left_join(maize2, select(coords, y2_hhid, lon, lat))",data cleaning,679957729065791e8,581
"maize3$cats <- cut2(maize3$output.kg, g = 4)",data cleaning,679957729065791e8,581
"maize3.split <- split(maize3, maize3$cats)",data cleaning,679957729065791e8,581
small <- maize3.split[[1]],data cleaning,679957729065791e8,581
big <- maize3.split[[4]],data cleaning,679957729065791e8,581
"with(small, plot(lon, lat))",visualization,679957729065791e8,581
table(big$region),evaluation,679957729065791e8,581
"TZA_map <- getData(""GADM"", country = ""TZA"", level = 1)",import,679957729065791e8,581
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,339501678012311e8,582
"rnaMeta = rnaSeq[1:10, 3:ncol(rnaSeq)]",setup,339501678012311e8,582
rnaMeta = as.data.frame(t(rnaMeta)),data cleaning,339501678012311e8,582
"for (folder in c(""input"", ""output"", ""temp"")) if (dir.exists(paste0(repository,      ""analysis/"", folder)) == 1) unlink(paste0(repository, ""analysis/"",      folder), recursive = TRUE)",setup,847443377366289e8,583
"colnames(rnaMeta) = rnaSeq[1:10, 2]",data cleaning,339501678012311e8,582
"dir.create(paste0(repository, ""analysis/"", folder))",setup,847443377366289e8,583
"rnaExp = rnaSeq[12:nrow(rnaSeq), 3:ncol(rnaSeq)]",setup,339501678012311e8,582
"for (file in c(""get_data.R"", ""line_complaints_by_district_year.R"",      ""line_homicides_by_district_year.R"")) source(paste0(repository,      ""analysis/src/"", file))",setup,847443377366289e8,583
"rnaExp = apply(rnaExp, 2, as.numeric)",data cleaning,339501678012311e8,582
"rnaExp = matrix(unlist(rnaExp), nrow = nrow(rnaExp))",setup,339501678012311e8,582
"rownames(rnaExp) = rnaSeq[12:nrow(rnaSeq), 1]",data cleaning,339501678012311e8,582
"rnaCelIDs = as.numeric(as.character(rnaSeq[12:nrow(rnaSeq), 2]))",data cleaning,339501678012311e8,582
"d1 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_bldg_psf.csv"",      header = TRUE, sep = "","")",import,741141770035028e8,584
"rnaExp = rnaExp[, rnaMeta$tissue %in% ""sscortex""]",data cleaning,339501678012311e8,582
"d2 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_land_size.csv"",      header = TRUE, sep = "","")",import,741141770035028e8,584
"d3 <- read.table(file = ""/home/evan/Documents/chicago/dssg-landbank-project/analysis/CA_ptype_median_land_psf.csv"",      header = TRUE, sep = "","")",import,741141770035028e8,584
"tresh <- rnaSeqTresh(rnaExp, ""analysis/02.Mouse Single Cell/tresholds"",      cores = 16)",setup,339501678012311e8,582
"d <- data.frame(d, d1[, 3], d2[, 3], d3[, 3])",data cleaning,741141770035028e8,584
"community_area <- str_trim(d1[, 1], side = ""both"")",data cleaning,741141770035028e8,584
rn(rnaExp),setup,339501678012311e8,582
"tresholds = matrix(rep(1, len(rn(rnaExp))))",setup,339501678012311e8,582
rownames(tresholds) = rn(rnaExp),data cleaning,339501678012311e8,582
"d <- data.frame(community_area, d[, -1])",data cleaning,741141770035028e8,584
"write.table(tresholds, file = ""analysis/02.Mouse Single Cell/noTresh"",      col.names = F, row.names = T, quote = F)",export,339501678012311e8,582
"path_analysis <- ""~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/analysis""",setup,339501678012311e8,582
"path_figs <- ""~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/figs""",setup,339501678012311e8,582
"path_obj <- ""~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/data_objects""",setup,339501678012311e8,582
"d <- adply(d, 1, transform, singleFamSellPrice = ((sqft_bldg_11 *      bldg_assmt_11_psf) + (sqft_land_11 * land_assmt_11_psf)))",data cleaning,741141770035028e8,584
"hr_ml <- data.frame(vitd = vitd, hr_ml = hr_ml, lci = hr_ml_lci,      uci = hr_ml_uci, variable = ""X1"")",setup,339501678012311e8,582
"p <- ggplot(data = d, aes(x = PTYOE2011, y = singleFamSellPrice)) +      geom_boxplot()",exploratory,741141770035028e8,584
"b_sim <- rmvnorm(nsamples, b, V)",modeling,339501678012311e8,582
"post_dens <- dmvnorm(b_sim, mean = b, sigma = V)",modeling,339501678012311e8,582
"cri <- quantile(post_dens, probs = c(0.025, 0.975), na.rm = TRUE)",modeling,339501678012311e8,582
"b_sim <- b_sim[post_dens > cri[1] & post_dens < cri[2], ]",data cleaning,339501678012311e8,582
pred_sim <- ns_vitd50 %*% t(b_sim),modeling,339501678012311e8,582
hr_sim <- exp(pred_sim),modeling,339501678012311e8,582
"hr_sim <- data.frame(vitd, hr_sim)",setup,339501678012311e8,582
"long_hr_sim <- melt(hr_sim, id.vars = ""vitd"")",data cleaning,339501678012311e8,582
long_hr_sim,evaluation,339501678012311e8,582
"t <- merge(long_hr_sim, hr_ml[, c(""vitd"", ""lci"", ""uci"")], all = TRUE)",data cleaning,339501678012311e8,582
"t[t$value < t$lci | t$value > t$uci, ""value""] <- NA",data cleaning,339501678012311e8,582
long_hr_sim <- t,not sure,339501678012311e8,582
"rug_frame <- data.frame(variable = ""X1"", value = NA, vitd = analysis$vd3.h)",setup,339501678012311e8,582
"p <- ggplot(data = long_hr_sim[!is.na(long_hr_sim$value), ],      aes(x = vitd, y = value, group = variable))",visualization,339501678012311e8,582
p <- p + theme_bw(base_size = 16),visualization,339501678012311e8,582
p <- p + geom_line(alpha = I(1/sqrt(nsamples * 15))),visualization,339501678012311e8,582
"p <- p + geom_line(data = hr_ml[!is.na(hr_ml$hr_ml), ], aes(x = vitd,      y = hr_ml), size = 0.8)",visualization,339501678012311e8,582
"p <- p + geom_line(data = hr_ml, aes(x = vitd, y = lci), size = 0.3,      linetype = ""dashed"")",visualization,339501678012311e8,582
"p <- p + geom_line(data = hr_ml, aes(x = vitd, y = uci), size = 0.3,      linetype = ""dashed"")",visualization,339501678012311e8,582
"p <- p + geom_rug(data = rug_frame, x = vitd, colour = rgb(0.3,      0.3, 0.3, 0.2), sides = ""b"")",visualization,339501678012311e8,582
"p <- p + scale_y_log10(""\n \n Hazard Ratio"", breaks = c(0.25,      0.5, 1, 2, 4), limits = c(0.25, 4))",visualization,339501678012311e8,582
"p <- p + scale_x_continuous(expression(paste(""25(OH)D""[3], "", nmol/L"")),      limits = c(4, 100))",visualization,339501678012311e8,582
"p <- p + ggtitle(""Figure 1"")",visualization,339501678012311e8,582
"p <- p + theme(legend.position = ""none"", plot.title = element_text(hjust = 1),      text = element_text(size = 12), axis.text = element_text(size = 10),      axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 0.3),      panel.grid.minor = element_blank())",visualization,339501678012311e8,582
"CairoFonts(regular = ""Palatino:style=Regular"", bold = ""Palatino:style=Bold"",      italic = ""Palatino:style=Italic"", bolditalic = ""Palatino:style=Bold Italic,BoldItalic"",      symbol = ""Symbol"")",visualization,339501678012311e8,582
"CairoPDF(file = ""./analysis/output/g04_hr.pdf"", width = 7, height = 5)",export,339501678012311e8,582
print(p),evaluation,339501678012311e8,582
dev.off(),evaluation,339501678012311e8,582
"CairoTIFF(file = ""./analysis/output/g04_hr.tiff"", res = 300,      width = 4.5 * 300, height = 3.6 * 300)",export,339501678012311e8,582
print(p),evaluation,339501678012311e8,582
dev.off(),evaluation,339501678012311e8,582
"hr <- hr_ml[hr_ml$vitd == 25 | hr_ml$vitd == 75, ]",data cleaning,339501678012311e8,582
print(hr),evaluation,339501678012311e8,582
print(survgrid),evaluation,339501678012311e8,582
sink(),not sure,339501678012311e8,582
"source(""../Analysis/ReadDiskPlot4.R"")",evaluation,339501678012311e8,582
"if (length(args) > 2) q(""no"")",evaluation,339501678012311e8,582
"table(xdata$HeightResponse, xdata$PinkieCurl)",export,647354864748195e8,585
"prop.table(table(xdata$HeightResponse, xdata$PinkieCurl), 2) %>%      round(2)",export,647354864748195e8,585
x <- table(xdata$ShapeResponse),export,647354864748195e8,585
y <- table(xdata$HeightResponse),export,647354864748195e8,585
"(xtab <- rbind(x, y))",export,647354864748195e8,585
chisq.test(xtab),export,647354864748195e8,585
"xmdl.shape <- glm(ShapeNum ~ PinkieCurl, xdata, family = ""binomial"")",export,647354864748195e8,585
summary(xmdl.shape),export,647354864748195e8,585
"xmdl.height <- glm(HeightNum ~ PinkieCurl, xdata, family = ""binomial"")",not sure,647354864748195e8,585
summary(xmdl.height),not sure,647354864748195e8,585
"xdata$Both <- ""both""",not sure,647354864748195e8,585
"shape_only <- which(xdata$ShapeResponse == ""yes"" & xdata$HeightResponse ==      ""no"")",not sure,647354864748195e8,585
"xdata[shape_only, ]$Both <- ""shape_only""",not sure,647354864748195e8,585
"height_only <- which(xdata$ShapeResponse == ""no"" & xdata$HeightResponse ==      ""yes"")",not sure,647354864748195e8,585
"xdata[height_only, ]$Both <- ""height_only""",not sure,647354864748195e8,585
table(xdata$Both),not sure,647354864748195e8,585
"aggregate(PinkieCurl ~ Both, xdata, mean)",not sure,647354864748195e8,585
"with(filter(xdata, Both != ""both""), t.test(PinkieCurl ~ Both,      var.equal = T))",not sure,647354864748195e8,585
"with(filter(xdata, Both != ""both""), t.test(PinkieCurl ~ Both,      var.equal = T))",not sure,647354864748195e8,585
"r3 <- cbind(wpl[[11]], wpl[[12]], wpl[[13]], wpl[[14]], wpl[[15]])",data cleaning,339501678012311e8,582
"r4 <- cbind(wpl[[16]], wpl[[17]], wpl[[18]], wpl[[19]], wpl[[20]])",data cleaning,339501678012311e8,582
"cat(""Plotting exemplars in 4 x 5 array"")",communication,339501678012311e8,582
"m <- rbind(r1, r2, r3, r4)",data cleaning,339501678012311e8,582
"plot.wp(m, asp.ratio = 4/5)",visualization,339501678012311e8,582
"setwd(paste0(repository, ""analysis/"", ""input""))",import,944461154285818e7,586
"plot(data$Freq.2012, data$Freq.2014)",setup,944461154285818e7,586
library(plyr),setup,527621570741758e8,587
"plot(log(data$Freq.2012), log(data$Freq.2014))",visualization,944461154285818e7,586
library(lme4),setup,339501678012311e8,582
library(psych),setup,339501678012311e8,582
library(stats),setup,339501678012311e8,582
library(scales),setup,339501678012311e8,582
library(smacof),setup,339501678012311e8,582
"plot(log(data$Freq.2012), log(data$Freq.2014))",visualization,944461154285818e7,586
rm(list = ls()),setup,339501678012311e8,582
library(stringr),setup,527621570741758e8,587
library(reshape2),setup,527621570741758e8,587
dev.off(),evaluation,339501678012311e8,582
library(xtable),setup,527621570741758e8,587
"data = read.csv(""complaints_by_district_year.csv"", header = TRUE,      stringsAsFactors = FALSE)",import,944461154285818e7,586
"d = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_charmeans.csv"")[-1]",import,339501678012311e8,582
sdN <- sd(RawNData$SampleSize),exploratory,944461154285818e7,586
glimpse(d),exploratory,339501678012311e8,582
"dd = read.csv(""/Users/kweisman/Documents/Research (Stanford)/Projects/GGW-kid/ggw-kid/data/adults/run-01_2015-05-09_data_anonymized.csv"")[-1]",import,339501678012311e8,582
glimpse(dd),exploratory,339501678012311e8,582
"source(""powerAnalysis/lib.R"")",setup,527621570741758e8,587
"d_white = d %>% filter(ethnicity == ""white"")",data cleaning,339501678012311e8,582
"dd_white = dd %>% filter(ethnicity == ""white"")",data cleaning,339501678012311e8,582
"d_nonwhite = d %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,339501678012311e8,582
"dd_nonwhite = dd %>% filter(ethnicity != ""white"" & ethnicity !=      ""NA"" & ethnicity != ""other_prefNo"")",data cleaning,339501678012311e8,582
"charmeans = dd %>% filter(phase == ""test"") %>% select(subid,      predicate, leftCharacter, rightCharacter, response, responseNum) %>%      mutate(grownup = ifelse(leftCharacter == ""grownup"", responseNum,          ifelse(rightCharacter == ""grownup"", -1 * responseNum,              NA)), kid = ifelse(leftCharacter == ""kid"", responseNum,          ifelse(rightCharacter == ""kid"", -1 * responseNum, NA)),          baby = ifelse(leftCharacter == ""baby"", responseNum, ifelse(rightCharacter ==              ""baby"", -1 * responseNum, NA)), dog = ifelse(leftCharacter ==              ""dog"", responseNum, ifelse(rightCharacter == ""dog"",              -1 * responseNum, NA)), bear = ifelse(leftCharacter ==              ""bear"", responseNum, ifelse(rightCharacter == ""bear"",              -1 * responseNum, NA)), bug = ifelse(leftCharacter ==              ""bug"", responseNum, ifelse(rightCharacter == ""bug"",              -1 * responseNum, NA)), robot = ifelse(leftCharacter ==              ""robot"", responseNum, ifelse(rightCharacter == ""robot"",              -1 * responseNum, NA)), computer = ifelse(leftCharacter ==              ""computer"", responseNum, ifelse(rightCharacter ==              ""computer"", -1 * responseNum, NA)), car = ifelse(leftCharacter ==              ""car"", responseNum, ifelse(rightCharacter == ""car"",              -1 * responseNum, NA)), stapler = ifelse(leftCharacter ==              ""stapler"", responseNum, ifelse(rightCharacter ==              ""stapler"", -1 * responseNum, NA))) %>% select(predicate,      subid, grownup, kid, baby, dog, bear, bug, robot, computer,      car, stapler) %>% gather(character, response, -predicate,      -subid) %>% group_by(predicate, character) %>% summarise(mean = mean(response,      na.rm = T))",data cleaning,339501678012311e8,582
glimpse(charmeans),exploratory,339501678012311e8,582
"charmeans_table = charmeans %>% spread(predicate, mean)",data cleaning,339501678012311e8,582
charnames = as.character(charmeans_table$character),data cleaning,339501678012311e8,582
d1 = charmeans_table[-1],data cleaning,339501678012311e8,582
rownames(d1) = charnames,data cleaning,339501678012311e8,582
print(d1),evaluation,339501678012311e8,582
demo = dd %>% distinct(subid),data cleaning,339501678012311e8,582
demo %>% summarise(n = length(subid)),exploratory,339501678012311e8,582
dd %>% group_by(sequence) %>% distinct(subid) %>% summarise(n = length(subid)),exploratory,339501678012311e8,582
demo %>% count(gender),exploratory,339501678012311e8,582
demo %>% count(ethnicity),exploratory,339501678012311e8,582
"demo %>% summarise(mean_age = mean(age, na.rm = T), sd_age = sd(age,      na.rm = T))",exploratory,339501678012311e8,582
qplot(demo$age),visualization,339501678012311e8,582
"levels(demo$education) = c(""hs_some"", ""hs_diploma"", ""college_some"",      ""college_assocDegree"", ""college_bachDegree"", ""grad_some"",      ""grad_degree"", ""other_prefNo"")",visualization,339501678012311e8,582
demo %>% count(education),exploratory,339501678012311e8,582
demo %>% count(englishNative),exploratory,339501678012311e8,582
demo %>% count(religionChild),exploratory,339501678012311e8,582
"demo = demo %>% filter(religionChild != ""prefNo"" & religionChild !=      ""NA"") %>% mutate(religCat = ifelse(grepl(""christ"", religionChild) ==      T | religionChild == ""judaism"", ""judeo-christian"", ifelse(religionChild ==      ""none"", ""non-religious"", ""other religious"")))",data cleaning,339501678012311e8,582
demo %>% count(religCat),exploratory,339501678012311e8,582
demo %>% count(religionNow),exploratory,339501678012311e8,582
View(demo %>% mutate(job = factor(tolower(as.character(job)))) %>%      count(job)),exploratory,339501678012311e8,582
"pca_A2 = principal(d1, nfactors = 2, rotate = ""none"")",modeling,339501678012311e8,582
pca_A2,evaluation,339501678012311e8,582
pca_A2$values,evaluation,339501678012311e8,582
"pca_A2_pc1 = pca_A2$loadings[, 1]",evaluation,339501678012311e8,582
sort(pca_A2_pc1),exploratory,339501678012311e8,582
"pca_A2_pc2 = pca_A2$loadings[, 2]",data cleaning,339501678012311e8,582
sort(pca_A2_pc2),exploratory,339501678012311e8,582
"ggplot(data.frame(pca_A2$loadings[1:3, ]), aes(x = PC1, y = PC2,      label = names(d1))) + geom_text() + theme_bw() + labs(title = ""Factor loadings\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,339501678012311e8,582
"ggplot(data.frame(pca_A2$scores), aes(x = PC1, y = PC2, label = rownames(d1))) +      geom_text() + theme_bw() + labs(title = ""Raw character factor scores\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,339501678012311e8,582
"ggplot(data.frame(pca_A2$scores), aes(x = rescale(PC1, to = c(0,      1)), y = rescale(PC2, to = c(0, 1)), label = rownames(d1))) +      geom_point() + geom_text(angle = 0, vjust = -1, size = 6) +      xlim(-0.01, 1.01) + ylim(-0.01, 1.01) + theme_bw() + theme(text = element_text(size = 20)) +      labs(title = ""Adjusted character factor scores\n"", x = ""\nPrincipal Component 1, rescaled"",          y = ""Principal Component 2, rescaled\n"")",visualization,339501678012311e8,582
"pca_A2_rot = principal(d1, nfactors = 2, rotate = ""varimax"")",evaluation,339501678012311e8,582
pca_A2_rot,evaluation,339501678012311e8,582
pca_A2_rot$values,exploratory,339501678012311e8,582
"pca_A2_rot_pc1 = pca_A2_rot$loadings[, 1]",data cleaning,339501678012311e8,582
sort(pca_A2_rot_pc1),exploratory,339501678012311e8,582
"pca_A2_rot_pc2 = pca_A2_rot$loadings[, 2]",data cleaning,339501678012311e8,582
sort(pca_A2_rot_pc2),exploratory,339501678012311e8,582
"ggplot(data.frame(pca_A2_rot$loadings[1:3, ]), aes(x = PC1, y = PC2,      label = names(d1))) + geom_text() + theme_bw() + labs(title = ""Factor loadings\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,339501678012311e8,582
"ggplot(data.frame(pca_A2_rot$scores), aes(x = PC1, y = PC2, label = rownames(d1))) +      geom_text() + theme_bw() + labs(title = ""Raw character factor scores\n"",      x = ""\nPrincipal Component 2"", y = ""Principal Component 1\n"")",visualization,339501678012311e8,582
"ggplot(data.frame(pca_A2_rot$scores), aes(x = rescale(PC1, to = c(0,      1)), y = rescale(PC2, to = c(0, 1)), label = rownames(d1))) +      geom_point() + geom_text(angle = 0, vjust = -1, size = 6) +      xlim(-0.01, 1.01) + ylim(-0.01, 1.01) + theme_bw() + theme(text = element_text(size = 20)) +      labs(title = ""Adjusted character factor scores\n"", x = ""\nPrincipal Component 1, rescaled"",          y = ""Principal Component 2, rescaled\n"")",visualization,339501678012311e8,582
dissim = NULL,setup,339501678012311e8,582
"dissim <- dd %>% filter(phase == ""test"") %>% mutate(character1 = array(),      character2 = array())",data cleaning,339501678012311e8,582
"charsort = sort(levels(dissim$leftCharacter), decreasing = TRUE)",data cleaning,339501678012311e8,582
"for (i in 1:length(charsort)) dissim <- dissim %>% mutate(character1 = ifelse(leftCharacter ==      charsort[i] | rightCharacter == charsort[i], as.character(charsort[i]),      as.character(character1)), character2 = ifelse(character1 ==      leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%      mutate(character1 = factor(character1), character2 = factor(character2))",data cleaning,339501678012311e8,582
"dissim <- dissim %>% select(predicate, subid, character1, character2,      responseNum) %>% group_by(character1, character2) %>% mutate(dist = abs(responseNum)) %>%      summarise(mean = mean(dist, na.rm = TRUE)) %>% spread(character2,      mean)",data cleaning,339501678012311e8,582
"dissim <- dissim %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,339501678012311e8,582
"dissim = dissim[, c(1, 11, 2:10)]",data cleaning,339501678012311e8,582
"names = sort(charsort, decreasing = FALSE)",data cleaning,339501678012311e8,582
"names = names[names != ""strawberries""]",data cleaning,339501678012311e8,582
"names = names[names != ""grapes""]",data cleaning,339501678012311e8,582
"names = names[names != ""icecream""]",data cleaning,339501678012311e8,582
"names = names[names != ""pizza""]",data cleaning,339501678012311e8,582
dissim = dissim[-1],data cleaning,339501678012311e8,582
rownames(dissim) = names,data cleaning,339501678012311e8,582
colnames(dissim) = names,data cleaning,339501678012311e8,582
"for (i in 1:9) for (j in (i + 1):10) dissim[j, i] = dissim[i,      j]",data cleaning,339501678012311e8,582
dissim = as.dist(dissim),data cleaning,339501678012311e8,582
"mds_Aordinal = mds(dissim, ndim = 2, type = ""ordinal"")",modeling,339501678012311e8,582
summary(mds_Aordinal),exploratory,339501678012311e8,582
mds_Aordinal,exploratory,339501678012311e8,582
"plot(mds_Aordinal, plot.type = ""confplot"", xlim = c(-1, 1), ylim = c(-1,      1), main = ""MDS solution: All conditions"")",visualization,339501678012311e8,582
"plot(mds_Aordinal, plot.type = ""bubbleplot"", xlim = c(-1, 1),      ylim = c(-1, 1), main = ""MDS bubble plot: All conditions"")",visualization,339501678012311e8,582
"plot(mds_Aordinal, plot.type = ""stressplot"", main = ""MDS stress: All conditions"")",visualization,339501678012311e8,582
"plot(mds_Aordinal, plot.type = ""Shepard"", main = ""MDS Shepard plot: All conditions"")",visualization,339501678012311e8,582
"plot(mds_Aordinal, plot.type = ""resplot"", main = ""MDS residuals: All conditions"")",visualization,339501678012311e8,582
dissim_thinking = NULL,setup,339501678012311e8,582
"dissim_thinking <- dd %>% filter(predicate == ""thinking"") %>%      mutate(character1 = array(), character2 = array())",data cleaning,339501678012311e8,582
"charsort = sort(levels(dissim_thinking$leftCharacter), decreasing = TRUE)",data cleaning,339501678012311e8,582
"for (i in 1:length(charsort)) dissim_thinking <- dissim_thinking %>%      mutate(character1 = ifelse(leftCharacter == charsort[i] |          rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%      mutate(character1 = factor(character1), character2 = factor(character2))",data cleaning,339501678012311e8,582
"dissim_thinking <- dissim_thinking %>% select(predicate, subid,      character1, character2, responseNum) %>% group_by(character1,      character2) %>% mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,      na.rm = TRUE)) %>% spread(character2, mean)",data cleaning,339501678012311e8,582
"ggplot(gdpEduc, aes(x = log10(Gdp), col = factor(`Income Group`),      fill = factor(`Income Group`))) + geom_histogram(binwidth = 0.7,      alpha = 0.5) + facet_grid(. ~ factor(`Income Group`)) + theme_dark() +      theme(legend.position = ""none"", strip.text = element_text(size = rel(0.4))) +      labs(x = ""log10(Gdp)"") + ggtitle(""count vs log GDP faceted by Income groups"") +      theme(plot.title = element_text(hjust = 0.5, face = ""bold.italic"",          size = rel(0.8), color = ""darkblue""))",visualization,284681850345805e8,588
"ggplot(gdpEduc, aes(x = log10(Gdp), fill = factor(`Income Group`))) +      geom_density(col = NA, alpha = 0.35) + theme_light() + theme(legend.text = element_text(size = rel(0.5))) +      labs(x = ""GDP log transformed"") + scale_fill_discrete(name = ""Income Group"") +      ggtitle(""Overlaying density plots for log GDP"") + theme(plot.title = element_text(hjust = 0.5,      face = ""bold.italic"", size = rel(0.8), color = ""darkblue""))",visualization,284681850345805e8,588
"ggplot(gdpEduc, aes(x = factor(`Income Group`), y = log10(Gdp))) +      stat_summary(geom = ""point"", fun.y = mean, col = ""blue"") +      stat_summary(geom = ""errorbar"", fun.data = mean_sdl, fun.args = list(mult = 1),          col = ""blue"", width = 0.1) + theme(axis.text = element_text(angle = 45,      hjust = c(1), size = rel(0.6))) + labs(x = ""Income Groups"") +      ggtitle(""mean and 1 SD from mean"") + theme(plot.title = element_text(hjust = 0.5,      face = ""bold.italic"", size = rel(0.8), color = ""darkblue""))",visualization,284681850345805e8,588
"ggplot(gdpEduc, aes(x = factor(`Income Group`), y = log10(Gdp))) +      geom_point(colour = ""lightblue"", alpha = 0.9, position = ""identity"") +      geom_boxplot(outlier.size = 0, alpha = 0.2) + theme_light() +      theme(axis.text = element_text(angle = 45, hjust = c(1),          size = rel(0.6))) + labs(x = ""Income Groups"") + ggtitle(""Box plot overlayed with actual values"") +      theme(plot.title = element_text(hjust = 0.5, face = ""bold.italic"",          size = rel(0.8), color = ""darkblue""))",visualization,284681850345805e8,588
"dissim_thinking <- dissim_thinking %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,339501678012311e8,582
"descStatsGDP <- describeBy(gdpEduc$Gdp, gdpEduc$`Income Group`,      mat = TRUE)",data cleaning,284681850345805e8,588
"descStatsGDP %>% select(-item, -vars, -mad) %>% print(row.names = FALSE)",data cleaning,284681850345805e8,588
gdpEducTemp <- gdpEduc,data cleaning,284681850345805e8,588
"dissim_thinking = dissim_thinking[, c(1, 11, 2:10)]",data cleaning,339501678012311e8,582
dissim_thinking = dissim_thinking[-1],data cleaning,339501678012311e8,582
"gdpEducTemp %>% mutate(quantiles = quantileCut(gdpEduc$Ranking,      5, labels = c(""Q1"", ""Q2"", ""Q3"", ""Q4"", ""Q5""))) %>% filter(as.character(quantiles) ==      ""Q1"", `Income Group` == ""Lower middle income"") %>% select(CountryCode,      Economy, Ranking, `Income Group`, quantiles)",data cleaning,284681850345805e8,588
rownames(dissim_thinking) = names,data cleaning,339501678012311e8,582
colnames(dissim_thinking) = names,data cleaning,339501678012311e8,582
setwd(rootDir),setup,284681850345805e8,588
"for (i in 1:9) for (j in (i + 1):10) dissim_thinking[j, i] = dissim_thinking[i,      j]",data cleaning,339501678012311e8,582
dissim_thinking = as.dist(dissim_thinking),modeling,339501678012311e8,582
dissim_feelings = NULL,setup,339501678012311e8,582
"dissim_feelings <- dd %>% filter(predicate == ""feelings"") %>%      mutate(character1 = array(), character2 = array())",data cleaning,339501678012311e8,582
"charsort = sort(levels(dissim_feelings$leftCharacter), decreasing = TRUE)",data cleaning,339501678012311e8,582
"for (i in 1:length(charsort)) dissim_feelings <- dissim_feelings %>%      mutate(character1 = ifelse(leftCharacter == charsort[i] |          rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%      mutate(character1 = factor(character1), character2 = factor(character2))",data cleaning,339501678012311e8,582
"dissim_feelings <- dissim_feelings %>% select(predicate, subid,      character1, character2, responseNum) %>% group_by(character1,      character2) %>% mutate(dist = abs(responseNum)) %>% summarise(mean = mean(dist,      na.rm = TRUE)) %>% spread(character2, mean)",data cleaning,339501678012311e8,582
"dissim_feelings <- dissim_feelings %>% mutate(baby = NA, character1 = as.character(character1)) %>%      rbind(c(""stapler"", rep(NA, 13))) %>% mutate(character1 = factor(character1))",data cleaning,339501678012311e8,582
"dissim_feelings = dissim_feelings[, c(1, 11, 2:10)]",data cleaning,339501678012311e8,582
dissim_feelings = dissim_feelings[-1],data cleaning,339501678012311e8,582
rownames(dissim_feelings) = names,data cleaning,339501678012311e8,582
colnames(dissim_feelings) = names,data cleaning,339501678012311e8,582
"for (i in 1:9) for (j in (i + 1):10) dissim_feelings[j, i] = dissim_feelings[i,      j]",data cleaning,339501678012311e8,582
dissim_feelings = as.dist(dissim_feelings),modeling,339501678012311e8,582
dissim_hunger = NULL,setup,339501678012311e8,582
"dissim_hunger <- dd %>% filter(predicate == ""hunger"") %>% mutate(character1 = array(),      character2 = array())",data cleaning,339501678012311e8,582
"charsort = sort(levels(dissim_hunger$leftCharacter), decreasing = TRUE)",data cleaning,339501678012311e8,582
"for (i in 1:length(charsort)) dissim_hunger <- dissim_hunger %>%      mutate(character1 = ifelse(leftCharacter == charsort[i] |          rightCharacter == charsort[i], as.character(charsort[i]),          as.character(character1)), character2 = ifelse(character1 ==          leftCharacter, as.character(rightCharacter), as.character(leftCharacter))) %>%      mutate(character1 = factor(character1), character2 = factor(character2))",data cleaning,339501678012311e8,582
"sig <- getSig(cuff, alpha = 0.05)",not sure,248358438489959e8,589
"sigGenes <- getGenes(cuff, sig)",not sure,248358438489959e8,589
"data <- read.csv(""middle_range_coding_v4_w_borrowing.csv"", header = TRUE,      fill = FALSE, fileEncoding = ""latin1"")",import,674747802317142e8,590
"data <- data[data$Year > 1994, ]",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Indiidual"",      replacement = ""Individual"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Org$"",      replacement = ""Organization"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Firm"",      replacement = ""Organization"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Project"",      replacement = ""Group"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Group/Network"",      replacement = ""Network"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Network"",      replacement = ""Network"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Interorg"",      replacement = ""Network"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Technical"",      replacement = ""Artifact"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Database"",      replacement = ""Artifact"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Organization/Government/national level"",      replacement = ""Government"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Multilevel"",      replacement = ""Other"")",data cleaning,674747802317142e8,590
"data$Unit.of.Analysis <- gsub(data$Unit.of.Analysis, pattern = ""Online Auction"",      replacement = ""Other"")",data cleaning,674747802317142e8,590
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Computational "",      replacement = ""Computational"")",data cleaning,674747802317142e8,590
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Tool "",      replacement = ""Tool"")",data cleaning,674747802317142e8,590
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Nominal "",      replacement = ""Nominal"")",data cleaning,674747802317142e8,590
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Proxy "",      replacement = ""Proxy"")",data cleaning,674747802317142e8,590
"data$Treatment.of.IT <- gsub(data$Treatment.of.IT, pattern = ""Ensemble "",      replacement = ""Ensemble"")",data cleaning,674747802317142e8,590
"data$Classification..Exploitation.Exploration[data$Primary..outside.of.IS..or.Secondary..inside.of.IS..borrowing. ==      ""Secondary""] <- ""Exploitation""",data cleaning,674747802317142e8,590
"extending_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Extending"")",data cleaning,674747802317142e8,590
"modifying_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Modifying"")",data cleaning,674747802317142e8,590
"instantiation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Instantiation"")",data cleaning,674747802317142e8,590
"exploitation_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..Exploitation.Exploration == ""Exploitation"")",data cleaning,674747802317142e8,590
"exploration_total_cites <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Classification..Exploitation.Exploration == ""Exploration"")",data cleaning,674747802317142e8,590
"instantiation_total_cites <- subset(instantiation_total_cites,      instantiation_total_cites != 0)",data cleaning,674747802317142e8,590
"modifying_total_cites <- subset(modifying_total_cites, modifying_total_cites !=      0)",data cleaning,674747802317142e8,590
"extending_total_cites <- subset(extending_total_cites, extending_total_cites !=      0)",data cleaning,674747802317142e8,590
"hist(instantiation_total_cites, breaks = 50, ylim = c(0, 30),      xlim = c(0, 750))",visualization,674747802317142e8,590
"hist(modifying_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,      750))",visualization,674747802317142e8,590
"hist(extending_total_cites, breaks = 50, ylim = c(0, 30), xlim = c(0,      750))",visualization,674747802317142e8,590
"wilcox.test(extending_total_cites, instantiation_total_cites,      probs = 0.05, alternative = c(""greater""))",visualization,674747802317142e8,590
"wilcox.test(extending_total_cites, modifying_total_cites, probs = 0.05,      alternative = c(""greater""))",modeling,674747802317142e8,590
"wilcox.test(instantiation_total_cites, modifying_total_cites,      probs = 0.05, alternative = c(""less""))",modeling,674747802317142e8,590
my.headers <- names(temp.new),evaluation,30649423552677e9,591
log_instantiation_total_cites <- log(instantiation_total_cites),data cleaning,674747802317142e8,590
log_modifying_total_cites <- log(modifying_total_cites),data cleaning,674747802317142e8,590
log_extending_total_cites <- log(extending_total_cites),data cleaning,674747802317142e8,590
hist(log_instantiation_total_cites),visualization,674747802317142e8,590
hist(log_modifying_total_cites),visualization,674747802317142e8,590
hist(log_extending_total_cites),visualization,674747802317142e8,590
"Trinity_gene_lengths_mod <- left_join(Trinity_gene_lengths, annot_feature_map,      by = c(X.gene_id = ""V1""))",data cleaning,259426138596609e8,592
"graph <- read.csv(""cg_entities.csv"", sep = "","")",import,30649423552677e9,591
length(log_instantiation_total_cites),evaluation,674747802317142e8,590
length(log_modifying_total_cites),evaluation,674747802317142e8,590
length(log_extending_total_cites),evaluation,674747802317142e8,590
"t.test(log_extending_total_cites, log_instantiation_total_cites,      var.equal = FALSE)",modeling,674747802317142e8,590
"setDT(Trinity_gene_lengths_mod)[is.na(V2), `:=`(V2, X.gene_id)]",not sure,259426138596609e8,592
"t.test(log_modifying_total_cites, log_instantiation_total_cites,      var.equal = FALSE)",modeling,674747802317142e8,590
"t.test(log_modifying_total_cites, log_extending_total_cites,      var.equal = FALSE)",modeling,674747802317142e8,590
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Classification..instantiation..modifying..or.extending),modeling,674747802317142e8,590
"posthoc <- TukeyHSD(x = a1, data$Classification..instantiation..modifying..or.extending,      conf.level = 0.95)",modeling,674747802317142e8,590
"Trinity_gene_lengths_mod[, ""X.gene_id""] <- Trinity_gene_lengths_mod$V2",data cleaning,259426138596609e8,592
d1 <- data.frame(blog),data cleaning,30649423552677e9,591
d2 <- data.frame(graph),data cleaning,30649423552677e9,591
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Total.Citations.by..ISI.Web.of.Science...SSCI. != ""-"")",data cleaning,674747802317142e8,590
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Total.Citations.by..ISI.Web.of.Science...SSCI. != """")",data cleaning,674747802317142e8,590
Trinity_gene_lengths_mod$V2 <- NULL,data cleaning,259426138596609e8,592
a0 <- aov(log(data$Total.Citations.by..ISI.Web.of.Science...SSCI.) ~      data$Classification..instantiation..modifying..or.extending),modeling,674747802317142e8,590
"posthoc <- TukeyHSD(x = a0, ""data$Classification..instantiation..modifying..or.extending"",      conf.level = 0.95)",modeling,674747802317142e8,590
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",data cleaning,30649423552677e9,591
"write.table(Trinity_gene_lengths_mod, file = ""Trinity_gene_lengths_mod.txt"",      quote = FALSE, row.names = FALSE, sep = ""\t"")",export,259426138596609e8,592
"extending_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Extending"")",data cleaning,674747802317142e8,590
"write.csv(both, ""both.csv"", row.names = FALSE, quote = FALSE)",export,30649423552677e9,591
"modifying_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Modifying"")",data cleaning,674747802317142e8,590
"bNOTg <- read.csv(""blog_not_graph.csv"", sep = "","")",import,30649423552677e9,591
"go_annotations_mod <- left_join(go_annotations, annot_feature_map,      by = c(V1 = ""V1""))",data cleaning,259426138596609e8,592
d3 <- data.frame(bNOTg),data cleaning,30649423552677e9,591
"instantiation_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Instantiation"")",data cleaning,674747802317142e8,590
"instantiation_IS_cites <- subset(instantiation_IS_cites, instantiation_IS_cites !=      0)",data cleaning,674747802317142e8,590
"go_annotations_mod[, ""V1""] <- go_annotations_mod$V2.y",data cleaning,259426138596609e8,592
go_annotations_mod$V2 <- NULL,data cleaning,259426138596609e8,592
"extending_IS_cites <- subset(extending_IS_cites, extending_IS_cites !=      0)",data cleaning,674747802317142e8,590
"wilcox.test(extending_IS_cites, instantiation_IS_cites, probs = 0.05,      alternative = c(""greater""))",data cleaning,674747802317142e8,590
"write.table(go_annotations_mod, file = ""go_annotations_mod.txt"",      quote = FALSE, row.names = FALSE, sep = ""\t"")",export,259426138596609e8,592
"wilcox.test(extending_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""greater""))",modeling,674747802317142e8,590
"print(zapsmall(binconf(k2, nrow(Acc_sampled) - 1, method = ""all"")))",evaluation,30649423552677e9,591
"wilcox.test(instantiation_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""less""))",modeling,674747802317142e8,590
log_instantiation_IS_cites <- log10(instantiation_IS_cites),modeling,674747802317142e8,590
log_modifying_IS_cites <- log10(modifying_IS_cites),data cleaning,674747802317142e8,590
log_extending_IS_cites <- log10(extending_IS_cites),data cleaning,674747802317142e8,590
sqrt_instantiation_IS_cites <- sqrt(instantiation_IS_cites),data cleaning,674747802317142e8,590
"print(zapsmall(binconf(k2, nrow(Acc_sampled) - 1, method = ""all"")))",evaluation,30649423552677e9,591
sqrt_modifying_IS_cites <- sqrt(modifying_IS_cites),data cleaning,674747802317142e8,590
sqrt_extending_IS_cites <- sqrt(extending_IS_cites),data cleaning,674747802317142e8,590
hist(log_instantiation_IS_cites),data cleaning,674747802317142e8,590
"CleanSpotPrices <- read.csv(path, header = TRUE, sep = "","", stringsAsFactors = FALSE)",import,30649423552677e9,591
hist(log_modifying_IS_cites),visualization,674747802317142e8,590
hist(log_extending_IS_cites),visualization,674747802317142e8,590
"filepath2 <- ""/Data/CleanRigCountByTrajectory.csv""",setup,30649423552677e9,591
hist(sqrt_instantiation_IS_cites),visualization,674747802317142e8,590
hist(sqrt_modifying_IS_cites),visualization,674747802317142e8,590
hist(sqrt_extending_IS_cites),visualization,674747802317142e8,590
"t.test(log_modifying_IS_cites, log_extending_IS_cites, var.equal = FALSE)",visualization,674747802317142e8,590
"path <- c(getwd(), filepath2)",setup,30649423552677e9,591
library(plyr),modeling,674747802317142e8,590
"path <- paste(path, collapse = """")",setup,30649423552677e9,591
"data$Treatment.of.IT <- revalue(data$Treatment.of.IT, c(`Ensemble ` = ""Ensemble"",      `Tool ` = ""Tool"", `Computational ` = ""Computational"", `Nominal ` = ""Nominal"",      `Proxy ` = ""Proxy""))",setup,674747802317142e8,590
"CleanRigCountByTrajectory <- read.csv(path, header = TRUE, sep = "","",      stringsAsFactors = FALSE)",import,30649423552677e9,591
"CleanSpotPrices <- CleanSpotPrices[, -1]",data cleaning,30649423552677e9,591
oneway.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),data cleaning,674747802317142e8,590
"CleanRigCountByTrajectory <- CleanRigCountByTrajectory[, -1]",data cleaning,30649423552677e9,591
kruskal.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),modeling,674747802317142e8,590
"model <- aov(data = data, formula = Total.Citations.by..ISI.Web.of.Science...SSCI. ~      Treatment.of.IT)",modeling,674747802317142e8,590
"MergeData2 <- merge(CleanSpotPrices, CleanRigCountByTrajectory,      by = ""Date"")",data cleaning,30649423552677e9,591
"TukeyHSD(model, which = ""Treatment.of.IT"", ordered = FALSE, conf.level = 0.95)",modeling,674747802317142e8,590
oldwd <- getwd(),setup,30649423552677e9,591
"filepath2 <- ""/Data/""",setup,30649423552677e9,591
"path <- c(getwd(), filepath2)",setup,30649423552677e9,591
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      NA, 1)",modeling,674747802317142e8,590
"path <- paste(path, collapse = """")",setup,30649423552677e9,591
setwd(path),setup,30649423552677e9,591
"write.csv(MergeData2, file = ""MergeData2.csv"")",export,30649423552677e9,591
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- mapvalues(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      0, 1)",data cleaning,674747802317142e8,590
a1 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~      data$Classification..Exploitation.Exploration),data cleaning,674747802317142e8,590
setwd(oldwd),setup,30649423552677e9,591
"posthoc1 <- TukeyHSD(x = a1, ""data$Classification..Exploitation.Exploration"",      conf.level = 0.95)",modeling,674747802317142e8,590
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Group""])",modeling,674747802317142e8,590
library(reshape2),setup,30649423552677e9,591
library(plyr),setup,30649423552677e9,591
"setwd(""/Users/pascaltimshel/git/snpsnap/analysis/validation_summary_stats_inputEQmatched"")",setup,30649423552677e9,591
dat %>% dplyr::select(metier.2010) %>% distinct %>% summarize(n()),data cleaning,514073827303946e8,47
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Artifact""])",exploratory,674747802317142e8,590
"path.base = ""/Users/pascaltimshel/snpsnap/validation_new""",setup,30649423552677e9,591
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Individual""])",exploratory,674747802317142e8,590
"analysis_name = ""SNPsnap_rand500_defaultMatchCrit_n500_excludeInputHLA""",setup,30649423552677e9,591
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Artifact""])",exploratory,674747802317142e8,590
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Market""])",exploratory,674747802317142e8,590
"path.analysis = file.path(path.base, analysis_name)",setup,30649423552677e9,591
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Group""])",exploratory,674747802317142e8,590
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Individual""])",exploratory,674747802317142e8,590
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Unit.of.Analysis ==      ""Market""])",exploratory,674747802317142e8,590
a2 <- aov(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI. ~      data$Treatment.of.IT),exploratory,674747802317142e8,590
"file.annotation.input = file.path(path.analysis, ""input_snps_annotated.tab"")",setup,30649423552677e9,591
"posthoc2 <- TukeyHSD(x = a2, ""data$Treatment.of.IT"", conf.level = 0.95)",modeling,674747802317142e8,590
"file.annotation.matched = file.path(path.analysis, ""matched_snps_annotated.tab"")",setup,30649423552677e9,591
df.input = read.delim(file.annotation.input),import,30649423552677e9,591
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Computational""])",modeling,674747802317142e8,590
df.matched = read.delim(file.annotation.matched),import,30649423552677e9,591
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Proxy""])",exploratory,674747802317142e8,590
"mean(data$Total.Citations.by..ISI.Web.of.Science...SSCI[data$Treatment.of.IT ==      ""Nominal""])",exploratory,674747802317142e8,590
a3 <- aov(data$Total.Citations.by..ISI.Web.of.Science...SSCI ~      data$Classification..Exploitation.Exploration),exploratory,674747802317142e8,590
"posthoc3 <- TukeyHSD(x = a3, ""data$Classification..Exploitation.Exploration"",      conf.level = 0.95)",modeling,674747802317142e8,590
instantiation_total_cites[instantiation_total_cites == 0] <- 1,modeling,674747802317142e8,590
m1 <- displ$new(instantiation_total_cites),data cleaning,674747802317142e8,590
max_freq_deviation = 5,setup,30649423552677e9,591
max_genes_count_deviation = 50,evaluation,30649423552677e9,591
max_distance_deviation = 50,evaluation,30649423552677e9,591
max_ld_buddy_count_deviation = 50,evaluation,30649423552677e9,591
m1 = displ$new(instantiation_total_cites),exploratory,674747802317142e8,590
m1$setPars(estimate_pars(m1)),exploratory,674747802317142e8,590
"delta_genes_count_deviation = max_genes_count_deviation/100 *      c(-1, 1)",evaluation,30649423552677e9,591
modifying_total_cites[modifying_total_cites == 0] <- 1,exploratory,674747802317142e8,590
"sample_snpID = c(""14:69873335"")",evaluation,30649423552677e9,591
m2 <- displ$new(modifying_total_cites),exploratory,674747802317142e8,590
m2 = displ$new(modifying_total_cites),data cleaning,674747802317142e8,590
m2$setPars(estimate_pars(m2)),data cleaning,674747802317142e8,590
extending_total_cites[extending_total_cites == 0] <- 1,data cleaning,674747802317142e8,590
m3 <- displ$new(extending_total_cites),data cleaning,674747802317142e8,590
m3 = displ$new(extending_total_cites),data cleaning,674747802317142e8,590
"sample_snpID_gene_count = df.input[df.input[, ""snpID""] == ""8:48128910"",      ]$gene_count",evaluation,30649423552677e9,591
m3$setPars(estimate_pars(m3)),data cleaning,674747802317142e8,590
"comp12 <- compare_distributions(m1, m2)",data cleaning,674747802317142e8,590
"df.sample.snp <- subset(df.matched, input_snp == sample_snpID,      select = c(snpID, gene_count))",data cleaning,30649423552677e9,591
"comp13 <- compare_distributions(m1, m3)",evaluation,674747802317142e8,590
"comp23 <- compare_distributions(m2, m3)",evaluation,674747802317142e8,590
comp12$p_two_sided,evaluation,674747802317142e8,590
range(df.sample.snp$gene_count),evaluation,30649423552677e9,591
comp13$p_two_sided,evaluation,674747802317142e8,590
comp23$p_two_sided,evaluation,674747802317142e8,590
kruskal.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Classification..instantiation..modifying..or.extending),evaluation,674747802317142e8,590
"t <- findInterval(df.sample.snp[, ""gene_count""], sample_snpID_gene_count *      (1 + delta_genes_count_deviation))",evaluation,30649423552677e9,591
"df.snpcomparison.input <- ddply(df.input, c(""snpID""), summarise,      origin = as.factor(""input_df""), mean_freq_bin = mean(freq_bin),      mean_gene_count = mean(gene_count), mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), median_gene_count = median(gene_count))",data cleaning,30649423552677e9,591
"dunn <- dunn.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      g = data$Classification..instantiation..modifying..or.extending)",modeling,674747802317142e8,590
"df.snpcomparison.matched <- ddply(df.matched, c(""input_snp""),      summarise, origin = as.factor(""matched_df""), mean_freq_bin = mean(freq_bin),      mean_gene_count = mean(gene_count), mean_dist_nearest_gene_snpsnap = mean(dist_nearest_gene_snpsnap),      mean_friends_ld05 = mean(friends_ld05), median_gene_count = median(gene_count))",data cleaning,30649423552677e9,591
kruskal.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI. ~      data$Classification..Exploitation.Exploration),modeling,674747802317142e8,590
"dunn <- dunn.test(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      g = data$Classification..Exploitation.Exploration)",modeling,674747802317142e8,590
exploitation_total_cites[exploitation_total_cites == 0] <- 1,modeling,674747802317142e8,590
m1 <- displ$new(exploitation_total_cites),exploratory,674747802317142e8,590
"names(df.snpcomparison.matched)[names(df.snpcomparison.matched) ==      ""input_snp""] <- ""snpID""",data cleaning,30649423552677e9,591
"df.snpcomparison <- rbind.fill(df.snpcomparison.input, df.snpcomparison.matched)",data cleaning,30649423552677e9,591
"df.snpcomparison.melt <- melt(df.snpcomparison, id.vars = c(""snpID"",      ""origin""), measure.vars = c(""mean_gene_count"", ""median_gene_count""))",data cleaning,30649423552677e9,591
"x <- df.snpcomparison.melt[df.snpcomparison.melt$origin == ""input_df"",      ""value""]",data cleaning,30649423552677e9,591
m1 = displ$new(exploitation_total_cites),evaluation,674747802317142e8,590
"y <- df.snpcomparison.melt[df.snpcomparison.melt$origin == ""matched_df"",      ""value""]",data cleaning,30649423552677e9,591
m1$setPars(estimate_pars(m1)),evaluation,674747802317142e8,590
exploration_total_cites[exploration_total_cites == 0] <- 1,evaluation,674747802317142e8,590
"tmp <- data.frame(input_df = x, matched_df = y)",data cleaning,30649423552677e9,591
"plot(x, y)",visualization,30649423552677e9,591
"abline(0, 1)",visualization,30649423552677e9,591
"results <- t(data.frame(split = live.data$split, merged = live.data$merged,      missed = live.data$missed))",data cleaning,30649423552677e9,591
"pdf(""NM2010_cells.pdf"", 8.5, 3.5)",visualization,30649423552677e9,591
"op <- par(ps = 14, mar = c(4, 4, 2.5, 2) + 0.1)",visualization,30649423552677e9,591
"barplot(as.matrix(results), col = c(""gray"", ""red"", ""yellow""),      names.arg = live.data$time - 850, ylab = ""Error Count"", ylim = c(0,          275), legend = F, xlab = ""Time (seconds)"")",visualization,30649423552677e9,591
par(op),visualization,30649423552677e9,591
dev.off(),visualization,30649423552677e9,591
"live.data <- read.delim(""live_data_output/072112_02_t11_50_static_analysis_ACME.txt"",      stringsAsFactors = F)",import,30649423552677e9,591
"live.data <- live.data[live.data$time - 850 <= 950, ]",data cleaning,30649423552677e9,591
"results <- t(data.frame(split = live.data$split, merged = live.data$merged,      missed = live.data$missed))",data cleaning,30649423552677e9,591
"pdf(""ACME_cells.pdf"", 8.5, 3.5)",export,30649423552677e9,591
"op <- par(ps = 14, mar = c(4, 4, 2.5, 2) + 0.1)",visualization,30649423552677e9,591
"barplot(as.matrix(results), col = c(""gray"", ""red"", ""yellow""),      names.arg = live.data$time - 850, ylab = ""Error Count"", ylim = c(0,          275), legend = F, xlab = ""Time (seconds)"")",visualization,30649423552677e9,591
par(op),visualization,30649423552677e9,591
dev.off(),visualization,30649423552677e9,591
library(magrittr),setup,30649423552677e9,591
library(ggplot2),setup,30649423552677e9,591
"path_out <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis""",setup,30649423552677e9,591
"path_script <- ""/data/liucj/github/autophagy-in-cancer/analysis/23-gene-set-enrichment-analysis""",setup,30649423552677e9,591
"path_gmt <- file.path(path_out, ""GSEA-collections-gmt"")",setup,30649423552677e9,591
dir.create(path_gmt),setup,30649423552677e9,591
"rda_filename <- file.path(""/data/liucj/project/06-autophagy/20-rda"",      ""01-autophagy-and-hallmarks-expresson.rda"")",setup,30649423552677e9,591
load(file = rda_filename),import,30649423552677e9,591
"fn_gsea <- function(.ds, .cls, .db, .output, .doc) GSEA(input.ds = .ds,      input.cls = .cls, gs.db = .db, output.directory = .output,      doc.string = .doc, non.interactive.run = F, reshuffling.type = ""gene.labels"",      nperm = 1000, weighted.score.type = 1, nom.p.val.threshold = -1,      fwer.p.val.threshold = -1, fdr.q.val.threshold = 0.25, topgs = 50,      adjust.FDR.q.val = F, gs.size.threshold.min = 10, gs.size.threshold.max = 1000,      reverse.sign = F, preproc.type = 0, random.seed = 111, perm.type = 0,      fraction = 1, replace = F, save.intermediate.results = F,      OLD.GSEA = F, use.fast.enrichment.routine = T)",not sure,30649423552677e9,591
"fn_run_gsea <- function(.x, .path = gsea_path, script_path = script_path) .gct <- file.path(.path,      glue::glue("".x_as_classify_mrna.gct""))",data cleaning,30649423552677e9,591
".cls <- file.path(.path, glue::glue("".x_as_classify_mrna.cls""))",setup,30649423552677e9,591
".gmt <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis/GSEA-collections-gmt/C2_CURATED.gmt""",setup,30649423552677e9,591
".output_dir <- file.path(.path, ""02-c2-curated-result/"")",setup,30649423552677e9,591
".doc <- paste(.x, ""GSEA.analysis"", sep = ""."")",setup,30649423552677e9,591
if (!file.exists(.output_dir)) dir.create(.output_dir),setup,30649423552677e9,591
"source(file.path(script_path, ""GSEA.1.0.r""))",setup,30649423552677e9,591
"fn_gsea(.ds = .gct, .cls = .cls, .db = .gmt, .output = .output_dir,      .doc = .doc)",not sure,30649423552677e9,591
"c(""DLBC"", ""ESCA"", ""HNSC"", ""READ"", ""SKCM"", ""TGCT"") %>% purrr::map(.f = fn_run_gsea,      .path = path_gsea_cancer_types, script_path = script_path)",data cleaning,30649423552677e9,591
"while (summary(pca_prop)[[6]][3, ][npc] < 0.8) npc = npc + 1",evaluation,30649423552677e9,591
"dat_setup <- pca_prop$x[, 1:npc]",data cleaning,30649423552677e9,591
row <- seq(1:nrow(dat_setup)),evaluation,30649423552677e9,591
"dat_setup <- cbind(dat_setup, row)",data cleaning,30649423552677e9,591
"dat_setup <- dat_setup[sample(nrow(dat_setup)), ]",exploratory,30649423552677e9,591
"dat_prop <- dat_setup[, 1:(ncol(dat_setup) - 1)]",data cleaning,30649423552677e9,591
"save(dat_setup, dat_prop, file = ""/Volumes/NOAA_Data/CNH/Analysis/Metiers/data/all_tickets/datSetup_datProp.Rdata"")",export,30649423552677e9,591
library(pander),setup,30649423552677e9,591
library(httr),setup,30649423552677e9,591
"save_directory <- ""/var/www/html/files/fe/plots""",setup,30649423552677e9,591
"site <- ""http://deq1.bse.vt.edu/d.dh""",setup,30649423552677e9,591
"fxn_locations = ""/usr/local/home/git/r-dh-ecohydro/Analysis""",setup,30649423552677e9,591
"source(paste(fxn_locations, ""fn_vahydro-1.0.R"", sep = ""/""))",setup,30649423552677e9,591
"source(paste(fxn_locations, ""fn_iha.R"", sep = ""/""))",setup,30649423552677e9,591
library(dataRetrieval),setup,30649423552677e9,591
library(rstan),setup,162533101625741e8,545
"siteNo <- ""02011460""",setup,30649423552677e9,591
rstan_options(auto_write = TRUE),setup,162533101625741e8,545
"pCode <- ""00060""",setup,30649423552677e9,591
options(mc.cores = parallel::detectCores()),setup,162533101625741e8,545
"start.date <- ""1980-01-01""",setup,30649423552677e9,591
"end.date <- ""2016-09-30""",setup,30649423552677e9,591
"load(""analysis/rdata-tmp/RoT-dat2.RData"")",import,162533101625741e8,545
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,162533101625741e8,545
"yahara <- readNWISdv(siteNumbers = siteNo, parameterCd = pCode,      startDate = start.date, endDate = end.date)",import,30649423552677e9,591
"fit <- stan(file = ""analysis/src-analysis/stan-models/binomial.stan"",      data = stan.dat2, iter = parameters$iters, chains = parameters$nchains,      seed = parameters$seed, verbose = T)",modeling,162533101625741e8,545
"titles = c(""Noise"", ""House Size"", ""Lot Size"", ""Year Built"", ""Owner Occupancy"",      ""Median Income"", ""School Test Scores"", ""Distance to Lake"",      ""Distance to Park"", ""Distance to Shop"", ""Distance to CBD"",      ""Percent White"", ""Percent Under Age 18"")",visualization,943400827469304e8,591
"pdf(""analysis/04MonteCarloSim/Revision/MCsimResultsSDsk500and2000.pdf"",      height = 8, width = 6, family = ""Palatino"")",export,943400827469304e8,591
"par(oma = c(0.5, 0.5, 3, 0.5))",visualization,943400827469304e8,591
"ylim <- c(0, 1)",setup,581987073644996e8,187
"layout(matrix(c(1, 1:14), 5, 3, byrow = TRUE))",visualization,943400827469304e8,591
"pp <- read.table(""~/selection/analysis/series/polypop_list.txt"",      as.is = TRUE)",import,581987073644996e8,187
"par(mar = c(0, 0, 0, 0))",visualization,943400827469304e8,591
"plot(0, 0, type = ""n"", ylab = """", xlab = """", axes = F)",visualization,943400827469304e8,591
"pp[, 1] <- gsub(""_"", "" "", pp[, 1])",data cleaning,581987073644996e8,187
"snpname <- ""rs12913832""",setup,581987073644996e8,187
flip <- TRUE,not sure,581987073644996e8,187
"outname <- ""herc2series.pdf""",not sure,581987073644996e8,187
"data <- read.table(""~/selection/counts/all.reads.freq"", as.is = TRUE,      header = TRUE)",import,581987073644996e8,187
"legend(""center"", c(""Simulated (2000)"", ""Actual (2000)"", ""Simulated (500)"",      ""Actual (500)""), col = c(""red"", ""red"", ""blue"", ""blue""), lty = c(1,      3, 1, 3), lwd = 2, box.col = ""white"", cex = 1.7)",visualization,943400827469304e8,591
"par(mar = c(2.5, 1, 2, 1.5))",visualization,943400827469304e8,591
"freq <- data[, 6:NCOL(data)]",data cleaning,581987073644996e8,187
"data <- data[, 1:5]",data cleaning,581987073644996e8,187
"for (i in 14:26) MCplotter(outputCOEFS[i], statCOEFS[i])",visualization,943400827469304e8,591
"title(titles[i - 13], main.cex = 1.5, line = 0)",visualization,943400827469304e8,591
"rownames(freq) <- data[, 1]",data cleaning,581987073644996e8,187
"title(""Distribution of Simulated and Actual\n LWR Regression Coefficient Standard Deviations"",      line = -0.5, outer = T, cex.main = 2)",visualization,943400827469304e8,591
dev.off(),visualization,943400827469304e8,591
"uci <- read.table(""~/selection/counts/all.reads.highCI.freq"",      as.is = TRUE, header = TRUE)",import,581987073644996e8,187
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,943400827469304e8,591
dev.off(),visualization,943400827469304e8,591
"uci <- unlist(uci[uci[, 1] == snpname, 6:NCOL(uci)])",data cleaning,581987073644996e8,187
"lci <- read.table(""~/selection/counts/all.reads.lowCI.freq"",      as.is = TRUE, header = TRUE)",import,581987073644996e8,187
"lci <- unlist(lci[lci[, 1] == snpname, 6:NCOL(lci)])",data cleaning,581987073644996e8,187
"EpiModelHPC::get_epi(indir = ""data/save/"", outdir = ""data/save/analysis/"",      vars = c(""num"", ""i.prev"", ""incid"", ""prepCov"", ""prepElig"",          ""prepCurr""), suffix = ""lim"")",import,943400827469304e8,591
"pops <- unique(pp[, 1])",exploratory,581987073644996e8,187
"ff <- freq[snpname, ]",exploratory,581987073644996e8,187
"econ_analysis$Region <- gsub("" region"", """", econ_analysis$Region)",data cleaning,943400827469304e8,591
econ_analysis$Region <- str_to_title(econ_analysis$Region),data cleaning,943400827469304e8,591
if (flip) ff <- 1 - ff,not sure,581987073644996e8,187
tmp1 <- 1 - uci,not sure,581987073644996e8,187
uci <- 1 - lci,not sure,581987073644996e8,187
"opt_nitrogen <- group_by(yield_gaps_gha, REGNAME) %>% summarise(Count = n(),      Nit = sum(yesN == 1), `Nit all (kg/ha)` = round(mean(N),          2), `Nit users (kg/ha)` = round(mean(N[yesN == 1]), 2),      `Opt. Nit (kg/ha)` = round(mean(Npm, na.rm = TRUE), 2)) %>%      rename(Region = REGNAME) %>% mutate(Region = tolower(Region))",data cleaning,943400827469304e8,591
lci <- tmp1,not sure,581987073644996e8,187
"opt_nitrogen$Region <- gsub("" region"", """", opt_nitrogen$Region)",data cleaning,943400827469304e8,591
opt_nitrogen$Region <- str_to_title(opt_nitrogen$Region),data cleaning,943400827469304e8,591
"pp$f <- unlist(ff[pp[, 2]])",data cleaning,581987073644996e8,187
"pp$lci <- unlist(lci[pp[, 2]])",data cleaning,581987073644996e8,187
"pp$uci <- unlist(uci[pp[, 2]])",data cleaning,581987073644996e8,187
"cols <- brewer.pal(length(pops), ""Set1"")",visualization,581987073644996e8,187
"download.file(url = ""http://www.mshp.dps.mo.gov/MSHPWeb/PatrolDivisions/CRID/SOR/msor.zip"",      destfile = ""analysis/data/msor.zip"", mode = ""wb"")",import,943400827469304e8,591
"cols[6] <- ""darkgrey""",visualization,581987073644996e8,187
"unzip(zipfile = ""analysis/data/msor.zip"", exdir = ""analysis/data"")",import,943400827469304e8,591
"pdf(paste0(out, outname), width = 12, height = 6)",export,581987073644996e8,187
"save(tree_1990_2015_boots, file = ""tree_1990_2015_boots.Rdata"")",export,943400827469304e8,591
"plot(0, 0, col = ""white"", xlim = c(-8000, 0), ylim = ylim, bty = ""n"",      xlab = ""Years before present"", ylab = ""HERC2 allele frequency"",      xaxt = ""n"")",visualization,581987073644996e8,187
"source(""analysis/utils.R"")",import,943400827469304e8,591
"source(""analysis/analysis.R"")",setup,943400827469304e8,591
"summarize_analyses <- function(analyses) evaluated_promise_type <- analyses$`evaluated-promise-type` %>%      select(promise_type, promise_value_type, count) %>% group_by(promise_type,      promise_value_type) %>% summarize(count = sum(as.numeric(count))) %>%      ungroup()",data cleaning,943400827469304e8,591
"plan <- bind_plans(scenarios_plan, combined_plan, run_plan, results_plan,      plot_plan)",exploratory,238056384259835e8,593
total_count <- sum(as.numeric(evaluated_promise_type$count)),exploratory,943400827469304e8,591
"evaluated_promise_type <- evaluated_promise_type %>% mutate(relative_count = count/total_count,      promise_type = ifelse(promise_type == ""ca"", ""Custom argument"",          ifelse(promise_type == ""na"", ""Non argument"", ""Default argument"")))",evaluation,943400827469304e8,591
config <- drake_config(plan),modeling,238056384259835e8,593
make(plan),visualization,238056384259835e8,593
"synapse <- import(""synapseclient"")",import,238056384259835e8,593
syn <- synapse$Synapse(),data cleaning,238056384259835e8,593
syn$login(),modeling,238056384259835e8,593
require(tidyverse),setup,238056384259835e8,593
"syn_file = ""syn5950004""",setup,238056384259835e8,593
"expData <- read.table(syn$get(syn_file)$path, sep = ""\t"")",import,238056384259835e8,593
"phenData <- read.table(syn$get(""syn5950620"")$path, sep = ""\t"",      header = T)",import,238056384259835e8,593
rownames(phenData) <- phenData$geo_accession,modeling,238056384259835e8,593
"phenData <- phenData %>% select(-geo_accession) %>% subset(cellType !=      ""reference"")",data cleaning,238056384259835e8,593
require(singleCellSeq),export,238056384259835e8,593
"analysis_dir = ""syn5908068""",setup,238056384259835e8,593
"rmd <- system.file(""heatmap_vis.Rmd"", package = ""singleCellSeq"")",setup,238056384259835e8,593
"kf <- rmarkdown::render(rmd, rmarkdown::html_document(), output_file = paste(getwd(),      ""/panNFHeatmap.html"", sep = """"), params = list(samp.mat = expData,      cell.annotations = phenData, seqData = FALSE))",visualization,238056384259835e8,593
"syn$store(synapse$File(kf, parentId = analysis_dir), used = syn_file)",export,238056384259835e8,593
"m = lmer(num_actions ~ factor(trial_repeat) + (1 | pid) + (1 |      initial_state), data = onlyexp3, REML = FALSE)",modeling,592293077614158e8,594
anova(m),modeling,592293077614158e8,594
comparing_experiments = df[],setup,592293077614158e8,594
"comparing_experiments$experiment = ifelse(comparing_experiments$high_stakes ==      ""1.1"", ""exp1"", ""exp2"")",setup,592293077614158e8,594
"m = lm(num_actions ~ factor(experiment), data = comparing_experiments)",modeling,592293077614158e8,594
anova(m),modeling,592293077614158e8,594
center.posi.ix = center.posi.ix + 1,data cleaning,592293077614158e8,594
st = en + 1,data cleaning,592293077614158e8,594
if (center.posi[1] - size/2 < 1) center.posi[1] = size/2 + 2,data cleaning,592293077614158e8,594
if (center.posi[length(center.posi)] + size/2 > chr.len) center.posi[length(center.posi)] = chr.len -      size/2 - 2,data cleaning,592293077614158e8,594
"path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/""",setup,592293077614158e8,594
"res = data.frame(chr = rep(paste0(""chr"", chr), length(center.posi)),      st.posi = center.posi - size/2 + 1, en.posi = center.posi +          size/2)",setup,592293077614158e8,594
"write.table(res, file = paste0(path, Treatment, ""."", size, "".chr"",      chr, "".locus""), col.names = TRUE, row.names = FALSE, quote = FALSE)",export,592293077614158e8,594
"event_locations_shared[which(shared_list[[1]] & shared_list[[4]],      arr.ind = T)] = 1.5",data cleaning,592293077614158e8,594
"event_locations_shared[which(shared_list[[2]] & shared_list[[4]],      arr.ind = T)] = -3",data cleaning,592293077614158e8,594
"event_locations_shared[which(shared_list[[2]] & shared_list[[3]],      arr.ind = T)] = -1.5",data cleaning,592293077614158e8,594
return(event_locations_shared),communication,592293077614158e8,594
event_locations_shared_all = create_event_locations_shared(shared_all),not sure,592293077614158e8,594
event_locations_shared_2 = create_event_locations_shared(shared_2),not sure,592293077614158e8,594
"concurrent_events_all = find_concurrent_events(event_locations_shared_all,      2, event_types = c(-1, 1))",not sure,592293077614158e8,594
"concurrent_events_2 = find_concurrent_events(event_locations_shared_2,      2, event_types = c(-1, 1))",not sure,592293077614158e8,594
"pdf(""analysis/F_subtract/replicates/replicate_shared_events.pdf"",      width = 14, height = 14)",export,592293077614158e8,594
"make_visual(data_mat, event_locations_shared_all, concurrent_events_all,      log_colors = T, diverging = T)",not sure,592293077614158e8,594
"make_visual(data_mat, event_locations_shared_2, concurrent_events_2,      log_colors = T, diverging = T)",not sure,592293077614158e8,594
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,376005188561976e8,341
dev.off(),export,592293077614158e8,594
abline(pylslm$coefficients),visualization,376005188561976e8,341
"pylslm <- lm(time ~ input, data = pyls)",modeling,376005188561976e8,341
"pyls$mean_times <- sapply(pyls$input, function(x) mean(pyls$time[pyls$input ==      x]))",exploratory,376005188561976e8,341
"plot(mean_times ~ input, data = pyls)",visualization,376005188561976e8,341
"mean_model <- lm(mean_times ~ input, data = pyls)",modeling,376005188561976e8,341
"event_locations1[20:30, 13]",setup,592293077614158e8,594
"event_locations2[20:30, 13]",setup,592293077614158e8,594
"event_locations3[20:30, 13]",setup,592293077614158e8,594
total_call_count <- sum(as.numeric(function_return_type_summary$call_count)),data cleaning,592293077614158e8,594
function_return_type_summary <- function_return_type_summary %>%      mutate(relative_call_count = call_count/total_call_count),data cleaning,592293077614158e8,594
"list(function_return_type_distribution = function_return_type_distribution,      function_return_type_summary = function_return_type_summary,      total_call_count = tibble(total_call_count = total_call_count))",data cleaning,592293077614158e8,594
visualize_analyses <- function(analyses) total_call_count <- analyses$total_call_count$total_call_count,data cleaning,592293077614158e8,594
"function_return_type_distribution <- analyses$function_return_type_summary %>%      ggplot(aes(return_type, weight = function_count)) + geom_bar() +      scale_y_continuous(labels = count_labels) + labs(y = ""Function count"",      x = ""Return type"", title = ""Function Count by return type"") +      scale_fill_gdocs() + theme(axis.text.x = element_text(angle = 60,      hjust = 1))",visualization,592293077614158e8,594
"call_return_type_distribution <- analyses$function_return_type_summary %>%      ggplot(aes(return_type, weight = relative_call_count)) +      geom_bar() + scale_y_continuous(sec.axis = sec_axis(~. *      total_call_count, labels = count_labels), labels = relative_labels) +      labs(y = ""Call count (%)"", x = ""Return type"", title = ""Call count by return type"") +      scale_fill_gdocs() + theme(axis.text.x = element_text(angle = 60,      hjust = 1))",visualization,592293077614158e8,594
"list(call_return_type_distribution = call_return_type_distribution,      function_return_type_distribution = function_return_type_distribution)",data cleaning,592293077614158e8,594
"latex_analyses <- function(analyses) main <- function() analyzer <- create_analyzer(""Function Return Type Analysis"",      combine_analyses, summarize_analyses, visualize_analyses,      latex_analyses)",data cleaning,592293077614158e8,594
drive_analysis(analyzer),not sure,592293077614158e8,594
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,622233785688877e7,595
me = net$MEs[[module]],data cleaning,622233785688877e7,595
order = order(sampleInfo$order),data cleaning,622233785688877e7,595
main(),not sure,592293077614158e8,594
color = sampleInfo$color,data cleaning,622233785688877e7,595
x11(),setup,622233785688877e7,595
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,622233785688877e7,595
"pdf(""9861.pdf"", width = 6, height = 3, pointsize = 8)",export,622233785688877e7,595
warnings(),evaluation,592293077614158e8,594
"source(""analysis/utils.R"")",setup,994357802672312e8,596
"source(""analysis/analysis.R"")",setup,994357802672312e8,596
summarize_analyses <- function(analyses) promise_count <- unname(c(sum(as.numeric(analyses$`evaluated-promise-type`$count))))[[1]] +      unname(c(sum(as.numeric(analyses$`unevaluated-promise-type`$count))))[[1]],exploratory,994357802672312e8,596
"object_count_size <- analyses$`object-count-size` %>% select(-vignette,      -package) %>% mutate(count = as.numeric(count), size = as.numeric(size)) %>%      add_row(object_type = ""Promise"", count = promise_count, size = promise_count *          56) %>% group_by(object_type) %>% summarize(count = sum(count),      size = sum(size)) %>% ungroup() %>% mutate(relative_size = 100 *      size/sum(size), relative_count = 100 * count/sum(count),      group_type = ifelse(object_type == ""Promise"", ""Promises"",          ""Other Objects""))",exploratory,994357802672312e8,596
"source(""Analysis/01_SM_load.R"")",exploratory,326698450837284e8,597
"source(""Analysis/02_SM_clean.R"")",exploratory,326698450837284e8,597
"source(""Analysis/03_SM_func.R"")",exploratory,326698450837284e8,597
"if (!file.exists(""Output"")) dir.create(""Output"")",exploratory,326698450837284e8,597
"ggsave(""Output/Fig1.png"", ephsurvplot_lognorm)",exploratory,326698450837284e8,597
"ggsave(""Output/SuplFig3.png"", int_plot)",exploratory,326698450837284e8,597
"ggsave(""Output/SuplFig3.png"", int_plot)",exploratory,326698450837284e8,597
"source(""Analysis/01_SM_load.R"")",import,326698450837284e8,597
for (analysis in analysisList) print(analysis$name),import,326698450837284e8,597
analysis$MakeBetterEventTable(),import,326698450837284e8,597
"analysis$betterEventTable$name = rep(analysis$name, nrow(analysis$betterEventTable))",import,326698450837284e8,597
"dt_analyses = rbind(dt_analyses, analysis$betterEventTable)",import,326698450837284e8,597
"if (!dir.exists(""Computed"")) dir.create(""Computed"")",communication,326698450837284e8,597
"write.table(dt_analyses, ""Computed/dt_analyses.csv"", sep = "";"",      row.names = F, quote = F)",data cleaning,326698450837284e8,597
return(dt_analyses),communication,326698450837284e8,597
"rmd <- system.file(""heatmap_vis.Rmd"", package = ""singleCellSeq"")",data cleaning,326698450837284e8,597
"kf <- rmarkdown::render(rmd, rmarkdown::html_document(), output_file = paste(getwd(),      ""/panNFHeatmap.html"", sep = """"), params = list(samp.mat = expData,      cell.annotations = phenData, seqData = FALSE))",data cleaning,326698450837284e8,597
"syn$store(synapse$File(kf, parentId = analysis_dir), used = syn_file)",data cleaning,326698450837284e8,597
"cut.tab <- read.table(syn$get(""syn5051784"")$path)",data cleaning,326698450837284e8,597
"annotes <- syn$tableQuery(""SELECT sampleIdentifier,Patient,TumorLocation,RNASeq FROM syn5556216 where usedforRNA=TRUE"")$asDataFrame() %>%      select(sampleIdentifier, Patient, TumorLocation, RNASeq)",data cleaning,326698450837284e8,597
"rownames(cut.tab) <- annotes$sampleIdentifier[match(rownames(cut.tab),      annotes$RNASeq)]",data cleaning,326698450837284e8,597
rownames(annotes) <- annotes$sampleIdentifier,data cleaning,326698450837284e8,597
"data2 <- read.table(""Analysis/Data/data2"", sep = "","")",import,389202133519575e8,598
MainData <- data2,exploratory,389202133519575e8,598
"write.table(MainData, file = ""Analysis/Data/MainData"", sep = "","")",export,389202133519575e8,598
rm(list = ls()),evaluation,389202133519575e8,598
dev.off(),export,389202133519575e8,598
"pdf(""/Users/cwillis/dev/uiucGSLIS/ecir-2016/analysis/301/301-la.pdf"")",export,389202133519575e8,598
"plot(density(d4$V4), xlim = c(0, 2000), col = ""orange"", ylim = c(0,      0.02), xlab = """", ylab = """", yaxt = ""n"", main = """")",visualization,389202133519575e8,598
dev.off(),visualization,389202133519575e8,598
"pdf(""/Users/cwillis/dev/uiucGSLIS/ecir-2016/analysis/301/301-ft.pdf"")",visualization,389202133519575e8,598
"plot(density(d3$V4), xlim = c(0, 2000), col = ""red"", ylim = c(0,      0.01), xlab = """", ylab = """", yaxt = ""n"", main = """")",visualization,389202133519575e8,598
dev.off(),export,389202133519575e8,598
"pdf(""/Users/cwillis/dev/uiucGSLIS/ecir-2016/analysis/301/301-fbis.pdf"")",export,389202133519575e8,598
"plot(density(d2$V4), xlim = c(0, 2000), col = ""blue"", xlab = """",      ylab = """", yaxt = ""n"", main = """")",visualization,389202133519575e8,598
dev.off(),export,389202133519575e8,598
head(team_stats_by_season),exploratory,389202133519575e8,598
summarize_all(df_limesurvey),evaluation,765524083049968e8,599
"df_limesurvey %>% summarize_at(vars(9:161), mean, na.rm = TRUE) %>%      data.frame()",evaluation,765524083049968e8,599
"sub_data <- data[, 9:161]",data cleaning,765524083049968e8,599
library(reshape2),data cleaning,444781726459041e8,600
"source(""powerAnalysis/lib.R"")",data cleaning,444781726459041e8,600
"kGroundtruthPath <- ""powerAnalysis/data/simChrom_groundtruth.txt""",modeling,444781726459041e8,600
"kClusterPattern <- ""results/mcmc_clusters_powerAnalysis_chrom%02d.txt""",communication,444781726459041e8,600
kReplicates <- 1:10,communication,444781726459041e8,600
"kPathClusterPower <- ""powerAnalysis/output_cluster_power.RData""",modeling,444781726459041e8,600
library(rstan),setup,46707042097114e9,601
"save(salix_climate, file = ""analysis/data/salix_climate.Rdata"")",export,587102972902358e8,602
rstan_options(auto_write = TRUE),communication,46707042097114e9,601
options(mc.cores = parallel::detectCores()),evaluation,46707042097114e9,601
"save(salix_climate, file = ""analysis/data/salix_climate.Rdata"")",export,587102972902358e8,602
"load(""analysis/rdata-tmp/RoT-dat3.RData"")",import,46707042097114e9,601
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,46707042097114e9,601
"coad_counts <- coad_counts[, match(common_cghub_ids, names(coad_counts))]",data cleaning,587102972902358e8,602
"stopifnot(all.equal(colnames(coad), coad_clinical$CGHubAnalysisID))",data cleaning,587102972902358e8,602
coad_clinical_pd <- data.frame(coad_clinical),data cleaning,587102972902358e8,602
fits <- list(),not sure,46707042097114e9,601
rownames(coad_clinical_pd) <- coad_clinical_pd$CGHubAnalysisID,data cleaning,587102972902358e8,602
"sce <- newSCESet(tpmData = as.matrix(coad), countData = coad_counts,      phenoData = AnnotatedDataFrame(coad_clinical_pd))",exploratory,587102972902358e8,602
fData(sce)$gene_type <- gene_type,not sure,587102972902358e8,602
"for (i in stan.dat3$REstart:stan.dat3$REend) curdat <- list(priorSD = parameters$prior_sd,      NormalPrior = stan.dat3$NormalPrior, T = stan.dat3$T, t = stan.dat3$t,      n = stan.dat3$n, N = stan.dat3$N, REPoint = i)",modeling,46707042097114e9,601
summary(mod2),exploratory,206419600406662e8,603
"Anova(mod2, type = ""2"")",exploratory,206419600406662e8,603
"fits[[i]] <- stan(file = ""analysis/src-analysis/stan-models/binomial-reanalysis.stan"",      data = curdat, iter = parameters$iters, chains = parameters$nchains,      seed = parameters$seed)",modeling,46707042097114e9,601
"saveRDS(fits, file = ""analysis/mcmc-runs/ToRaising-Stan-Fit3.RDS"")",export,46707042097114e9,601
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""erep""]])",modeling,206419600406662e8,603
summary(mod2),exploratory,206419600406662e8,603
"Anova(mod2, type = ""2"")",exploratory,206419600406662e8,603
"mod2 = lm(data[[""Ka""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""Ka_pos""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""Ka_neg""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""alpha""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,206419600406662e8,603
"mod2 = lm(data[[""omega_A""]] ~ data[[""chr""]] + data[[""recombination""]] +      data[[""mutation""]] + data[[""expression""]] + data[[""breadth""]])",modeling,206419600406662e8,603
summary(mod2),exploratory,206419600406662e8,603
"Anova(mod2, type = ""2"")",exploratory,206419600406662e8,603
"colnames(nominal) <- c(""nominal"", ""common"")",data cleaning,61235105083324e9,604
"reg <- spid[-grep(""NOM."", spid$common_name), ]",data cleaning,61235105083324e9,604
"reg <- select(reg, SPID, common)",data cleaning,61235105083324e9,604
"colnames(reg) <- c(""reg"", ""common"")",data cleaning,61235105083324e9,604
"species.key <- merge(reg, nominal, by = ""common"", all.x = TRUE,      all.y = TRUE)",data cleaning,61235105083324e9,604
inds <- which(!is.na(species.key$nominal)),data cleaning,61235105083324e9,604
new_df <- filtered_ftl,data cleaning,61235105083324e9,604
new_df$modified <- NA,data cleaning,61235105083324e9,604
for (i in inds) new_df$modified[which(new_df$spid == species.key$nominal[i])] <- species.key$reg[i],data cleaning,61235105083324e9,604
cat(i),communication,61235105083324e9,604
"new_df$modified <- ifelse(is.na(new_df$modified), new_df$spid,      new_df$modified)",data cleaning,61235105083324e9,604
"saveRDS(new_df, file = ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-24/filtered_ftl_new.RDS"")",export,61235105083324e9,604
"save(model2, file = ""./analysis/wood_density_distribution/models/gls_models/model2.R"")",setup,913341281237081e8,605
"load(""./analysis/wood_density_distribution/bootstrapped/coef_CI_gls_wooddensity_VS_elevation.R"")",import,913341281237081e8,605
coef_CI,modeling,913341281237081e8,605
"booter(model2, data = wood_density_data_178ha, )",modeling,913341281237081e8,605
library(plyr),import,913341281237081e8,605
library(ggplot2),import,913341281237081e8,605
library(stringr),import,913341281237081e8,605
library(reshape2),import,913341281237081e8,605
library(yaml),import,913341281237081e8,605
summary(U2),exploratory,205722046550363e8,606
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",data cleaning,205722046550363e8,606
"write.csv(both, ""both.csv"", row.names = FALSE, quote = FALSE)",export,205722046550363e8,606
"bNOTg <- read.csv(""blog_not_graph.csv"", sep = "","")",import,205722046550363e8,606
d3 <- data.frame(bNOTg),data cleaning,205722046550363e8,606
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",data cleaning,205722046550363e8,606
genoIX = genoIX.list[ss],not sure,205722046550363e8,606
"path = paste0(locus.path, ""chr"", chr, "".loc"")",import,205722046550363e8,606
"loc_dat = read.table(path, as.is = TRUE)",import,205722046550363e8,606
"chrIX = loc_dat[site, 1]",setup,205722046550363e8,606
"locus.start = loc_dat[site, 2]",setup,205722046550363e8,606
"locus.end = loc_dat[site, 3] - 1",setup,205722046550363e8,606
"geno.info.path = paste0(geno.info.dir.path, ""maf_chr"", chr, ""."",      site, "".geno"")",import,205722046550363e8,606
"res = read.DNase.data(hdf5.data.path = hdf5.data.path, hdf5.mapp.path = hdf5.mapp.path,      geno.info.path = geno.info.path, inds.IDs = inds.IDs, chrIX = chrIX,      locus.start = locus.start, locus.end = locus.end)",import,205722046550363e8,606
phenoD = res$DNase.dat,setup,205722046550363e8,606
"geno.path = paste0(geno.dir.path, ""chr"", chr, ""."", site, "".geno"")",import,205722046550363e8,606
"genoF = read.table(geno.path, as.is = TRUE)",import,205722046550363e8,606
"genoD = genoF[genoIX, 4:73]",setup,205722046550363e8,606
genoR = as.numeric(round(genoD)),setup,205722046550363e8,606
wh0 = which(genoR == 0),data cleaning,205722046550363e8,606
wh1 = which(genoR == 1),data cleaning,205722046550363e8,606
"sig0 = apply(phenoD[wh0, ], 2, mean)",evaluation,205722046550363e8,606
"sig1 = apply(phenoD[wh1, ], 2, mean)",evaluation,205722046550363e8,606
library(wavethresh),setup,205722046550363e8,606
"sig.all = c(sig0, sig1)",setup,205722046550363e8,606
sig.all.smooth = BAYES.THR(sig.all),evaluation,205722046550363e8,606
sig0.smooth = sig.all.smooth[1:1024],setup,205722046550363e8,606
sig1.smooth = sig.all.smooth[1025:2048],setup,205722046550363e8,606
delix = which(abs(sig0.smooth - sig1.smooth) <= 1/70),data cleaning,205722046550363e8,606
sig1.smooth[delix] = sig0.smooth[delix],setup,205722046550363e8,606
wh.zero = which(sig0.smooth <= 1/70),data cleaning,205722046550363e8,606
if (length(wh.zero) > 0) sig0.smooth[wh.zero] = 1/70,data cleaning,205722046550363e8,606
wh.zero = which(sig1.smooth <= 1/70),data cleaning,205722046550363e8,606
if (length(wh.zero) > 0) sig1.smooth[wh.zero] = 1/70,data cleaning,205722046550363e8,606
smooth.ratio = sig1.smooth/sig0.smooth,modeling,205722046550363e8,606
map = res$mappability,not sure,205722046550363e8,606
xmin = locus.start,not sure,205722046550363e8,606
xmax = locus.end,not sure,205722046550363e8,606
xval = xmin:xmax,not sure,205722046550363e8,606
xval_mapp = xval[which(map == 1)],data cleaning,205722046550363e8,606
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,684626340633258e8,607
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,684626340633258e8,607
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,684626340633258e8,607
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,684626340633258e8,607
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,876944333082065e8,608
"quantModel2 <- rq(e ~ d, data = wood_density_data_178ha, tau = taus2)",modeling,876944333082065e8,608
"slopes <- quantModel2$coefficients[2, ]",modeling,876944333082065e8,608
"int <- quantModel2$coefficients[2, ]",modeling,876944333082065e8,608
"load(file = ""./analysis/wood_density_distribution/bootstrapped/CI_quantreg_slopes_n=5000.R"")",import,876944333082065e8,608
"taus_data <- data.frame(taus = taus2, slopes, int, CI025 = CI_slopes[1,      seq(2, 30, by = 2)], CI975 = CI_slopes[2, seq(2, 30, by = 2)])",evaluation,876944333082065e8,608
"p1 <- ggplot(taus_data, aes(x = taus, y = slopes)) + geom_errorbar(aes(ymin = CI025,      ymax = CI975), width = 0.025, color = ""grey"") + geom_point() +      theme_bw() + stat_smooth(size = 1, se = F, color = cols[5],      linetype = 2, method = ""loess"") + xlab(""Quantile"") + ylab(""Beta"") +      theme(text = element_text(size = 20))",visualization,876944333082065e8,608
p1,not sure,876944333082065e8,608
"ggsave(p1, file = ""./analysis/wood_density_distribution/graph_code/graphs/quantreg_slopes_graph.png"",      width = 6, height = 6)",export,876944333082065e8,608
"save(quantModel, file = ""./analysis/wood_density_distribution/models/quanreg_models/wooddensity_VS_elevation_quantreg.R"")",export,876944333082065e8,608
"quantModel2 <- rq(e ~ d, data = wood_density_data_178ha, tau = taus2)",modeling,876944333082065e8,608
"get_event_group <- function(event_locations_temp, event_group) return(sapply(1:ncol(event_locations_temp),      function(i) event_locations_temp[, i] %in% event_group))",data cleaning,876944333082065e8,608
"get_shared_all <- function(event_group) return((get_event_group(event_locations1,      event_group) & get_event_group(event_locations2, event_group)) &      get_event_group(event_locations3, event_group))",data cleaning,876944333082065e8,608
"get_shared_2 <- function(event_group) return((get_event_group(event_locations1,      event_group) + get_event_group(event_locations2, event_group) +      get_event_group(event_locations3, event_group)) >= 2)",data cleaning,876944333082065e8,608
"shared_all = lapply(list(c(2, 3, 1.5), -c(2, 3, 1.5), c(1, 3,      -1.5), -c(1, 3, -1.5)), function(i) get_shared_all(i))",data cleaning,876944333082065e8,608
"shared_2 = lapply(list(c(2, 3, 1.5), -c(2, 3, 1.5), c(1, 3, -1.5),      -c(1, 3, -1.5)), function(i) get_shared_2(i))",data cleaning,876944333082065e8,608
create_event_locations_shared <- function(shared_list) event_locations_shared = event_locations1 *      0,data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[1]], arr.ind = T)] = 2",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[2]], arr.ind = T)] = -2",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[3]], arr.ind = T)] = 1",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[4]], arr.ind = T)] = -1",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[1]] & shared_list[[3]],      arr.ind = T)] = 3",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[1]] & shared_list[[4]],      arr.ind = T)] = 1.5",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[2]] & shared_list[[4]],      arr.ind = T)] = -3",data cleaning,876944333082065e8,608
"event_locations_shared[which(shared_list[[2]] & shared_list[[3]],      arr.ind = T)] = -1.5",data cleaning,876944333082065e8,608
return(event_locations_shared),not sure,876944333082065e8,608
event_locations_shared_all = create_event_locations_shared(shared_all),not sure,876944333082065e8,608
event_locations_shared_2 = create_event_locations_shared(shared_2),not sure,876944333082065e8,608
"concurrent_events_all = find_concurrent_events(event_locations_shared_all,      2, event_types = c(-1, 1))",data cleaning,876944333082065e8,608
"concurrent_events_2 = find_concurrent_events(event_locations_shared_2,      2, event_types = c(-1, 1))",data cleaning,876944333082065e8,608
"pdf(""analysis/F_subtract/replicates/replicate_shared_events.pdf"",      width = 14, height = 14)",export,876944333082065e8,608
"make_visual(data_mat, event_locations_shared_all, concurrent_events_all,      log_colors = T, diverging = T)",visualization,876944333082065e8,608
"make_visual(data_mat, event_locations_shared_2, concurrent_events_2,      log_colors = T, diverging = T)",visualization,876944333082065e8,608
dev.off(),visualization,876944333082065e8,608
"event_locations1[20:30, 13]",exploratory,876944333082065e8,608
"event_locations2[20:30, 13]",exploratory,876944333082065e8,608
"event_locations3[20:30, 13]",exploratory,876944333082065e8,608
"print(paste(""Using URI: "", elf_statistics))",exploratory,876944333082065e8,608
region <- feature_ftype,not sure,876944333082065e8,608
XV <- xvar,not sure,876944333082065e8,608
YV <- yvar,not sure,876944333082065e8,608
"elf_statistics <- read.table(elf_statistics, header = TRUE, sep = "","")",import,876944333082065e8,608
"write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",      region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,      quote = TRUE)",export,876944333082065e8,608
return(elf_statistics),not sure,876944333082065e8,608
"silo3_9.clus <- cbind(names, silo3_9.clus)",exploratory,876944333082065e8,608
rownames(silo3_9.clus) <- NULL,import,876944333082065e8,608
"colnames(silo3_9.clus)[1] <- ""ID""",data cleaning,876944333082065e8,608
"colnames(silo3_9.clus)[2] <- ""Cluster""",data cleaning,876944333082065e8,608
"silo3_9.all <- merge(silo3_9.clus, silo3.9, by.x = ""ID"", by.y = ""row.names"")",data cleaning,876944333082065e8,608
library(ggthemes),setup,876944333082065e8,608
library(reshape),setup,876944333082065e8,608
library(ggplot2),setup,876944333082065e8,608
"melted_all_s3_9 <- melt(silo3_9.all, id.vars = c(""ID"", ""Cluster""))",data cleaning,876944333082065e8,608
"silo <- substr(melted_all_s3_9$ID, 0, 1)",data cleaning,876944333082065e8,608
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/lineplot-allprot.jpeg"",      width = 1000, height = 1000)",export,876944333082065e8,608
"ggplot(melted_all_s3_9, aes(x = variable, y = value, group = ID,      color = silo)) + geom_line(alpha = 0.8) + theme_bw() + facet_wrap(~Cluster,      scales = ""free_y"") + labs(x = ""Time Point"", y = ""Normalized Spectral Abundance Factor"")",visualization,876944333082065e8,608
dev.off(),visualization,876944333082065e8,608
silo3_9.edit <- silo3_9.all,not sure,876944333082065e8,608
"silo3_9.edit$Silo <- substr(silo3_9.edit$ID, 1, 1)",data cleaning,876944333082065e8,608
class(silo3_9.edit$ID),exploratory,876944333082065e8,608
silo3_9.edit$ID <- as.character(unlist(silo3_9.edit$ID)),data cleaning,876944333082065e8,608
"silo3_9.edit$ID <- substr(silo3_9.edit$ID, 3, nchar(silo3_9.edit$ID))",data cleaning,876944333082065e8,608
library(dplyr),setup,876944333082065e8,608
"silo3_9.edit <- silo3_9.edit %>% select(Silo, everything())",exploratory,876944333082065e8,608
"silo3_9.edit <- silo3_9.edit %>% select(Cluster, everything())",exploratory,876944333082065e8,608
"silo3_9.annot <- merge(silo3_9.edit, annotations, by.x = ""ID"",      by.y = ""Protein.ID"")",data cleaning,876944333082065e8,608
"write.csv(silo3_9.annot, file = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/all-prot-anno.csv"",      row.names = FALSE)",export,876944333082065e8,608
library(data.table),import,876944333082065e8,608
"unique.prot <- silo3_9.edit[!(duplicated(silo3_9.edit[c(""ID"",      ""Cluster"")]) | duplicated(silo3_9.edit[c(""ID"", ""Cluster"")],      fromLast = TRUE)), ]",data cleaning,876944333082065e8,608
"anyDuplicated(silo3_9.edit[, c(""ID"", ""Cluster"")])",data cleaning,876944333082065e8,608
"anyDuplicated(unique.prot[, c(""ID"", ""Cluster"")])",data cleaning,876944333082065e8,608
"final.unique.prot <- merge(unique.prot, annotations, by.x = ""ID"",      by.y = ""Protein.ID"")",data cleaning,876944333082065e8,608
"sum(final.unique.prot$Silo == ""3"")",exploratory,876944333082065e8,608
"sum(final.unique.prot$Silo == ""9"")",exploratory,876944333082065e8,608
"write.csv(final.unique.prot, file = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/unq-prot-anno.csv"",      row.names = FALSE)",export,876944333082065e8,608
plot.unq <- unique.prot,not sure,876944333082065e8,608
"plot.unq$S.ID <- paste(plot.unq$Silo, plot.unq$ID, sep = ""_"")",not sure,876944333082065e8,608
"plot.unq <- plot.unq[, -c(2:3)]",not sure,876944333082065e8,608
"unq_melted_all_s3_9 <- melt(plot.unq, id.vars = c(""S.ID"", ""Cluster""))",data cleaning,876944333082065e8,608
"silo <- substr(unq_melted_all_s3_9$S.ID, 0, 1)",data cleaning,876944333082065e8,608
"jpeg(filename = ""Documents/robertslab/labnotebook/analysis/clustering/silo3_9-NSAF/techreps-avgs/silo3and9_nozerovals_AVGs/lineplots-unq-prot.jpeg"",      width = 1000, height = 1000)",export,876944333082065e8,608
"ggplot(unq_melted_all_s3_9, aes(x = variable, y = value, group = S.ID,      color = silo)) + geom_line(alpha = 0.8) + theme_bw() + facet_wrap(~Cluster,      scales = ""free_y"") + labs(x = ""Time Point"", y = ""Normalized Spectral Abundance Factor"")",visualization,876944333082065e8,608
dev.off(),visualization,876944333082065e8,608
"annotations <- read.csv(""Documents/robertslab/labnotebook/data/allsilos-tag_and_annot.csv"")",import,876944333082065e8,608
"annotations <- annotations[, c(1, 63)]",data cleaning,876944333082065e8,608
"annotations$Protein.ID <- sub(""\\|"", ""."", annotations$Protein.ID)",data cleaning,876944333082065e8,608
"unq.anno <- merge(unique.prot, annotations, by.x = ""ID"", by.y = ""Protein.ID"")",data cleaning,876944333082065e8,608
"write.csv(unq.anno, ""Documents/robertslab/labnotebook/analysis/clustering/NSAF-s3s9/unqprot-travg-anno.csv"")",export,876944333082065e8,608
library(dplyr),setup,876944333082065e8,608
"count(unq.anno, Entry)",exploratory,876944333082065e8,608
"silo3_9.clus <- cbind(names, silo3_9.clus)",data cleaning,876944333082065e8,608
box(),visualization,876944333082065e8,608
dev.off(),visualization,876944333082065e8,608
drive_analysis(analyzer),setup,876944333082065e8,608
main(),setup,876944333082065e8,608
warnings(),setup,876944333082065e8,608
"par(mfrow = c(2, 1))",visualization,876944333082065e8,608
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
filter.cut = 20,not sure,876944333082065e8,608
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,876944333082065e8,608
xmax = 1,not sure,876944333082065e8,608
xmin = 0,not sure,876944333082065e8,608
"par(mfrow = c(2, 1))",visualization,876944333082065e8,608
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
filter.cut = 30,visualization,876944333082065e8,608
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,876944333082065e8,608
xmax = 1,visualization,876944333082065e8,608
xmin = 0,visualization,876944333082065e8,608
"par(mfrow = c(2, 1))",visualization,876944333082065e8,608
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
filter.cut = 60,visualization,876944333082065e8,608
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",data cleaning,876944333082065e8,608
"source(""C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\NOAA_Shrimp_ELB_Analysis\\Analysis\\ResultsFigures\\Figure5.R"")",import,205691221635789e8,609
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,876944333082065e8,608
xmax = 1,visualization,876944333082065e8,608
xmin = 0,visualization,876944333082065e8,608
"par(mfrow = c(2, 1))",visualization,876944333082065e8,608
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,876944333082065e8,608
dev.off(),visualization,876944333082065e8,608
"library(""qvalue"")",import,876944333082065e8,608
siteSize = 2048,not sure,876944333082065e8,608
"treatment = ""Copper""",not sure,876944333082065e8,608
"strand = ""both""",not sure,876944333082065e8,608
window.size = 300,visualization,876944333082065e8,608
sessionInfo(),communication,205691221635789e8,609
numSam = 6,not sure,876944333082065e8,608
"all.name = paste0(treatment, ""."", siteSize, ""."", strand)",communication,876944333082065e8,608
tpr.wave = NULL,not sure,205691221635789e8,609
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.pval.discrete.Robj"")",communication,876944333082065e8,608
fpr.wave = NULL,not sure,205691221635789e8,609
load(out.path),import,876944333082065e8,608
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/pval.ms.wave."",      all.name, "".Robj"")",communication,876944333082065e8,608
load(input.path),import,876944333082065e8,608
uni.p.wave = unique(p.wave),data cleaning,205691221635789e8,609
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,876944333082065e8,608
"pdf(""FDR.DESeq2.discrete.pdf"")",export,876944333082065e8,608
filter.cut = 0,visualization,876944333082065e8,608
pval.deseq = pval.deseq.3.0,modeling,876944333082065e8,608
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",data cleaning,876944333082065e8,608
qval.wave = qvalue(pval.wave[-del.ix.deseq]),modeling,876944333082065e8,608
qval.ms = qvalue(pval.ms[-del.ix.deseq]),modeling,876944333082065e8,608
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),evaluation,876944333082065e8,608
qval.wave$pi0,evaluation,876944333082065e8,608
qval.ms$pi0,evaluation,876944333082065e8,608
qval.deseq$pi0,evaluation,876944333082065e8,608
"alpha.list = seq(0, 0.2, by = 0.01)",evaluation,876944333082065e8,608
length(alpha.list),evaluation,876944333082065e8,608
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",evaluation,876944333082065e8,608
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),evaluation,876944333082065e8,608
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),evaluation,876944333082065e8,608
num.deseq[i] = sum(qval.deseq$qvalues < alpha.list[i]),evaluation,876944333082065e8,608
num.wave = num.wave/length(qval.wave$qvalues),evaluation,876944333082065e8,608
num.ms = num.ms/length(qval.wave$qvalues),evaluation,876944333082065e8,608
num.deseq = num.deseq/length(qval.wave$qvalues),data cleaning,876944333082065e8,608
"ymax = max(num.wave, num.ms, num.deseq)",visualization,876944333082065e8,608
ymin = 0,visualization,876944333082065e8,608
"plot(alpha.list, num.ms, ylim = c(ymin, ymax), col = ""red"", type = ""l"",      main = paste0(""filter : "", filter.cut), xlab = ""FDR"", ylab = ""number of significant tests"")",visualization,876944333082065e8,608
"points(alpha.list, num.wave, ylim = c(ymin, ymax), col = ""blue"",      type = ""l"")",visualization,876944333082065e8,608
"points(alpha.list, num.deseq, ylim = c(ymin, ymax), col = ""darkgreen"",      type = ""l"")",visualization,876944333082065e8,608
"legend(0.01, ymax * 0.99, c(""multiseq"", ""WaveQTL"", ""DESeq""),      col = c(""red"", ""blue"", ""darkgreen""), lty = c(1, 1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,876944333082065e8,608
filter.cut = 10,visualization,876944333082065e8,608
pval.deseq = pval.deseq.3.10,evaluation,876944333082065e8,608
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",evaluation,876944333082065e8,608
qval.wave = qvalue(pval.wave[-del.ix.deseq]),evaluation,876944333082065e8,608
qval.ms = qvalue(pval.ms[-del.ix.deseq]),evaluation,876944333082065e8,608
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),evaluation,876944333082065e8,608
qval.wave$pi0,modeling,876944333082065e8,608
qval.ms$pi0,modeling,876944333082065e8,608
qval.deseq$pi0,modeling,876944333082065e8,608
"alpha.list = seq(0, 0.2, by = 0.01)",modeling,876944333082065e8,608
length(alpha.list),modeling,876944333082065e8,608
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",modeling,876944333082065e8,608
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),modeling,876944333082065e8,608
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),modeling,876944333082065e8,608
num.deseq[i] = sum(qval.deseq$qvalues < alpha.list[i]),modeling,876944333082065e8,608
num.wave = num.wave/length(qval.wave$qvalues),modeling,876944333082065e8,608
num.ms = num.ms/length(qval.wave$qvalues),modeling,876944333082065e8,608
num.deseq = num.deseq/length(qval.wave$qvalues),modeling,876944333082065e8,608
"ymax = max(num.wave, num.ms, num.deseq)",modeling,876944333082065e8,608
ymin = 0,visualization,876944333082065e8,608
"plot(alpha.list, num.ms, ylim = c(ymin, ymax), col = ""red"", type = ""l"",      main = paste0(""filter : "", filter.cut), xlab = ""FDR"", ylab = ""number of significant tests"")",visualization,876944333082065e8,608
"points(alpha.list, num.wave, ylim = c(ymin, ymax), col = ""blue"",      type = ""l"")",visualization,876944333082065e8,608
"points(alpha.list, num.deseq, ylim = c(ymin, ymax), col = ""darkgreen"",      type = ""l"")",visualization,876944333082065e8,608
"legend(0.01, ymax * 0.99, c(""multiseq"", ""WaveQTL"", ""DESeq""),      col = c(""red"", ""blue"", ""darkgreen""), lty = c(1, 1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,876944333082065e8,608
filter.cut = 20,visualization,876944333082065e8,608
pval.deseq = pval.deseq.3.20,visualization,876944333082065e8,608
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",evaluation,876944333082065e8,608
qval.wave = qvalue(pval.wave[-del.ix.deseq]),evaluation,876944333082065e8,608
qval.ms = qvalue(pval.ms[-del.ix.deseq]),modeling,876944333082065e8,608
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),modeling,876944333082065e8,608
qval.wave$pi0,modeling,876944333082065e8,608
qval.ms$pi0,modeling,876944333082065e8,608
rnk.ms = order(pval.ms),visualization,601721487473696e8,610
p.ms = pval.ms[rnk.ms],not sure,601721487473696e8,610
d.ms = disc.ms[rnk.ms],not sure,601721487473696e8,610
fdp.ms = NULL,import,601721487473696e8,610
sig.ms = NULL,import,601721487473696e8,610
tpr.ms = NULL,import,601721487473696e8,610
fpr.ms = NULL,import,601721487473696e8,610
uni.p.ms = unique(p.ms),data cleaning,601721487473696e8,610
for (i in 1:length(uni.p.ms)) wh = which(p.ms <= uni.p.ms[i]),evaluation,601721487473696e8,610
sig.ms[i] = length(wh),evaluation,601721487473696e8,610
fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh)),exploratory,601721487473696e8,610
tpr.ms[i] = sum(d.ms[wh])/574,exploratory,601721487473696e8,610
fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/574,exploratory,601721487473696e8,610
given.FDR = 0.05,exploratory,601721487473696e8,610
posi = max(which(fdp.ms <= given.FDR)),exploratory,601721487473696e8,610
tpr.ms[posi],exploratory,601721487473696e8,610
fdp.ms[posi],exploratory,601721487473696e8,610
fpr.ms.1000 = fpr.ms,exploratory,601721487473696e8,610
tpr.ms.1000 = tpr.ms,exploratory,601721487473696e8,610
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",exploratory,601721487473696e8,610
"disc.ms = c(rep(0, 574), rep(1, 574))",import,601721487473696e8,610
rank.ms = rank(pval.ms),exploratory,601721487473696e8,610
rank.ms.1000 = rank.ms,exploratory,601721487473696e8,610
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/null/multiscale/sum_10000/pval.Robj"")",setup,601721487473696e8,610
pval.null.ms = as.numeric(pval_list),exploratory,601721487473696e8,610
done.null.ms = done_res,exploratory,601721487473696e8,610
sum(done.null.ms),exploratory,601721487473696e8,610
"max(pval.null.ms, na.rm = TRUE)",exploratory,601721487473696e8,610
"min(pval.null.ms, na.rm = TRUE)",exploratory,601721487473696e8,610
"load(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_578/alt/multiscale/sum_10000/pval.Robj"")",import,601721487473696e8,610
pval.alt.ms = as.numeric(pval_list),exploratory,601721487473696e8,610
done.alt.ms = done_res,exploratory,601721487473696e8,610
sum(done.alt.ms),exploratory,601721487473696e8,610
"max(pval.alt.ms, na.rm = TRUE)",exploratory,601721487473696e8,610
"min(pval.alt.ms, na.rm = TRUE)",exploratory,601721487473696e8,610
"delIX = c(305, 368, 451, 464)",exploratory,601721487473696e8,610
pval.null.ms = pval.null.ms[-delIX],exploratory,601721487473696e8,610
pval.alt.ms = pval.alt.ms[-delIX],exploratory,601721487473696e8,610
"pval.ms = as.numeric(c(pval.null.ms, pval.alt.ms))",exploratory,601721487473696e8,610
"disc.ms = c(rep(0, 574), rep(1, 574))",exploratory,601721487473696e8,610
"latex_analyses <- function(analyses) relative_count_size <- analyses$object_count_size %>%      group_by(group_type) %>% summarize(relative_size = sum(relative_size),      relative_count = sum(relative_count))",not sure,256637755781412e8,611
"count_size <- analyses$object_count_size %>% group_by(group_type) %>%      summarize(size = sum(size), count = sum(count))",evaluation,256637755781412e8,611
"p <- ggplot(df, aes(x = ideology_dist, y = adjusted_alignment_score)) +      stat_binhex(bins = 80) + xlab(""Ideological Distance"") + ylab(""Alignment Score"") +      scale_fill_gradient(low = cbPalette[1], high = cbPalette[2],          trans = ""log"", labels = c(""1"", ""60"", ""3,000"", ""160,000"",              ""9,000,000"")) + guides(fill = guide_legend(title = ""Count"")) +      plot_theme",visualization,417187191778794e8,612
"cat(""Saving plot...\n"")",export,417187191778794e8,612
"ggsave(plot = p, ""../../paper/figures/ideology_plot.png"", width = p_width,      height = 0.65 * p_width)",export,417187191778794e8,612
"p <- p + scale_y_log10() + ylab(""Log Alignment Score"")",visualization,417187191778794e8,612
"cat(""Saving plot...\n"")",export,417187191778794e8,612
"ggsave(plot = p, ""../../paper/figures/ideology_plot_log.png"",      width = p_width, height = 0.65 * p_width)",export,417187191778794e8,612
coef[1] + coef[2] * 1.96,evaluation,417187191778794e8,612
coef[1] - coef[2] * 1.96,evaluation,417187191778794e8,612
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_hosts.rda""))",import,417187191778794e8,612
"load(file = getwd() %>% paste0(""/analysis/data/rdata/ucas_applicants.rda""))",import,417187191778794e8,612
computer_subjects <- c(),setup,417187191778794e8,612
for (subject in ucas_applicants$`Subject Group (Detailed Level)` %>%      unique()) lowerSubject <- subject %>% tolower(),data cleaning,417187191778794e8,612
"if ((grepl(""compu"", lowerSubject) || grepl(""cyber"", lowerSubject) ||      grepl(""engineer"", lowerSubject) || grepl(""software"", lowerSubject)) &&      (!grepl(""comb"", lowerSubject) & !grepl(""other"", lowerSubject) &          !grepl(""any"", lowerSubject) & !grepl(""general"", lowerSubject) &          !grepl(""audio"", lowerSubject) & !grepl(""aerospace"", lowerSubject) &          !grepl(""civil"", lowerSubject) & !grepl(""mechanical"",          lowerSubject) & !grepl(""manufact"", lowerSubject) & !grepl(""chemical"",          lowerSubject))) computer_subjects %<>% append(subject)",data cleaning,417187191778794e8,612
"filters <- list(subjects = computer_subjects, applicationRoute = ""'Insurance choice'"",      domicile = ""'Northern Ireland'"")",setup,417187191778794e8,612
ucas_data <- ucas_applicants %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Applicant Domicile (High Level)` == filters$domicile),data cleaning,417187191778794e8,612
hostEntrants <- ucas_hosts %>% subset(`Subject Group (Detailed Level)` %in%      filters$subject) %>% subset(`Acceptance Route` %in% filters$applicationRoute) %>%      subset(`Provider Country` == filters$domicile),exploratory,417187191778794e8,612
allYears <- ucas_data$`Cycle Year` %>% unique(),exploratory,417187191778794e8,612
totalYears <- totalHostYears <- c(),exploratory,417187191778794e8,612
library(survival),modeling,40833585569635e9,613
library(dplyr),modeling,40833585569635e9,613
library(OIsurv),modeling,40833585569635e9,613
library(ranger),modeling,40833585569635e9,613
library(ggplot2),visualization,40833585569635e9,613
t1 <- Sys.time(),evaluation,40833585569635e9,613
library(tidyverse),setup,821920445654541e8,614
library(adegenet),setup,821920445654541e8,614
library(ReproWorkshop),setup,821920445654541e8,614
data(ReproWorkshop),setup,821920445654541e8,614
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,777953486423939e8,615
"prop.table(table(xdata$ShapeResponse, xdata$PinkieCurl), 2) %>%      round(2)",setup,777953486423939e8,615
"prop.table(table(xdata$HeightResponse, xdata$PinkieCurl), 2) %>%      round(2)",setup,777953486423939e8,615
x <- table(xdata$ShapeResponse),setup,777953486423939e8,615
y <- table(xdata$HeightResponse),setup,777953486423939e8,615
"(xtab <- rbind(x, y))",setup,777953486423939e8,615
chisq.test(xtab),exploratory,777953486423939e8,615
"xmdl.shape <- glm(ShapeNum ~ PinkieCurl, xdata, family = ""binomial"")",modeling,777953486423939e8,615
library(ggplot2),setup,149872896028683e8,126
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,149872896028683e8,126
"d <- read.csv(""Analysis/Parsed Data/pilots_eyetracking.csv"")",import,149872896028683e8,126
"fixmap = ggplot(d, aes(x = leftX, y = leftY)) + geom_point(alpha = 0.25)",visualization,149872896028683e8,126
"ggsave(""Analysis/Plots/fixmap_full.png"")",export,149872896028683e8,126
"fixmap_zoom = ggplot(d, aes(x = leftX, y = leftY)) + geom_point(alpha = 0.25) +      coord_cartesian(xlim = c(0, 1500), ylim = c(0, 1000))",visualization,149872896028683e8,126
"ggsave(""Analysis/Plots/fixmap_zoom.png"")",export,149872896028683e8,126
"fixmap_aoi = ggplot(d, aes(x = leftX, y = leftY)) + geom_point(alpha = 0.25) +      coord_cartesian(xlim = c(0, 1250), ylim = c(0, 1000)) + geom_vline(xintercept = 175,      color = ""blue"") + geom_vline(xintercept = 375, color = ""blue"") +      geom_vline(xintercept = 575, color = ""blue"") + geom_vline(xintercept = 775,      color = ""blue"") + geom_vline(xintercept = 975, color = ""blue"") +      geom_vline(xintercept = 1175, color = ""blue"") + geom_hline(yintercept = 225,      color = ""blue"") + geom_hline(yintercept = 425, color = ""blue"") +      geom_hline(yintercept = 625, color = ""blue"") + geom_hline(yintercept = 825,      color = ""blue"") + geom_hline(yintercept = 1025, color = ""blue"") +      geom_hline(yintercept = 1225, color = ""blue"")",visualization,149872896028683e8,126
"ggsave(""Analysis/Plots/fixmap_aoi.png"")",export,149872896028683e8,126
"d2 <- d %>% filter(trialType != ""filler"")",data cleaning,149872896028683e8,126
"filter(choiceCorrect == 1) %>% mutate(AOI = ifelse(leftX >= 375 &      leftX <= 575 & leftY >= 825 & leftY <= 1025, 1, ifelse(leftX >=      775 & leftX <= 975 & leftY >= 825 & leftY <= 1025, 2, ifelse(leftX >=      375 & leftX <= 575 & leftY >= 425 & leftY <= 625, 3, ifelse(leftX >=      775 & leftX <= 975 & leftY >= 425 & leftY <= 625, 4, NA))))) %>%      mutate(TargetFix = ifelse(AOI == 1 & pictype1 == ""target"",          1, ifelse(AOI == 2 & pictype2 == ""target"", 1, ifelse(AOI ==              3 & pictype3 == ""target"", 1, ifelse(AOI == 4 & pictype4 ==              ""target"", 1, 0))))) %>% mutate(CompFix = ifelse(AOI ==      1 & pictype1 == ""competitor"", 1, ifelse(AOI == 2 & pictype2 ==      ""competitor"", 1, ifelse(AOI == 3 & pictype3 == ""competitor"",      1, ifelse(AOI == 4 & pictype4 == ""competitor"", 1, 0))))) %>%      mutate(ConFix = ifelse(AOI == 1 & pictype1 == ""contrast"",          1, ifelse(AOI == 2 & pictype2 == ""contrast"", 1, ifelse(AOI ==              3 & pictype3 == ""contrast"", 1, ifelse(AOI == 4 &              pictype4 == ""contrast"", 1, 0))))) %>% mutate(RelAdj = trialStart -      (audioStart + adjOnset))",data cleaning,149872896028683e8,126
library(ggplot2),setup,149872896028683e8,126
if (length(wh.zero) > 0) sig1[wh.zero] = 1/70,data cleaning,149872896028683e8,126
library(wavethresh),setup,149872896028683e8,126
w.sig0 = wd(sig0),data cleaning,149872896028683e8,126
w.sig0.smooth = threshold(w.sig0),data cleaning,149872896028683e8,126
sig0.smooth = wr(w.sig0.smooth),data cleaning,149872896028683e8,126
w.sig1 = wd(sig1),data cleaning,149872896028683e8,126
w.sig1.smooth = threshold(w.sig1),data cleaning,149872896028683e8,126
sig1.smooth = wr(w.sig1.smooth),data cleaning,149872896028683e8,126
wh.zero = which(sig0.smooth <= 1/70),data cleaning,149872896028683e8,126
if (length(wh.zero) > 0) sig0.smooth[wh.zero] = 1/70,data cleaning,149872896028683e8,126
wh.zero = which(sig1.smooth <= 1/70),data cleaning,149872896028683e8,126
if (length(wh.zero) > 0) sig1.smooth[wh.zero] = 1/70,data cleaning,149872896028683e8,126
smooth.ratio = sig1.smooth/sig0.smooth,modeling,149872896028683e8,126
map = res$mappability,evaluation,149872896028683e8,126
xmin = locus.start,setup,149872896028683e8,126
xmax = locus.end,setup,149872896028683e8,126
xval = xmin:xmax,setup,149872896028683e8,126
xval_mapp = xval[which(map == 1)],setup,149872896028683e8,126
"nf <- layout(matrix(1:5, 5, 1, byrow = TRUE))",visualization,149872896028683e8,126
"ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)",visualization,149872896028683e8,126
"par(mar = c(3, 3, 1, 1))",visualization,149872896028683e8,126
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,      xmax), ylim = c(0, ymax), axes = FALSE, main = ""Major Homozygotes"")",visualization,149872896028683e8,126
"axis(1, at = xval_mapp, labels = xval_mapp)",visualization,149872896028683e8,126
"lines(xval, sig0, type = ""l"", col = ""orange"")",visualization,149872896028683e8,126
"lines(xval, sig0.smooth, type = ""l"", col = ""red"")",visualization,149872896028683e8,126
"axis(2, font = 2)",visualization,149872896028683e8,126
box(),visualization,149872896028683e8,126
"ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)",visualization,149872896028683e8,126
"par(mar = c(3, 3, 1, 1))",visualization,149872896028683e8,126
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,      xmax), ylim = c(0, ymax), axes = FALSE, main = ""Heterozygotes"")",visualization,149872896028683e8,126
"axis(1, at = xval_mapp, labels = xval_mapp)",visualization,149872896028683e8,126
"lines(xval, sig1, type = ""l"", col = ""skyblue"")",visualization,149872896028683e8,126
"lines(xval, sig1.smooth, type = ""l"", col = ""blue"")",visualization,149872896028683e8,126
"axis(2, font = 2)",visualization,149872896028683e8,126
box(),visualization,149872896028683e8,126
"ymax = max(sig0, sig0.smooth, sig1, sig1.smooth)",visualization,149872896028683e8,126
"par(mar = c(3, 3, 1, 1))",visualization,149872896028683e8,126
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,      xmax), ylim = c(0, ymax), axes = FALSE, main = """")",visualization,149872896028683e8,126
"axis(1, at = xval_mapp, labels = xval_mapp)",visualization,149872896028683e8,126
"lines(xval, sig0.smooth, type = ""l"", col = ""red"")",visualization,149872896028683e8,126
"lines(xval, sig1.smooth, type = ""l"", col = ""blue"")",visualization,149872896028683e8,126
"axis(2, font = 2)",visualization,149872896028683e8,126
box(),visualization,149872896028683e8,126
ymax = max(sig0.smooth - sig1.smooth),visualization,149872896028683e8,126
ymin = min(sig0.smooth - sig1.smooth),visualization,149872896028683e8,126
"par(mar = c(3, 3, 1, 1))",visualization,149872896028683e8,126
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,      xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""Major Homozygotes - Heterozygotes"")",visualization,149872896028683e8,126
"axis(1, at = xval_mapp, labels = xval_mapp)",visualization,149872896028683e8,126
"lines(xval, sig0.smooth - sig1.smooth, type = ""l"", col = ""darkgreen"")",visualization,149872896028683e8,126
abline(h = 0),visualization,149872896028683e8,126
"axis(2, font = 2)",visualization,149872896028683e8,126
box(),visualization,149872896028683e8,126
ymax = max(log(sig0.smooth) - log(sig1.smooth)),visualization,149872896028683e8,126
ymin = min(log(sig0.smooth) - log(sig1.smooth)),visualization,149872896028683e8,126
"par(mar = c(3, 3, 1, 1))",visualization,149872896028683e8,126
"plot(1, 1, type = ""n"", xlab = ""position"", ylab = """", xlim = c(xmin,      xmax), ylim = c(ymin, ymax), axes = FALSE, main = ""log(Major Homozygotes) - log(Heterozygotes)"")",visualization,149872896028683e8,126
"axis(1, at = xval_mapp, labels = xval_mapp)",visualization,149872896028683e8,126
"lines(xval, log(sig0.smooth) - log(sig1.smooth), type = ""l"",      col = ""darkgreen"")",visualization,149872896028683e8,126
abline(h = 0),visualization,149872896028683e8,126
"axis(2, font = 2)",visualization,149872896028683e8,126
box(),visualization,149872896028683e8,126
dev.off(),visualization,149872896028683e8,126
library(dplyr),setup,363418939523399e8,616
library(lubridate),setup,363418939523399e8,616
"cc <- read.csv(""data-raw/COMU_condition_june2018.csv"", header = T,      as.is = T)",import,363418939523399e8,616
"cc <- subset(cc, rec != """")",data cleaning,363418939523399e8,616
cc$year <- as.numeric(cc$year),data cleaning,363418939523399e8,616
"cc <- subset(cc, colony == ""Funk"")",data cleaning,363418939523399e8,616
"cc <- subset(cc, species == ""COMU"")",data cleaning,363418939523399e8,616
cc$dates <- dmy(cc$date),data cleaning,363418939523399e8,616
"setwd(""c:/Users/ATE/thesisDoc"")",setup,841981243574992e8,617
"tikzDevice::tikz(file = ""figures/p.analysis.merton.hedge.deltas.tex"",      width = 4.5, height = 3.2)",export,841981243574992e8,617
"grid.arrange(p1, p2, p3, p4, p5)",visualization,841981243574992e8,617
dev.off(),visualization,841981243574992e8,617
"Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))",data cleaning,199204075615853e8,618
"genesInTerm <- sapply(goIDs, function(x) paste(CC.genes[[which(names(CC.genes) ==      x)]], collapse = "",""))",data cleaning,199204075615853e8,618
"DEGenesInTerm <- sapply(goIDs, function(x) paste(intersect(CC.genes[[which(names(CC.genes) ==      x)]], DEgeneNam1), collapse = "",""))",data cleaning,199204075615853e8,618
"aDF <- data.frame(Term, genesInTerm, DEGenesInTerm)",data cleaning,199204075615853e8,618
"bDF <- cbind(CC.Fisher.elim.Table, aDF)",data cleaning,199204075615853e8,618
"write.csv(bDF, paste0(results, ""media_pathway_analysis_CC.csv""))",export,199204075615853e8,618
"Term <- unlist(lapply(goIDs, function(x) (Term(x)[[1]])))",data cleaning,199204075615853e8,618
"saveRDS(ARI, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-10/3_analyzeMetiers/adjustRandIndex.RDS"")",export,199204075615853e8,618
"for (k in 1:ncol(prior4b1)) prior_b = function(b) dlnorm(b, meanlog = as.numeric(prior4b1[1,      k]), sdlog = as.numeric(prior4b1[2, k]), log = TRUE)",modeling,199204075615853e8,618
"mclapply(1:chains, FUN = function(xxx) pbd_Bayes(brts = branches[[k]],      initparsopt = rep(xxx, 4), prior_b = prior_b, prior_mu1 = prior_mu1,      prior_la1 = prior_la1, prior_mu2 = prior_mu2, step = 0.7,      rep = rep, file = paste0(files[i], ""_region_"", paste(b1names[[k]],          collapse = ""_""), ""."", xxx)), mc.cores = cores)",modeling,199204075615853e8,618
colnames(mat) <- mets,data cleaning,199204075615853e8,618
rownames(mat) <- mets,data cleaning,199204075615853e8,618
"for (i in 1:nrow(mat)) cat(i, "":\n"")",exploratory,199204075615853e8,618
for (j in i:ncol(mat)) sub_i <- tickets$veid[which(tickets$metier ==      rownames(mat)[i])],data cleaning,199204075615853e8,618
sub_j <- tickets$veid[which(tickets$metier == colnames(mat)[j])],data cleaning,199204075615853e8,618
"mat[i, j] <- length(union(sub_i, sub_j))",data cleaning,199204075615853e8,618
"cat(j, "" "")",exploratory,199204075615853e8,618
"cat(""\n"")",exploratory,199204075615853e8,618
"g2 <- graph.adjacency(mat, weighted = TRUE, mode = ""undirected"",      diag = FALSE)",modeling,199204075615853e8,618
V(g2)$size <- diag(mat),modeling,199204075615853e8,618
"plot(g2, edge.width = log(E(g2)$weight)/10, layout = layout.fruchterman.reingold,      vertex.size = 5)",visualization,199204075615853e8,618
"port_popularity <- ddply(tickets, .(pcid), summarize, num_Ves = length(unique(veid)))",data cleaning,199204075615853e8,618
"port_popularity <- port_popularity[order(port_popularity$num_Ves,      decreasing = T), ]",data cleaning,199204075615853e8,618
"gs09NEW <- define_participationPlot(2009, ""NEW"")",visualization,199204075615853e8,618
"gs09COS <- define_participationPlot(2009, ""COS"")",visualization,199204075615853e8,618
"gs09AST <- define_participationPlot(2009, ""AST"")",visualization,199204075615853e8,618
"gs09SF <- define_participationPlot(2009, ""SF"")",visualization,199204075615853e8,618
"gs09BFG <- define_participationPlot(2009, ""BRG"")",visualization,199204075615853e8,618
"gs09WPT <- define_participationPlot(2009, ""WPT"")",visualization,199204075615853e8,618
"gs09LWC <- define_participationPlot(2009, ""LWC"")",visualization,199204075615853e8,618
"gs09BDG <- define_participationPlot(2009, ""BDG"")",visualization,199204075615853e8,618
"gs09PRN <- define_participationPlot(2009, ""PRN"")",visualization,199204075615853e8,618
"gs09TLL <- define_participationPlot(2009, ""TLL"")",visualization,199204075615853e8,618
"top_ports <- list(gs09NEW, gs09COS, gs09AST, gs09SF, gs09BFG,      gs09WPT, gs09LWC, gs09BDG, gs09PRN, gs09TLL)",data cleaning,199204075615853e8,618
"saveRDS(top_ports, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/top_ports.RDS"")",export,199204075615853e8,618
"names(top_ports) = c(""newport"", ""coos bay"", ""astoria"", ""san francisco"",      ""bfg"", ""westport"", ""illawco"", ""bdg"", ""princeton"", ""tll"")",data cleaning,199204075615853e8,618
"degree <- lapply(top_ports, degree)",data cleaning,199204075615853e8,618
degree <- melt(unlist(degree)),data cleaning,199204075615853e8,618
"degree$metier <- str_sub(rownames(degree), start = -7)",data cleaning,199204075615853e8,618
"degree$metier <- gsub(pattern = ""[.]"", replacement = """", x = degree$metier)",data cleaning,199204075615853e8,618
"colnames(degree) <- c(""degree"", ""metier"")",data cleaning,199204075615853e8,618
"degree$ggplot(degree, aes(x = degree, fill = factor(metier))) +      geom_density(alpha = 0.3) + theme_minimal()",visualization,199204075615853e8,618
counting <- as.data.frame(table(degree$metier)),data cleaning,199204075615853e8,618
"paint <- colorRampPalette(brewer.pal(8, ""Spectral""))(max(counting$Freq))",visualization,199204075615853e8,618
counting$color <- paint[counting$Freq],data cleaning,199204075615853e8,618
"meds <- with(degree, reorder(metier, -degree, fun = median))",data cleaning,199204075615853e8,618
by_row <- data.frame(meds = levels(meds)),data cleaning,199204075615853e8,618
"coloring <- merge(by_row, counting[, c(""Var1"", ""color"")], by.x = ""meds"",      by.y = ""Var1"", sort = F)",visualization,199204075615853e8,618
"ggplot(degree, aes(y = degree, x = reorder(metier, -degree, fun = median))) +      geom_boxplot(fill = coloring$color, colour = coloring$color) +      theme_minimal() + xlab(""metier"") + theme(axis.text.x = element_text(angle = 45,      hjust = 1))",visualization,199204075615853e8,618
"saveRDS(degree, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/degree.RDS"")",export,199204075615853e8,618
"saveRDS(coloring, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/coloring.RDS"")",export,199204075615853e8,618
"trl <- subset(tickets, metier %in% c(""TWS_12"", ""TWL_12""))",data cleaning,199204075615853e8,618
"trl$date <- paste(trl$year, trl$month, trl$day, sep = ""-"")",data cleaning,199204075615853e8,618
"by_day <- ddply(trl, .(date, metier), summarize, trips = length(unique(trip_id)))",data cleaning,199204075615853e8,618
by_day$date <- as.POSIXlt(by_day$date),data cleaning,199204075615853e8,618
"ggplot(by_day, aes(x = date, y = trips, group = metier, color = metier)) +      geom_bar(stat = ""identity"", position = ""dodge"") + theme_minimal()",visualization,199204075615853e8,618
numSam = 6,import,199204075615853e8,618
numS = siteSize%/%300,data cleaning,199204075615853e8,618
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,199204075615853e8,618
numSites.list = scan(path),import,199204075615853e8,618
"rc.dat = vector(""list"", 22)",data cleaning,199204075615853e8,618
"for (chr in 1:22) deseq.dat = read.table(paste0(deseq.dat.path,      treatment, ""."", siteSize, ""."", strand, "".300.alt.run/data.each.site."",      chr, "".txt""), as.is = TRUE)",import,199204075615853e8,618
"rc.dat[[chr]] = apply(deseq.dat, 1, sum)",data cleaning,199204075615853e8,618
temp = unlist(rc.dat),data cleaning,199204075615853e8,618
all.rc = temp[temp > 0],data cleaning,199204075615853e8,618
median(msOnly.rc),data cleaning,199204075615853e8,618
median(both.rc),exploratory,199204075615853e8,618
median(all.rc),exploratory,199204075615853e8,618
sum(both.rc > 6000),exploratory,199204075615853e8,618
sum(msOnly.rc > 6000),exploratory,199204075615853e8,618
sum(all.rc > 6000),exploratory,199204075615853e8,618
"pdf(""distReadCountVio.pdf"")",export,199204075615853e8,618
"vioplot(both.rc[both.rc <= 6000], msOnly.rc[msOnly.rc <= 6000],      all.rc[all.rc <= 6000], names = c(""multiseq and WaveQTL"",          ""only multiseq"", ""all sites""), col = ""gold"")",visualization,199204075615853e8,618
"title(ylab = ""read count"")",visualization,199204075615853e8,618
dev.off(),visualization,199204075615853e8,618
"write.csv(file = ""peoplePerRepo.csv"", x = peoplePerRepo)",export,114033189136535e8,619
"write.csv(file = ""peoplePerRepo.csv"", x = peoplePerRepo)",export,114033189136535e8,619
arid2.x.data <- arid2$X45729909,not sure,114033189136535e8,619
arid2.y.data <- arid2$X1,not sure,114033189136535e8,619
"sort.data <- sort(arid2.x.data, index.return = TRUE)",not sure,114033189136535e8,619
arid2.x <- arid2.x.data[sort.data$ix],not sure,114033189136535e8,619
arid2.y <- arid2.y.data[sort.data$ix],not sure,114033189136535e8,619
"k <- seq(3, 31, by = 2)",not sure,114033189136535e8,619
"cvrss <- function(k, y) n <- length(y)",not sure,114033189136535e8,619
"S <- matrix(0, n, n)",not sure,114033189136535e8,619
a <- (k - 1)/2,not sure,114033189136535e8,619
"model_data = varInfo %>% select(transcription_shift, eigen:DeepSeaDnaase,      matches(""Broad|Syd"")) %>% na.omit",setup,112034786026925e8,545
predictors = names(model_data)[-1],modeling,112034786026925e8,545
"lasso_model = cv.glmnet(alpha = 1, x = model_data %>% select(-transcription_shift) %>%      as.matrix, y = model_data %>% select(transcription_shift) %>%      as.matrix, nfolds = 10)",modeling,112034786026925e8,545
"plot(lasso_model, label = TRUE)",modeling,112034786026925e8,545
"plot(lasso_model, label = TRUE)",visualization,112034786026925e8,545
"load(""~/bayesianMPRA/analysis_data/varInfoWithHistoneMarkAnnotations.RData"")",setup,112034786026925e8,545
"lasso_model = cv.glmnet(alpha = 1, x = model_data %>% select(-transcription_shift) %>%      as.matrix, y = model_data %>% select(transcription_shift) %>%      as.matrix, nfolds = 10)",modeling,112034786026925e8,545
"plot(lasso_model, label = TRUE)",visualization,112034786026925e8,545
"benchmark <- tbl_df(read.xlsx(""./Data/level_1_cross_validation.xlsx"",      sheetIndex = 7, colIndex = 6))",import,112034786026925e8,545
names <- vector(),data cleaning,112034786026925e8,545
"for (i in 1:dim(rawData)[1]) temp <- rep(rawData[[1]][i], dim(benchmark)[1])",data cleaning,112034786026925e8,545
"names <- c(names, temp)",data cleaning,112034786026925e8,545
"tidyData <- data.frame(name = names, result = rep(TRUE, length(names)),      benchmark = rep(benchmark$Decision, dim(rawData)[1]))",data cleaning,112034786026925e8,545
"source(""./Analysis/effectSize.R"")",setup,112034786026925e8,545
"source(""./Analysis/prepare_data.R"")",setup,112034786026925e8,545
"source(""./Analysis/analysis.R"")",setup,112034786026925e8,545
"sample_names = read.table(""analysis/data/sample_lists/SL1344_names_all.txt"",      sep = ""\t"", comment.char = """", stringsAsFactors = FALSE)[,      1]",import,112034786026925e8,545
"design_matrix = constructDesignMatrix_SL1344(sample_names) %>%      dplyr::filter(!(donor == ""fpdj"")) %>% tbl_df() %>% dplyr::filter(!(donor ==      ""fpdl"" & replicate == 2)) %>% dplyr::filter(!(donor == ""ougl"" &      replicate == 2)) %>% dplyr::filter(!(donor == ""mijn"")) %>%      dplyr::filter(!(donor == ""qaqx"")) %>% dplyr::mutate(replicate = ifelse(donor ==      ""babk"", 2, replicate)) %>% dplyr::arrange(donor, condition) %>%      as.data.frame()",data cleaning,112034786026925e8,545
"count_matrix = loadCounts(""processed/salmonella/featureCounts/"",      design_matrix$sample_id, sub_dir = FALSE, counts_suffix = "".featureCounts.txt"")",import,112034786026925e8,545
"transcript_data = tbl_df(readRDS(""../../annotations/GRCh38/genes/Ensembl_87/Homo_sapiens.GRCh38.87.transcript_data.rds"")) %>%      dplyr::rename(gene_id = ensembl_gene_id, transcript_id = ensembl_transcript_id,          gene_name = external_gene_name, chr = chromosome_name)",data cleaning,112034786026925e8,545
"valid_chromosomes = c(""1"", ""10"", ""11"", ""12"", ""13"", ""14"", ""15"",      ""16"", ""17"", ""18"", ""19"", ""2"", ""20"", ""21"", ""22"", ""3"", ""4"",      ""5"", ""6"", ""7"", ""8"", ""9"", ""MT"", ""X"", ""Y"")",data cleaning,112034786026925e8,545
"valid_gene_biotypes = c(""lincRNA"", ""protein_coding"", ""IG_C_gene"",      ""IG_D_gene"", ""IG_J_gene"", ""IG_V_gene"", ""TR_C_gene"", ""TR_D_gene"",      ""TR_J_gene"", ""TR_V_gene"", ""3prime_overlapping_ncrna"", ""known_ncrna"",      ""processed_transcript"", ""antisense"", ""sense_intronic"", ""sense_overlapping"")",data cleaning,112034786026925e8,545
"filtered_tx_data = dplyr::filter(transcript_data, gene_biotype %in%      valid_gene_biotypes, chr %in% valid_chromosomes)",data cleaning,112034786026925e8,545
"length_df = dplyr::select(count_matrix, gene_id, length)",data cleaning,112034786026925e8,545
"gene_metadata = filtered_tx_data %>% dplyr::group_by(gene_id) %>%      dplyr::mutate(start = min(transcript_start), end = max(transcript_end)) %>%      dplyr::select(gene_id, gene_biotype, chr, start, end, gene_name,          strand, percentage_gc_content) %>% dplyr::left_join(length_df,      by = ""gene_id"") %>% unique() %>% dplyr::ungroup() %>% as.data.frame()",data cleaning,112034786026925e8,545
rownames(gene_metadata) = gene_metadata$gene_id,data cleaning,112034786026925e8,545
"filtered_data = dplyr::filter(count_matrix, gene_id %in% gene_metadata$gene_id)",data cleaning,112034786026925e8,545
"counts = dplyr::select(filtered_data, -gene_id, -length)",data cleaning,112034786026925e8,545
rownames(counts) = filtered_data$gene_id,data cleaning,112034786026925e8,545
"counts = counts[gene_metadata$gene_id, ]",data cleaning,112034786026925e8,545
"cqn_matrix = calculateCQN(counts, gene_metadata)",modeling,112034786026925e8,545
"sample_metadata = readRDS(""analysis/data/covariates/compiled_salmonella_metadata.rds"")",import,112034786026925e8,545
"sample_meta = dplyr::left_join(design_matrix, sample_metadata,      by = c(""donor"", ""replicate"")) %>% as.data.frame()",data cleaning,112034786026925e8,545
rownames(sample_meta) = sample_meta$sample_id,data cleaning,112034786026925e8,545
"se = SummarizedExperiment::SummarizedExperiment(assays = list(counts = counts,      cqn = cqn_matrix), colData = sample_meta, rowData = gene_metadata)",modeling,112034786026925e8,545
"saveRDS(se, ""results/SummarizedExperiments/salmonella_featureCounts.rds"")",export,112034786026925e8,545
max(emp_check_one$date_of_record),exploratory,112034786026925e8,545
max(emp_check_one$emp_quit_date),exploratory,112034786026925e8,545
print(emp_check_one$emp_id),exploratory,112034786026925e8,545
"action_types <- readr::read_csv(file = ""C:/Users/MonticT/Documents/AnalysisProjects/Vol_Terms/Vol. Terms_action.csv"",      col_types = cols(.default = ""c""), progress = T)",import,112034786026925e8,545
"colnames(action_types) <- colnames(action_types) %>% map_chr(function(x) x %>%      str_replace_all(pattern = ""EMPLOYEE_"", replacement = ""Emp_"") %>%      str_to_lower())",data cleaning,112034786026925e8,545
"action_types <- action_types %>% mutate(term = ifelse(emp_quit_date >      0, 1, 0))",data cleaning,112034786026925e8,545
"tidy.name.vector <- make.names(colnames(action_types), unique = TRUE)",data cleaning,112034786026925e8,545
colnames(action_types) <- tidy.name.vector,data cleaning,112034786026925e8,545
emp_check_action <- action_types %>% filter(emp_id == emp_one),data cleaning,112034786026925e8,545
weird_vol_terms <- action_types %>% filter(emp_id %in% weird_data$emp_id),data cleaning,112034786026925e8,545
weird_vol_terms <- weird_vol_terms %>% group_by(emp_id) %>% mutate(max_record = max(date_of_record)) %>%      ungroup() %>% filter(date_of_record == max_record),data cleaning,112034786026925e8,545
"write_csv(weird_vol_terms, path = ""C:/Users/MonticT/Documents/AnalysisProjects/Vol_Terms/Models/ModelExplanation/weird_non_terms.csv"")",export,112034786026925e8,545
"print(paste(""Significance of"", gene, ""in"", dis, ""is"", expr.sig$pval,      ""(expression) and"", mut.sig$pval, ""(mutation)""))",exploratory,112034786026925e8,545
"colMeans(Res[[2]][, 5:8])",exploratory,112034786026925e8,545
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",export,112034786026925e8,545
"get_moving_averages <- function(time_series, ww) if (ww > length(time_series)) stop(""Window width is greater than length of time series"")",setup,112034786026925e8,545
"all_avgs <- seq(1, length(time_series))",exploratory,112034786026925e8,545
"for (start in 1:length(time_series)) all_avgs[start] <- moving_average(start,      time_series, ww)",exploratory,112034786026925e8,545
return(all_avgs),exploratory,112034786026925e8,545
plot.log.analysis <- function() nn <- nrow(delays_per_day),visualization,112034786026925e8,545
lag <- 1,data cleaning,112034786026925e8,545
lag1 <- delays_per_day$DEP_DELAY_TOT[1:(nn - lag)],data cleaning,112034786026925e8,545
current <- delays_per_day$DEP_DELAY_TOT[(lag + 1):nn],data cleaning,112034786026925e8,545
"lag_df <- data.frame(current, lag1)",data cleaning,112034786026925e8,545
"ggplot(lag_df) + geom_line(aes(x = lag1, y = current)) + geom_abline(intercept = 0,      slope = 1, color = ""red"") + labs(x = ""Past"", y = ""Present/Future"",      title = ""Lag by 1 Plot"")",visualization,112034786026925e8,545
lag1 <- delays_per_day$ARR_DELAY_TOT[1:(nn - lag)],data cleaning,112034786026925e8,545
current <- delays_per_day$ARR_DELAY_TOT[(lag + 1):nn],data cleaning,112034786026925e8,545
"lag_df <- data.frame(current, lag1)",data cleaning,112034786026925e8,545
"ggplot(lag_df) + geom_line(aes(x = lag1, y = current)) + geom_abline(intercept = 0,      slope = 1, color = ""red"") + labs(x = ""Past"", y = ""Present/Future"",      title = ""Lag by 1 Plot"")",visualization,112034786026925e8,545
"my_acf <- function(time_series) acf_df <- data.frame(seq(1:26),      acf(time_series, plot = FALSE)$acf)",data cleaning,112034786026925e8,545
"colnames(acf_df) <- c(""lag"", ""acf"")",data cleaning,112034786026925e8,545
"acf_plot <- ggplot(acf_df, aes(x = lag, y = acf)) + labs(x = ""Lag"",      y = ""ACF"", title = ""Auto-Correlation Plot"") + geom_hline(yintercept = 0) +      geom_hline(yintercept = 1.96/sqrt(nrow(acf_df)), color = ""blue"",          linetype = ""dashed"") + geom_hline(yintercept = -1.96/sqrt(nrow(acf_df)),      color = ""blue"", linetype = ""dashed"")",visualization,112034786026925e8,545
"for (lag in 1:nrow(acf_df)) acf_plot <- acf_plot + geom_segment(aes(xend = lag,      yend = 0))",visualization,112034786026925e8,545
"acf_plot + scale_y_continuous(limits = c(-1, 1))",visualization,112034786026925e8,545
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,112034786026925e8,545
dev.off(),visualization,112034786026925e8,545
theta_hat = theta[cvs[[j]][1]],modeling,112034786026925e8,545
"K = CauchyKernel(t(X), theta_hat)",modeling,112034786026925e8,545
diag(K) = 1,modeling,112034786026925e8,545
n = nrow(K),modeling,112034786026925e8,545
"v = matrix(1, n, 1)",modeling,112034786026925e8,545
K = M %*% K %*% M,modeling,112034786026925e8,545
K = K/mean(diag(K)),modeling,112034786026925e8,545
"Kn = K[ind, ind]",modeling,112034786026925e8,545
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,112034786026925e8,545
MAE.G = mean(abs(y[-ind] - fhat[-ind])),modeling,112034786026925e8,545
"R2_G = cor(y[-ind], fhat[-ind])^2",modeling,112034786026925e8,545
"X = ECs[!is.na(Y[, j]), ]",modeling,112034786026925e8,545
X = scale(X),modeling,112034786026925e8,545
"X = cbind(rep(1, nrow(X)), X)",modeling,112034786026925e8,545
theta_hat = theta[cvs[[j]][4]],data cleaning,112034786026925e8,545
"K = CauchyKernel(t(X), theta_hat)",modeling,112034786026925e8,545
diag(K) = 1,modeling,112034786026925e8,545
n = nrow(K),modeling,112034786026925e8,545
"v = matrix(1, n, 1)",modeling,112034786026925e8,545
M = diag(n) - v %*% t(v)/n,modeling,112034786026925e8,545
K = M %*% K %*% M,modeling,112034786026925e8,545
K = K/mean(diag(K)),modeling,112034786026925e8,545
"Kn = K[ind, ind]",modeling,112034786026925e8,545
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,112034786026925e8,545
MAE.ECs = mean(abs(y[-ind] - fhat[-ind])),modeling,112034786026925e8,545
"R2_ECs = cor(y[-ind], fhat[-ind])^2",modeling,112034786026925e8,545
"c(MAE.G, MAE.Morph, MAE.Geo, MAE.ECs, R2_G, R2_Morph, R2_Geo,      R2_ECs)",modeling,112034786026925e8,545
"Final = matrix(unlist(Results), nrow = ndatasets, ncol = 8, byrow = TRUE)",modeling,112034786026925e8,545
"mod.names = c(""Expression"", ""Morph"", ""Geo"", ""ECs"")",modeling,112034786026925e8,545
"colnames(Final) = c(paste(""MAE"", mod.names, sep = ""_""), paste(""R2"",      mod.names, sep = ""_""))",data cleaning,112034786026925e8,545
Res[[j]] = Final,data cleaning,112034786026925e8,545
"cat(""Completed Phenotype"", j, ""\n"")",data cleaning,112034786026925e8,545
"colMeans(Res[[1]][, 1:4])",data cleaning,112034786026925e8,545
"colMeans(Res[[1]][, 5:8])",data cleaning,112034786026925e8,545
"colMeans(Res[[2]][, 1:4])",data cleaning,112034786026925e8,545
"colMeans(Res[[2]][, 5:8])",data cleaning,112034786026925e8,545
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",data cleaning,112034786026925e8,545
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",export,112034786026925e8,545
theta_hat = theta[cvs[[j]][1]],export,112034786026925e8,545
"K = CauchyKernel(t(X), theta_hat)",export,112034786026925e8,545
diag(K) = 1,modeling,112034786026925e8,545
n = nrow(K),modeling,112034786026925e8,545
"v = matrix(1, n, 1)",modeling,112034786026925e8,545
M = diag(n) - v %*% t(v)/n,modeling,112034786026925e8,545
K = M %*% K %*% M,modeling,112034786026925e8,545
K = K/mean(diag(K)),modeling,112034786026925e8,545
"Kn = K[ind, ind]",modeling,112034786026925e8,545
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,112034786026925e8,545
MAE.G = mean(abs(y[-ind] - fhat[-ind])),modeling,112034786026925e8,545
"R2_G = cor(y[-ind], fhat[-ind])^2",modeling,112034786026925e8,545
"X = ECs[!is.na(Y[, j]), ]",modeling,112034786026925e8,545
X = scale(X),modeling,112034786026925e8,545
"X = cbind(rep(1, nrow(X)), X)",modeling,112034786026925e8,545
theta_hat = theta[cvs[[j]][4]],modeling,112034786026925e8,545
"K = CauchyKernel(t(X), theta_hat)",modeling,112034786026925e8,545
diag(K) = 1,modeling,112034786026925e8,545
n = nrow(K),modeling,112034786026925e8,545
"v = matrix(1, n, 1)",modeling,112034786026925e8,545
M = diag(n) - v %*% t(v)/n,modeling,112034786026925e8,545
K = M %*% K %*% M,modeling,112034786026925e8,545
K = K/mean(diag(K)),modeling,112034786026925e8,545
"Kn = K[ind, ind]",modeling,112034786026925e8,545
"fhat = K[, ind] %*% solve(Kn + diag(sigma, nrow(Kn)), y[ind])",modeling,112034786026925e8,545
MAE.ECs = mean(abs(y[-ind] - fhat[-ind])),modeling,112034786026925e8,545
"R2_ECs = cor(y[-ind], fhat[-ind])^2",modeling,112034786026925e8,545
"c(MAE.G, MAE.Morph, MAE.Geo, MAE.ECs, R2_G, R2_Morph, R2_Geo,      R2_ECs)",modeling,112034786026925e8,545
"Final = matrix(unlist(Results), nrow = ndatasets, ncol = 8, byrow = TRUE)",data cleaning,112034786026925e8,545
"mod.names = c(""Expression"", ""Morph"", ""Geo"", ""ECs"")",data cleaning,112034786026925e8,545
"colnames(Final) = c(paste(""MAE"", mod.names, sep = ""_""), paste(""R2"",      mod.names, sep = ""_""))",data cleaning,112034786026925e8,545
Res[[j]] = Final,data cleaning,112034786026925e8,545
"cat(""Completed Phenotype"", j, ""\n"")",data cleaning,112034786026925e8,545
"colMeans(Res[[1]][, 1:4])",data cleaning,112034786026925e8,545
"colMeans(Res[[1]][, 5:8])",data cleaning,112034786026925e8,545
"colMeans(Res[[2]][, 1:4])",modeling,112034786026925e8,545
"colMeans(Res[[2]][, 5:8])",modeling,112034786026925e8,545
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",modeling,112034786026925e8,545
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",export,112034786026925e8,545
theta_hat = theta[cvs[[j]][1]],modeling,112034786026925e8,545
"qqplot(qq.exp.pts, -log10(results$p), pch = 1, col = ""red"", xlab = ""Expected"",      ylab = ""Observed"", bty = ""n"", cex = 0.5)",visualization,112034786026925e8,545
"abline(0, 1, col = ""black"")",visualization,112034786026925e8,545
dev.off(),visualization,112034786026925e8,545
"res <- data.frame(ID = results$ID, PVAL = results$p)",data cleaning,112034786026925e8,545
"res <- merge(res, data, by = ""ID"")",data cleaning,112034786026925e8,545
"res <- res[order(res$CHR, res$POS), ]",data cleaning,112034786026925e8,545
"res <- res[!is.na(res$PVAL), ]",data cleaning,112034786026925e8,545
"png(paste0(""~/selection/analysis/s_estimates/mh_plot"", results.tag,      "".png""), width = 800, height = 400)",export,112034786026925e8,545
"par(mar = c(2, 4, 1, 1))",visualization,112034786026925e8,545
MH.plot(res),visualization,112034786026925e8,545
"abline(h = 6.79, col = ""red"", lty = 2)",visualization,112034786026925e8,545
dev.off(),visualization,112034786026925e8,545
"ai_f = rbind(ai_missense, ai_truncation)",not sure,227549529867247e8,620
ai_f$TumorByNormalVAF = ai_f$TumorVAF/ai_f$NormalVAF,not sure,227549529867247e8,620
"ai_f_brief = ai_f[, c(3, 14:21)]",not sure,227549529867247e8,620
"colnames(ai_f_brief)[1] = ""Start""",not sure,227549529867247e8,620
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,124125925591215e8,621
"with(subset(dat_annual, Tx == FALSE), hist(ps, xlim = c(0, 1),      breaks = 50, main = paste(n_grp[1], ""Untreated"")))",exploratory,124125925591215e8,621
"with(subset(dat_annual, Tx == TRUE), hist(ps, xlim = c(0, 1),      breaks = 50, main = paste(n_grp[2], ""Treated"")))",not sure,124125925591215e8,621
mth_sum = mth %>% group_by(year) %>% summarise(count = sum(count)),exploratory,919876614585519e8,622
"joined = ann %>% left_join(mth_sum, by = ""year"") %>% mutate(diff = count.x -      count.y)",data cleaning,919876614585519e8,622
hist(joined$diff),exploratory,919876614585519e8,622
"sibMobJsonCyc = getFiledata(""CyclesSibMob.json"")",import,241783702978864e8,623
"sibDeskJsonCyc = getFiledata(""CyclesSibDesk.json"")",import,241783702978864e8,623
mobileCyc = mobileJsonCyc$Cycle$Data,data cleaning,241783702978864e8,623
desktopCyc = desktopJsonCyc$Cycle$Data,data cleaning,241783702978864e8,623
siblingCyc = siblingJsonCyc$Cycle$Data,data cleaning,241783702978864e8,623
sibMobCyc = sibMobJsonCyc$Cycle$Data,data cleaning,241783702978864e8,623
sibDesktCyc = sibDeskJsonCyc$Cycle$Data,data cleaning,241783702978864e8,623
siblingCyc = siblingCyc[-which(siblingCyc %in% c(max(siblingCyc)))],data cleaning,241783702978864e8,623
"RunAnalysis <- function() print(t.test(mobileCyc, desktopCyc,      alternative = ""two.sided"", var.equal = FALSE))",modeling,241783702978864e8,623
"gene_metadata = filtered_tx_data %>% dplyr::group_by(gene_id) %>%      dplyr::mutate(start = min(transcript_start), end = max(transcript_end)) %>%      dplyr::select(gene_id, gene_biotype, chr, start, end, gene_name,          strand, percentage_gc_content) %>% dplyr::left_join(length_df,      by = ""gene_id"") %>% unique() %>% dplyr::ungroup() %>% as.data.frame()",data cleaning,218559311237186e8,132
rownames(gene_metadata) = gene_metadata$gene_id,data cleaning,218559311237186e8,132
"filtered_data = dplyr::filter(count_matrix, gene_id %in% gene_metadata$gene_id)",data cleaning,218559311237186e8,132
"counts = dplyr::select(filtered_data, -gene_id, -length)",data cleaning,218559311237186e8,132
rownames(counts) = filtered_data$gene_id,data cleaning,218559311237186e8,132
"counts = counts[gene_metadata$gene_id, ]",data cleaning,218559311237186e8,132
"cqn_matrix = calculateCQN(counts, gene_metadata)",modeling,218559311237186e8,132
"sample_metadata = readRDS(""analysis/data/covariates/compiled_acLDL_metadata.rds"")",import,218559311237186e8,132
"sample_meta = dplyr::left_join(design_matrix, sample_metadata,      by = c(""donor"")) %>% as.data.frame()",data cleaning,218559311237186e8,132
rownames(sample_meta) = sample_meta$sample_id,data cleaning,218559311237186e8,132
"se = SummarizedExperiment::SummarizedExperiment(assays = list(counts = counts,      cqn = cqn_matrix), colData = sample_meta, rowData = gene_metadata)",data cleaning,218559311237186e8,132
"saveRDS(se, ""results/SummarizedExperiments/acLDL_featureCounts.rds"")",import,218559311237186e8,132
"source(""./analysis/data/GDPdata.R"")",import,218559311237186e8,132
"source(""./analysis/data/Edudata.R"")",import,218559311237186e8,132
"source(""./analysis/data/Merge.R"")",import,218559311237186e8,132
"source(""./src/5_tables.R"")",import,218559311237186e8,132
"source(""./src/6_figures.R"")",import,218559311237186e8,132
"source(""./src/7_analysis.R"")",import,218559311237186e8,132
"write.csv(tables(2), ""./output/vbgf_app.csv"")",export,218559311237186e8,132
"write.csv(tables(3), ""./output/struc_app.csv"")",export,218559311237186e8,132
df$tl_y <- df$y + 0.25,data cleaning,218559311237186e8,132
df$br_y <- df$y - 0.25,data cleaning,218559311237186e8,132
df$tr_y <- df$y + 0.25,data cleaning,218559311237186e8,132
"polygon_file = SpatialPolygons(lapply(1:nrow(df), function(x) Polygons(list(Polygon(cbind(t(df[x,      c(""bl_x"", ""tl_x"", ""tr_x"", ""br_x"")]), t(df[x, c(""bl_y"", ""tl_y"",      ""tr_y"", ""br_y"")])))), paste0(x))))",data cleaning,218559311237186e8,132
"c(MAE.G, MAE.Morph, MAE.Geo, MAE.ECs, R2_G, R2_Morph, R2_Geo,      R2_ECs)",not sure,824724957812577e8,624
"Final = matrix(unlist(Results), nrow = ndatasets, ncol = 8, byrow = TRUE)",not sure,824724957812577e8,624
"mod.names = c(""Expression"", ""Morph"", ""Geo"", ""ECs"")",setup,824724957812577e8,624
"colnames(Final) = c(paste(""MAE"", mod.names, sep = ""_""), paste(""R2"",      mod.names, sep = ""_""))",setup,824724957812577e8,624
Res[[j]] = Final,export,824724957812577e8,624
"cat(""Completed Phenotype"", j, ""\n"")",export,824724957812577e8,624
"colMeans(Res[[1]][, 1:4])",evaluation,824724957812577e8,624
"colMeans(Res[[1]][, 5:8])",evaluation,824724957812577e8,624
"colMeans(Res[[2]][, 1:4])",evaluation,824724957812577e8,624
"colMeans(Res[[2]][, 5:8])",evaluation,824724957812577e8,624
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Linear_SECT.RData"")",export,824724957812577e8,624
subsets_novictims <- subsets_list[5:length(subsets_list)],data cleaning,189236118225381e8,625
subset_names <- names(subsets_list)[5:length(subsets_list)],data cleaning,189236118225381e8,625
"subset_names_twice <- unlist(lapply(subset_names, function(i) rep(i,      2)))",data cleaning,189236118225381e8,625
"ivs <- c(""black_not_white"", ""agency_offenders_count"", ""mean_inc"")",data cleaning,189236118225381e8,625
"continuous_ivs <- c(""agency_offenders_count"", ""mean_inc"")",data cleaning,189236118225381e8,625
"ivs_string <- paste0(ivs, "" + "", collapse = """")",data cleaning,189236118225381e8,625
"iv_names <- c(""Constant"", ""Offender Black (ref = White)"", ""Offenders Reported to Agency"",      ""County Mean Income"")",data cleaning,189236118225381e8,625
d <- dist(1 - stat.val),exploratory,977835069643333e8,626
"fit <- fit.clust(d, cluster.method, dim = k)",modeling,977835069643333e8,626
"plot.clust(fit, cluster.method)",visualization,977835069643333e8,626
gc(),visualization,977835069643333e8,626
set.seed(132),setup,977835069643333e8,626
ncores = 40,not sure,977835069643333e8,626
"source(""bergan_cole_analysis.R"")",setup,977835069643333e8,626
"source(""bergan_tables.R"")",setup,977835069643333e8,626
gc(),setup,977835069643333e8,626
"fit <- glmpath::glmpath(x = xx[-hold_out, ], y = yy[-hold_out],      family = binomial, max.arclength = 1)",modeling,977835069643333e8,626
bestdex <- which.min(fit$bic),modeling,977835069643333e8,626
"ggsave(p1, file = ""./analysis/inundation_wooddensity_relationship/graph_code/graphs/inundation_VS_wooddensity.png"",      width = 6, height = 6)",exploratory,229306508554146e8,627
"mod = stan(file = ""salmon/analysis/portfolio-offset-linear.stan"",      data = stan_data, verbose = TRUE, chains = 3, thin = 1, warmup = 4000,      iter = 9000, pars = stan_pars)",import,229306508554146e8,627
"save.image(""salmon/analysis/model-linear.Rdata"")",export,229306508554146e8,627
"getUniqueFiles(""/Users/ashleychen/desktop/reuse/reuse/Analysis/Filenames/openjpa_fileNames.txt"",      ""openjpa"")",import,229306508554146e8,627
names(null.result.columns) <- null.result.colnames,data cleaning,229306508554146e8,627
"null.results.list <- lapply(null.result.paths, function(path) data.frame(sapply(null.result.columns,      function(col) ReadColumnViaPipe(path, col, skip = 1))))",data cleaning,229306508554146e8,627
for (i in 1:length(null.results.list)) null.results.list[[i]]$replicate <- i,data cleaning,229306508554146e8,627
"null.df <- Reduce(rbind, null.results.list)",data cleaning,229306508554146e8,627
rm(null.results.list),evaluation,229306508554146e8,627
gc(),data cleaning,229306508554146e8,627
"variables.of.interest <- names(null.df)[str_detect(names(null.df),      kVariableRegexp)]",not sure,229306508554146e8,627
"tail.probs <- ddply(null.df, .(replicate), ExtractTailProbabilities,      variables = variables.of.interest, thresholds = kThresholds)",data cleaning,229306508554146e8,627
"quantiles <- ddply(null.df, .(replicate), ExtractQuantiles, variables = variables.of.interest,      p = kQuantiles)",exploratory,229306508554146e8,627
"tail.prob.means <- dcast(melt(tail.probs, id.vars = ""threshold""),      threshold ~ variable, mean)",exploratory,229306508554146e8,627
"quantile.means <- dcast(melt(quantiles, id.vars = ""quantile""),      quantile ~ variable, mean)",data cleaning,229306508554146e8,627
"save(null.df, file = kDataPath)",data cleaning,229306508554146e8,627
"save(tail.probs, quantiles, tail.prob.means, quantile.means,      file = kOutputPath)",export,229306508554146e8,627
"save(tail.probs, quantiles, tail.prob.means, quantile.means,      file = kOutputPath)",export,229306508554146e8,627
"cuff <- readCufflinks(dir = dir, gtfFile = ""/n/rinn_data1/seq/lgoff/Projects/BrainMap/data/annotation/mm10_gencode_vM2_with_lncRNAs_and_LacZ.gtf"",      genome = genome)",import,229306508554146e8,627
"sig <- getSig(cuff, alpha = 0.05)",evaluation,229306508554146e8,627
"sigGenes <- getGenes(cuff, sig)",not sure,229306508554146e8,627
annot <- annotation(sigGenes),not sure,229306508554146e8,627
names <- annot$gene_short_name,exploratory,229306508554146e8,627
"forgmt <- c(""Sexdiffs"", ""NA"", unlist(names))",evaluation,229306508554146e8,627
gmt <- data.frame(forgmt),exploratory,229306508554146e8,627
"cat(forgmt, file = ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"",      sep = ""\t"")",evaluation,229306508554146e8,627
library(GSA),setup,229306508554146e8,627
"test <- GSA.read.gmt(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs_upper.gmt"")",import,229306508554146e8,627
rm(req),setup,229306508554146e8,627
set.seed(893749),setup,229306508554146e8,627
sessionInfo(),setup,229306508554146e8,627
"poisson_ods_full_centred <- stan_model(""./analysis/m01_poisson_ods_full_centred.stan"",      verbose = TRUE)",modeling,229306508554146e8,627
"save(poisson_ods_full_centred, file = ""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",export,229306508554146e8,627
sink(),not sure,229306508554146e8,627
mn.homes$outliers <- (log10(mn.homes$sale.price.n) <= 5) + 0,evaluation,229306508554146e8,627
"mn.homes <- mn.homes[which(mn.homes$outliers == 0), ]",data cleaning,229306508554146e8,627
"plot(mn.homes$gross.sqft, mn.homes$sale.price.n)",visualization,229306508554146e8,627
"write.csv(mn.homes, file = ""rollingsales_manhattan_familyhome.csv"")",export,229306508554146e8,627
"req <- c(""rstan"")",evaluation,229306508554146e8,627
"lapply(req, library, character.only = TRUE)",setup,229306508554146e8,627
rm(req),setup,229306508554146e8,627
set.seed(3749),setup,229306508554146e8,627
sessionInfo(),setup,229306508554146e8,627
"load(""./data/d00_ci5.Rdta"")",import,229306508554146e8,627
"load(""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",import,229306508554146e8,627
d <- ci5_bycancer[[idx]],not sure,229306508554146e8,627
"dlist <- with(d, list(N = nrow(d), n_coef = 1, y = n_ca, x = as.matrix(male),      reg = as.numeric(registry_cde), n_reg = max(as.numeric(registry_cde)),      age = as.numeric(age_group), n_age = max(as.numeric(age_group)),      year = as.numeric(factor(year)), n_year = max(as.numeric(factor(year))),      log_offset = log(n_pop)))",data cleaning,229306508554146e8,627
"fit <- sampling(poisson_ods_full_centred, data = dlist, iter = 2000,      chains = 10, cores = 10, control = list(max_treedepth = 15))",modeling,229306508554146e8,627
"fn <- paste0(""./analysis/output/o03_fit_"", gsub("" "", ""_"", names(ci5_bycancer)[idx]),      "".Rdta"")",data cleaning,229306508554146e8,627
"save(fit, file = fn)",export,229306508554146e8,627
library(stringr),setup,229306508554146e8,627
"source(""Analysis/remove_self_node.R"")",import,229306508554146e8,627
"source(""Analysis/compute_triplets.R"")",import,229306508554146e8,627
"source(""Analysis/compute_all_triplets.R"")",import,229306508554146e8,627
"source(""Analysis/categorize_all_triplets.R"")",import,229306508554146e8,627
"source(""Analysis/categorize_triplet1.R"")",import,229306508554146e8,627
"coffeeG05 = read_graph(""Data/iGraphs/coffeeG05.gml"", format = ""gml"")",import,229306508554146e8,627
"gasG05 = read_graph(""Data/iGraphs/gasG05.gml"", format = ""gml"")",import,229306508554146e8,627
"all_triplets = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",not sure,229306508554146e8,627
"all_triplets_test = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",not sure,229306508554146e8,627
"ids = unique(unlist(all_triplets %>% filter(category == ""ABC"") %>%      select(X, Y, Z)))",data cleaning,229306508554146e8,627
"subG = induced_subgraph(coffeeG05, vids = ids)",not sure,229306508554146e8,627
lay = layout.circle(subG),evaluation,229306508554146e8,627
"par(mfrow = c(1, 1))",visualization,229306508554146e8,627
"plot(subG, layout = lay)",visualization,229306508554146e8,627
r = 14,evaluation,229306508554146e8,627
"plot(induced_subgraph(coffeeG05, vids = as.character(unlist(all_triplets[r,      1:3]))), main = all_triplets[r, 5])",visualization,229306508554146e8,627
plot160c <- (plot160c/max(plot160c@data@values)) * (137.9 - 55.9) +      55.9,visualization,229306508554146e8,627
rVals <- plot160c@data@values,visualization,229306508554146e8,627
comPlot <- plot160c,visualization,229306508554146e8,627
for (i in 1:length(bands) - 1) cVals <- which(rVals >= bands[i] &      rVals <= bands[i + 1]),evaluation,229306508554146e8,627
comPlot@data@values[cVals] <- md1[i],evaluation,229306508554146e8,627
"ggCom <- as.data.frame(comPlot, xy = TRUE)",evaluation,229306508554146e8,627
"colnames(ggCom) <- c(""x"", ""y"", ""z"")",evaluation,229306508554146e8,627
"brk <- round(seq(min(comPlot@data@values), 0.97, length = 5),      2)",data cleaning,229306508554146e8,627
"ggplot(ggCom) + geom_raster(aes(x, y, fill = z)) + scale_fill_gradient(low = ""#232d29"",      high = ""#6A9113"", name = """", breaks = brk)",visualization,229306508554146e8,627
"writeRaster(comPlot, ""analysis/community_elevation_analysis/data/community_analysis_Fig1.tif"",      format = ""GTiff"")",export,229306508554146e8,627
original_events[original_events == 1.5] = 1,visualization,229306508554146e8,627
original_events[original_events == 2] = 0,data cleaning,229306508554146e8,627
original_events[original_events == -2] = 0,data cleaning,229306508554146e8,627
"concurrent_events = matrix(NA, nrow = 0, ncol = 4)",data cleaning,229306508554146e8,627
"event_locations = expand_runs(event_scan[winner][[1]], data_mat)",data cleaning,229306508554146e8,627
event_locations[is.na(event_locations)] = 0,not sure,229306508554146e8,627
"agreement = which((event_locations == original_events) & (event_locations !=      0) & (original_events != 0), arr.ind = T)",data cleaning,229306508554146e8,627
"disagreement_FP = which((event_locations != original_events) &      (original_events == 0), arr.ind = T)",data cleaning,229306508554146e8,627
"disagreement_FN = which((event_locations != original_events) &      (event_locations == 0), arr.ind = T)",data cleaning,229306508554146e8,627
"disagreement_TN = which((original_events == 0) & (event_locations ==      0), arr.ind = T)",data cleaning,229306508554146e8,627
"pdf(paste(outfile_name, "".pdf"", sep = """"), width = 14, height = 14,      useDingbats = F)",data cleaning,229306508554146e8,627
temp = data_mat * 0,export,229306508554146e8,627
temp[agreement] = event_locations[agreement],not sure,229306508554146e8,627
"make_visual(data_mat, temp, concurrent_events)",data cleaning,229306508554146e8,627
par(new = T),visualization,229306508554146e8,627
"event_colors = list(upswing = color_to_hex(""purple"", 0.1), downswing = color_to_hex(""purple"",      0.1))",visualization,229306508554146e8,627
temp = data_mat * 0,data cleaning,229306508554146e8,627
temp[disagreement_FP] = event_locations[disagreement_FP],not sure,229306508554146e8,627
"make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3, 3),      ramp_draw = c(-1, 1), event_colors = event_colors, box_resize = 1,      lwd = 2)",data cleaning,229306508554146e8,627
par(new = T),not sure,229306508554146e8,627
"event_colors = list(upswing = color_to_hex(""forestgreen"", 0.1),      downswing = color_to_hex(""forestgreen"", 0.1))",visualization,229306508554146e8,627
temp = data_mat * 0,data cleaning,229306508554146e8,627
temp[disagreement_FN] = original_events[disagreement_FN],not sure,229306508554146e8,627
"make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3, 3),      ramp_draw = c(-1, 1), event_colors = event_colors, box_resize = 1,      lwd = 2)",data cleaning,229306508554146e8,627
par(new = F),visualization,229306508554146e8,627
"make_visual(data_mat, original_events, concurrent_events)",visualization,229306508554146e8,627
"title(""Original"")",visualization,229306508554146e8,627
"make_visual(data_mat, event_locations, concurrent_events)",setup,229306508554146e8,627
"title(""Optimized"")",visualization,229306508554146e8,627
"temp = cbind(matrix(threshold_distance/max(threshold_distance),      ncol = 1), matrix(event_distance, ncol = 1))",visualization,229306508554146e8,627
ND = find_ND(temp),data cleaning,229306508554146e8,627
"par(mar = c(8, 8, 8, 8))",not sure,229306508554146e8,627
"plot(x = temp[ND, 1], y = temp[ND, 2], xlab = ""Normalized threshold sum"",      ylab = ""Normalized event number"", xlim = c(0, 1), ylim = c(0,          1), col = ""grey50"", pch = 20, cex = 2)",visualization,229306508554146e8,627
par(new = T),visualization,229306508554146e8,627
"plot(x = threshold_distance[winner]/max(threshold_distance),      y = event_distance[winner], xaxt = ""n"", yaxt = ""n"", xlim = c(0,          1), ylim = c(0, 1), xlab = """", ylab = """", bty = ""n"",      pch = 20, col = ""red"", cex = 3)",visualization,229306508554146e8,627
"lines(x = c(0, threshold_distance[winner]/max(threshold_distance)),      y = c(0, event_distance[winner]), lty = 2)",visualization,229306508554146e8,627
dev.off(),visualization,229306508554146e8,627
TP = nrow(agreement),visualization,229306508554146e8,627
FP = nrow(disagreement_FP),visualization,229306508554146e8,627
FN = nrow(disagreement_FN),visualization,229306508554146e8,627
TN = nrow(disagreement_TN),visualization,229306508554146e8,627
TPR = TP/(TP + FN),visualization,229306508554146e8,627
FPR = FP/(FP + TN),exploratory,229306508554146e8,627
precision = TP/(TP + FP),exploratory,229306508554146e8,627
"return(list(TPR = TPR, FPR = FPR, precision = precision))",exploratory,229306508554146e8,627
"compare_optimized(""optimized_thresholds_SRP_2.RData"", ""analysis/SRP/replicates/SRP.csv"",      ""optimized_comparison_SRP_2"")",not sure,229306508554146e8,627
"compare_optimized(""optimized_thresholds_F_0mM_2.RData"", ""analysis/F/replicates/F_0mM.csv"",      ""optimized_comparison_F_0mM_2"")",export,229306508554146e8,627
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",export,229306508554146e8,627
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",export,229306508554146e8,627
original_events[original_events == 3] = 1,export,229306508554146e8,627
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,84033941780217e9,628
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,84033941780217e9,628
"make_visual(data_mat, temp, concurrent_events)",visualization,84033941780217e9,628
par(new = T),visualization,84033941780217e9,628
"event_colors = list(upswing = color_to_hex(""purple"", 0.1), downswing = color_to_hex(""purple"",      0.1))",visualization,84033941780217e9,628
temp = data_mat * 0,data cleaning,84033941780217e9,628
"make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3, 3),      ramp_draw = c(-1, 1), event_colors = event_colors, box_resize = 1,      lwd = 2)",data cleaning,84033941780217e9,628
par(new = T),visualization,84033941780217e9,628
"event_colors = list(upswing = color_to_hex(""forestgreen"", 0.1),      downswing = color_to_hex(""forestgreen"", 0.1))",visualization,84033941780217e9,628
temp = data_mat * 0,visualization,84033941780217e9,628
temp[disagreement_FN] = original_events[disagreement_FN],data cleaning,84033941780217e9,628
"make_visual_PID(temp, event_draw = c(-1, 1, -1.5, 1.5, -3, 3),      ramp_draw = c(-1, 1), event_colors = event_colors, box_resize = 1,      lwd = 2)",data cleaning,84033941780217e9,628
par(new = F),visualization,84033941780217e9,628
"make_visual(data_mat, original_events, concurrent_events)",visualization,84033941780217e9,628
"title(""Original"")",visualization,84033941780217e9,628
"make_visual(data_mat, event_locations, concurrent_events)",visualization,84033941780217e9,628
"title(""Optimized"")",visualization,84033941780217e9,628
"temp = cbind(matrix(threshold_distance/max(threshold_distance),      ncol = 1), matrix(event_distance, ncol = 1))",visualization,84033941780217e9,628
ND = find_ND(temp),data cleaning,84033941780217e9,628
"par(mar = c(8, 8, 8, 8))",data cleaning,84033941780217e9,628
"plot(x = temp[ND, 1], y = temp[ND, 2], xlab = ""Normalized threshold sum"",      ylab = ""Normalized event number"", xlim = c(0, 1), ylim = c(0,          1), col = ""grey50"", pch = 20, cex = 2)",visualization,84033941780217e9,628
par(new = T),visualization,84033941780217e9,628
"plot(x = threshold_distance[winner]/max(threshold_distance),      y = event_distance[winner], xaxt = ""n"", yaxt = ""n"", xlim = c(0,          1), ylim = c(0, 1), xlab = """", ylab = """", bty = ""n"",      pch = 20, col = ""red"", cex = 3)",visualization,84033941780217e9,628
"lines(x = c(0, threshold_distance[winner]/max(threshold_distance)),      y = c(0, event_distance[winner]), lty = 2)",visualization,84033941780217e9,628
dev.off(),visualization,84033941780217e9,628
TP = nrow(agreement),visualization,84033941780217e9,628
FP = nrow(disagreement_FP),not sure,84033941780217e9,628
FN = nrow(disagreement_FN),not sure,84033941780217e9,628
TN = nrow(disagreement_TN),not sure,84033941780217e9,628
TPR = TP/(TP + FN),evaluation,84033941780217e9,628
FPR = FP/(FP + TN),evaluation,84033941780217e9,628
precision = TP/(TP + FP),evaluation,84033941780217e9,628
"return(list(TPR = TPR, FPR = FPR, precision = precision))",evaluation,84033941780217e9,628
"compare_optimized(""optimized_thresholds_SRP_2.RData"", ""analysis/SRP/replicates/SRP.csv"",      ""optimized_comparison_SRP_2"")",communication,84033941780217e9,628
"compare_optimized(""optimized_thresholds_F_0mM_2.RData"", ""analysis/F/replicates/F_0mM.csv"",      ""optimized_comparison_F_0mM_2"")",not sure,84033941780217e9,628
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",not sure,84033941780217e9,628
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",not sure,84033941780217e9,628
"source(""../code/gtexpca.functions.R"")",exploratory,634340103482827e8,629
gtex <- read.gtex.data(gtex.data.file),exploratory,634340103482827e8,629
"cat(sprintf(""Total number of tissue types: %d\n"", nrow(gtex)))",exploratory,634340103482827e8,629
"cat(sprintf(""Total number of genes: %d\n"", ncol(gtex)))",exploratory,634340103482827e8,629
"rows <- !is.element(rownames(gtex), c(""pancreas"", ""whole blood""))",exploratory,634340103482827e8,629
"gtex <- gtex[rows, ]",data cleaning,634340103482827e8,629
gtex.pca <- prcomp(gtex),data cleaning,634340103482827e8,629
"print(summary(gtex.pca)$importance[, 1:2])",data cleaning,634340103482827e8,629
"df <- data.frame(annotes[, 2:3])",exploratory,778677627211437e8,630
"rownames(df) <- annotes[, 1]",data cleaning,778677627211437e8,630
"colnames(df) <- c(""Genotype"", ""Synapse ID"")",data cleaning,778677627211437e8,630
pData(expr) <- df,not sure,778677627211437e8,630
"write.table(df, row.names = T, col.names = T, sep = ""\t"", file = ""pnfPhenoData.tsv"")",export,778677627211437e8,630
"synStore(File(""pnfPhenoData.tsv"", parentId = ""syn5579785""), executed = ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2016-08-17/reformatRnaSeq.R"",      used = ""syn5580347"")",export,778677627211437e8,630
pval.null = as.numeric(pval_list),evaluation,613080654526129e8,631
done.null = done_res,evaluation,613080654526129e8,631
sum(done.alt),not sure,613080654526129e8,631
sum(done.null),modeling,613080654526129e8,631
cluster.meme.res <- list(),setup,24310775147751e9,632
ind <- 0,setup,24310775147751e9,632
total.motifs <- c(),setup,24310775147751e9,632
pv <- iva$pval[iva$pval <= p],modeling,333849765360355e8,633
"fr <- apply(fam.hel > 0, 2, sum)[iva$pval <= p]",exploratory,333849765360355e8,633
"fidg <- data.frame(group = gr, indval = iv, pvalue = pv, freq = fr)",data cleaning,333849765360355e8,633
"hg38 <- getGEOInfo(genome = ""hg38"", simplify = TRUE)",not sure,732700866879895e8,634
head(hg38),exploratory,732700866879895e8,634
"downloadGSMbedFiles(""GSM733656"", destDir = ""hg19"")",import,732700866879895e8,634
"K562_hg19_H3k27ac <- ""GSM733656_hg19_wgEncodeBroadHistoneK562H3k27acStdPk.broadPeak""",evaluation,732700866879895e8,634
K562_hg19_H3k27ac <- readPeakFile(K562_hg19_H3k27ac),import,732700866879895e8,634
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",visualization,232627056539059e8,635
"ggsave(""Analysis/Plots/record_subj.png"")",export,232627056539059e8,635
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",visualization,232627056539059e8,635
"ggsave(""Analysis/Plots/record_section.png"")",export,232627056539059e8,635
"afc = read.csv(""Analysis/Parsed Data/pilots_4afc.csv"")",import,232627056539059e8,635
"afc %<>% mutate(Mapping = ifelse(Subj == ""1MK"", 1, ifelse(Subj ==      ""2DC"", 1, ifelse(Subj == ""3BR"", 1, ifelse(Subj == ""4KK"",      1, ifelse(Subj == ""5HB"", 2, ifelse(Subj == ""6MA"", 2, ifelse(Subj ==          ""7SQ"", 2, ifelse(Subj == ""8EW"", 2, NA)))))))))",data cleaning,232627056539059e8,635
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",data cleaning,232627056539059e8,635
"limits <- aes(ymax = mean + se, ymin = mean - se)",visualization,232627056539059e8,635
"afc1 <- ddply(afc_nonce, c(""Section""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",data cleaning,232627056539059e8,635
l.gdptotc <- log(urban$gdptotc/urban$gdpdef),data cleaning,209901458583772e6,636
"urban <- cbind(urban, lpoptotc, l.gdptotc)",data cleaning,209901458583772e6,636
library(plm),data cleaning,209901458583772e6,636
"U1 <- plm(ncampus ~ lpoptotc + log(fditotc + 1) + l.gdptotc +      log(empavec), data = urban, index = c(""cityid"", ""year""),      effect = ""individual"", model = ""within"")",import,209901458583772e6,636
print(summary(U1)),modeling,209901458583772e6,636
"U2 <- glm(dcampus ~ l.poptotc + log(fditotc + 1) + l.gdptotc +      log(empavec), data = urban, family = ""binomial"")",visualization,209901458583772e6,636
summary(U2),modeling,209901458583772e6,636
summary(U2),communication,209901458583772e6,636
plot(rad.2005),visualization,848194164922461e8,126
radlattice(rad.2005),visualization,848194164922461e8,126
"rad.2014 <- radfit(as.data.frame(select(abund_2014_wide, -plotid))[k.2014,      ], family = poisson)",modeling,848194164922461e8,126
plot(rad.2014),visualization,848194164922461e8,126
radlattice(rad.2014),visualization,848194164922461e8,126
"Permutations <- as.data.frame(table(replicate(NumSimulations,      SampleSites())))",export,848194164922461e8,126
"colnames(Permutations) <- c(""NumAntigenic"", ""Frequency"")",modeling,848194164922461e8,126
Permutations$NumAntigenic <- as.integer(as.character(Permutations$NumAntigenic)),data cleaning,848194164922461e8,126
Permutations$Frequency <- as.integer(as.character(Permutations$Frequency)),modeling,848194164922461e8,126
NumEmpirical <- (WithinAntigenic %>% filter(AAChange == sitetype))$NumAntigenic,data cleaning,848194164922461e8,126
"pvalue <- (Permutations %>% filter(NumAntigenic < NumEmpirical) %>%      mutate(pvalue = 1 - sum(Frequency)/NumSimulations) %>% mutate(Gene = ""4-HA"",      AAChange = sitetype, NumSimulations = NumSimulations) %>%      dplyr::select(Gene, AAChange, NumSimulations, pvalue)) %>%      distinct()",data cleaning,848194164922461e8,126
return(pvalue),evaluation,848194164922461e8,126
"PermuteAll <- do.call(rbind, lapply(c(""NS"", ""S""), RunPermutation))",export,848194164922461e8,126
"write.table(PermuteAll, ""analysis/figures/Permutations/AntigenicSitesPermutation.data"",      row.names = FALSE, quote = FALSE)",evaluation,848194164922461e8,126
"write.table(PermuteAll, ""analysis/figures/Permutations/AntigenicSitesPermutation.data"",      row.names = FALSE, quote = FALSE)",export,848194164922461e8,126
"points(c(0, fpr.ms.overS[[3]]), c(0, tpr.ms.overS[[3]]), type = ""l"",      col = ""red"", lty = ""twodash"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave.overS[[3]]), c(0, tpr.wave.overS[[3]]),      type = ""l"", col = ""orange"", lty = ""twodash"")",visualization,848194164922461e8,126
"legend(0.6, 0.4, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10"", ""binomial"", ""beta-binomial (small)""),      col = c(""blue"", ""skyblue"", ""darkgreen"", ""green"", ""red"", ""orange"",          ""black"", ""black""), lty = c(rep(""solid"", 7), ""twodash""),      text.col = ""black"", merge = FALSE, bg = ""white"")",visualization,848194164922461e8,126
dev.off(),visualization,848194164922461e8,126
"pdf(""ROC_withoverB.pdf"")",export,848194164922461e8,126
xmax = 1,visualization,848194164922461e8,126
ymax = 1,visualization,848194164922461e8,126
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms[[1]]), c(0, tpr.ms[[1]]), type = ""l"", col = ""blue"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave[[1]]), c(0, tpr.wave[[1]]), type = ""l"",      col = ""skyblue"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms[[2]]), c(0, tpr.ms[[2]]), type = ""l"", col = ""darkgreen"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave[[2]]), c(0, tpr.wave[[2]]), type = ""l"",      col = ""green"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms[[3]]), c(0, tpr.ms[[3]]), type = ""l"", col = ""red"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave[[3]]), c(0, tpr.wave[[3]]), type = ""l"",      col = ""orange"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms.overB[[1]]), c(0, tpr.ms.overB[[1]]), type = ""l"",      col = ""blue"", lty = ""dashed"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave.overB[[1]]), c(0, tpr.wave.overB[[1]]),      type = ""l"", col = ""skyblue"", lty = ""dashed"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms.overB[[2]]), c(0, tpr.ms.overB[[2]]), type = ""l"",      col = ""darkgreen"", lty = ""dashed"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave.overB[[2]]), c(0, tpr.wave.overB[[2]]),      type = ""l"", col = ""green"", lty = ""dashed"")",visualization,848194164922461e8,126
"points(c(0, fpr.ms.overB[[3]]), c(0, tpr.ms.overB[[3]]), type = ""l"",      col = ""red"", lty = ""dashed"")",visualization,848194164922461e8,126
"points(c(0, fpr.wave.overB[[3]]), c(0, tpr.wave.overB[[3]]),      type = ""l"", col = ""orange"", lty = ""dashed"")",visualization,848194164922461e8,126
"legend(0.6, 0.4, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10"", ""binomial"", ""beta-binomial (big)""),      col = c(""blue"", ""skyblue"", ""darkgreen"", ""green"", ""red"", ""orange"",          ""black"", ""black""), lty = c(rep(""solid"", 7), ""dashed""),      text.col = ""black"", merge = FALSE, bg = ""white"")",visualization,848194164922461e8,126
dev.off(),visualization,848194164922461e8,126
"qs <- group_by(mats, s) %>% summarise(q = logSumExp(lp__) - log(n()))",modeling,848194164922461e8,126
qs$p <- qs$q - logSumExp(qs$q),modeling,848194164922461e8,126
"mats <- merge(mats, qs)",data cleaning,848194164922461e8,126
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",import,848194164922461e8,126
set.seed(parameters$seed),setup,848194164922461e8,126
"newmcmc <- sample_n(mats, 8000, replace = T, weight = exp(mats$p))",evaluation,848194164922461e8,126
"saveRDS(newmcmc, ""analysis/mcmc-runs/ToRaising-Stan-Fit4-resample.RDS"")",export,848194164922461e8,126
"treatment = ""Retinoic""",data cleaning,473797354614362e8,637
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",import,473797354614362e8,637
numSites.list = scan(path),import,473797354614362e8,637
"chr.list = sites.list = vector(""list"", 22)",import,473797354614362e8,637
"for (chr in 1:22) chr.list[[chr]] = rep(chr, numSites.list[chr])",data cleaning,473797354614362e8,637
sites.list[[chr]] = 1:numSites.list[chr],data cleaning,473797354614362e8,637
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,473797354614362e8,637
"save(""chr.list"", ""sites.list"", file = out.path)",export,473797354614362e8,637
"x = gsub(""\\\\_"", ""_"", x)",data cleaning,473797354614362e8,637
"x = gsub(""tabular"", ""longtable"", x)",data cleaning,473797354614362e8,637
"x = gsub(""\\\\begin\\table"", ""%\\\\begin\\table"", x)",communication,473797354614362e8,637
"cat(x, file = ""../Writeup/SupportingInformation/Grammars/GrammarTable.tex"")",export,473797354614362e8,637
"source(""make_kegg_pics.R"")",visualization,473797354614362e8,637
rm(list = ls()),setup,473797354614362e8,637
for (sp.i in sp.list) pa_data <- all_dat_op %>% dplyr::filter(SVSPP ==      sp.i) %>% na.omit,data cleaning,473797354614362e8,637
name <- unique(pa_data$name),data cleaning,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",import,473797354614362e8,637
"cat(paste0(""Starting "", name, "" at "", Sys.time(), "".\n To recreate, make sure: set.seed("",      seed, "")""), file = log_con)",not sure,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"pa_y <- pa_data[, ""PRESENCE""]",data cleaning,473797354614362e8,637
"pa_x <- pa_data[, !colnames(pa_data) %in% c(""LAT"", ""LON"", ""BIOMASS"",      ""PRESENCE"", ""ABUNDANCE"", ""name"", ""SVSPP"", ""YEAR"")]",data cleaning,473797354614362e8,637
"pa_x <- Filter(var, pa_x)",data cleaning,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",setup,473797354614362e8,637
"cat(paste0(""\n\nFirst we'll fit the occupancy model with "", nrow(pa_x),      "" observations and "", ncol(pa_x), "" explanatory variables.\n""),      file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"vsurf_url <- vsurf_bb(file_x = pa_x, file_y = pa_y, ntree = 500,      mtry = floor(sqrt(ncol(pa_x))), nfor_thres = 50, nmin = 5,      nfor_interp = 25, nsd = 1, nfor_pred = 25, parallel = ""true"",      ncores = 20, clusterType = ""FORK"", seed = seed, name = paste0(name,          ""_PA""), save_template = FALSE, username = username, token = token)",import,473797354614362e8,637
stop_condition_fail <- stop_condition_success <- FALSE,evaluation,473797354614362e8,637
"sleepy <- ifelse(length(pa_y) <= 600, length(pa_y), 600)",data cleaning,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",setup,473797354614362e8,637
"cat(paste0(""Sent to BB and will monitor: "", vsurf_url, "" \nevery "",      round(sleepy/60, 2), "" minutes.\n""), file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"while (!stop_condition_fail && !stop_condition_success) log_con <- file(log_name,      open = ""a"")",not sure,473797354614362e8,637
"cat(paste0(""Checking in at "", Sys.time(), "".\n""), file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"out1 <- GET(url = vsurf_url, config = c(authenticate(username,      token, type = ""basic"")), handle = NULL, timeout(3600))",export,473797354614362e8,637
"stop_condition_success <- grepl(""ProcessSucceeded"", as.character(content(out1,      encoding = ""UTF-8"")))",not sure,473797354614362e8,637
"stop_condition_fail <- grepl(""Exception"", as.character(content(out1,      encoding = ""UTF-8"")))",not sure,473797354614362e8,637
Sys.sleep(sleepy),not sure,473797354614362e8,637
"if (stop_condition_success) output_url <- xml2::xml_text(xml2::xml_find_all(xml2::read_xml(out1),      "".//d4science:Data""))",export,473797354614362e8,637
"output_df <- data.frame(NAME = paste0(name, ""_PA""), LOG = output_url[1],      OUTPUT = output_url[2], stringsAsFactors = FALSE)",export,473797354614362e8,637
stop_condition_success <- FALSE,not sure,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",not sure,473797354614362e8,637
"cat(""Success! "", name, ""is all finished and output files can be found: "",      output_url, ""\n\n"", file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"if (stop_condition_fail) log_con <- file(log_name, open = ""a"")",not sure,473797354614362e8,637
"cat(""Shoot! "", name, "" failed."", ""\n\n"", file = log_con)",not sure,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
next,not sure,473797354614362e8,637
"download.file(output_df$LOG, paste0(derived_path, season, ""/"",      name, ""-PA-VSURFlog.txt""), mode = ""wb"", cacheOK = FALSE)",import,473797354614362e8,637
"download.file(output_df$OUTPUT, paste0(derived_path, season,      ""/"", name, ""-PA-VSURFoutput.rds""), mode = ""wb"", cacheOK = FALSE)",import,473797354614362e8,637
"temp_vsurf <- readRDS(paste0(derived_path, season, ""/"", name,      ""-PA-VSURFoutput.rds""))",import,473797354614362e8,637
pa_rf_vars <- names(pa_x)[temp_vsurf$varselect.pred],data cleaning,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",import,473797354614362e8,637
"cat(""P/A VSURF model identified "", pa_rf_vars, "" as the best variables for prediction.\n"",      file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"pa_rf <- pa_data[, c(""PRESENCE"", pa_rf_vars)]",data cleaning,473797354614362e8,637
"pa_rf <- Filter(var, pa_rf)",data cleaning,473797354614362e8,637
"pa_rf[, ""PRESENCE""] <- as.factor(pa_rf[, ""PRESENCE""])",data cleaning,473797354614362e8,637
"pa_rf[, ""PRESENCE""] <- dplyr::recode_factor(pa_rf[, ""PRESENCE""],      `0` = ""ABSENT"", `1` = ""PRESENT"")",data cleaning,473797354614362e8,637
"selection <- caret::createDataPartition(y = pa_rf[, ""PRESENCE""],      p = 0.75, list = FALSE)",modeling,473797354614362e8,637
"pa_rf_train <- pa_rf[selection, ]",data cleaning,473797354614362e8,637
"pa_rf_test <- pa_rf[-selection, ]",data cleaning,473797354614362e8,637
"trainX <- pa_rf_train[, names(pa_rf_train) %in% pa_rf_vars]",data cleaning,473797354614362e8,637
"trainY <- pa_rf_train[, ""PRESENCE""]",data cleaning,473797354614362e8,637
"h <- ifelse(pa_rf_train[, ""PRESENCE""] == ""ABSENT"", 1/(unname(table(pa_rf_train[,      ""PRESENCE""])[""ABSENT""])/length(pa_rf_train[, ""PRESENCE""])),      ifelse(pa_rf_train[, ""PRESENCE""] == ""PRESENT"", 1/(unname(table(pa_rf_train[,          ""PRESENCE""])[""PRESENT""])/length(pa_rf_train[, ""PRESENCE""])),          0))",data cleaning,473797354614362e8,637
strt_time <- Sys.time(),communication,473797354614362e8,637
"train_control <- caret::trainControl(method = ""repeatedcv"", repeats = 5,      number = 10, search = ""random"", classProbs = TRUE, summaryFunction = caret::twoClassSummary,      allowParallel = TRUE, verboseIter = TRUE)",modeling,473797354614362e8,637
"cluster <- parallel::makeCluster(parallel::detectCores() - 1,      type = ""PSOCK"")",modeling,473797354614362e8,637
doParallel::registerDoParallel(cluster),setup,473797354614362e8,637
"wf_pa <- caret::train(x = trainX, y = trainY, method = ""rf"",      trControl = train_control, weights = h, keep.inbag = TRUE,      replace = TRUE, importance = TRUE, metric = ""ROC"", preProc = c(""center"",          ""scale""))",modeling,473797354614362e8,637
parallel::stopCluster(cluster),setup,473797354614362e8,637
foreach::registerDoSEQ(),setup,473797354614362e8,637
stp_time <- Sys.time(),communication,473797354614362e8,637
stp_time - strt_time,communication,473797354614362e8,637
"predRoc <- predict(wf_pa, pa_rf_test, type = ""prob"")",modeling,473797354614362e8,637
"myroc <- pROC::roc(pa_rf_test$PRESENCE, as.vector(predRoc[, 2]))",modeling,473797354614362e8,637
"roc_plot <- pROC::ggroc(myroc) + ggplot2::geom_abline(intercept = 1,      slope = 1, col = ""grey70"") + ggplot2::labs(title = gsub(""_"",      "" "", name), subtitle = paste(""AUC ="", sprintf(""%.3f"", myroc$auc))) +      ggplot2::theme_bw() + ggplot2::coord_equal()",visualization,473797354614362e8,637
"ggplot2::ggsave(paste0(""analysis/figures/"", name, ""-"", season,      ""-"", ""roc.png""), plot = roc_plot)",visualization,473797354614362e8,637
"threshold <- pROC::coords(myroc, x = ""best"", best.method = ""closest.topleft"")[[1]]",evaluation,473797354614362e8,637
"predCut <- factor(ifelse(predRoc[, ""PRESENT""] > threshold, ""PRESENT"",      ""ABSENT""))",evaluation,473797354614362e8,637
"curConfusionMatrix <- caret::confusionMatrix(predCut, pa_rf_test$PRESENCE,      positive = ""PRESENT"")",evaluation,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",export,473797354614362e8,637
"cat(paste0(""PA rf completed.\n"", capture.output(stp_time - strt_time),      ""\nAccuracy = "", round(curConfusionMatrix$overall[1], 2),      "", Kappa = "", round(curConfusionMatrix$overall[2], 2), "", and threshold = "",      threshold, "".\n""), file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"rf_name <- paste0(name, ""-PA-RFmodel"")",communication,473797354614362e8,637
"saveRDS(assign(value = wf_pa, x = rf_name), paste0(derived_path,      season, ""/"", rf_name, "".rds""))",export,473797354614362e8,637
bm_data <- all_dat_op %>% dplyr::filter(SVSPP == sp.i) %>% na.omit,data cleaning,473797354614362e8,637
"bm_data$PRESPROB <- predict(wf_pa, newdata = bm_data, type = ""prob"")[,      2]",data cleaning,473797354614362e8,637
"bm_y <- bm_data[, ""BIOMASS""]",data cleaning,473797354614362e8,637
"bm_x <- bm_data[, !colnames(bm_data) %in% c(""LAT"", ""LON"", ""BIOMASS"",      ""PRESENCE"", ""ABUNDANCE"", ""name"", ""SVSPP"", ""YEAR"")]",data cleaning,473797354614362e8,637
"bm_x <- Filter(var, bm_x)",data cleaning,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",export,473797354614362e8,637
"cat(paste0(""Now we fit the biomass VSURF model with "", nrow(bm_x),      "" observations and "", ncol(bm_x), "" explanatory variables.\n""),      file = log_con)",communication,473797354614362e8,637
close(log_con),export,473797354614362e8,637
"bm_url <- vsurf_bb(file_x = bm_x, file_y = bm_y, ntree = 500,      mtry = max(floor(ncol(bm_x)/3), 1), nfor_thres = 50, nmin = 5,      nfor_interp = 25, nsd = 1, nfor_pred = 25, parallel = ""true"",      ncores = 20, clusterType = ""FORK"", seed = seed, name = paste0(name,          ""_BM""), save_template = FALSE, username = username, token = token)",export,473797354614362e8,637
stop_condition_fail <- stop_condition_success <- FALSE,not sure,473797354614362e8,637
"sleepy <- ifelse(length(bm_y) <= 600, length(bm_y), 600)",not sure,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",communication,473797354614362e8,637
"for (stageDir in stage_directories) stage = substr(stageDir,      1, 1)",not sure,107356313150376e8,638
"cat(paste0(""Sent to BB and will monitor: "", bm_url, "" \nevery "",      round(sleepy/60, 2), "" minutes.\n""), file = log_con)",communication,473797354614362e8,637
close(log_con),export,473797354614362e8,637
"while (!stop_condition_fail && !stop_condition_success) log_con <- file(log_name,      open = ""a"")",export,473797354614362e8,637
"analysisDirectories <- dir(path = stageDir, pattern = ""_analysis"")",import,107356313150376e8,638
"cat(paste0(""Checking in at "", Sys.time(), "".\n""), file = log_con)",export,473797354614362e8,637
close(log_con),export,473797354614362e8,637
"out1 <- GET(url = bm_url, config = c(authenticate(username, token,      type = ""basic"")), handle = NULL, timeout(3600))",import,473797354614362e8,637
"stop_condition_success <- grepl(""ProcessSucceeded"", as.character(content(out1,      encoding = ""UTF-8"")))",not sure,473797354614362e8,637
"stop_condition_fail <- grepl(""Exception"", as.character(content(out1,      encoding = ""UTF-8"")))",not sure,473797354614362e8,637
Sys.sleep(sleepy),not sure,473797354614362e8,637
"if (stop_condition_success) output_bm_url <- xml2::xml_text(xml2::xml_find_all(xml2::read_xml(out1),      "".//d4science:Data""))",not sure,473797354614362e8,637
"output_bm_df <- data.frame(NAME = paste0(name, ""_BM""), LOG = output_bm_url[1],      OUTPUT = output_bm_url[2], stringsAsFactors = FALSE)",export,473797354614362e8,637
stop_condition_success <- FALSE,not sure,473797354614362e8,637
"log_con <- file(log_name, open = ""a"")",export,473797354614362e8,637
"cat(""Success! "", name, ""is all finished and output files can be found: "",      output_bm_url, ""\n\n"", file = log_con)",communication,473797354614362e8,637
close(log_con),not sure,473797354614362e8,637
"if (stop_condition_fail) log_con <- file(log_name, open = ""a"")",import,473797354614362e8,637
"cat(""Shoot! "", name, "" failed."", ""\n\n"", file = log_con)",communication,473797354614362e8,637
close(log_con),export,473797354614362e8,637
next,not sure,473797354614362e8,637
"download.file(output_bm_df$LOG, paste0(""analysis/data/derived_data/"",      season, ""/"", name, ""-BM-VSURFlog.txt""), mode = ""wb"", cacheOK = FALSE)",import,473797354614362e8,637
"download.file(output_bm_df$OUTPUT, paste0(""analysis/data/derived_data/"",      season, ""/"", name, ""-BM-VSURFoutput.rds""), mode = ""wb"", cacheOK = FALSE)",import,473797354614362e8,637
"temp_vsurf <- readRDS(paste0(derived_path, season, ""/"", name,      ""-BM-VSURFoutput.rds""))",import,473797354614362e8,637
bm_rf_vars <- names(bm_x)[temp_vsurf$varselect.pred],data cleaning,473797354614362e8,637
"print(""Done?"")",not sure,974474121117964e8,639
"harshAllmelt = harshAll %>% select(type, est, category, b, mu_1,      lambda_1, mu_2) %>% reshape2::melt(., id.vars = 1:3)",data cleaning,974474121117964e8,639
"ggplot(harshAllmelt, aes(value, fill = category)) + geom_histogram(aes(y = ..density..)) +      facet_grid(variable ~ type) + xlim(0, 20)",visualization,974474121117964e8,639
"load(file = ""analysis/data/subclade_harshness/subclade_harshness_SpecExt.RData"")",import,974474121117964e8,639
library(ggplot2),setup,974474121117964e8,639
"harshAllSpecExt = rbind(harshSpcExt, harshSpcExtClean)",data cleaning,974474121117964e8,639
"harshAllSpecExtmelt = reshape2::melt(harshAllSpecExt, id.vars = 3:5)",data cleaning,974474121117964e8,639
"ggplot(harshAllSpecExtmelt, aes(value, fill = category)) + geom_histogram(aes(y = ..density..)) +      facet_grid(variable ~ type)",visualization,974474121117964e8,639
"pelev_data <- read.table(""./data/pelev_data.txt"", header = TRUE)",import,397864077240229e8,545
"mortality <- predict(r3, preds, type = ""response"", re.form = NA)",modeling,397864077240229e8,545
require(ggplot2),setup,397864077240229e8,545
"pred_diff <- preds[1:16, ]",data cleaning,397864077240229e8,545
pred_diff$diff_mort <- mortality[17:32] - mortality[1:16],data cleaning,397864077240229e8,545
"pred_diff$CI025 <- as.numeric(booted_seedling_mortality[1, 33:48])",data cleaning,397864077240229e8,545
"pred_diff$CI975 <- as.numeric(booted_seedling_mortality[2, 33:48])",data cleaning,397864077240229e8,545
pred_diff$pe <- pelev_data$pe,data cleaning,397864077240229e8,545
"pred_diff$`Different from Zero` <- rep(""diff"", 16)",data cleaning,397864077240229e8,545
"pred_diff$`Different from Zero`[which(pred_diff$CI025 < 0)] <- ""no diff""",modeling,397864077240229e8,545
"pred_diff$Wooddensity <- read.table(""./data/dden_adult.txt"",      header = TRUE)$dden_adult",import,397864077240229e8,545
"write.table(pred_diff, file = ""./analysis/inundation_predicts_species_distributions/data/riskratio.txt"")",export,397864077240229e8,545
"p1 <- ggplot(pred_diff, aes(x = reorder(sp, pe), y = diff_mort,      color = `Different from Zero`)) + geom_errorbar(aes(ymin = CI025,      ymax = CI975), width = 0.5, alpha = 0.5, size = 1) + theme_bw() +      xlab(""Species"") + ylab(""Risk ratio (Mortality)"") + theme(axis.text.x = element_text(face = ""italic"",      angle = 45, vjust = 0.7)) + scale_color_manual(values = c(""black"",      cols[4])) + geom_point(size = 3, pch = 21, fill = ""white"") +      geom_hline(aes(yintercept = 0), linetype = 2, col = cols[5]) +      theme(legend.position = c(0.15, 0.8)) + theme(text = element_text(size = 20))",visualization,397864077240229e8,545
p1,visualization,397864077240229e8,545
"ggsave(p1, file = ""./analysis/seedling_mortality_analysis/graph_code/graphs/species_interaction_mortality_difference.png"",      width = 13, height = 6)",export,397864077240229e8,545
"voteupTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50VoteUp.csv"",      header = TRUE, sep = "";"")",import,986741351895034e8,640
"votedownTop50 = read.csv(""C:\\Users\\thiag_000\\Desktop\\experts-semantic-analysis\\analysis\\bio\\mediasTop50VoteDown.csv"",      header = TRUE, sep = "";"")",import,986741351895034e8,640
event_locations[downswings] = -1,setup,519006379181519e8,641
"concurrent_events = find_concurrent_events(event_locations, 2,      event_types = c(-1, 1))",setup,519006379181519e8,641
"pdf(outfile, width = 14, height = 14)",visualization,519006379181519e8,641
"make_visual(data_mat, event_locations, concurrent_events, log_colors = T,      diverging = T)",visualization,519006379181519e8,641
dev.off(),visualization,519006379181519e8,641
event_locations[downswings] = -1,setup,519006379181519e8,641
"Owners <- read.csv(""/wrk2/efuller/NOAA/Data_Analysis/Ownership/csvVersions/Linked_IFQ_Vessel_Accounts_01-27-14_EFmod_VesselAccounts_Exact.csv"")",import,519006379181519e8,641
"shrimps <- subset(nhObs, sector == ""Pink Shrimp"")",data cleaning,519006379181519e8,641
uniqueShrimps <- unique(shrimps$CG_NUM),data cleaning,519006379181519e8,641
tracks <- unique(VMS$Doc_Number),data cleaning,519006379181519e8,641
captured <- length(uniqueShrimps[which(uniqueShrimps %in% tracks)]),exploratory,519006379181519e8,641
"filtered_d897_nms_domains_withClusters = vector(""list"", 11)",data cleaning,43271685577929e9,642
for (i in 1:length(filtered_d897_nms_domains_withClusters)) filtered_d897_nms_domains_withClusters[[i]] = kmeans_nms_domains_models[[i]]$cluster,setup,43271685577929e9,642
"nms_heatmaps = vector(""list"", 11)",import,43271685577929e9,642
library(RJSONIO),setup,22091217036359e9,643
"load(""9861.RData"")",import,22091217036359e9,643
thresholdPower = 10,not sure,22091217036359e9,643
numRows = 10000,setup,22091217036359e9,643
"datExprR = datExpr[sample(1:nrow(datExpr), numRows, replace = FALSE),      ]",data cleaning,22091217036359e9,643
"net = blockwiseModules(t(datExprR), power = thresholdPower, networkType = ""signed"",      maxBlockSize = numRows)",modeling,22091217036359e9,643
moduleColorsAutomatic = labels2colors(net$colors),visualization,22091217036359e9,643
mColors = moduleColorsAutomatic[net$blockGenes[[1]]],visualization,22091217036359e9,643
x11(),not sure,22091217036359e9,643
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,22091217036359e9,643
module = 1,setup,22091217036359e9,643
me = net$MEs[[module]],data cleaning,22091217036359e9,643
order = order(sampleInfo$order),data cleaning,22091217036359e9,643
color = sampleInfo$color,visualization,22091217036359e9,643
x11(),not sure,22091217036359e9,643
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,22091217036359e9,643
"pdf(""9861.pdf"", width = 6, height = 3, pointsize = 8)",export,22091217036359e9,643
"plotDendroAndColors(net$dendrograms[[1]], colors = mColors, dendroLabels = FALSE,      groupLabels = c(""Module colors""), addGuide = TRUE, main = ""H0351.2001 Cluster Dendrogram"")",visualization,22091217036359e9,643
"barplot(me[order], col = color[order], border = NA, main = ""First Module Eigengene Expression Pattern"")",visualization,22091217036359e9,643
dev.off(),not sure,22091217036359e9,643
"dsHeight2 <- subset(dsHeight, select = c(""CID"", ""CRace"", ""CGender"",      ""htst"", ""age_ht""))",setup,125665127299726e8,644
"colnames(dsHeight1) <- c(""CID"", ""CRace1"", ""CGender1"", ""HtSt1"",      ""AgeHt1"")",exploratory,125665127299726e8,644
"colnames(dsHeight2) <- c(""CID"", ""CRace2"", ""CGender2"", ""HtSt2"",      ""AgeHt2"")",visualization,125665127299726e8,644
"dsLeftHand <- merge(x = dsLinksLeftHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",visualization,125665127299726e8,644
"dsLeftHand <- merge(x = dsLeftHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",data cleaning,125665127299726e8,644
"dsRightHand <- merge(x = dsLinksRightHand, y = dsHeight1, by.x = ""Subject1Tag"",      by.y = ""CID"")",evaluation,125665127299726e8,644
"dsRightHand <- merge(x = dsRightHand, y = dsHeight2, by.x = ""Subject2Tag"",      by.y = ""CID"")",modeling,125665127299726e8,644
"rm(dsLinksLeftHand, dsLinksRightHand, dsHeight1, dsHeight2)",import,125665127299726e8,644
"ds <- rbind(dsLeftHand, dsRightHand)",visualization,125665127299726e8,644
"rm(dsLeftHand, dsRightHand)",import,125665127299726e8,644
"write.csv(ds, pathOutput)",setup,125665127299726e8,644
ageFloor <- 19,communication,125665127299726e8,644
"ds <- subset(ds, AgeHt1 >= ageFloor & AgeHt2 >= ageFloor)",setup,125665127299726e8,644
"ds[is.na(ds$R), ""R""] <- 0.375",modeling,125665127299726e8,644
library(e1071),evaluation,125665127299726e8,644
"brief <- summary(lm(HtSt1 ~ 1 + HtSt2 + R + HtSt2 * R, data = ds))",export,125665127299726e8,644
coeficients <- coef(brief),communication,125665127299726e8,644
count <- length(brief$residuals),setup,125665127299726e8,644
"hSquared <- coeficients[""HtSt2:R"", ""Estimate""]",evaluation,125665127299726e8,644
"cSquared <- coeficients[""HtSt2"", ""Estimate""]",evaluation,125665127299726e8,644
eSquared <- 1 - hSquared - cSquared,evaluation,125665127299726e8,644
mean(ds$HtSt1),evaluation,125665127299726e8,644
sd(ds$HtSt1),not sure,125665127299726e8,644
skewness(ds$HtSt1),modeling,125665127299726e8,644
"dsResult <- data.frame(N = count, H2 = hSquared, C2 = cSquared,      E2 = eSquared, Mean = mean(ds$HtSt1), SD = sd(ds$HtSt1),      Skew = skewness(ds$HtSt1))",setup,125665127299726e8,644
"dsResult <- data.frame(N = count, H2 = hSquared, C2 = cSquared,      E2 = eSquared, Mean = mean(ds$HtSt1), SD = sd(ds$HtSt1),      Skew = skewness(ds$HtSt1))",exploratory,125665127299726e8,644
"total <- rbind(genomeAvgData, bgData, blData, pgData, plData,      bgplData, blpgData, bgblData, pgplData, passengers, solitariesData)",setup,827542608836666e8,645
"svg(filename = ""figures/speciesCopyNumber.svg"", width = 9.5,      height = 4, pointsize = 18)",export,827542608836666e8,645
"ggplot(total, aes(x = factor(segment), y = value, fill = variable,      color = variable)) + geom_point(position = position_jitterdodge(dodge.width = 0.8,      jitter.height = 0.25), size = 0.5) + geom_boxplot(fill = ""white"",      outlier.colour = NA, position = position_dodge(width = 0.8),      notch = TRUE, notchwidth = 0.5) + coord_cartesian(ylim = c(-0.31,      13.31)) + scale_y_continuous(breaks = seq(0, 13, 2)) + scale_color_manual(values = c(""#000000"",      ""#009c73"", ""#e69f00""), name = ""Status"", limits = c(""onetoone"",      ""dup"", ""noortho""), labels = c(""Unchanged"", ""Duplicated"",      ""No ortholog"")) + scale_fill_manual(values = c(""#000000"",      ""#009c73"", ""#e69f00""), name = ""Status"", limits = c(""onetoone"",      ""dup"", ""noortho""), labels = c(""Unchanged"", ""Duplicated"",      ""No ortholog"")) + theme(axis.text.x = element_blank(), axis.text.y = element_text(size = 14),      axis.title.x = element_blank(), legend.position = ""bottom"") +      labs(y = ""Number of species"") + scale_x_discrete(limits = c(""genomeAvg"",      ""solitaries"", ""pg"", ""pl"", ""pgpl"", ""bg"", ""bl"", ""bgbl"", ""bgpl"",      ""blpg"", ""passengers""))",visualization,827542608836666e8,645
dev.off(),not sure,827542608836666e8,645
"total <- rbind(genomeAvgData, bgData, blData, pgData, plData,      bgplData, blpgData, bgblData, pgplData, passengers, solitariesData)",setup,827542608836666e8,645
"for (i in seq(1, (dim(mastersheet)[1]))) strain <- mastersheet[i,      1]",not sure,827542608836666e8,645
"dir <- mastersheet[i, 2]",setup,827542608836666e8,645
print(dir),exploratory,827542608836666e8,645
print(strain),exploratory,827542608836666e8,645
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,      "".md"", sep = """"), quiet = TRUE)",export,827542608836666e8,645
print(dir),exploratory,827542608836666e8,645
print(strain),exploratory,827542608836666e8,645
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",evaluation,827542608836666e8,645
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",evaluation,827542608836666e8,645
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",evaluation,827542608836666e8,645
"test_master_sheet <- (rbind(test1, test2, test3))",data cleaning,827542608836666e8,645
"for (i in seq(1, (dim(test_master_sheet)[1]))) strain <- test_master_sheet[i,      1]",not sure,827542608836666e8,645
"dir <- test_master_sheet[i, 2]",setup,827542608836666e8,645
print(dir),exploratory,827542608836666e8,645
print(strain),exploratory,827542608836666e8,645
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,      "".md"", sep = """"))",export,827542608836666e8,645
print(dir),exploratory,827542608836666e8,645
print(strain),exploratory,827542608836666e8,645
Report,export,506925278808922e8,646
"mods <- list(Ratem1pop1 = model_run(DT, pinsamp = 1, option = 1,      pop = 1), Ratem1pop2 = model_run(DT, pinsamp = 1, option = 1,      pop = 2), Ratem1 = model_run(DT, pinsamp = 1, option = 1,      pop = 1:2))",setup,506925278808922e8,646
"DT[, `:=`(Ratem1pop1, c(mods$Ratem1pop1$RR))]",not sure,506925278808922e8,646
"DT[, `:=`(Ratem1pop2, c(mods$Ratem1pop2$RR))]",not sure,506925278808922e8,646
"DT[, `:=`(Ratem1, c(c(mods$Ratem1$RR)))]",export,506925278808922e8,646
"save(mods, file = ""~/Documents/MXU5MR/analysis/outputs/model_covs.Rdata"")",export,506925278808922e8,646
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,548945621820167e8,647
max(logLR.null),visualization,548945621820167e8,647
wave.null[[2]] = logLR.null,export,548945621820167e8,647
wave.alt[[2]] = logLR.alt,setup,548945621820167e8,647
"plot_india = d_analysis %>% filter(country == ""india"") %>% filter(condition ==      ""animal"") %>% ggplot(aes(x = reorder(swatch, animal_selfrank),      y = mean, label = n)) + geom_bar(stat = ""identity"", position = ""identity"",      width = 0.5) + geom_errorbar(aes(ymin = mean - 2 * sd/sqrt(n),      ymax = mean + 2 * sd/sqrt(n), width = 0.1)) + theme_bw() +      coord_cartesian(ylim = c(-3, 3)) + theme(text = element_text(size = 20),      legend.position = ""none"", axis.text.x = element_text(angle = 60,          hjust = 1)) + labs(title = ""Mean scaled responses, by condition: Indian adults\n"",      x = ""Pictures (sorted by mean Indian adult response to ANIMAL)"") +      stat_smooth(aes(group = 1))",not sure,541526407003403e8,648
plot_india,visualization,541526407003403e8,648
"plot_us = d_analysis %>% filter(country == ""us"") %>% filter(condition ==      ""animal"") %>% ggplot(aes(x = reorder(swatch, animal_selfrank),      y = mean, label = n)) + geom_bar(stat = ""identity"", position = ""identity"",      width = 0.5) + geom_errorbar(aes(ymin = mean - 2 * sd/sqrt(n),      ymax = mean + 2 * sd/sqrt(n), width = 0.1)) + theme_bw() +      coord_cartesian(ylim = c(-3, 3)) + theme(text = element_text(size = 20),      legend.position = ""none"", axis.text.x = element_text(angle = 60,          hjust = 1)) + labs(title = ""Mean scaled responses, by condition: usn adults\n"",      x = ""Pictures (sorted by mean usn adult response to ANIMAL)"") +      stat_smooth(aes(group = 1))",visualization,541526407003403e8,648
plot_us,visualization,541526407003403e8,648
"exprs_combat <- ComBat(exprs(sc), batch, design)",setup,110297321807593e7,649
sc2 <- sc,setup,110297321807593e7,649
exprs(sc2) <- exprs_combat,setup,110297321807593e7,649
"plotPCA(sc2, ncomponents = 3, colour_by = ""plate"")",visualization,110297321807593e7,649
"plotPCA(sc2, ncomponents = 3, colour_by = ""censored"")",visualization,110297321807593e7,649
"plotPCA(sc2, ncomponents = 3, colour_by = ""patient.days_to_birth"")",visualization,110297321807593e7,649
"plotPCA(sc2, ncomponents = 3, colour_by = ""patient.days_to_death"")",visualization,110297321807593e7,649
"plotPCA(sc2, colour_by = ""patient.stage_event.clinical_stage"",      ncomponents = 3)",visualization,110297321807593e7,649
"plotQC(sc2, type = ""find"", var = ""plate"")",visualization,110297321807593e7,649
"plotQC(sc2, type = ""find"", var = ""censored"")",visualization,110297321807593e7,649
"plotQC(sc2, type = ""find"", var = ""patient.days_to_birth"")",visualization,110297321807593e7,649
"plotQC(sc2, type = ""find"", var = ""patient.days_to_death"")",visualization,110297321807593e7,649
"plotQC(sc2, type = ""find"", var = ""patient.stage_event.clinical_stage"")",visualization,110297321807593e7,649
library(ggrepel),setup,110297321807593e7,649
"hgnc_symbols <- sapply(strsplit(featureNames(sc2), ""_""), `[`,      2)",data cleaning,110297321807593e7,649
"dvar <- data_frame(mean = rowMeans(exprs(sc2)), var = matrixStats::rowVars(exprs(sc2)),      hgnc_symbols, gene = featureNames(sc2))",data cleaning,110297321807593e7,649
"ggplot(dvar, aes(x = mean, y = var)) + geom_point(color = ""grey"") +      xlab(""Mean"") + ylab(""Variance"") + geom_text_repel(data = filter(dvar,      var > 8.5), aes(label = hgnc_symbols), color = ""blue"")",visualization,110297321807593e7,649
is_exprs(sce) <- exprs(sce) > 0,visualization,110297321807593e7,649
sce <- calculateQCMetrics(sce),visualization,110297321807593e7,649
"plotHighestExprs(sce, col_by_variable = ""plate"")",visualization,110297321807593e7,649
"plotQC(sc2, type = ""expl"", variables = c(""plate"", ""censored"",      ""patient.age_at_initial_pathologic_diagnosis""))",visualization,110297321807593e7,649
library(rstan),visualization,110297321807593e7,649
library(coda),visualization,110297321807593e7,649
library(MCMCglmm),visualization,110297321807593e7,649
"X <- model.matrix(~censored + patient.age_at_initial_pathologic_diagnosis,      pData(sc2))",visualization,110297321807593e7,649
"X <- t(scale(X[, -1]))",not sure,110297321807593e7,649
"Y <- t(scale(t(exprs(sc2)[matrixStats::rowVars(exprs(sc2)) >      5, ])))",not sure,110297321807593e7,649
"X <- rbind(X, rnorm(ncol(X)))",not sure,110297321807593e7,649
N <- ncol(Y),not sure,110297321807593e7,649
G <- nrow(Y),not sure,110297321807593e7,649
P = nrow(X),not sure,110297321807593e7,649
"dlist <- list(N = N, G = G, P = P, X = X, Y = Y)",not sure,110297321807593e7,649
"model <- stan_model(""~/oxford/phenot/synthetic/phenot.stan"",      model_name = ""phenotime"")",not sure,110297321807593e7,649
"fit <- vb(model, dlist, grad_samples = 3)",not sure,110297321807593e7,649
library(rstan),setup,743626102339476e8,650
rstan_options(auto_write = TRUE),import,743626102339476e8,650
options(mc.cores = parallel::detectCores()),exploratory,743626102339476e8,650
colnames(ARI) <- years,data cleaning,46667206985876e9,651
"for (i in 1:length(grgroups)) for (j in 1:length(years)) ARI[i,      j] <- classAgreement(agreement(grgroups[i], years[j]))$crand",import,46667206985876e9,651
"saveRDS(ARI, ""/Users/efuller/1/CNH/Analysis/Metiers/writing/code/3_analyzeMetiers/adjustRandIndex.RDS"")",export,46667206985876e9,651
"library(""adegenet"")",setup,950373326195404e8,652
"library(""parallel"")",setup,950373326195404e8,652
"load(""gl_1990_merge_rmNA.Rdata"")",import,950373326195404e8,652
"load(""gl_2015_merge_rmNA.Rdata"")",import,950373326195404e8,652
"pca_merge_1990 <- glPca(gl_1990_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",setup,950373326195404e8,652
"save(pca_merge_1990, file = ""pca_merge_1990.Rdata"")",export,950373326195404e8,652
"pca_merge_2015 <- glPca(gl_2015_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",setup,950373326195404e8,652
"save(pca_merge_2015, file = ""pca_merge_2015.Rdata"")",export,950373326195404e8,652
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,594785701949149e8,653
"pp$uci <- unlist(uci[pp[, 2]])",data cleaning,594785701949149e8,653
"cols <- brewer.pal(length(pops), ""Set1"")",visualization,594785701949149e8,653
"cols[6] <- ""darkgrey""",visualization,594785701949149e8,653
"pdf(paste0(out, outname), width = 12, height = 6)",export,594785701949149e8,653
"plot(0, 0, col = ""white"", xlim = c(-8000, 0), ylim = ylim, bty = ""n"",      xlab = ""Years before present"", ylab = ""HERC2 allele frequency"",      xaxt = ""n"")",visualization,594785701949149e8,653
for (i in 1:length(pops)) pop <- pops[i],evaluation,594785701949149e8,653
"int.starts <- pp[pp[, 1] == pop, 3]",exploratory,594785701949149e8,653
"int.ends <- pp[pp[, 1] == pop, 4]",data cleaning,594785701949149e8,653
int.mids <- 0.5 * (int.starts + int.ends),evaluation,594785701949149e8,653
library(coda),setup,234209591988474e8,654
"source(""Analysis/03_Func_GxE.R"")",setup,910071215825155e8,655
"source(""Analysis/03_Func_selection.R"")",setup,910071215825155e8,655
"EUmanifesto <- filter(EUmanifesto, country != 10)",data cleaning,910071215825155e8,655
"EUmanifesto <- filter(EUmanifesto, vote >= -777)",data cleaning,910071215825155e8,655
"ggsave(filename = ""analysis/output/Botero14_HarshnessClean3par_b.png"",      plot = ggb)",visualization,175664250971749e8,656
"n.eff.list <- lapply(kChromList, function(chrom) data.frame(chrom = chrom,      n.eff = ReadColumnViaPipe(sprintf(kSummariesPattern, chrom),          col = kNEffField, skip = 1)))",import,964203155599534e8,657
"n.eff.df <- Reduce(rbind, n.eff.list)",data cleaning,964203155599534e8,657
rm(n.eff.list),data cleaning,964203155599534e8,657
"theta.postmean.list <- lapply(kChromList, function(chrom) data.frame(chrom = chrom,      theta.postmean = ReadColumnViaPipe(sprintf(kSummariesPattern,          chrom), col = kThetaPostmeanField, skip = 1)))",import,964203155599534e8,657
"theta.postmean.df <- Reduce(rbind, theta.postmean.list)",exploratory,964203155599534e8,657
rm(theta.postmean.list),evaluation,964203155599534e8,657
"n.eff.summaries <- c(summary(n.eff.df$n.eff, SD = sd(n.eff.df$n.eff)),      quantile(n.eff.df$n.eff, kQuantiles))",exploratory,964203155599534e8,657
"n.eff.hist <- qplot(x = n.eff.df$n.eff, geom = ""histogram"", binwidth = 25,      xlab = expression(paste(""Effective sample size for "", theta[k])),      ylab = ""Frequency"")",visualization,964203155599534e8,657
"n.eff.scatter <- ggplot(mapping = aes(x = theta.postmean.df$theta.postmean,      y = n.eff.df$n.eff))",visualization,964203155599534e8,657
"n.eff.scatter <- n.eff.scatter + stat_density2d(geom = ""tile"",      contour = FALSE, aes(fill = ..density..))",visualization,964203155599534e8,657
"n.eff.scatter <- n.eff.scatter + ylab(expression(paste(""Effective sample size for "",      theta[k])))",visualization,964203155599534e8,657
"n.eff.scatter <- n.eff.scatter + xlab(expression(paste(""Posterior mean of "",      theta[k])))",visualization,964203155599534e8,657
"print(ascii(data.frame(n.eff.summaries)), type = ""rest"", file = kSummaryPath)",export,964203155599534e8,657
"pdf(kPlotPath, width = 5, height = 3.1, onefile = TRUE)",communication,964203155599534e8,657
theme.default <- theme_get(),visualization,964203155599534e8,657
theme_set(theme_bw()),visualization,964203155599534e8,657
print(n.eff.hist),export,964203155599534e8,657
print(n.eff.scatter),export,964203155599534e8,657
theme_set(theme.default),visualization,964203155599534e8,657
dev.off(),export,964203155599534e8,657
"par(mfrow = c(1, 2))",visualization,964203155599534e8,657
"par(mar = c(4, 4, 2, 0))",visualization,964203155599534e8,657
"hist(SA_notscaled, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200), breaks = 20)",visualization,964203155599534e8,657
"mtext(""(a)"", side = 3, line = 0, at = 0)",visualization,964203155599534e8,657
"hist(SA_richness, xlab = """", main = """", ylab = """", xlim = c(-0.5,      25), ylim = c(0, 200))",visualization,964203155599534e8,657
"mtext(""(b)"", side = 3, line = 0, at = 0)",visualization,964203155599534e8,657
"mtext(""Frequency"", side = 2, outer = TRUE, line = -1.5, las = 0,      at = 0.55)",visualization,964203155599534e8,657
"mtext(""% Change"", side = 1, outer = TRUE, line = -1.5, las = 0)",visualization,964203155599534e8,657
dev.off(),export,964203155599534e8,657
parameterization <- as.character(args[1]),data cleaning,964203155599534e8,657
i_dataset <- as.integer(args[2]),data cleaning,964203155599534e8,657
n_repetition <- as.integer(args[3]),data cleaning,964203155599534e8,657
"model_name <- ""DDM""",modeling,964203155599534e8,657
"project_dir <- rprojroot::find_root(rprojroot::has_file(""DESCRIPTION""))",setup,964203155599534e8,657
"analysis_dir <- file.path(project_dir, ""analysis"")",setup,964203155599534e8,657
"notebook_reports_dir <- file.path(project_dir, ""data"", ""reports"",      ""notebooks"")",setup,964203155599534e8,657
"optimizations_dir <- file.path(project_dir, ""data"", ""optimizations"")",setup,964203155599534e8,657
"notebook_name <- ""parameter_and_model_recovery""",communication,964203155599534e8,657
"rmd_file <- file.path(analysis_dir, ""parameter_and_model_recovery.Rmd"")",setup,964203155599534e8,657
"itchmodel::verify_output_dirs(base_dirs = list(optimizations_dir,      notebook_reports_dir), notebook_name = notebook_name)",export,964203155599534e8,657
"input <- file.path(analysis_dir, ""parameter_and_model_recovery.Rmd"")",setup,964203155599534e8,657
"output_format <- ""html""",export,964203155599534e8,657
"fmt <- ""parameter_and_model_recovery_model_%s_parameterization_%s_ix_%d_nrep_%d.html""",communication,964203155599534e8,657
"output_file <- sprintf(fmt = fmt, model_name, parameterization,      i_dataset, n_repetition)",export,964203155599534e8,657
"output_dir <- file.path(notebook_reports_dir, notebook_name)",export,964203155599534e8,657
"rmarkdown::render(input = input, output_file = output_file, output_dir = output_dir,      params = list(parameterization = parameterization, i_dataset = i_dataset,          n_repetition = n_repetition))",communication,964203155599534e8,657
"gs_all <- define_participationPlot(c(2009, 2010, 2011, 2012,      2013))",visualization,964203155599534e8,657
"graphs <- list(gs_09, gs_10, gs_11, gs_12, gs_13, pre_ITQ, post_ITQ,      gs_all, l)",visualization,964203155599534e8,657
"saveRDS(graphs, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/particp_graph.RDS"")",export,964203155599534e8,657
"mat <- matrix(nrow = length(mets), ncol = length(mets))",setup,964203155599534e8,657
colnames(mat) <- mets,setup,964203155599534e8,657
rownames(mat) <- mets,setup,964203155599534e8,657
"for (i in 1:nrow(mat)) cat(i, "":\n"")",exploratory,964203155599534e8,657
for (j in i:ncol(mat)) sub_i <- tickets$veid[which(tickets$metier ==      rownames(mat)[i])],exploratory,964203155599534e8,657
sub_j <- tickets$veid[which(tickets$metier == colnames(mat)[j])],exploratory,964203155599534e8,657
"mat[i, j] <- length(union(sub_i, sub_j))",data cleaning,964203155599534e8,657
"cat(j, "" "")",not sure,964203155599534e8,657
"cat(""\n"")",not sure,964203155599534e8,657
"g2 <- graph.adjacency(mat, weighted = TRUE, mode = ""undirected"",      diag = FALSE)",visualization,964203155599534e8,657
V(g2)$size <- diag(mat),modeling,964203155599534e8,657
"plot(g2, edge.width = log(E(g2)$weight)/10, layout = layout.fruchterman.reingold,      vertex.size = 5)",visualization,964203155599534e8,657
"port_popularity <- ddply(tickets, .(pcid), summarize, num_Ves = length(unique(veid)))",exploratory,964203155599534e8,657
"port_popularity <- port_popularity[order(port_popularity$num_Ves,      decreasing = T), ]",data cleaning,964203155599534e8,657
"gs09NEW <- define_participationPlot(2009, ""NEW"")",visualization,964203155599534e8,657
"gs09COS <- define_participationPlot(2009, ""COS"")",visualization,964203155599534e8,657
"gs09AST <- define_participationPlot(2009, ""AST"")",visualization,964203155599534e8,657
"gs09SF <- define_participationPlot(2009, ""SF"")",visualization,964203155599534e8,657
"gs09BFG <- define_participationPlot(2009, ""BRG"")",visualization,964203155599534e8,657
"gs09WPT <- define_participationPlot(2009, ""WPT"")",visualization,964203155599534e8,657
"gs09LWC <- define_participationPlot(2009, ""LWC"")",visualization,964203155599534e8,657
"gs09BDG <- define_participationPlot(2009, ""BDG"")",visualization,964203155599534e8,657
"gs09PRN <- define_participationPlot(2009, ""PRN"")",visualization,964203155599534e8,657
"gs09TLL <- define_participationPlot(2009, ""TLL"")",visualization,964203155599534e8,657
"top_ports <- list(gs09NEW, gs09COS, gs09AST, gs09SF, gs09BFG,      gs09WPT, gs09LWC, gs09BDG, gs09PRN, gs09TLL)",exploratory,964203155599534e8,657
"saveRDS(top_ports, ""/Users/efuller/1/CNH/Analysis/Metiers/results/2014-10-08/top_ports.RDS"")",export,964203155599534e8,657
"names(top_ports) = c(""newport"", ""coos bay"", ""astoria"", ""san francisco"",      ""bfg"", ""westport"", ""illawco"", ""bdg"", ""princeton"", ""tll"")",data cleaning,964203155599534e8,657
"degree <- lapply(top_ports, degree)",exploratory,964203155599534e8,657
degree <- melt(unlist(degree)),data cleaning,964203155599534e8,657
"source(""make_supp_tables.R"")",setup,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"source(""make_volcano.R"")",setup,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"source(""make_mabox.R"")",setup,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"source(""make_venn.R"")",setup,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"knitr::knit(""kegg.Rmd"")",setup,874289061641321e8,658
"rmarkdown::render(""kegg.md"")",visualization,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"source(""make_kegg_pics.R"")",import,874289061641321e8,658
rm(list = ls()),setup,874289061641321e8,658
"source(""make_supp_tables.R"")",import,874289061641321e8,658
library(synapseClient),import,874289061641321e8,658
library(tidyverse),import,874289061641321e8,658
library(pheatmap),import,874289061641321e8,658
"this.script <- ""https://raw.githubusercontent.com/sgosline/pnfCellLines/master/analysis/2017-12-05/nf1SurvAnalysis.R""",setup,874289061641321e8,658
synapseLogin(),setup,874289061641321e8,658
"geneVals <- read.csv(synGet(""syn11274043"")@filePath)",import,874289061641321e8,658
"geneVals$NFStatus <- rep(""Up in NF1 Mutants"", nrow(geneVals))",evaluation,874289061641321e8,658
"geneVals$NFStatus[which(geneVals$b < 0)] <- ""Down in NF1 Mutants""",evaluation,874289061641321e8,658
"df_analysis = df_analysis %>% group_by(jobid, type, tgt) %>%      mutate(class = paste(type, tgt, sep = ""_""))",not sure,452017180388793e8,659
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,254667043685913e8,660
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,254667043685913e8,660
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,254667043685913e8,660
dir.create(path_gmt),setup,684141803300008e8,661
"rda_filename <- file.path(""/data/liucj/project/06-autophagy/20-rda"",      ""01-autophagy-and-hallmarks-expresson.rda"")",import,684141803300008e8,661
load(file = rda_filename),import,684141803300008e8,661
"fn_gsea <- function(.ds, .cls, .db, .output, .doc) GSEA(input.ds = .ds,      input.cls = .cls, gs.db = .db, output.directory = .output,      doc.string = .doc, non.interactive.run = F, reshuffling.type = ""gene.labels"",      nperm = 1000, weighted.score.type = 1, nom.p.val.threshold = -1,      fwer.p.val.threshold = -1, fdr.q.val.threshold = 0.25, topgs = 50,      adjust.FDR.q.val = F, gs.size.threshold.min = 10, gs.size.threshold.max = 1000,      reverse.sign = F, preproc.type = 0, random.seed = 111, perm.type = 0,      fraction = 1, replace = F, save.intermediate.results = F,      OLD.GSEA = F, use.fast.enrichment.routine = T)",setup,684141803300008e8,661
"fn_run_gsea <- function(.x, .path = gsea_path, script_path = script_path) .gct <- file.path(.path,      glue::glue("".x_as_classify_mrna.gct""))",setup,684141803300008e8,661
".cls <- file.path(.path, glue::glue("".x_as_classify_mrna.cls""))",setup,684141803300008e8,661
".gmt <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis/GSEA-collections-gmt/C2_CURATED.gmt""",setup,684141803300008e8,661
".output_dir <- file.path(.path, ""02-c2-curated-result/"")",setup,684141803300008e8,661
".doc <- paste(.x, ""GSEA.analysis"", sep = ""."")",export,684141803300008e8,661
if (!file.exists(.output_dir)) dir.create(.output_dir),setup,684141803300008e8,661
"source(file.path(script_path, ""GSEA.1.0.r""))",setup,684141803300008e8,661
"fn_gsea(.ds = .gct, .cls = .cls, .db = .gmt, .output = .output_dir,      .doc = .doc)",setup,684141803300008e8,661
"fn_run_gsea(.x = ""pancan"", .path = path_gsea_all, script_path = path_script)",setup,684141803300008e8,661
"results <- data.frame(pops = colnames(totals), size = apply(totals,      2, max), effective.size = colMeans(totals))",import,996786241885275e8,662
"write.table(results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,996786241885275e8,662
"read.results <- data.frame(pops = colnames(read.totals), effective.size = colMeans(read.totals))",import,996786241885275e8,662
"write.table(read.results, paste0(""~/selection/analysis/"", version,      ""/effsize/effective_sample_size_reads.txt""), row.names = FALSE,      col.names = FALSE, quote = FALSE, sep = ""\t"")",export,996786241885275e8,662
"RunAnalysis <- function() print(t.test(mobileCyc, desktopCyc,      alternative = ""two.sided"", var.equal = FALSE))",evaluation,131674443604425e8,663
hist(log10(mn.homes$sale.price.n)),visualization,131674443604425e8,663
"summary(mn.homes[which(mn.homes$sale.price.n < 1e+05), ])",exploratory,131674443604425e8,663
filter.cut = 60,data cleaning,477157585788518e8,663
pval = pval.deseq.3.60,data cleaning,477157585788518e8,663
"deseq.alt = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",import,477157585788518e8,663
"deseq.null = as.numeric(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.min.pval."",      filter.cut, "".txt""))[, 1])",import,477157585788518e8,663
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,477157585788518e8,663
xmax = 1,setup,477157585788518e8,663
xmin = 0,setup,477157585788518e8,663
"par(mfrow = c(3, 1))",setup,477157585788518e8,663
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,477157585788518e8,663
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,477157585788518e8,663
"hist(pval[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : pvalue "", length(pval) - length(del.ix.deseq)), xlim = c(xmin,      xmax), xlab = ""p=value"")",visualization,477157585788518e8,663
dev.off(),setup,477157585788518e8,663
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,477157585788518e8,663
"pdf(""hist.statistic.pval.DESeq2.debug.discrete.pooling.pdf"")",export,477157585788518e8,663
filter.cut = 0,setup,477157585788518e8,663
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",import,477157585788518e8,663
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",import,477157585788518e8,663
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,477157585788518e8,663
xmax = 1,setup,477157585788518e8,663
xmin = 0,setup,477157585788518e8,663
"par(mfrow = c(2, 1))",setup,477157585788518e8,663
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,477157585788518e8,663
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,477157585788518e8,663
filter.cut = 10,setup,477157585788518e8,663
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".alt.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",import,477157585788518e8,663
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 300, "".null.run/output/DESeq2.all.pval."",      filter.cut, "".txt""))))",import,477157585788518e8,663
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",setup,477157585788518e8,663
"tmp <- TreeCmp.Read(""Chain"", verbose = TRUE)",modeling,395813846262172e8,664
"ML_bootstraps <- NTS(tmp, Random51)",modeling,395813846262172e8,664
"setwd(""../../../../Analysis"")",setup,395813846262172e8,664
"save(ML_bootstraps, file = ""../Data/R_data/TreeCmp-ML_bootstraps.Rda"")",export,395813846262172e8,664
"setwd(""../Data/Tree_Comparisons/Bayesian/consensus"")",setup,395813846262172e8,664
"tmp <- TreeCmp.Read(""Chain"", verbose = TRUE)",modeling,395813846262172e8,664
"Bayesian_contrees <- NTS(tmp, Random51)",modeling,395813846262172e8,664
"setwd(""../../../../Analysis"")",setup,395813846262172e8,664
"save(Bayesian_contrees, file = ""../Data/R_data/TreeCmp-Bayesian_contrees.Rda"")",export,395813846262172e8,664
"setwd(""../Data/Tree_Comparisons/Bayesian/treesets"")",setup,395813846262172e8,664
"tmp <- TreeCmp.Read(""Chain"", verbose = TRUE)",modeling,395813846262172e8,664
"Bayesian_treesets <- NTS(tmp, Random51)",modeling,395813846262172e8,664
"setwd(""../../../../Analysis"")",setup,395813846262172e8,664
"save(Bayesian_treesets, file = ""../Data/R_data/TreeCmp-Bayesian_treesets.Rda"")",export,395813846262172e8,664
"par_ML <- c(1, 26, 51, 76, 101)",evaluation,395813846262172e8,664
"par_MF <- c(1, 6, 11, 16, 21)",setup,395813846262172e8,664
par_MC <- c(1:5),setup,395813846262172e8,664
"par_MLMF <- c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61,      66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121)",setup,395813846262172e8,664
"par_MLMC <- c(1:5, 26:30, 51:55, 76:80, 101:105)",setup,395813846262172e8,664
par_MFMC <- c(1:25),setup,395813846262172e8,664
par_MLMFMC <- c(1:125),modeling,395813846262172e8,664
"cat(""Four different datasets have been loaded:\n\n    ML_besttrees\n    ML_bootstraps\n    Bayesian_contrees\n    Bayesian_treesets\n\nAnd 7 parameters combination sets:\n\n    par_ML ; par_MF ; par_MC ;\n    par_MLMF ; par_MLMC ; par_MFMC ;\n    par_MLMFMC ;"")",communication,395813846262172e8,664
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,664803134044632e8,665
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,664803134044632e8,665
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,664803134044632e8,665
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,664803134044632e8,665
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,664803134044632e8,665
"par(mar = c(1, 4, 1, 1), cex = 0.97)",setup,664803134044632e8,665
"M_partFlags = matrix(c(2996, 24, 1764, 711, 397, 943, 0), ncol = 1,      byrow = T)",setup,664803134044632e8,665
"rownames(M_partFlags) = c(""IGNORECASE 2,996 (43.8%)"", ""LOCALE 24 (0.4%)"",      ""MULTILINE 1,764 (25.8%)"", ""DOTALL 711 (10.4%)"", ""UNICODE 397 (5.8%)"",      ""VERBOSE 943 (13.8%)"", ""multiple flags 0 (0%)"")",data cleaning,664803134044632e8,665
set.seed(20110330),setup,125346265733242e8,666
samples <- 1000,setup,125346265733242e8,666
"additive.model <- function(y, z, b, tau) y - as.numeric(z) *      tau",modeling,125346265733242e8,666
"model1 <- min.max.model(additive.model, lower = 0, upper = 6)",modeling,125346265733242e8,666
twins$match <- propensity$matching[row.names(twins)],exploratory,125346265733242e8,666
"twins.complete <- twins[twins$ideology.complete & !is.na(twins$match),      ]",data cleaning,125346265733242e8,666
"analysis.m1 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,      twins.complete$treated * 1, test.stat = mean.difference,      moe = model1, samples = samples, parameters = list(tau = seq(-0.9,          0.3, 0.05)))",modeling,125346265733242e8,666
"tmp <- function(y, z, b, beta) round(y/beta^(as.numeric(z)))",modeling,125346265733242e8,666
"model2 <- min.max.model(tmp, lower = 0, upper = 6)",modeling,125346265733242e8,666
"analysis.m2 <- parameterizedRandomizationDistribution(twins.complete$ideology.abs,      twins.complete$treated * 1, test.stat = mean.difference,      moe = model2, samples = samples, parameters = list(beta = c(8:18)/20))",modeling,125346265733242e8,666
"save(file = ""analysis/randomization-inference.rda"", analysis.m1,      analysis.m2, twins.complete)",export,125346265733242e8,666
set.seed(20110330),setup,125346265733242e8,666
"source(""support_functions/plotting/make_visual.R"")",import,125346265733242e8,666
"source(""support_functions/load_data.R"")",import,125346265733242e8,666
"file_list = c(""analysis/F/replicates/shared_F_0mM.csv"", ""analysis/F/replicates/shared_F_10mM.csv"",      ""analysis/F_subtract/F_subtract.csv"")",setup,125346265733242e8,666
"outfile = ""analysis/F/compare_F_and_F_subtract.pdf""",export,125346265733242e8,666
"data_mat = load_data(""example_data/other_data/F_subtract.txt"")",import,125346265733242e8,666
"event_locations1 = read.csv(file_list[[1]], row.names = 1)",import,125346265733242e8,666
"event_locations2 = read.csv(file_list[[2]], row.names = 1)",import,125346265733242e8,666
event_locations3 = read.csv(file_list[[3]]),import,125346265733242e8,666
"get_event_group <- function(event_locations_temp, event_group) return(sapply(1:ncol(event_locations_temp),      function(i) event_locations_temp[, i] %in% event_group))",exploratory,125346265733242e8,666
"event_group = c(1, 3, -1.5)",setup,125346265733242e8,666
"upswings = ((get_event_group(event_locations1, -c(event_group,      2, -2, 0)) & get_event_group(event_locations2, event_group)) &      get_event_group(event_locations3, event_group)) | ((get_event_group(event_locations1,      -event_group) & get_event_group(event_locations2, c(event_group,      2, -2, 0))) & get_event_group(event_locations3, event_group))",data cleaning,125346265733242e8,666
"downswings = ((get_event_group(event_locations1, c(event_group,      2, -2, 0)) & get_event_group(event_locations2, -event_group)) &      get_event_group(event_locations3, -event_group)) | ((get_event_group(event_locations1,      event_group) & get_event_group(event_locations2, -c(event_group,      2, -2, 0))) & get_event_group(event_locations3, -event_group))",data cleaning,125346265733242e8,666
event_locations = upswings * 0,data cleaning,125346265733242e8,666
event_locations[upswings] = 1,data cleaning,125346265733242e8,666
event_locations[downswings] = -1,data cleaning,125346265733242e8,666
"concurrent_events = find_concurrent_events(event_locations, 2,      event_types = c(-1, 1))",data cleaning,125346265733242e8,666
"pdf(outfile, width = 14, height = 14)",visualization,125346265733242e8,666
"make_visual(data_mat, event_locations, concurrent_events, log_colors = T,      diverging = T)",visualization,125346265733242e8,666
dev.off(),visualization,125346265733242e8,666
"path_obj <- ""~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/data_objects""",import,125346265733242e8,666
"ggplot(param.summ, aes(x = epoch)) + stat_summary(aes(y = train_loss,      color = nlayers), fun.y = ""mean"", geom = ""line"") + ggsave(""analysis/charts/epoch-train_loss-nlayers.pdf"",      device = ""pdf"")",visualization,125346265733242e8,666
"ggplot(param.summ) + geom_bar(aes(emsize, epoch_time), stat = ""summary"",      fun.y = ""mean"")",visualization,125346265733242e8,666
"ggplot(param.summ) + geom_bar(aes(nlayers, epoch_time), stat = ""summary"",      fun.y = ""mean"")",visualization,125346265733242e8,666
"param.summ.optimal <- subset(param.summ, nhid == ""64"" & emsize ==      ""500"" & nlayers == ""2"")",data cleaning,125346265733242e8,666
"param.summ.speaker <- read_csv(""results/include_speaker/summary.txt"")",import,125346265733242e8,666
"param.summ.speaker <- merge(param.summ.optimal, param.summ.speaker,      all = TRUE)",data cleaning,125346265733242e8,666
param.summ.speaker$emsize <- as.factor(param.summ.speaker$emsize),data cleaning,125346265733242e8,666
param.summ.speaker$nhid <- as.factor(param.summ.speaker$nhid),data cleaning,125346265733242e8,666
param.summ.speaker$nlayers <- as.factor(param.summ.speaker$nlayers),data cleaning,125346265733242e8,666
summary(param.summ.speaker),exploratory,125346265733242e8,666
"spkr.acc = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_acc,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""Accuracy"", x = ""Number of epochs"", y = ""Mean proportion correct\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"spkr.loss = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_loss,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""Loss"", x = ""Number of epochs"", y = ""Mean loss\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"spkr.f = ggplot(param.summ.speaker, aes(x = epoch)) + stat_summary(aes(y = val_f,      color = ignore_speaker), fun.y = ""mean"", geom = ""line"") +      labs(title = ""F-Score"", x = ""Number of epochs"", y = ""Mean F-score\non validation set"",          color = ""Use speaker info"") + scale_color_manual(labels = c(""Yes"",      ""No""), values = c(""#F8766D"", ""#00BFC4"")) + theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"ggsave(""analysis/charts/spkr/epoch-val-acc.jpeg"", spkr.acc +      guides(color = FALSE), width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/spkr/epoch-val-f.jpeg"", spkr.f + guides(color = FALSE),      width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/spkr/epoch-val-loss.jpeg"", spkr.loss,      width = 3.375, height = 2)",export,125346265733242e8,666
"param.summ.optimal <- subset(param.summ.speaker, ignore_speaker ==      ""False"")",data cleaning,125346265733242e8,666
"param.summ.optimal$full_context = rep(""True"", nrow(param.summ.optimal))",data cleaning,125346265733242e8,666
"param.summ.context <- read_csv(""results/partial_context/summary.txt"")",import,125346265733242e8,666
"param.summ.context <- merge(param.summ.context, param.summ.optimal,      all = TRUE)",data cleaning,125346265733242e8,666
"cont.acc = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_acc,      color = full_context, group = save) + geom_line() + labs(title = ""Accuracy"",      x = ""Number of epochs"", y = ""Proportion correct\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"cont.loss = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_loss,      color = full_context, group = save) + geom_line() + labs(title = ""Loss"",      x = ""Number of epochs"", y = ""Loss\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"cont.f = ggplot(param.summ.context, aes(x = epoch)) + aes(y = val_f,      color = full_context, group = save) + geom_line() + labs(title = ""F-score"",      x = ""Number of epochs"", y = ""F-score\non validation set"",      color = ""Amount of context"") + theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"ggsave(""analysis/charts/context/epoch-val-acc.jpeg"", cont.acc +      guides(color = FALSE), width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/context/epoch-val-f.jpeg"", cont.f + guides(color = FALSE),      width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/context/epoch-val-loss.jpeg"", cont.loss +      labs(color = ""Amount of context"") + scale_color_manual(labels = c(""Current utterance"",      ""Full discourse""), values = c(""#F8766D"", ""#00BFC4"")), width = 3.375,      height = 2)",export,125346265733242e8,666
"param.summ.rnn <- read_csv(""results/rnns/summary.txt"")",import,125346265733242e8,666
"param.summ.rnn <- merge(param.summ.rnn, param.summ.optimal, all = TRUE)",data cleaning,125346265733242e8,666
"param.summ.rnn <- subset(param.summ.rnn, model != ""RNN_RELU"")",data cleaning,125346265733242e8,666
"rnn.acc = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_acc,      color = model, group = save) + geom_line() + labs(title = ""Accuracy"",      x = ""Number of epochs"", y = ""Proportion correct\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"rnn.loss = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_loss,      color = model, group = save) + geom_line() + labs(title = ""Loss"",      x = ""Number of epochs"", y = ""Loss\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"rnn.f = ggplot(param.summ.rnn, aes(x = epoch)) + aes(y = val_f,      color = model, group = save) + geom_line() + labs(title = ""F-score"",      x = ""Number of epochs"", y = ""F-score\non validation set"") +      theme(plot.title = element_text(hjust = 0.5))",visualization,125346265733242e8,666
"ggsave(""analysis/charts/rnn/epoch-val-acc.jpeg"", rnn.acc + guides(color = FALSE),      width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/rnn/epoch-val-f.jpeg"", rnn.f + guides(color = FALSE),      width = 2.25, height = 2)",export,125346265733242e8,666
"ggsave(""analysis/charts/rnn/epoch-val-loss.jpeg"", rnn.loss +      labs(color = ""Recurrent Unit Type""), width = 3.375, height = 2)",export,125346265733242e8,666
"unevaluated_promise_type <- analyses$`unevaluated-promise-type` %>%      select(promise_type, promise_expression_type, count) %>%      mutate(evaluated = ""U"")",data cleaning,878325102152303e8,667
"promise_type <- evaluated_promise_type %>% rbind(unevaluated_promise_type) %>%      group_by(promise_type, promise_expression_type, evaluated) %>%      summarize(count = sum(as.numeric(count))) %>% ungroup()",data cleaning,878325102152303e8,667
total_count <- sum(as.numeric(promise_type$count)),exploratory,878325102152303e8,667
"promise_type <- promise_type %>% mutate(promise_type = ifelse(promise_type ==      ""ca"", ""Custom argument"", ifelse(promise_type == ""na"", ""Non argument"",      ""Default argument"")), evaluated = ifelse(evaluated == ""E"",      ""Evaluated"", ""Unevaluated"")) %>% spread(evaluated, count,      fill = 0) %>% mutate(All = Evaluated + Unevaluated)",data cleaning,878325102152303e8,667
list(promise_type = promise_type),not sure,878325102152303e8,667
"source(""Analysis/UsefulFunctions.R"")",setup,582658224739134e8,668
"data4 <- data.frame(Lat = data3$Lat, Long = data3$Long, Dist = 500,      Type = rep(""movie_theater|bar|night_club"", 21613))",import,582658224739134e8,668
start <- 1,setup,582658224739134e8,668
end <- 2,setup,582658224739134e8,668
"data15 <- rep(21, end - start + 1)",import,582658224739134e8,668
"for (i in start:end) data15[i] <- geo(i, data4)",import,582658224739134e8,668
"source(""Analysis/Data/ZillowAPICalls.R"")",setup,196458387188613e8,669
"source(""Analysis/Data/ZillowAPICalls2.R"")",setup,196458387188613e8,669
"source(""Analysis/Data/ZillowAPICalls3.R"")",setup,196458387188613e8,669
"Marriages <- rbind(Marriages, MarriageBerHam)",data cleaning,196458387188613e8,669
rm(MarriageBerHam),data cleaning,196458387188613e8,669
"names(Marriages)[names(Marriages) == ""verheiratet / eingetragene Lebenspartnerschaft""] <- ""marriageTotal""",data cleaning,196458387188613e8,669
"write.csv(Marriages, file = ""Analysis/data/Marriages2.csv"")",export,196458387188613e8,669
"Marriages <- rbind(Marriages, MarriageBerHam)",data cleaning,196458387188613e8,669
"plot(port_link$ic_pre, port_link$eff.shannon_2010, cex = 0.45,      col = ""black"", pch = 3, bty = ""n"", xlab = expression(C[pre]),      ylab = expression(H[pre]))",visualization,196458387188613e8,669
dev.off(),setup,196458387188613e8,669
"plot(ic_pre ~ before.nves, port_link, cex = 0.45, pch = 3, bty = ""n"")",visualization,196458387188613e8,669
"plot(eff.shannon_2010 ~ before.nves, port_link, cex = 0.45, pch = 3,      bty = ""n"")",visualization,196458387188613e8,669
"abline(lm(ic_pre ~ before.nves, port_link))",visualization,196458387188613e8,669
"display(lm(ic_pre ~ before.nves, port_link))",visualization,196458387188613e8,669
"d <- kde2d(port_link$ic_delta, port_link$delta.eff.shannon_2010)",data cleaning,196458387188613e8,669
image(d),exploratory,196458387188613e8,669
"contour(d, add = T, col = ""grey10"")",visualization,196458387188613e8,669
"points(port_link$ic_delta, port_link$delta.eff.shannon_2010,      cex = 0.15, col = ""steelblue"")",visualization,196458387188613e8,669
"pred1$p <- predict(r3, pred1, type = ""response"", re.form = ~0)",evaluation,196458387188613e8,669
"pred1$lo <- predict(r3, pred1, re.form = ~0)",evaluation,196458387188613e8,669
"rr <- with(pred1, tapply(p, sp, diff))",evaluation,196458387188613e8,669
"riskratio_data <- data.frame(sp = levels(data$sp), rr = rr)",evaluation,196458387188613e8,669
"write.table(riskratio_data, file = ""./analysis/seedling_mortality_analysis/data/riskratio_data.txt"")",export,196458387188613e8,669
"geneOut = ""analysis//01.Gene Selection/Fold""",import,196458387188613e8,669
"rotationOut = ""analysis//01.Gene Selection/Rotation""",import,196458387188613e8,669
"rotSelOut = ""analysis/01.Gene Selection/RotSel""",import,196458387188613e8,669
cores = 15,data cleaning,196458387188613e8,669
"rotateSelect(rotationOut, rotSelOut, cores = cores)",data cleaning,196458387188613e8,669
"rotateSelect(paste0(rotationOut, 2), paste0(rotSelOut, 2), cores = cores)",data cleaning,196458387188613e8,669
"allGenes = list(genes1 = allPuristOut(paste0(rotSelOut, ""/Relax"")),      genes2 = allPuristOut(paste0(rotSelOut, ""2"", ""/Relax"")))",import,196458387188613e8,669
for (n in 1:len(allGenes)) genes = allGenes[[n]],data cleaning,196458387188613e8,669
"for (i in 1:len(genes)) pieces = strsplit(names(genes)[i], ""_"")[[1]]",data cleaning,196458387188613e8,669
if (is.na(pieces[2])) pieces[2] = pieces[1],data cleaning,196458387188613e8,669
"pieces[1] = ""All""",data cleaning,196458387188613e8,669
"dir.create(paste0(""analysis//01.Gene Selection/FinalGenes"", n,      ""/"", pieces[2], ""/"", pieces[1]), showWarnings = F, recursive = T)",setup,196458387188613e8,669
"for (j in 1:len(genes[[i]])) write.table(genes[[i]][[j]], paste0(""analysis/01.Gene Selection/FinalGenes"",      n, ""/"", pieces[2], ""/"", pieces[1], ""/"", names(genes[[i]])[j]),      row.names = F, quote = F, col.names = F)",not sure,196458387188613e8,669
"system(""rm -rf \""analysis/01.Gene Selection/FinalGenes/\"""")",not sure,196458387188613e8,669
"MCstats0109 = read.csv(""analysis/04MonteCarloSim/Revision/Model3/k4000/LWRMonteCarloStats2014-04-09.csv"")",setup,109369089594111e8,670
"MCstats1034 = read.csv(""analysis/04MonteCarloSim/Revision/Model3/k4000/LWRMonteCarloStats2014-04-13.csv"")",setup,109369089594111e8,670
"MCstats = rbind(MCstats0109, MCstats1034)",import,109369089594111e8,670
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,609454602468759e8,671
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,609454602468759e8,671
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,609454602468759e8,671
"path <- c(getwd(), filepath2)",setup,609454602468759e8,671
"path <- paste(path, collapse = """")",setup,609454602468759e8,671
"colMeans(Res[[1]][, 5:8])",setup,351842617383227e8,672
"colMeans(Res[[2]][, 1:4])",setup,351842617383227e8,672
"colMeans(Res[[2]][, 5:8])",setup,351842617383227e8,672
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",setup,351842617383227e8,672
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",setup,351842617383227e8,672
"colMeans(Res[[1]][, 5:8])",setup,351842617383227e8,672
"colMeans(Res[[2]][, 5:8])",setup,351842617383227e8,672
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",setup,351842617383227e8,672
"save(Res, file = ""~/Dropbox/Columbia Radiogenomics/Analysis/Results/Cauchy_SECT.RData"")",setup,351842617383227e8,672
"colMeans(Res[[1]][, 5:8])",setup,351842617383227e8,672
"source(""./Analysis/ImportFormat.R"")",setup,351842617383227e8,672
"source(""./Analysis/KnownFateModels.R"")",import,351842617383227e8,672
"p <- ggplot(TopModel.real, aes(x = Year, y = estimate))",import,351842617383227e8,672
"p <- p + geom_pointrange(data = TopModel.real, aes(x = Year,      y = estimate, ymin = lcl, ymax = ucl), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Daily Survival Rate"")",import,351842617383227e8,672
p,import,351842617383227e8,672
"ggsave(""./Figures/DailySurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",import,351842617383227e8,672
library(ggplot2),import,351842617383227e8,672
"p <- ggplot(TopModel.derived, aes(x = Year, y = Estimate))",import,351842617383227e8,672
"p <- p + geom_pointrange(data = TopModel.derived, aes(x = Year,      y = Estimate, ymin = LCL, ymax = UCL), size = 1, fill = ""white"",      shape = 22) + xlab(""Year"") + ylab(""Annual Survival Rate"")",import,351842617383227e8,672
p,import,351842617383227e8,672
"ggsave(""./Figures/AnnualSurvivalEstimates.pdf"", width = 6, height = 4,      units = ""in"")",import,351842617383227e8,672
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,579032824607566e8,673
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",modeling,241850062506273e8,674
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",not sure,241850062506273e8,674
"knit2html(""./src/8_analysis.Rmd"", fragment.only = TRUE)",communication,241850062506273e8,674
library(ggplot2),import,275488121900707e8,675
"source(""./plot.R"")",import,275488121900707e8,675
"source(""./preprocessing.R"")",import,275488121900707e8,675
"source(""./expertValidation.R"")",import,275488121900707e8,675
"source(""./lakeSU.R"")",import,275488121900707e8,675
"source(""./analysis_DCL.R"")",import,275488121900707e8,675
"source(""./analysis_TRM.R"")",modeling,275488121900707e8,675
"source(""./global.R"")",modeling,275488121900707e8,675
"source(""./seg_comparison.R"")",modeling,275488121900707e8,675
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,572665076935664e8,676
"dat %>% filter(year != 2011, removal_type %in% c(""C"", ""D""), pargrp ==      ""C"") %>% dplyr::select(adj_revenue) %>% summarize(total.rev = sum(as.numeric(adj_revenue),      na.rm = T))",exploratory,572665076935664e8,676
"vessel_landings %>% dplyr::select(adj_revenue) %>% summarize(total.rev = sum(as.numeric(adj_revenue),      na.rm = T))",exploratory,572665076935664e8,676
vessel_stats %>% filter(alaska == 0 & both.periods == 1) %>%      group_by(ifq_flag) %>% summarize(n = length(unique(drvid))),exploratory,572665076935664e8,676
"table(vessel_stats$composition, vessel_stats$delta.nfisheries)",exploratory,572665076935664e8,676
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,547318174038082e8,677
"m.2mo.dur.la <- gam(log(towhours + 1) ~ factor(yr) + la_fuel_price +      hrs + +s(depth) + s(ppnd) + s(jd) + s(cent_lon, cent_lat) +      s(cent_lon, cent_lat, by = do), data = gam.2mo.dur.la)",exploratory,547318174038082e8,677
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,890231050318107e8,678
"time_average <- ed_summary %>% filter(yyear > 1912) %>% group_by(variable,      run_id) %>% summarize(value_mean = mean(value_mean)) %>%      left_join(params_sub)",data cleaning,890231050318107e8,678
"linmod <- time_average %>% group_by(variable, pft, parameter) %>%      nest() %>% mutate(fit = map(data, possibly(lm, NULL), formula = value_mean ~      parameter_value), failed_fit = map_lgl(fit, is.null), ) %>%      filter(!failed_fit) %>% mutate(r2 = map2_dbl(fit, data, modelr::rsquare),      slope = map_dbl(fit, ~coefficients(.x)[[2]]))",modeling,890231050318107e8,678
linmod %>% arrange(desc(r2)),evaluation,890231050318107e8,678
"time_average %>% filter(pft == ""Early hardwood"", parameter ==      ""nonlocal_dispersal"") %>% ggplot() + aes(x = parameter_value,      y = value_mean) + geom_smooth(method = ""lm"") + geom_point() +      facet_wrap(~variable, scales = ""free_y"")",visualization,890231050318107e8,678
"ed_summary %>% left_join(params_wide %>% filter(pft == ""Early hardwood"")) %>%      ggplot() + aes(x = yyear, y = value_mean, group = run_id,      color = nonlocal_dispersal) + geom_line(alpha = 0.5) + facet_wrap(~variable,      scales = ""free_y"") + scale_color_viridis_c()",visualization,890231050318107e8,678
"ggsave(""analysis/figures/prelim-ed-ensemble-out.png"", width = 8,      height = 8)",export,890231050318107e8,678
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,356715259607881e8,679
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,356715259607881e8,679
allYears <- ucas_data$`Cycle Year` %>% unique(),exploratory,356715259607881e8,679
totalYears <- totalHostYears <- c(),not sure,356715259607881e8,679
"blog <- read.csv(""blog_entities.csv"", sep = "","")",setup,901305961655453e8,680
"graph <- read.csv(""cg_entities.csv"", sep = "","")",setup,901305961655453e8,680
d1 <- data.frame(blog),exploratory,901305961655453e8,680
d2 <- data.frame(graph),exploratory,901305961655453e8,680
"both <- join(d1, d2, by = ""Name"", type = ""inner"", match = ""all"")",evaluation,901305961655453e8,680
"write.csv(both, ""both.csv"", row.names = FALSE, quote = FALSE)",evaluation,901305961655453e8,680
"bNOTg <- read.csv(""blog_not_graph.csv"", sep = "","")",export,901305961655453e8,680
d3 <- data.frame(bNOTg),import,901305961655453e8,680
"source(""./functions/booter.R"")",setup,901305961655453e8,680
"booter(model, coef = TRUE, n = 5000, data = data)",evaluation,901305961655453e8,680
"write.table(data, file = ""./analysis/inundation_wooddensity_relationship/data/data_sap_adult_rr_density.txt"")",evaluation,901305961655453e8,680
"source(""./analysis/2018-11-30/testing/00_settings_simulation_test_init.R"")",setup,901305961655453e8,680
"out_pgas <- pgas(N = num_particles, MM = num_mcmc, TT = TT, y = y_t,      Za1 = za1_t, Za2 = za2_t, Za3 = za3_t, Za4 = za4_t, priors = c(prior_a,          prior_b), par_init = par_init, par_true = true_vals,      traj_init = deviate_states_init, filtering = pgas_run, num_plots_states = 1)",modeling,901305961655453e8,680
"source(""./analysis/2018-11-30/testing/99_analyse_convergence_test.R"")",setup,901305961655453e8,680
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,426662633195519e8,681
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,822096445364877e8,682
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,426662633195519e8,681
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,426662633195519e8,681
"source(""Rcode/create_minfile.r"")",visualization,426662633195519e8,681
"metadata$Exclude_data[is.na(metadata$Exclude_data)] <- ""include""",visualization,426662633195519e8,681
"aid_loc_China <- read.csv(""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_China/locations.csv"",      sep = "";"")",import,934006752911955e8,683
"aid_loc_China$latitude <- as.numeric(gsub(""\\,"", ""."", aid_loc_China$latitude))",exploratory,934006752911955e8,683
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,179620973998681e8,684
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,179620973998681e8,684
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,179620973998681e8,684
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,179620973998681e8,684
xmax = 1,not sure,179620973998681e8,684
xmin = 0,not sure,179620973998681e8,684
"par(mfrow = c(2, 1))",visualization,179620973998681e8,684
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,179620973998681e8,684
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [100]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,179620973998681e8,684
"s2_infos <- read_csv(""data/study2/00_child_info.csv"") %>% mutate(Dialect = factor(AAE,      levels = c(0, 1), labels = c(""MAE"", ""AAE"")), medu = normalize_medu(medu)) %>%      rename(Subj = Participant_ID) %>% select(-householdIncome,      -pcedu) %>% rename(EVT_standard = EVT_Standard, PPVT_standard = PPVT_Standard)",exploratory,834806845290586e8,685
s2_infos$medu <- medu_codes[s2_infos$medu],exploratory,834806845290586e8,685
"s2_binned <- standard_model_pipeline(s2_looks, bins = bin_width,      draw = TRUE)",exploratory,834806845290586e8,685
"stopifnot(setdiff(s2_binned$Subj, s2_infos$Subj) == 0)",exploratory,834806845290586e8,685
dev.off(),visualization,179620973998681e8,684
"s2 <- make_model_data(s2_binned, s2_infos)",exploratory,834806845290586e8,685
"write_csv(s2, ""data/study2/02_analysis1.csv"")",exploratory,834806845290586e8,685
"s2_bias_dfs <- compute_bias_growth_curves(looks = s2_looks, infos = s2_infos,      bins = 3, phon_set = good_phon, semy_set = good_semy)",exploratory,834806845290586e8,685
"library(""ggplot2"")",not sure,834806845290586e8,685
"p_four <- ggplot(data = s2_bias_dfs$fourway_bias) + aes(x = Time,      y = plogis(elogit), color = Bias) + stat_summary(fun.data = ""mean_se"",      geom = ""pointrange"")",not sure,834806845290586e8,685
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,947550210403278e8,686
"gasG05 = read_graph(""Data/iGraphs/gasG05.gml"", format = ""gml"")",import,947550210403278e8,686
"all_triplets = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",exploratory,947550210403278e8,686
"all_triplets_test = compute_all_triplets(coffeeG05, ""Ethiopia:ETH"")",exploratory,947550210403278e8,686
"ids = unique(unlist(all_triplets %>% filter(category == ""ABC"") %>%      select(X, Y, Z)))",data cleaning,947550210403278e8,686
"subG = induced_subgraph(coffeeG05, vids = ids)",visualization,947550210403278e8,686
lay = layout.circle(subG),visualization,947550210403278e8,686
"all_data = read.csv(foreign_file, header = TRUE)",modeling,201873319456354e8,687
"foreign_data = read.csv(foreign_file, header = TRUE)",visualization,201873319456354e8,687
"demo_file = ""/Users/elplatt/src_archive/Global-Coverage-Study/analysis/output/demographics.csv""",visualization,201873319456354e8,687
"demo = read.csv(demo_file, header = TRUE)",visualization,201873319456354e8,687
"estimate_file = ""/Users/elplatt/src_archive/Global-Coverage-Study/analysis/output/estimate.csv""",visualization,201873319456354e8,687
"df.compare <- rbind.fill(df.compare, df.ratio)",data cleaning,385735073592514e8,688
"csv.filename <- paste(analysis_name, ""_compare.csv"", sep = """")",setup,385735073592514e8,688
"write.csv(df.compare, file = csv.filename, row.names = FALSE)",export,385735073592514e8,688
"EpiModelHPC::get_epi(indir = ""data/save/"", outdir = ""data/save/analysis/"",      vars = c(""num"", ""i.prev"", ""incid"", ""prepCov"", ""prepElig"",          ""prepCurr""), suffix = ""lim"")",modeling,385735073592514e8,688
"ROC.file.name = ""ROC_overS_RD.pdf""",setup,385735073592514e8,688
"hist.file.name = ""hist_overS_RD.pdf""",setup,385735073592514e8,688
"ms.null = vector(""list"", length(case.name))",setup,385735073592514e8,688
"ms.alt = vector(""list"", length(case.name))",setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/pval."",      case.name[1], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),setup,385735073592514e8,688
done.alt = done_res,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/pval."",      case.name[1], "".Robj""))",import,385735073592514e8,688
pval.null = as.numeric(pval_list),setup,385735073592514e8,688
done.null = done_res,setup,385735073592514e8,688
sum(done.alt),evaluation,385735073592514e8,688
sum(done.null),evaluation,385735073592514e8,688
min(pval.alt),evaluation,385735073592514e8,688
max(pval.alt),evaluation,385735073592514e8,688
min(pval.null),evaluation,385735073592514e8,688
max(pval.null),evaluation,385735073592514e8,688
ms.null[[1]] = pval.null,setup,385735073592514e8,688
ms.alt[[1]] = pval.alt,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),setup,385735073592514e8,688
done.alt = done_res,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/pval."",      case.name[2], "".Robj""))",import,385735073592514e8,688
pval.null = as.numeric(pval_list),setup,385735073592514e8,688
done.null = done_res,setup,385735073592514e8,688
sum(done.alt),evaluation,385735073592514e8,688
sum(done.null),evaluation,385735073592514e8,688
min(pval.alt),evaluation,385735073592514e8,688
max(pval.alt),evaluation,385735073592514e8,688
min(pval.null),evaluation,385735073592514e8,688
max(pval.null),evaluation,385735073592514e8,688
ms.null[[2]] = pval.null,setup,385735073592514e8,688
ms.alt[[2]] = pval.alt,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),setup,385735073592514e8,688
done.alt = done_res,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/multiscale/sum/pval."",      case.name[3], "".Robj""))",import,385735073592514e8,688
pval.null = as.numeric(pval_list),setup,385735073592514e8,688
done.null = done_res,setup,385735073592514e8,688
sum(done.alt),evaluation,385735073592514e8,688
sum(done.null),evaluation,385735073592514e8,688
min(pval.alt),evaluation,385735073592514e8,688
max(pval.alt),evaluation,385735073592514e8,688
min(pval.null),evaluation,385735073592514e8,688
max(pval.null),evaluation,385735073592514e8,688
ms.null[[3]] = pval.null,setup,385735073592514e8,688
ms.alt[[3]] = pval.alt,setup,385735073592514e8,688
"wave.null = vector(""list"", length(case.name))",setup,385735073592514e8,688
"wave.alt = vector(""list"", length(case.name))",setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/pval."",      case.name[1], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),setup,385735073592514e8,688
done.alt = done_res,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/pval."",      case.name[1], "".Robj""))",import,385735073592514e8,688
pval.null = as.numeric(pval_list),setup,385735073592514e8,688
done.null = done_res,setup,385735073592514e8,688
sum(done.alt),evaluation,385735073592514e8,688
sum(done.null),evaluation,385735073592514e8,688
min(pval.alt),evaluation,385735073592514e8,688
max(pval.alt),evaluation,385735073592514e8,688
min(pval.null),evaluation,385735073592514e8,688
max(pval.null),evaluation,385735073592514e8,688
wave.null[[1]] = pval.null,setup,385735073592514e8,688
wave.alt[[1]] = pval.alt,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/pval."",      case.name[2], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),setup,385735073592514e8,688
done.alt = done_res,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/pval."",      case.name[2], "".Robj""))",import,385735073592514e8,688
pval.null = as.numeric(pval_list),setup,385735073592514e8,688
done.null = done_res,setup,385735073592514e8,688
sum(done.alt),evaluation,385735073592514e8,688
sum(done.null),evaluation,385735073592514e8,688
min(pval.alt),evaluation,385735073592514e8,688
max(pval.alt),evaluation,385735073592514e8,688
min(pval.null),evaluation,385735073592514e8,688
max(pval.null),evaluation,385735073592514e8,688
wave.null[[2]] = pval.null,setup,385735073592514e8,688
wave.alt[[2]] = pval.alt,setup,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/pval."",      case.name[3], "".Robj""))",import,385735073592514e8,688
pval.alt = as.numeric(pval_list),exploratory,385735073592514e8,688
done.alt = done_res,exploratory,385735073592514e8,688
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/pval."",      case.name[3], "".Robj""))",exploratory,385735073592514e8,688
pval.null = as.numeric(pval_list),exploratory,385735073592514e8,688
done.null = done_res,exploratory,385735073592514e8,688
sum(done.alt),exploratory,385735073592514e8,688
sum(done.null),exploratory,385735073592514e8,688
min(pval.alt),exploratory,385735073592514e8,688
max(pval.alt),exploratory,385735073592514e8,688
min(pval.null),exploratory,385735073592514e8,688
max(pval.null),exploratory,385735073592514e8,688
wave.null[[3]] = pval.null,exploratory,385735073592514e8,688
wave.alt[[3]] = pval.alt,exploratory,385735073592514e8,688
pdf(hist.file.name),exploratory,385735073592514e8,688
"par(mfrow = c(4, 1))",exploratory,385735073592514e8,688
"hist(wave.null[[1]], main = ""null Wavelet (70)"", breaks = 47)",exploratory,385735073592514e8,688
"hist(ms.null[[1]], main = ""null multiscale (70)"", breaks = 47)",exploratory,385735073592514e8,688
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,738542260602117e8,689
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,738542260602117e8,689
"Foundations$district <- gsub(""\u009f"", ""?"", Foundations$district)",not sure,407668326748535e8,690
"Foundations$district <- gsub(pattern = ""\u008a"", replacement = ""?"",      x = Foundations$district)",not sure,407668326748535e8,690
"Foundations$district <- gsub(pattern = ""\u009a"", replacement = ""?"",      x = Foundations$district)",not sure,407668326748535e8,690
"Foundations$district <- gsub(pattern = ""?"", replacement = ""?"",      x = Foundations$district)",exploratory,407668326748535e8,690
"Foundations[, 4] <- as.numeric(as.character(Foundations[, 4]))",not sure,407668326748535e8,690
"Foundations[, 5] <- as.numeric(as.character(Foundations[, 5]))",not sure,407668326748535e8,690
"Foundations <- Foundations[, -c(1, 3)]",not sure,407668326748535e8,690
"rr_explaied_variation <- paste(""ANOVA:"", round(var_res_rr/sum(var_res_rr) *      100, 1)[2], ""%"")",evaluation,191621869336814e8,691
"vj_rr <- rep(2.5, 16)",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Spar"")] <- -2.5",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Smac"")] <- 12",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Slep"")] <- -4",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Smec"")] <- -3",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Pmal"")] <- -4",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Sgib"")] <- 8",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Ssmi"")] <- -4",data cleaning,191621869336814e8,691
"vj_rr[which(riskratio$sp == ""Sacu"")] <- -4",data cleaning,191621869336814e8,691
"hj_rr <- rep(0.01, 16)",data cleaning,191621869336814e8,691
"hj_rr[which(riskratio$sp == ""Ssmi"")] <- -0.02",data cleaning,191621869336814e8,691
"hj_rr[which(riskratio$sp == ""Sbec"")] <- -0.02",data cleaning,191621869336814e8,691
"hj_rr[which(riskratio$sp == ""Sxan"")] <- 0.01",data cleaning,191621869336814e8,691
"p1_riskratio <- ggplot(preds_riskratio, aes(x = diff_mort, y = elev)) +      geom_line(data = partial_lines_data, aes(x = x, y = y, group = factor(x)),          alpha = 0.3) + geom_line() + geom_point(data = riskratio,      aes(y = elev, x = diff_mort), alpha = 0.5, color = ""red"") +      geom_ribbon(aes(ymin = CI025, ymax = CI975), alpha = 0.2) +      theme_bw() + geom_point(data = riskratio, aes(y = partials_rr,      x = diff_mort), color = ""black"", pch = 21, fill = ""grey"",      size = 3) + geom_text(aes(x = 0.12, y = 120, label = rr_explaied_variation),      size = 5) + ylab(""E(elevation) m asl"") + xlab(""Water inundation sensitivity"") +      ylim(40, 120) + stat_smooth(data = riskratio, aes(x = diff_mort,      y = elev), se = F, method = ""lm"", color = ""red"", linetype = 2,      size = 0.5) + theme(text = element_text(size = 20)) + geom_text(data = riskratio,      aes(label = sp), size = 5, nudge_y = vj_rr, nudge_x = hj_rr,      fontface = ""italic"")",visualization,191621869336814e8,691
"rr_explaied_variation <- paste(""ANOVA:"", round(var_res_rr/sum(var_res_rr) *      100, 1)[2], ""%"")",evaluation,191621869336814e8,691
"anova(m_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",evaluation,191621869336814e8,691
"m_e_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_fxl_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp,      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"anova(m_e_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",evaluation,191621869336814e8,691
"anova(m_e_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",evaluation,191621869336814e8,691
"anova(m_er_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",evaluation,191621869336814e8,691
"anova(m_er_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0),      c(0, 0, 1, 0), c(0, 0, 0, 1)))",evaluation,191621869336814e8,691
"anova(m_o_fxl_kelp, L = rbind(c(1, -1, 0, 0), c(0, 1, -1, 0),      c(0, 1, 0, -1), c(0, 0, -1, 1), c(1, 0, 0, -1), c(1, 0, -1,          0)))",evaluation,191621869336814e8,691
"anova(m_o_fxl_kelp, L = rbind(c(1, 0, 0, 0), c(0, 1, 0, 0), c(0,      0, 1, 0), c(0, 0, 0, 1)))",evaluation,191621869336814e8,691
anova(m_depth_fucales),evaluation,191621869336814e8,691
"m_e_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_depth_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~depth_m_relative_to_mllw,      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$observational)",modeling,191621869336814e8,691
anova(m_e_depth_fucales),evaluation,191621869336814e8,691
anova(m_er_depth_fucales),evaluation,191621869336814e8,691
anova(m_o_depth_fucales),evaluation,191621869336814e8,691
"m_e_depth_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~coralline * depth_m_relative_to_mllw, random = ~1 |          unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~coralline * depth_m_relative_to_mllw, random = ~1 |          unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"m_e_depth_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
anova(m_depth_kelp),evaluation,191621869336814e8,691
"metadat_lnrr_kelp %>% ggplot(aes(x = depth_m_relative_to_mllw,      color = expt_type)) + geom_density(aes(fill = expt_type),      alpha = 0.5)",visualization,191621869336814e8,691
"m_e_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_depth_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~fxl_grp +      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"anova(m_e_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",evaluation,191621869336814e8,691
"anova(m_er_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",evaluation,191621869336814e8,691
"anova(m_o_depth_kelp, L = rbind(c(1, 0, 0, 0, 0), c(0, 1, 0,      0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0, 0, 0,      1)))",evaluation,191621869336814e8,691
"m_e_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_depth_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~coralline *      depth_m_relative_to_mllw, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"m_e_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_depth_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~crust * depth_m_relative_to_mllw, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
summary(m_lat_fucales),exploratory,191621869336814e8,691
"m_e_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lat_fucales <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_fucales_list$observational)",modeling,191621869336814e8,691
"m_e_lat_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"m_e_lat_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~abs(latitude) * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
summary(m_lat_kelp),exploratory,191621869336814e8,691
"m_e_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lat_kelp <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude),      random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"m_e_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lat_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"m_e_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lat_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~abs(latitude) *      crust, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
summary(m_lh),exploratory,191621869336814e8,691
"m_e_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~kelp_life_stage *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lh_grp_kelp_cor <- rma.mv(yi = sigma_rr, V = sigma_var, mods = ~kelp_life_stage *      coralline, random = ~1 | unique_type, data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"anova(m_er_lh_grp_kelp_cor, L = rbind(c(1, 0, 0, 0, 0, 0), c(0,      1, 0, 0, 0, 0), c(0, 0, 1, 0, 0, 0), c(0, 0, 0, 1, 0, 0),      c(0, 0, 0, 0, 1, 0), c(0, 0, 0, 0, 0, 1)))",evaluation,191621869336814e8,691
"m_e_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental)",modeling,191621869336814e8,691
"m_er_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$experimental_removal)",modeling,191621869336814e8,691
"m_o_lh_grp_kelp_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_kelp_list$observational)",modeling,191621869336814e8,691
"anova(m_er_lh_grp_kelp_crust, L = rbind(c(1, 0, 0, 0, 0), c(0,      1, 0, 0, 0), c(0, 0, 1, 0, 0), c(0, 0, 0, 1, 0), c(0, 0,      0, 0, 1), c(1, 0, 0, 1, 0)))",evaluation,191621869336814e8,691
"m_e_lh_grp_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_lh_grp_fucales_cor <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * coralline, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"m_e_lh_grp_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental)",modeling,191621869336814e8,691
"m_er_lh_grp_fucales_crust <- rma.mv(yi = sigma_rr, V = sigma_var,      mods = ~kelp_life_stage * crust, random = ~1 | unique_type,      data = metadat_lnrr_fucales_list$experimental_removal)",modeling,191621869336814e8,691
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,447537552332506e8,692
library(magrittr),not sure,447537552332506e8,692
library(dplyr),import,447537552332506e8,692
library(ggplot2),import,447537552332506e8,692
"setwd(""C:/Users/Bethany Gardner/Google Drive/Lab/Kinder/ArtificialLanguageEyeTracking"")",setup,447537552332506e8,692
"record = read.csv(""Analysis/Parsed Data/exp1_production.csv"")",setup,447537552332506e8,692
"rec_subj = ggplot(record %>% filter(Section == ""test"") %>% group_by(Subject,      Type), aes(x = Result, fill = Result)) + geom_bar() + facet_wrap(~Subject)",import,447537552332506e8,692
"ggsave(""Analysis/Plots/record_subj.png"")",visualization,447537552332506e8,692
"rec_section = ggplot(record %>% group_by(Section, Type), aes(x = Result,      fill = Result)) + geom_bar() + facet_wrap(~Section)",export,447537552332506e8,692
"ggsave(""Analysis/Plots/record_section.png"")",visualization,447537552332506e8,692
"afc = read.csv(""Analysis/Parsed Data/exp1_4afc.csv"")",export,447537552332506e8,692
"afc$Mapping <- ifelse(afc$Subj == ""9EH"" | afc$Subj == ""10DC"" |      afc$Subj == ""11DA"" | afc$Subj == ""12KM"" | afc$Subj == ""13CS"" |      afc$Subj == ""18TW"" | afc$Subj == ""19JL"" | afc$Subj == ""20ST"" |      afc$Subj == ""21MY"" | afc$Subj == ""26SK"" | afc$Subj == ""27RB"" |      afc$Subj == ""28JJ"" | afc$Subj == ""29PP"", ""A"", ifelse(afc$Subj ==      ""14CL"" | afc$Subj == ""15SJ"" | afc$Subj == ""16YK"" | afc$Subj ==      ""17JI"" | afc$Subj == ""22DT"" | afc$Subj == ""23KV"" | afc$Subj ==      ""24JF"" | afc$Subj == ""25AL"" | afc$Subj == ""30HO"" | afc$Subj ==      31 | afc$Subj == 32 | afc$Subj == 33, ""B"", NA))",import,447537552332506e8,692
afc$Mapping <- as.factor(afc$Mapping),data cleaning,447537552332506e8,692
"afc_nonce = filter(afc, Section == ""Practice"" | Section == ""Test"")",data cleaning,447537552332506e8,692
"limits <- aes(ymax = mean + se, ymin = mean - se)",data cleaning,447537552332506e8,692
"afc1 <- ddply(afc_nonce, c(""Section""), summarise, N = sum(!is.na(Correct)),      mean = mean(Correct, na.rm = TRUE), sd = sd(Correct, na.rm = TRUE),      se = sd/sqrt(N))",modeling,447537552332506e8,692
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,410663659451529e8,693
dim(mn.condos),import,50173316989094e9,694
count(is.na(mn.condos$gross.sqft)),exploratory,50173316989094e9,694
"lines(density(apply(randSamp, 2, mean)), col = ""red"", lty = 2)",visualization,410663659451529e8,693
count(is.na(mn.condos$land.sqft)),evaluation,50173316989094e9,694
"lines(density(go[which(go[, 1] %in% double[, 1]), 2]), col = ""blue"")",visualization,410663659451529e8,693
summary(mn.condos$sale.price.n),communication,50173316989094e9,694
getmode(mn.condos$sale.price.n),exploratory,50173316989094e9,694
"sampSz = length(which(go[, 1] %in% double[, 1]))",exploratory,410663659451529e8,693
"randSamp = matrix(0, 1000, sampSz)",setup,410663659451529e8,693
"for (i in 1:1000) randSamp[i, ] = sort(go[sample(1:nrow(go),      sampSz), 2])",not sure,410663659451529e8,693
"lines(density(apply(randSamp, 2, mean)), col = ""blue"", lty = 2)",visualization,410663659451529e8,693
"lines(density(go[which(go[, 1] %in% triple[, 1]), 2]), col = ""green"")",visualization,410663659451529e8,693
"sampSz = length(which(go[, 1] %in% triple[, 1]))",exploratory,410663659451529e8,693
"randSamp = matrix(0, 1000, sampSz)",not sure,410663659451529e8,693
"for (i in 1:1000) randSamp[i, ] = sort(go[sample(1:nrow(go),      sampSz), 2])",import,410663659451529e8,693
"lines(density(apply(randSamp, 2, mean)), col = ""green"", lty = 2)",visualization,410663659451529e8,693
"legend(""topright"", legend = c(""all"", ""single"", ""double"", ""triple""),      text.col = c(""black"", ""red"", ""blue"", ""green""))",visualization,410663659451529e8,693
"pdf(file = ""GO_term_density_overlap.pdf"", height = 11, width = 8.5)",export,410663659451529e8,693
"par(mfrow = c(3, 2))",setup,410663659451529e8,693
"plot.goterm(go.bio, type = ""Biological Process"", xlim = c(0,      max(go.bio[, 2])))",visualization,410663659451529e8,693
"plot.goterm(go.bio, type = ""Biological Process"", xlim = c(0,      30))",visualization,410663659451529e8,693
"plot.goterm(go.mol, type = ""Molecular Function"", xlim = c(0,      max(go.mol[, 2])))",visualization,410663659451529e8,693
"plot.goterm(go.mol, type = ""Molecular Function"", xlim = c(0,      15))",visualization,410663659451529e8,693
"plot.goterm(go.cel, type = ""Cellular Component"", xlim = c(0,      max(go.cel[, 2])))",visualization,410663659451529e8,693
"plot.goterm(go.cel, type = ""Cellular Component"", xlim = c(0,      10))",visualization,410663659451529e8,693
dev.off(),setup,410663659451529e8,693
load(out.path),setup,410663659451529e8,693
"input.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/summary/pval.ms.wave."",      all.name, "".Robj"")",setup,410663659451529e8,693
load(input.path),import,410663659451529e8,693
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,410663659451529e8,693
"pdf(""discovery.FDR.both.discrete.pdf"")",export,410663659451529e8,693
filter.cut = 0,setup,410663659451529e8,693
pval.deseq = pval.deseq.3,setup,410663659451529e8,693
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",not sure,410663659451529e8,693
qval.wave = qvalue(pval.wave[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.ms = qvalue(pval.ms[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.wave$pi0,exploratory,410663659451529e8,693
qval.ms$pi0,exploratory,410663659451529e8,693
qval.deseq$pi0,exploratory,410663659451529e8,693
"alpha.list = seq(0.01, 0.2, by = 0.01)",setup,410663659451529e8,693
length(alpha.list),exploratory,410663659451529e8,693
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",setup,410663659451529e8,693
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),setup,410663659451529e8,693
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),setup,410663659451529e8,693
num.deseq[i] = sum(qval.deseq$qvalues < alpha.list[i]),exploratory,410663659451529e8,693
"ymax = max(num.wave, num.ms, num.deseq)",exploratory,410663659451529e8,693
ymin = 0,setup,410663659451529e8,693
"plot(alpha.list, num.ms, ylim = c(ymin, ymax), col = ""red"", type = ""l"",      main = paste0(""filter : "", filter.cut), xlab = ""FDR"", ylab = ""number of significant tests"")",visualization,410663659451529e8,693
"points(alpha.list, num.wave, ylim = c(ymin, ymax), col = ""blue"",      type = ""l"")",visualization,410663659451529e8,693
"points(alpha.list, num.deseq, ylim = c(ymin, ymax), col = ""darkgreen"",      type = ""l"")",visualization,410663659451529e8,693
"legend(0.01, ymax * 0.99, c(""multiseq"", ""WaveQTL"", ""DESeq""),      col = c(""red"", ""blue"", ""darkgreen""), lty = c(1, 1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,410663659451529e8,693
filter.cut = 10,setup,410663659451529e8,693
pval.deseq = pval.deseq.3.10,setup,410663659451529e8,693
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",not sure,410663659451529e8,693
qval.wave = qvalue(pval.wave[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.ms = qvalue(pval.ms[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.wave$pi0,exploratory,410663659451529e8,693
qval.ms$pi0,exploratory,410663659451529e8,693
qval.deseq$pi0,exploratory,410663659451529e8,693
"alpha.list = seq(0.01, 0.2, by = 0.01)",setup,410663659451529e8,693
length(alpha.list),exploratory,410663659451529e8,693
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",setup,410663659451529e8,693
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),evaluation,410663659451529e8,693
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),exploratory,410663659451529e8,693
num.deseq[i] = sum(qval.deseq$qvalues < alpha.list[i]),exploratory,410663659451529e8,693
"ymax = max(num.wave, num.ms, num.deseq)",exploratory,410663659451529e8,693
ymin = 0,setup,410663659451529e8,693
"plot(alpha.list, num.ms, ylim = c(ymin, ymax), col = ""red"", type = ""l"",      main = paste0(""filter : "", filter.cut), xlab = ""FDR"", ylab = ""number of significant tests"")",visualization,410663659451529e8,693
"points(alpha.list, num.wave, ylim = c(ymin, ymax), col = ""blue"",      type = ""l"")",visualization,410663659451529e8,693
"points(alpha.list, num.deseq, ylim = c(ymin, ymax), col = ""darkgreen"",      type = ""l"")",visualization,410663659451529e8,693
"legend(0.01, ymax * 0.99, c(""multiseq"", ""WaveQTL"", ""DESeq""),      col = c(""red"", ""blue"", ""darkgreen""), lty = c(1, 1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",visualization,410663659451529e8,693
filter.cut = 20,setup,410663659451529e8,693
pval.deseq = pval.deseq.3.20,setup,410663659451529e8,693
"del.ix.deseq = union(union(which(is.na(pval.deseq) == TRUE),      which(is.na(pval.ms) == TRUE)), which(is.na(pval.wave) ==      TRUE))",setup,410663659451529e8,693
qval.wave = qvalue(pval.wave[-del.ix.deseq]),setup,410663659451529e8,693
qval.ms = qvalue(pval.ms[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.deseq = qvalue(pval.deseq[-del.ix.deseq]),exploratory,410663659451529e8,693
qval.wave$pi0,exploratory,410663659451529e8,693
qval.ms$pi0,exploratory,410663659451529e8,693
qval.deseq$pi0,exploratory,410663659451529e8,693
"alpha.list = seq(0.01, 0.2, by = 0.01)",setup,410663659451529e8,693
length(alpha.list),exploratory,410663659451529e8,693
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",setup,410663659451529e8,693
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),evaluation,410663659451529e8,693
"ggplot(pred, aes(x = si, y = slm, fill = Dden)) + geom_raster()",visualization,168764179572463e8,695
"d1 <- dredge(mod2, rank = ""AIC"")",modeling,168764179572463e8,695
head(d1),exploratory,168764179572463e8,695
"mod2 <- lmer(Dden.y ~ carbon.fraction2 + diameter.y * sp.y +      (1 | block.y) + (1 | mother.y), newdata)",modeling,168764179572463e8,695
summary(mod2),modeling,168764179572463e8,695
"source(""./functions/booter.R"")",import,168764179572463e8,695
"CI_coef <- booter(mod2, data = newdata, ceof = TRUE, n = 10)",modeling,168764179572463e8,695
CI_coef,modeling,168764179572463e8,695
require(remef),import,168764179572463e8,695
"partial_data <- newdata[!is.na(newdata$Dden.y) & !is.na(newdata$carbon.fraction2) &      !is.na(newdata$diameter.y), ]",data cleaning,168764179572463e8,695
"partial_data$y_partial <- remef(mod2, fix = c(""diameter.y"", ""sp.ypmal"",      ""sp.yptom"", ""sp.ysbec"", ""sp.ysjoh"", ""sp.yslep"", ""sp.yspar"",      ""sp.yssem"", ""sp.yssmi"", ""sp.ysxan""), ran = ""all"", grouping = TRUE,      keep.intercept = FALSE)",modeling,168764179572463e8,695
"pred <- expand.grid(carbon.fraction2 = seq(min(data$carbon.fraction2,      na.rm = T), max(data$carbon.fraction2, na.rm = T), length = 100),      sp.y = ""dry"", diameter.y = mean(newdata$diameter.y, na.rm = T))",not sure,168764179572463e8,695
"pred$Dden <- predict(mod2, pred, type = ""response"", re.form = NA)",modeling,168764179572463e8,695
sum(done.alt),exploratory,524195301579311e8,696
sum(done.null),not sure,524195301579311e8,696
min(pval.alt),evaluation,524195301579311e8,696
max(pval.alt),evaluation,524195301579311e8,696
min(pval.null),not sure,524195301579311e8,696
max(pval.null),not sure,524195301579311e8,696
wave.null[[2]] = pval.null,not sure,524195301579311e8,696
wave.alt[[2]] = pval.alt,not sure,524195301579311e8,696
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/alt/wave/sum/pval."",      case.name[3], "".Robj""))",import,524195301579311e8,696
pval.alt = as.numeric(pval_list),not sure,524195301579311e8,696
done.alt = done_res,not sure,524195301579311e8,696
"load(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/simulation/sample_size/simulation_footprint/null/wave/sum/pval."",      case.name[3], "".Robj""))",not sure,524195301579311e8,696
pval.null = as.numeric(pval_list),not sure,524195301579311e8,696
done.null = done_res,not sure,524195301579311e8,696
sum(done.alt),not sure,524195301579311e8,696
sum(done.null),not sure,524195301579311e8,696
min(pval.alt),not sure,524195301579311e8,696
max(pval.alt),not sure,524195301579311e8,696
min(pval.null),not sure,524195301579311e8,696
max(pval.null),not sure,524195301579311e8,696
wave.null[[3]] = pval.null,not sure,524195301579311e8,696
wave.alt[[3]] = pval.alt,not sure,524195301579311e8,696
pdf(hist.file.name),not sure,524195301579311e8,696
"par(mfrow = c(4, 1))",not sure,524195301579311e8,696
"hist(wave.null[[1]], main = ""null Wavelet (70)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.null[[1]], main = ""null multiscale (70)"", breaks = 47)",not sure,524195301579311e8,696
"hist(wave.alt[[1]], main = ""alt Wavelet (70)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.alt[[1]], main = ""alt multiscale (70)"", breaks = 47)",not sure,524195301579311e8,696
"par(mfrow = c(4, 1))",not sure,524195301579311e8,696
"hist(wave.null[[2]], main = ""null Wavelet (30)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.null[[2]], main = ""null multiscale (30)"", breaks = 47)",not sure,524195301579311e8,696
"hist(wave.alt[[2]], main = ""alt Wavelet (30)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.alt[[2]], main = ""alt multiscale (30)"", breaks = 47)",not sure,524195301579311e8,696
"par(mfrow = c(4, 1))",not sure,524195301579311e8,696
"hist(wave.null[[3]], main = ""null Wavelet (10)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.null[[3]], main = ""null multiscale (10)"", breaks = 47)",not sure,524195301579311e8,696
"hist(wave.alt[[3]], main = ""alt Wavelet (10)"", breaks = 47)",not sure,524195301579311e8,696
"hist(ms.alt[[3]], main = ""alt multiscale (10)"", breaks = 47)",not sure,524195301579311e8,696
dev.off(),not sure,524195301579311e8,696
"fpr.wave.list = vector(""list"", length(case.name))",not sure,524195301579311e8,696
"tpr.wave.list = vector(""list"", length(case.name))",not sure,524195301579311e8,696
"fpr.ms.list = vector(""list"", length(case.name))",not sure,524195301579311e8,696
"tpr.ms.list = vector(""list"", length(case.name))",not sure,524195301579311e8,696
"for (cc in 1:length(case.name)) pval = as.numeric(c(wave.null[[cc]],      wave.alt[[cc]]))",not sure,524195301579311e8,696
"disc = c(rep(0, 500), rep(1, 500))",not sure,524195301579311e8,696
rnk = order(pval),not sure,524195301579311e8,696
p.wave = pval[rnk],not sure,524195301579311e8,696
d.wave = disc[rnk],not sure,524195301579311e8,696
fdp.wave = NULL,not sure,524195301579311e8,696
sig.wave = NULL,not sure,524195301579311e8,696
tpr.wave = NULL,not sure,524195301579311e8,696
fpr.wave = NULL,not sure,524195301579311e8,696
uni.p.wave = unique(p.wave),not sure,524195301579311e8,696
for (i in 1:length(uni.p.wave)) wh = which(p.wave <= uni.p.wave[i]),not sure,524195301579311e8,696
sig.wave[i] = length(wh),not sure,524195301579311e8,696
fdp.wave[i] = 1 - (sum(d.wave[wh])/length(wh)),not sure,524195301579311e8,696
tpr.wave[i] = sum(d.wave[wh])/500,not sure,524195301579311e8,696
fpr.wave[i] = (length(wh) - sum(d.wave[wh]))/500,not sure,524195301579311e8,696
fpr.wave.list[[cc]] = fpr.wave,not sure,524195301579311e8,696
tpr.wave.list[[cc]] = tpr.wave,not sure,524195301579311e8,696
"for (cc in 1:length(case.name)) pval = as.numeric(c(ms.null[[cc]],      ms.alt[[cc]]))",not sure,524195301579311e8,696
"disc = c(rep(0, 500), rep(1, 500))",not sure,524195301579311e8,696
rnk = order(pval),not sure,524195301579311e8,696
p.ms = pval[rnk],not sure,524195301579311e8,696
d.ms = disc[rnk],not sure,524195301579311e8,696
fdp.ms = NULL,not sure,524195301579311e8,696
sig.ms = NULL,not sure,524195301579311e8,696
tpr.ms = NULL,not sure,524195301579311e8,696
fpr.ms = NULL,not sure,524195301579311e8,696
uni.p.ms = unique(p.ms),not sure,524195301579311e8,696
for (i in 1:length(uni.p.ms)) wh = which(p.ms <= uni.p.ms[i]),not sure,524195301579311e8,696
sig.ms[i] = length(wh),not sure,524195301579311e8,696
fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh)),not sure,524195301579311e8,696
tpr.ms[i] = sum(d.ms[wh])/500,not sure,524195301579311e8,696
fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/500,not sure,524195301579311e8,696
fpr.ms.list[[cc]] = fpr.ms,not sure,524195301579311e8,696
tpr.ms.list[[cc]] = tpr.ms,not sure,524195301579311e8,696
"save(""fpr.wave.list"", ""tpr.wave.list"", ""fpr.ms.list"", ""tpr.ms.list"",      file = output.path)",not sure,524195301579311e8,696
pdf(ROC.file.name),not sure,524195301579311e8,696
xmax = 1,not sure,524195301579311e8,696
ymax = 1,not sure,524195301579311e8,696
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",not sure,524195301579311e8,696
"points(c(0, fpr.wave.list[[1]]), c(0, tpr.wave.list[[1]]), type = ""l"",      col = ""skyblue"")",not sure,524195301579311e8,696
"points(c(0, fpr.ms.list[[2]]), c(0, tpr.ms.list[[2]]), type = ""l"",      col = ""darkgreen"")",not sure,524195301579311e8,696
"points(c(0, fpr.wave.list[[2]]), c(0, tpr.wave.list[[2]]), type = ""l"",      col = ""green"")",not sure,524195301579311e8,696
"points(c(0, fpr.ms.list[[3]]), c(0, tpr.ms.list[[3]]), type = ""l"",      col = ""red"")",not sure,524195301579311e8,696
"points(c(0, fpr.wave.list[[3]]), c(0, tpr.wave.list[[3]]), type = ""l"",      col = ""orange"")",not sure,524195301579311e8,696
"legend(0.7, 0.3, c(""multiscale 70"", ""wave 70"", ""multiscale 30"",      ""wave 30"", ""multiscale 10"", ""wave 10""), col = c(""blue"", ""skyblue"",      ""darkgreen"", ""green"", ""red"", ""orange""), lty = c(1, 1), text.col = ""black"",      merge = FALSE, bg = ""white"")",not sure,524195301579311e8,696
dev.off(),not sure,524195301579311e8,696
dev.off(),not sure,524195301579311e8,696
library(tidyverse),setup,165195528650656e8,697
library(fst),setup,165195528650656e8,697
"ed_in <- read_fst(""analysis/data/derived-data/ed-ensemble-out.fst"") %>%      as_tibble()",import,165195528650656e8,697
"params <- read_fst(""analysis/data/derived-data/ed-params.fst"") %>%      as_tibble()",import,165195528650656e8,697
"params_sub <- params %>% semi_join(params %>% group_by(pft, variable) %>%      filter(sd(value) > 0) %>% ungroup() %>% distinct(variable)) %>%      rename(parameter = variable, parameter_value = value)",data cleaning,165195528650656e8,697
"data$Total.Citations.by..ISI.Web.of.Science...SSCI. <- subset(data$Total.Citations.by..ISI.Web.of.Science...SSCI.,      data$Total.Citations.by..ISI.Web.of.Science...SSCI. != """")",data cleaning,306602035881951e8,698
a0 <- aov(log(data$Total.Citations.by..ISI.Web.of.Science...SSCI.) ~      data$Classification..instantiation..modifying..or.extending),exploratory,306602035881951e8,698
"posthoc <- TukeyHSD(x = a0, ""data$Classification..instantiation..modifying..or.extending"",      conf.level = 0.95)",exploratory,306602035881951e8,698
"extending_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Extending"")",data cleaning,306602035881951e8,698
"modifying_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Modifying"")",data cleaning,306602035881951e8,698
"instantiation_IS_cites <- subset(data$Information.Science...Library.Science.Citations..ISI.Web.of.Science...SSCI.,      data$Classification..instantiation..modifying..or.extending ==          ""Instantiation"")",data cleaning,306602035881951e8,698
"instantiation_IS_cites <- subset(instantiation_IS_cites, instantiation_IS_cites !=      0)",data cleaning,306602035881951e8,698
"modifying_IS_cites <- subset(modifying_IS_cites, modifying_IS_cites !=      0)",data cleaning,306602035881951e8,698
"extending_IS_cites <- subset(extending_IS_cites, extending_IS_cites !=      0)",data cleaning,306602035881951e8,698
"wilcox.test(extending_IS_cites, instantiation_IS_cites, probs = 0.05,      alternative = c(""greater""))",exploratory,306602035881951e8,698
"wilcox.test(extending_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""greater""))",exploratory,306602035881951e8,698
"wilcox.test(instantiation_IS_cites, modifying_IS_cites, probs = 0.05,      alternative = c(""less""))",exploratory,306602035881951e8,698
log_instantiation_IS_cites <- log10(instantiation_IS_cites),data cleaning,306602035881951e8,698
log_modifying_IS_cites <- log10(modifying_IS_cites),data cleaning,306602035881951e8,698
log_extending_IS_cites <- log10(extending_IS_cites),data cleaning,306602035881951e8,698
sqrt_instantiation_IS_cites <- sqrt(instantiation_IS_cites),data cleaning,306602035881951e8,698
sqrt_modifying_IS_cites <- sqrt(modifying_IS_cites),data cleaning,306602035881951e8,698
sqrt_extending_IS_cites <- sqrt(extending_IS_cites),data cleaning,306602035881951e8,698
hist(log_instantiation_IS_cites),exploratory,306602035881951e8,698
hist(log_modifying_IS_cites),exploratory,306602035881951e8,698
hist(log_extending_IS_cites),exploratory,306602035881951e8,698
hist(sqrt_instantiation_IS_cites),exploratory,306602035881951e8,698
hist(sqrt_modifying_IS_cites),exploratory,306602035881951e8,698
hist(sqrt_extending_IS_cites),exploratory,306602035881951e8,698
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,589418205432594e8,699
"t.test(log_modifying_IS_cites, log_extending_IS_cites, var.equal = FALSE)",exploratory,306602035881951e8,698
library(plyr),import,306602035881951e8,698
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,589418205432594e8,699
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,624004704179242e8,700
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,624004704179242e8,700
"out <- jags(jagsData, inits = inits, params, ""analysis/model.txt"",      n.chains = nc, n.iter = ni, n.burnin = nb, n.thin = nt, parallel = T,      codaOnly = codaOnly)",visualization,624004704179242e8,700
"saveRDS(out, ""results/out.rds"")",export,624004704179242e8,700
"save(adf, jct, lag_selection, var_model, file = ""analysis-output/results.rda"")",data cleaning,369523306842893e8,701
main(),modeling,369523306842893e8,701
warnings(),communication,369523306842893e8,701
return(word_freq),exploratory,369523306842893e8,701
"for (i in 1:length(cluster.weeder.res)) for (j in 1:length(cluster.weeder.res[[i]]$res)) cluster.weeder.m[cluster.weeder.res[[i]]$id,      as.character(names(cluster.weeder.res[[i]]$res[j]))] <- cluster.weeder.res[[i]]$res[j]",setup,659367516636848e7,702
"save.image(file = ""weeder_postCluster_analysis.RData"")",setup,659367516636848e7,702
tmp = cluster.weeder.m,exploratory,659367516636848e7,702
"tx2gene = dplyr::select(transcript_data, gene_id, transcript_id,      transcript_version) %>% dplyr::mutate(TXNAME = paste(transcript_id,      transcript_version, sep = ""."")) %>% dplyr::transmute(TXNAME,      gene_id, transcript_id)",not sure,38606648822315e9,703
"raw_educ <- read.csv(""analysis/data/getdata-data-EDSTATS_Country.csv"",      header = TRUE)",import,365111923776567e8,704
"sapply(raw_educ, function(x) length(which(is.na(x))))",exploratory,365111923776567e8,704
"colnames(raw_educ)[1] <- ""country_code""",data cleaning,365111923776567e8,704
colnames(raw_educ),exploratory,365111923776567e8,704
"clean_gdp_education_data <- merge(x = raw_gdp, y = raw_educ,      by = ""country_code"", all = FALSE)",data cleaning,365111923776567e8,704
"sapply(clean_gdp_education_data, class)",exploratory,365111923776567e8,704
head(clean_gdp_education_data),exploratory,365111923776567e8,704
"write.csv(clean_gdp_education_data, ""analysis/data/tidy_gdp_educ_data.csv"",      row.names = FALSE)",export,365111923776567e8,704
"raw_educ <- read.csv(""analysis/data/getdata-data-EDSTATS_Country.csv"",      header = TRUE)",import,365111923776567e8,704
"colnames(dd2) <- c(""x"", ""y"", ""time"")",data cleaning,365111923776567e8,704
"dd1$hand <- ""1""",data cleaning,365111923776567e8,704
"dd2$hand <- ""2""",data cleaning,365111923776567e8,704
"ddb <- rbind(dd1, dd2)",data cleaning,365111923776567e8,704
"h3 <- ggplot(ddb, aes(y = y * -1, x = x, color = time)) + geom_path() +      theme_bw() + scale_color_gradient(low = ""red"", high = ""blue"") +      facet_grid(hand ~ .) + theme_bw()",visualization,365111923776567e8,704
"dfm <- melt(df[c(""h1x_position"", ""h1y_position"", ""h2x_position"",      ""h2y_position"", ""time"")], id.var = ""time"")",data cleaning,365111923776567e8,704
"g7 <- ggplot(dfm, aes(x = time, y = value)) + geom_line() + facet_grid(scales = ""free"",      variable ~ .) + theme_bw()",visualization,365111923776567e8,704
"dfm <- melt(df[c(""hand_distance"", ""center_vel"", ""hand1_to_center"",      ""hand2_to_center"", ""h1vel"", ""h2vel"", ""time"")], id.var = ""time"")",data cleaning,365111923776567e8,704
"g8 <- ggplot(dfm, aes(x = time, y = value)) + geom_line() + facet_grid(scales = ""free"",      variable ~ .) + theme_bw()",visualization,365111923776567e8,704
"mm1 <- melt(df, id.var = ""time"")",data cleaning,365111923776567e8,704
"ggplot(mm1, aes(x = time, y = value)) + geom_point() + facet_grid(scales = ""free"",      variable ~ .)",visualization,365111923776567e8,704
"ggsave(""../data/allVars_mostRecent.pdf"", height = 20)",export,365111923776567e8,704
"path_out <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis""",setup,365111923776567e8,704
"path_script <- ""/data/liucj/github/autophagy-in-cancer/analysis/23-gene-set-enrichment-analysis""",setup,365111923776567e8,704
"path_gmt <- file.path(path_out, ""GSEA-collections-gmt"")",setup,365111923776567e8,704
dir.create(path_gmt),setup,365111923776567e8,704
"rda_filename <- file.path(""/data/liucj/project/06-autophagy/20-rda"",      ""01-autophagy-and-hallmarks-expresson.rda"")",setup,365111923776567e8,704
load(file = rda_filename),import,365111923776567e8,704
"fn_gsea <- function(.ds, .cls, .db, .output, .doc) GSEA(input.ds = .ds,      input.cls = .cls, gs.db = .db, output.directory = .output,      doc.string = .doc, non.interactive.run = F, reshuffling.type = ""gene.labels"",      nperm = 1000, weighted.score.type = 1, nom.p.val.threshold = -1,      fwer.p.val.threshold = -1, fdr.q.val.threshold = 0.25, topgs = 50,      adjust.FDR.q.val = F, gs.size.threshold.min = 10, gs.size.threshold.max = 1000,      reverse.sign = F, preproc.type = 0, random.seed = 111, perm.type = 0,      fraction = 1, replace = F, save.intermediate.results = F,      OLD.GSEA = F, use.fast.enrichment.routine = T)",setup,365111923776567e8,704
"fn_run_gsea <- function(.x, .path = gsea_path, script_path = script_path) .gct <- file.path(.path,      glue::glue("".x_as_classify_mrna.gct""))",setup,365111923776567e8,704
".cls <- file.path(.path, glue::glue("".x_as_classify_mrna.cls""))",setup,365111923776567e8,704
".gmt <- ""/data/liucj/project/06-autophagy/23-gene-set-enrichment-analysis/GSEA-collections-gmt/C2_CURATED.gmt""",setup,365111923776567e8,704
".output_dir <- file.path(.path, ""02-c2-curated-result/"")",setup,365111923776567e8,704
".doc <- paste(.x, ""GSEA.analysis"", sep = ""."")",data cleaning,365111923776567e8,704
if (!file.exists(.output_dir)) dir.create(.output_dir),setup,365111923776567e8,704
"source(file.path(script_path, ""GSEA.1.0.r""))",import,365111923776567e8,704
"fn_gsea(.ds = .gct, .cls = .cls, .db = .gmt, .output = .output_dir,      .doc = .doc)",not sure,365111923776567e8,704
"c(""DLBC"", ""ESCA"", ""HNSC"", ""READ"", ""SKCM"", ""TGCT"") %>% purrr::map(.f = fn_run_gsea,      .path = path_gsea_cancer_types, script_path = script_path)",not sure,365111923776567e8,704
"c(""DLBC"", ""ESCA"", ""HNSC"", ""READ"", ""SKCM"", ""TGCT"") %>% purrr::map(.f = fn_run_gsea,      .path = path_gsea_cancer_types, script_path = script_path)",not sure,365111923776567e8,704
benchmark$scheduler = as.factor(benchmark$scheduler),visualization,931931668892503e7,705
"factors = split(benchmark, list(benchmark$scheduler, benchmark$script))",visualization,931931668892503e7,705
"lapply(factors, function(j) summary(lm(j$memory_MB ~ j$chans +      j$samples)))",data cleaning,931931668892503e7,705
"lapply(factors, function(j) summary(lm(j$elapsed_time ~ j$chans +      j$samples)))",modeling,931931668892503e7,705
"source(""./global.R"")",setup,455492673441768e8,706
"source(""./seg_comparison.R"")",setup,455492673441768e8,706
"otherData <- function() waterChemistry <- expertNotes <- read.csv(""../../input/All_Lakes_through2012.csv"")",import,455492673441768e8,706
"main <- function() locations <- read.csv(""../../input/station_loc.csv"")",import,455492673441768e8,706
"source(""~/CaseStudy2/Analysis/merge_data.R"", echo = TRUE)",setup,468051557894796e8,707
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,27267808560282e9,708
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,27267808560282e9,708
"FTL <- read.csv(""/Volumes/NOAA_Data/CNH/Data/Catch/FTL_2009-2013_2014-03-21.csv"",      as.is = TRUE)",modeling,27267808560282e9,708
"pcares = prcomp(d, center = TRUE, scale = TRUE)",modeling,951039603212848e8,709
presults = data.frame(pcares$rotation),modeling,951039603212848e8,709
"presults$Study = sapply(rownames(presults), function(x) strsplit(x,      ""\\:"")[[1]][1])",setup,951039603212848e8,709
presults$Name = names2plot[presults$Study],not sure,951039603212848e8,709
"write.csv(shrimpVMS, ""/wrk2/efuller/NOAA/Data_Analysis/VMS/Code/processed_data/shrimpVMS.csv"")",export,38822087040171e9,710
owned <- unique(Owners$VESSEL.DOC..),data cleaning,38822087040171e9,710
captured <- length(which(owned %in% unique(nhObs$CG_NUM))),exploratory,38822087040171e9,710
"ownedObs <- nhObs[nhObs$CG_NUM %in% owned, ]",exploratory,38822087040171e9,710
length(unique(ownedObs$CG_NUM)) == captured,exploratory,38822087040171e9,710
uniqueOwnedObs <- unique(ownedObs$CG_NUM),data cleaning,38822087040171e9,710
captured <- length(uniqueOwnedObs[which(uniqueOwnedObs %in% tracks)]),not sure,38822087040171e9,710
"ownedObsVMS <- VMS[VMS$Doc_Number %in% uniqueOwnedObs, ]",modeling,38822087040171e9,710
length(unique(ownedObsVMS$Doc_Number)) == captured,not sure,38822087040171e9,710
"write.csv(ownedObsVMS, ""/wrk2/efuller/NOAA/Data_Analysis/VMS/Code/processed_data/ownedObsVMS.csv"")",export,38822087040171e9,710
"write.csv(shrimpVMS, ""/wrk2/efuller/NOAA/Data_Analysis/VMS/Code/processed_data/shrimpVMS.csv"")",export,38822087040171e9,710
mean(detect.d$z),evaluation,218118232907727e8,711
sum(detect.d$z < 0),evaluation,218118232907727e8,711
sum(detect.d$z < 0)/nrow(detect.d),evaluation,218118232907727e8,711
mean(detect.d$z),evaluation,218118232907727e8,711
sum(detect.d$p > 0.95 & detect.d$z < 0),exploratory,218118232907727e8,711
sum(detect.d$p > 0.95 & detect.d$z < 0)/nrow(detect.d),exploratory,218118232907727e8,711
"Marriages <- Marriages[, -c(2, 5:8)]",import,770037008682266e8,712
"Marriages[, 1] <- as.numeric(as.character(Marriages[, 1]))",exploratory,770037008682266e8,712
"Marriages[, 3] <- as.numeric(as.character(Marriages[, 3]))",exploratory,770037008682266e8,712
"Marriages <- spread(Marriages, ""PersonalStatus"", ""Total"")",exploratory,770037008682266e8,712
"Marriages <- Marriages[, c(1, 6)]",exploratory,770037008682266e8,712
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,818032345268875e8,713
qval.deseq.100$pi0,evaluation,818032345268875e8,713
qval.deseq.300$pi0,evaluation,818032345268875e8,713
"alpha.list = seq(0, 0.2, by = 0.01)",evaluation,818032345268875e8,713
length(alpha.list),evaluation,818032345268875e8,713
"num.wave = num.ms = num.deseq.100 = num.deseq.300 = rep(NA, length(alpha.list))",not sure,818032345268875e8,713
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),evaluation,818032345268875e8,713
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),not sure,818032345268875e8,713
num.deseq.100[i] = sum(qval.deseq.100$qvalues < alpha.list[i]),not sure,818032345268875e8,713
num.deseq.300[i] = sum(qval.deseq.300$qvalues < alpha.list[i]),not sure,818032345268875e8,713
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/code/"")",setup,818032345268875e8,713
"pdf(""discovery_FDR_JSM2014.pdf"")",export,818032345268875e8,713
"ymax = max(num.wave, num.ms, num.deseq.100, num.deseq.300)",modeling,818032345268875e8,713
ymin = 0,not sure,818032345268875e8,713
"plot(alpha.list, num.ms, ylim = c(ymin, ymax), col = ""red"", type = ""l"",      ylab = ""number of significant tests"", xlab = ""FDR"", main = """",      lty = 1, cex = 1)",visualization,818032345268875e8,713
"points(alpha.list, num.wave, ylim = c(ymin, ymax), col = ""blue"",      type = ""l"", lty = 1, cex = 1)",not sure,818032345268875e8,713
"legend(0, ymax, c(""multiseq"", ""WaveQTL""), col = c(""red"", ""blue""),      lty = c(1, 1), cex = 1, text.col = ""black"", merge = FALSE,      bg = ""white"")",modeling,818032345268875e8,713
dev.off(),not sure,818032345268875e8,713
alpha = 0.2,not sure,818032345268875e8,713
sum(qval.wave$qvalues < alpha),not sure,818032345268875e8,713
sum(qval.ms$qvalues < alpha),not sure,818032345268875e8,713
sum((qval.wave$qvalues < alpha) & (qval.ms$qvalues < alpha)),not sure,818032345268875e8,713
sum((qval.wave$qvalues < alpha) & (qval.ms$qvalues < alpha))/sum(qval.ms$qvalues <      alpha),not sure,818032345268875e8,713
"load(""./analysis/wood_density_distribution/bootstrapped/coef_CI_gls_wooddensity_VS_elevation.R"")",visualization,769531913567334e8,714
coef_CI,visualization,769531913567334e8,714
"booter(model2, data = wood_density_data_178ha, )",setup,769531913567334e8,714
"setwd(""/Users/efuller/1/CNH/Analysis/VMS/results/2014-10-29/"")",setup,641446736641228e8,715
"starec.dat$YR <- format(starec.dat$date, format = ""%Y"")",modeling,313739670673385e8,716
starec.dat$YR <- as.numeric(starec.dat$YR),modeling,313739670673385e8,716
starec.dat$month <- as.numeric(starec.dat$month),modeling,313739670673385e8,716
"starec.dat <- starec.dat[, c(1:7, 14:17, 24:33, 36:40, 42:51)]",modeling,313739670673385e8,716
starec.dat$STAT_ZONE[starec.dat$STAT_ZONE == (-9)] = NA,modeling,313739670673385e8,716
"starec.dat <- subset(starec.dat, starec.dat$STAT_ZONE != ""NA"")",modeling,313739670673385e8,716
"starec.dat <- subset(starec.dat, starec.dat$STAT_ZONE >= 1 &      starec.dat$STAT_ZONE <= 21)",modeling,313739670673385e8,716
summary(starec.dat),modeling,313739670673385e8,716
"invrec.dat <- read.csv(""C:/Users/kevin.purcell/Documents/seamap_2013/INVREC.csv"")",modeling,313739670673385e8,716
names(invrec.dat),modeling,313739670673385e8,716
"invrec.dat <- invrec.dat[, c(2, 11)]",modeling,313739670673385e8,716
"bgsrec.dat <- read.csv(""C:/Users/kevin.purcell/Documents/seamap_2013/BGSREC.csv"")",modeling,313739670673385e8,716
"specinfo.dat <- read.csv(""C:/Users/kevin.purcell/Documents/comm_analysis/spec_info_summary.csv"")",modeling,313739670673385e8,716
"colnames(specinfo.dat)[1] <- ""BIO_BGS""",modeling,313739670673385e8,716
"bycatch.dat <- read.csv(""C:/Users/kevin.purcell/Documents/comm_analysis/bycatch_status.csv"")",modeling,313739670673385e8,716
bycatch.dat$TAXONOMIC <- NULL,modeling,313739670673385e8,716
bycatch.dat$common_name <- NULL,modeling,313739670673385e8,716
"specinfo.dat <- merge(specinfo.dat, bycatch.dat, by = ""BIO_BGS"",      all.x = T)",modeling,313739670673385e8,716
"jkc.fish <- read.csv(""C:/Users/kevin.purcell/Documents/comm_analysis/seamap_keepers_comm_analysis.csv"")",modeling,313739670673385e8,716
"info.dat <- merge(jkc.fish, specinfo.dat, by = ""BIO_BGS"")",modeling,313739670673385e8,716
"write.csv(info.dat, file = ""C:/Users/kevin.purcell/Documents/comm_analysis/matrix_plot/infoDat.csv"")",modeling,313739670673385e8,716
"bgsrec.dat2 <- merge(bgsrec.dat, jkc.fish, by = ""BIO_BGS"")",modeling,313739670673385e8,716
"bgsrec.dat2 <- merge(bgsrec.dat2, specinfo.dat, by = ""BIO_BGS"")",modeling,313739670673385e8,716
"bgsrec.dat2 <- merge(bgsrec.dat2, invrec.dat, by = intersect(names(bgsrec.dat2),      names(invrec.dat)))",modeling,313739670673385e8,716
"bgsrec.dat2 <- merge(bgsrec.dat2, starec.dat, by = intersect(names(bgsrec.dat2),      names(starec.dat)))",communication,313739670673385e8,716
"bgsrec.dat2 <- subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD !=      ""NA"")",communication,313739670673385e8,716
"bgsrec.dat2 <- subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD < 30)",not sure,313739670673385e8,716
"bgsrec.dat2 <- subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD > 0)",not sure,313739670673385e8,716
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,838193154893815e8,717
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,838193154893815e8,717
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,838193154893815e8,717
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,838193154893815e8,717
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,838193154893815e8,717
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,1077147773467e10,718
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,1077147773467e10,718
library(rstan),setup,1077147773467e10,718
rstan_options(auto_write = TRUE),setup,1077147773467e10,718
options(mc.cores = parallel::detectCores()),setup,1077147773467e10,718
"load(""analysis/rdata-tmp/RoT-dat2.RData"")",setup,1077147773467e10,718
"parameters <- read.csv(""analysis/parameters/parameters.csv"")",setup,1077147773467e10,718
"fit <- stan(file = ""analysis/src-analysis/stan-models/binomial.stan"",      data = stan.dat2, iter = parameters$iters, chains = parameters$nchains,      seed = parameters$seed, verbose = T)",setup,1077147773467e10,718
"saveRDS(fit, file = ""analysis/mcmc-runs/ToRaising-Stan-Fit2.RDS"")",communication,1077147773467e10,718
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,242888981010765e7,719
"time_average %>% filter(pft == ""Early hardwood"", parameter ==      ""nonlocal_dispersal"") %>% ggplot() + aes(x = parameter_value,      y = value_mean) + geom_smooth(method = ""lm"") + geom_point() +      facet_wrap(~variable, scales = ""free_y"")",setup,242888981010765e7,719
library(shiny),setup,351300466340035e8,720
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Time-based Requests Type Analysis"",      sidebarPanel(actionButton(inputId = ""duration"", label = ""Avg. Processing Time"",          width = 200), br(), actionButton(inputId = ""bymonth"",          label = ""Requests by Month"", width = 200), br(), actionButton(inputId = ""byweek"",          label = ""Requests by Weekday"", width = 200), br(), actionButton(inputId = ""weekday_hour"",          label = ""Weekday and Hour"", width = 200), br(), actionButton(inputId = ""type_month"",          label = ""Request Type by Month"", width = 200), br(),          actionButton(inputId = ""type_weekday"", label = ""Request Type by Weekday"",              width = 200)), mainPanel(plotOutput(""plot""))), tabPanel(""Time-based Requests Source Analysis"",      sidebarPanel(actionButton(inputId = ""source_count"", label = ""Requests by Source"",          width = 200), br(), actionButton(inputId = ""source_type_count"",          label = ""Requests by Source and Type"", width = 200),          br(), actionButton(inputId = ""source_eff"", label = ""Efficiency by Source"",              width = 200), br(), actionButton(inputId = ""source_month"",              label = ""Request Source by Month"", width = 200),          br(), actionButton(inputId = ""source_weekday"", label = ""Request Source by Weekday"",              width = 200), br(), actionButton(inputId = ""calls_month"",              label = ""Calls by Month"", width = 200), br(), actionButton(inputId = ""calls_hour"",              label = ""Calls by Hour"", width = 200)), mainPanel(plotOutput(""plot2""))))",setup,351300466340035e8,720
"ui <- navbarPage(""Requesting Analysis"", fluid = TRUE, tabPanel(""Time-based Requests Type Analysis"",      sidebarPanel(actionButton(inputId = ""duration"", label = ""Avg. Processing Time"",          width = 200), br(), actionButton(inputId = ""bymonth"",          label = ""Requests by Month"", width = 200), br(), actionButton(inputId = ""byweek"",          label = ""Requests by Weekday"", width = 200), br(), actionButton(inputId = ""weekday_hour"",          label = ""Weekday and Hour"", width = 200), br(), actionButton(inputId = ""type_month"",          label = ""Request Type by Month"", width = 200), br(),          actionButton(inputId = ""type_weekday"", label = ""Request Type by Weekday"",              width = 200)), mainPanel(plotOutput(""plot""))), tabPanel(""Time-based Requests Source Analysis"",      sidebarPanel(actionButton(inputId = ""source_count"", label = ""Requests by Source"",          width = 200), br(), actionButton(inputId = ""source_type_count"",          label = ""Requests by Source and Type"", width = 200),          br(), actionButton(inputId = ""source_eff"", label = ""Efficiency by Source"",              width = 200), br(), actionButton(inputId = ""source_month"",              label = ""Request Source by Month"", width = 200),          br(), actionButton(inputId = ""source_weekday"", label = ""Request Source by Weekday"",              width = 200), br(), actionButton(inputId = ""calls_month"",              label = ""Calls by Month"", width = 200), br(), actionButton(inputId = ""calls_hour"",              label = ""Calls by Hour"", width = 200)), mainPanel(plotOutput(""plot2""))))",exploratory,351300466340035e8,720
library(shiny),exploratory,351300466340035e8,720
owned <- unique(Owners$VESSEL.DOC..),setup,391058926703408e8,721
captured <- length(which(owned %in% unique(nhObs$CG_NUM))),setup,391058926703408e8,721
"ownedObs <- nhObs[nhObs$CG_NUM %in% owned, ]",setup,391058926703408e8,721
length(unique(ownedObs$CG_NUM)) == captured,data cleaning,391058926703408e8,721
uniqueOwnedObs <- unique(ownedObs$CG_NUM),exploratory,391058926703408e8,721
captured <- length(uniqueOwnedObs[which(uniqueOwnedObs %in% tracks)]),exploratory,391058926703408e8,721
"ownedObsVMS <- VMS[VMS$Doc_Number %in% uniqueOwnedObs, ]",exploratory,391058926703408e8,721
length(unique(ownedObsVMS$Doc_Number)) == captured,data cleaning,391058926703408e8,721
"write.csv(ownedObsVMS, ""/wrk2/efuller/NOAA/Data_Analysis/VMS/Code/processed_data/ownedObsVMS.csv"")",export,391058926703408e8,721
pred_long$p <- 1/exp(pred_long$log_scale),data cleaning,796602256828919e8,722
pred_long$lambda <- exp(-pred_long$p * pred_long$xb),evaluation,796602256828919e8,722
pred_long$surv <- exp(-pred_long$lambda * (pred_long$time - 30)^pred_long$p),evaluation,796602256828919e8,722
pred_long$pr <- 1 - pred_long$surv,evaluation,796602256828919e8,722
"pred_long$plotgroup <- paste0(pred_long$x, pred_long$sim)",evaluation,796602256828919e8,722
"source(""Analysis/compute_triplets.R"")",setup,39973380509764e8,723
"source(""Analysis/compute_all_triplets.R"")",setup,39973380509764e8,723
"source(""Analysis/categorize_all_triplets.R"")",exploratory,39973380509764e8,723
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,976870395243168e6,724
"reg <- spid[-grep(""NOM."", spid$common_name), ]",data cleaning,976870395243168e6,724
"reg <- select(reg, SPID, common)",exploratory,976870395243168e6,724
"colnames(reg) <- c(""reg"", ""common"")",data cleaning,976870395243168e6,724
"alpha.list = seq(0.01, 0.2, by = 0.01)",communication,751114324200898e8,725
length(alpha.list),communication,751114324200898e8,725
"num.wave = num.ms = num.deseq = rep(NA, length(alpha.list))",data cleaning,751114324200898e8,725
for (i in 1:length(alpha.list)) num.wave[i] = sum(qval.wave$qvalues <      alpha.list[i]),export,751114324200898e8,725
num.ms[i] = sum(qval.ms$qvalues < alpha.list[i]),visualization,751114324200898e8,725
num.deseq[i] = sum(qval.deseq$qvalues < alpha.list[i]),visualization,751114324200898e8,725
number.of.random.samples = allLangN,evaluation,73338795825839e9,726
set.seed(563),setup,73338795825839e9,726
"compareWordsWithinLanguage(d.unanalyzable.wh.m, d.random.unanalyzable.m,      ""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_unanalyzable_AllSegments.csv"",      F)",evaluation,73338795825839e9,726
set.seed(38),setup,73338795825839e9,726
"compareWordsWithinLanguage(d.unanalyzable.wh.m, d.random.unanalyzable.m,      ""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_unanalyzable_FirstSegments.csv"",      T)",exploratory,73338795825839e9,726
number.of.random.samples = domainLangN,not sure,73338795825839e9,726
set.seed(939),not sure,73338795825839e9,726
"compareWordsWithinLanguage_Domain(d.unanalyzable.wh.m, d.random.unanalyzable.m,      ""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_unanalyzable_AllSegments_Domain"",      F)",evaluation,73338795825839e9,726
set.seed(444),setup,73338795825839e9,726
"compareWordsWithinLanguage_Domain(d.unanalyzable.wh.m, d.random.unanalyzable.m,      ""../Results/SimplifiedPhonology/PermutationResults/WithinLanguages/WithinRes_unanalyzable_FirstSegments_Domain"",      T)",modeling,73338795825839e9,726
"if (!dir.exists(""Computed"")) dir.create(""Computed"")",data cleaning,400602337904274e7,727
"save(timeAnalyses, file = ""Computed/timeAnalyses.RData"")",export,400602337904274e7,727
return(timeAnalyses),evaluation,400602337904274e7,727
"CNH <- ""/Volumes/NOAA_Data/CNH/""",communication,400602337904274e7,727
"FTL <- read.csv(paste(CNH, ""Data/Catch/FTL_2009-2013_w-o-c_samhouri.csv"",      sep = """"), stringsAsFactors = F, skip = 2)",import,400602337904274e7,727
"FTL <- head(FTL, -2)",data cleaning,400602337904274e7,727
"spid <- read.csv(paste(CNH, ""Analysis/Metiers/data/spid.csv"",      sep = """"), stringsAsFactors = F)",import,400602337904274e7,727
"mgmt_grp <- dlply(spid, .(mgmt_grp))",data cleaning,400602337904274e7,727
mgmt_grp <- mgmt_grp[2:9],data cleaning,400602337904274e7,727
"complex <- dlply(mgmt_grp[[""OTHR""]], .(complex))",data cleaning,400602337904274e7,727
"complex2 <- dlply(mgmt_grp[[""OTHR""]], .(complex2))",data cleaning,400602337904274e7,727
"mgmt_grp[[""SHRK""]] <- complex2[[""SHRK""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""SKAT""]] <- complex2[[""SKAT""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""BASS""]] <- complex[[""BASS""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""ECHN""]] <- complex[[""ECHN""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""MLSK""]] <- complex[[""MLSK""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""STRG""]] <- complex[[""STRG""]]",data cleaning,400602337904274e7,727
"mgmt_grp[[""TUNA""]] <- complex[[""TUNA""]]",data cleaning,400602337904274e7,727
"new_other <- intersect(complex[[""NA""]], complex2[[""NA""]])",data cleaning,400602337904274e7,727
"nrow(mgmt_grp[[""SHRK""]]) + nrow(mgmt_grp[[""SKAT""]]) + nrow(mgmt_grp[[""BASS""]]) +      nrow(mgmt_grp[[""ECHN""]]) + nrow(mgmt_grp[[""MLSK""]]) + nrow(mgmt_grp[[""STRG""]]) +      nrow(mgmt_grp[[""TUNA""]]) + nrow(new_other) == nrow(mgmt_grp[[""OTHR""]])",evaluation,400602337904274e7,727
"analysis <- read.dta(""data/d01_cacoh_stset_barlow.dta"", convert.underscore = TRUE)",exploratory,536581877619028e8,728
analysis_stata <- analysis,evaluation,536581877619028e8,728
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,902795517351478e8,729
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,902795517351478e8,729
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,902795517351478e8,729
"if (!file.exists(""Output"")) dir.create(""Output"")",export,902795517351478e8,729
"source(""Analysis/flower_script.R"")",exploratory,902795517351478e8,729
"source(""Analysis/growth_script.R"")",exploratory,902795517351478e8,729
"source(""Analysis/seed_script.R"")",exploratory,902795517351478e8,729
"source(""Analysis/surv_script.R"")",exploratory,902795517351478e8,729
"source(""Analysis/pca_script.R"")",evaluation,902795517351478e8,729
"download.file(gdp_url, ""GDP.csv"")",import,614781690295786e8,730
"library(""readr"")",setup,614781690295786e8,730
"columnNames <- c(""CountryCode"", ""Ranking"", ""Economy"", ""Gdp"")",data cleaning,614781690295786e8,730
"gdpData <- read_csv(gdp_url, col_names = columnNames, col_types = ""ci_cc"",      skip = 5, n_max = 231, na = c("".."", ""NA"", """"))",import,614781690295786e8,730
"species <- read.table(""data/dden_adult_new.txt"", header = TRUE)$sp",import,614781690295786e8,730
"occurance <- rep(0, dim(data)[1])",data cleaning,614781690295786e8,730
fun <- function(i) occurance[which(data$sp == as.character(i))] <- 1,setup,614781690295786e8,730
data$occurance <- occurance,setup,614781690295786e8,730
data$species <- i,setup,614781690295786e8,730
return(data),exploratory,614781690295786e8,730
"species_occurance_data <- foreach(i = species, .combine = rbind) %do%      fun(i)",setup,614781690295786e8,730
str(species_occurance_data),not sure,614781690295786e8,730
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,64479048945941e9,731
"ggplot(species_occurance_data, aes(x = elev, y = occurance, color = species)) +      facet_wrap(~species) + geom_point() + stat_smooth()",visualization,614781690295786e8,730
"write.table(species_occurance_data, file = ""./analysis/adult_distribution_analysis/data/species_occurance_data.txt"")",export,614781690295786e8,730
"save(poisson_ods_full_centred, file = ""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",modeling,64479048945941e9,731
sink(),modeling,64479048945941e9,731
sink(),modeling,64479048945941e9,731
"save(poisson_ods_full_centred, file = ""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",modeling,64479048945941e9,731
sink(),modeling,64479048945941e9,731
library(stringr),setup,843355897814035e8,732
library(tidyr),setup,843355897814035e8,732
"flavors = sort(c(""c4.large"", ""m4.large"", ""r3.large"", ""c3.large"",      ""m3.medium""))",setup,843355897814035e8,732
"f_str = str_sub(flavors, 1, 2)",setup,843355897814035e8,732
"df_analysis = read.table(file = ""../data/hp/scaling-analysis-SM-SF.dat"",      header = T)",import,843355897814035e8,732
"googledrive::drive_mkdir(""fall"", parent = ""temp_for_scott/analysis/data/raw_data"")",setup,834624914918095e8,733
"googledrive::drive_mkdir(""spring"", parent = ""temp_for_scott/analysis/data/raw_data"")",setup,834624914918095e8,733
"googledrive::drive_mkdir(""derived_data"", parent = ""temp_for_scott/analysis/data"")",import,834624914918095e8,733
"googledrive::drive_mkdir(""fall"", parent = ""temp_for_scott/analysis/data/derived_data"")",exploratory,834624914918095e8,733
"googledrive::drive_mkdir(""spring"", parent = ""temp_for_scott/analysis/data/derived_data"")",import,834624914918095e8,733
"raw_files <- file.path(raw_path, grep(""biomass_habmod-.*.rds"",      list.files(raw_path), value = TRUE))",import,834624914918095e8,733
"rw_dat <- googledrive::as_dribble(""temp_for_scott/analysis/output/fall/"")",import,834624914918095e8,733
"files <- purrr::map(raw_files, googledrive::drive_upload, path = raw_data_folder,      verbose = TRUE)",import,834624914918095e8,733
"spring_figures <- list.files(file.path(figure_path, ""spring""),      full.names = TRUE)",import,834624914918095e8,733
"df12$predicted_metier <- paste0(df12$predicted_metier, ""_12"")",not sure,985270210308954e8,734
"predicted_df <- merge(df10, df12, by = ""trip_id"")",not sure,985270210308954e8,734
"table(predicted_df$predicted_metier.x, predicted_df$predicted_metier.y)",not sure,985270210308954e8,734
"classAgreement(agreement(""NET"", 2013))$crand",not sure,985270210308954e8,734
"classAgreement(agreement(""POT"", 2009))$crand",export,985270210308954e8,734
"grgroups <- c(""TLS"", ""TWS"", ""TWL"", ""POT"", ""NET"", ""HKL"", ""MSC"")",export,985270210308954e8,734
pb <- progress::progress_bar$new(total = length(years)),data cleaning,313748412299901e8,735
for (year in years) pb$tick(),data cleaning,313748412299901e8,735
"ncfile <- paste0(year, "".nc"")",data cleaning,313748412299901e8,735
"target_file <- file.path(rundir, ncfile)",setup,313748412299901e8,735
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",modeling,455743056954816e8,736
par(op),modeling,455743056954816e8,736
"setwd(""/Users/rweiss/Dropbox/research/projects/InternetArchive/analysis"")",setup,353497693082318e8,737
"source(""config.R"")",setup,353497693082318e8,737
"source(""preprocess.R"")",modeling,353497693082318e8,737
"red_etel_plan <- ts(red_etel_plan_vect, start = c(2008, 1), end = c(2013,      12), frequency = 12)",modeling,629125419072807e8,738
"total_etel_plan <- ts(total_etel_plan_vect, start = c(2008, 1),      end = c(2013, 12), frequency = 12)",modeling,629125419072807e8,738
"efak_plan <- ts(efak_plan_vect, start = c(2008, 1), end = c(2013,      12), frequency = 12)",modeling,629125419072807e8,738
list.net.deg[[p]] <- list.deg,setup,612937248311937e8,739
list.net.numb[[p]] <- list.numb,import,612937248311937e8,739
q = 8,import,612937248311937e8,739
Temp.deg <- list.net.deg[[q]],import,612937248311937e8,739
Temp.numb <- list.net.numb[[q]],import,612937248311937e8,739
"Temp.numb <- lapply(Temp.numb, log)",evaluation,612937248311937e8,739
"par(mfrow = c(2, 1), mar = c(3, 4, 2, 2))",import,612937248311937e8,739
"boxplot(Temp.deg[[1]], Temp.deg[[2]], Temp.deg[[3]], Temp.deg[[4]],      Temp.deg[[5]], main = ""Degree"", col = ""darkgray"")",visualization,612937248311937e8,739
"boxplot(Temp.numb[[1]], Temp.numb[[2]], Temp.numb[[3]], Temp.numb[[4]],      Temp.numb[[5]], main = ""Number"", col = ""darkgray"")",visualization,612937248311937e8,739
"axis(1, at = 1:5, label = rownames(beta.par))",visualization,612937248311937e8,739
m <- 10,import,612937248311937e8,739
n <- 5,import,612937248311937e8,739
"mat <- matrix(rbinom(100, 10, 0.1), m, n)",import,612937248311937e8,739
"if (min(c(rowSums(mat), colSums(mat))) == 0) stop(""Hey, you have a species in your network that does not interact with any other species. The following functions will get stuck."")",evaluation,612937248311937e8,739
"par(mfrow = c(2, 3))",import,612937248311937e8,739
"hist(list.deg[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,612937248311937e8,739
"hist(list.deg[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,612937248311937e8,739
"hist(list.deg[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",visualization,612937248311937e8,739
"hist(list.deg[[4]], xlab = ""number"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",visualization,612937248311937e8,739
"hist(list.deg[[5]], xlab = ""number"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",visualization,612937248311937e8,739
"par(mfrow = c(2, 3))",import,612937248311937e8,739
"hist(list.numb[[1]], xlab = ""degree"", main = ""beta(1,1) 'uniform'"",      ylim = c(0, 1000))",exploratory,612937248311937e8,739
"hist(list.numb[[2]], xlab = ""degree"", main = ""beta(0.1,1) 'exponential'"",      ylim = c(0, 1000))",exploratory,612937248311937e8,739
"hist(list.numb[[3]], xlab = ""degree"", main = ""beta(3,3) 'normal'"",      ylim = c(0, 1000))",exploratory,612937248311937e8,739
print(dir),setup,373354240320623e8,740
print(strain),exploratory,373354240320623e8,740
"knit2html(""StrainTemplate_embryonic.Rmd"", output = paste(strain,      "".md"", sep = """"))",communication,373354240320623e8,740
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,123774906620383e8,741
"names(res) <- as.character(motif[, 2])",data cleaning,123774906620383e8,741
"total.motifs <- c(total.motifs, res)",data cleaning,123774906620383e8,741
ind <- ind + 1,not sure,123774906620383e8,741
results <- list(),data cleaning,123774906620383e8,741
results$id <- i,data cleaning,123774906620383e8,741
results$res <- res,data cleaning,123774906620383e8,741
cluster.weeder.res[[ind]] <- results,data cleaning,123774906620383e8,741
"cluster.weeder.m <- matrix(0, length(clusters), length(unique(sort(as.character(names(total.motifs))))))",data cleaning,123774906620383e8,741
rownames(cluster.weeder.m) <- 1:length(clusters),data cleaning,123774906620383e8,741
colnames(cluster.weeder.m) <- unique(sort(as.character(names(total.motifs)))),data cleaning,123774906620383e8,741
"for (i in 1:length(cluster.weeder.res)) for (j in 1:length(cluster.weeder.res[[i]]$res)) cluster.weeder.m[cluster.weeder.res[[i]]$id,      as.character(names(cluster.weeder.res[[i]]$res[j]))] <- cluster.weeder.res[[i]]$res[j]",data cleaning,123774906620383e8,741
"save.image(file = ""weeder_postCluster_analysis.RData"")",export,123774906620383e8,741
tmp = cluster.weeder.m,exploratory,123774906620383e8,741
"for (i in 1:nrow(tmp)) if (length(which(tmp[i, ] > 1.1)) > 0) cat(i,      ""\t"", paste(colnames(tmp)[which(tmp[i, ] > 1.1)], sep = ""\t""),      ""\t"", paste(tmp[i, which(tmp[i, ] > 1.1)], sep = ""\t""), ""\n"",      file = ""weeder_results.txt"", append = T)",export,123774906620383e8,741
"names(res) <- as.character(motif[, 2])",data cleaning,123774906620383e8,741
"ndad <- b.diffste(adall, ndall, 1024)",modeling,123774906620383e8,741
"print(sprintf(""AD ND difference is %f, standard error estimate: %f"",      ndad$meandiff, ndad$stderr))",communication,123774906620383e8,741
"sdad <- b.diffste(adall, sdall, 1024)",modeling,123774906620383e8,741
"print(sprintf(""AD SD difference is %f, standard error estimate: %f"",      sdad$meandiff, sdad$stderr))",communication,123774906620383e8,741
"print(""-----------------------------------------"")",communication,123774906620383e8,741
"print(""Studentized bootstrapped hypothesis test (Algo 16.2)"")",communication,123774906620383e8,741
"ndsd_tst <- b.studentized_ttest(sdall, ndall, 1000)",modeling,123774906620383e8,741
"b.showsiglev(ndsd_tst, ""SD vs ND"")",visualization,123774906620383e8,741
"ndad_tst <- b.studentized_ttest(adall, ndall, 1000)",modeling,123774906620383e8,741
"b.showsiglev(ndad_tst, ""AD vs ND"")",visualization,123774906620383e8,741
"sdad_tst <- b.studentized_ttest(adall, sdall, 1000)",modeling,123774906620383e8,741
"b.showsiglev(sdad_tst, ""AD vs SD"")",visualization,123774906620383e8,741
"print(""-----------------------------------------"")",communication,123774906620383e8,741
"source(""~/Github/DataScienceLiveSessionAssignment06/Analysis/getmode.R"",      echo = FALSE)",import,123774906620383e8,741
dim(mn.rentals),exploratory,123774906620383e8,741
count(is.na(mn.rentals$gross.sqft)),exploratory,123774906620383e8,741
count(is.na(mn.rentals$land.sqft)),exploratory,123774906620383e8,741
summary(mn.rentals$sale.price.n),exploratory,123774906620383e8,741
getmode(mn.rentals$sale.price.n),exploratory,123774906620383e8,741
hist(log10(mn.rentals$sale.price.n)),visualization,123774906620383e8,741
"minval = min(wave.null[[2]], ms.null[[2]], wave.alt[[2]], ms.alt[[2]])",data cleaning,123774906620383e8,741
"hist(wave.null[[2]], main = ""null Wavelet (10 2full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(ms.null[[2]], main = ""null multiscale (10 2full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(wave.alt[[2]], main = ""alt Wavelet (10 2full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(ms.alt[[2]], main = ""alt multiscale (10 2full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"par(mfrow = c(4, 1))",setup,123774906620383e8,741
"maxval = max(wave.null[[3]], ms.null[[3]], wave.alt[[3]], ms.alt[[3]])",exploratory,123774906620383e8,741
"minval = min(wave.null[[3]], ms.null[[3]], wave.alt[[3]], ms.alt[[3]])",exploratory,123774906620383e8,741
"hist(wave.null[[3]], main = ""null Wavelet (10 4full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(ms.null[[3]], main = ""null multiscale (10 4full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(wave.alt[[3]], main = ""alt Wavelet (10 4full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
"hist(ms.alt[[3]], main = ""alt multiscale (10 4full)"", breaks = 47,      xlim = c(minval, maxval))",visualization,123774906620383e8,741
dev.off(),visualization,123774906620383e8,741
"fpr.wave.list = vector(""list"", length(case.name))",data cleaning,123774906620383e8,741
"tpr.wave.list = vector(""list"", length(case.name))",data cleaning,123774906620383e8,741
"fpr.ms.list = vector(""list"", length(case.name))",data cleaning,123774906620383e8,741
"tpr.ms.list = vector(""list"", length(case.name))",data cleaning,123774906620383e8,741
"for (cc in 1:length(case.name)) logLR = as.numeric(c(wave.null[[cc]],      wave.alt[[cc]]))",modeling,123774906620383e8,741
"disc = c(rep(0, 500), rep(1, 500))",modeling,123774906620383e8,741
"rnk = order(logLR, decreasing = TRUE)",modeling,123774906620383e8,741
p.wave = logLR[rnk],modeling,123774906620383e8,741
d.wave = disc[rnk],data cleaning,123774906620383e8,741
fdp.wave = NULL,data cleaning,123774906620383e8,741
sig.wave = NULL,data cleaning,123774906620383e8,741
tpr.wave = NULL,data cleaning,123774906620383e8,741
fpr.wave = NULL,data cleaning,123774906620383e8,741
uni.p.wave = unique(p.wave),data cleaning,123774906620383e8,741
for (i in 1:length(uni.p.wave)) wh = which(p.wave >= uni.p.wave[i]),data cleaning,123774906620383e8,741
sig.wave[i] = length(wh),data cleaning,123774906620383e8,741
fdp.wave[i] = 1 - (sum(d.wave[wh])/length(wh)),modeling,123774906620383e8,741
tpr.wave[i] = sum(d.wave[wh])/500,modeling,123774906620383e8,741
fpr.wave[i] = (length(wh) - sum(d.wave[wh]))/500,modeling,123774906620383e8,741
fpr.wave.list[[cc]] = fpr.wave,data cleaning,123774906620383e8,741
tpr.wave.list[[cc]] = tpr.wave,data cleaning,123774906620383e8,741
"for (cc in 1:length(case.name)) logLR = as.numeric(c(ms.null[[cc]],      ms.alt[[cc]]))",modeling,123774906620383e8,741
"disc = c(rep(0, 500), rep(1, 500))",modeling,123774906620383e8,741
"rnk = order(logLR, decreasing = TRUE)",data cleaning,123774906620383e8,741
p.ms = logLR[rnk],modeling,123774906620383e8,741
d.ms = disc[rnk],data cleaning,123774906620383e8,741
fdp.ms = NULL,data cleaning,123774906620383e8,741
sig.ms = NULL,data cleaning,123774906620383e8,741
tpr.ms = NULL,data cleaning,123774906620383e8,741
uni.p.ms = unique(p.ms),data cleaning,123774906620383e8,741
for (i in 1:length(uni.p.ms)) wh = which(p.ms >= uni.p.ms[i]),data cleaning,123774906620383e8,741
sig.ms[i] = length(wh),data cleaning,123774906620383e8,741
fdp.ms[i] = 1 - (sum(d.ms[wh])/length(wh)),data cleaning,123774906620383e8,741
tpr.ms[i] = sum(d.ms[wh])/500,modeling,123774906620383e8,741
fpr.ms[i] = (length(wh) - sum(d.ms[wh]))/500,modeling,123774906620383e8,741
fpr.ms.list[[cc]] = fpr.ms,modeling,123774906620383e8,741
tpr.ms.list[[cc]] = tpr.ms,data cleaning,123774906620383e8,741
"save(""fpr.wave.list"", ""tpr.wave.list"", ""fpr.ms.list"", ""tpr.ms.list"",      file = output.path)",data cleaning,123774906620383e8,741
pdf(ROC.file.name),export,123774906620383e8,741
xmax = 1,visualization,123774906620383e8,741
ymax = 1,evaluation,123774906620383e8,741
"plot(0, 0, xlim = c(0, xmax), ylim = c(0, ymax), xlab = ""FPR (1 - Specificity)"",      ylab = ""TPR (Sensitivity)"", type = ""n"")",evaluation,123774906620383e8,741
"points(c(0, fpr.ms.list[[1]]), c(0, tpr.ms.list[[1]]), type = ""l"",      col = ""red"")",export,123774906620383e8,741
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,530126608442515e8,742
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,530126608442515e8,742
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,530126608442515e8,742
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,530126608442515e8,742
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,777227611746639e8,743
"packages <- c(""RSQLite"", ""logging"", ""stringr"", ""zoo"", ""dplyr"",      ""jsonlite"", ""lubridate"", ""data.table"", ""ggplot2"", ""tidyverse"",      ""geosphere"", ""rgdal"", ""sp"", ""raster"", ""rgeos"", ""leaflet"",      ""htmlwidgets"")",exploratory,777227611746639e8,743
"namesTable <- read.delim(""D:/TCC/miRNA_predict/Analysis/RNAs/mart_names.txt"",      stringsAsFactors = FALSE, sep = "","")",not sure,744536516722292e7,744
"sequencesTable <- read.delim(""D:/TCC/miRNA_predict/Analysis/RNAs/mart_sequences.txt"",      stringsAsFactors = FALSE, sep = "","", header = FALSE, col.names = c(""Gene stable ID"",          ""Sequence""))",visualization,744536516722292e7,744
"mergedTable <- merge(x = namesTable, y = sequencesTable, by = ""Gene.stable.ID"")",evaluation,744536516722292e7,744
"cleanedTable <- mergedTable[(mergedTable$Sequence != ""Sequence unavailable""),      ]",data cleaning,744536516722292e7,744
cleanedTable <- unique(cleanedTable),exploratory,744536516722292e7,744
"for (chr in 1:22) chr.list[[chr]] = rep(chr, numSites.list[chr])",not sure,153730086050928e8,745
sites.list[[chr]] = 1:numSites.list[chr],not sure,153730086050928e8,745
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,153730086050928e8,745
"save(""chr.list"", ""sites.list"", file = out.path)",export,153730086050928e8,745
siteSize = 2048,setup,153730086050928e8,745
"treatment = ""Retinoic""",setup,153730086050928e8,745
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",setup,153730086050928e8,745
numSites.list = scan(path),setup,153730086050928e8,745
"chr.list = sites.list = vector(""list"", 22)",setup,153730086050928e8,745
"for (chr in 1:22) chr.list[[chr]] = rep(chr, numSites.list[chr])",setup,153730086050928e8,745
sites.list[[chr]] = 1:numSites.list[chr],setup,153730086050928e8,745
"out.path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/info/"",      treatment, ""."", siteSize, "".chr.sites.Robj"")",export,153730086050928e8,745
"save(""chr.list"", ""sites.list"", file = out.path)",export,153730086050928e8,745
siteSize = 1024,export,153730086050928e8,745
"head(player_per_game_by_season, 10)",exploratory,862273023696616e8,746
synapseLogin(),setup,911169755039737e8,747
library(data.table),data cleaning,911169755039737e8,747
"estimate <- as.data.frame(t(read.table(synGet(""syn5908274"")@filePath,      sep = ""\t"")))",data cleaning,911169755039737e8,747
require(ggplot2),data cleaning,911169755039737e8,747
"patient <- synTableQuery(""select Patient,Length_in_mm,RNASeq,TumorLocation from syn5556216"")@values",data cleaning,911169755039737e8,747
"t.test(wide_exp2$geom_k_p.1x, wide_exp2$geom_k_p.3x, paired = TRUE)",exploratory,11431774427183e9,748
"df = read.csv(""/Users/carlos/pu/multigoals/analysis/geom_k_models.csv"")",import,11431774427183e9,748
"df$experiment = ifelse(df$condition %in% c(""No Bonus"", ""Bonus""),      ""exp4"", ""exp1"")",data cleaning,11431774427183e9,748
"m = lme(geom_k_p ~ factor(condition), random = ~1 | pid, data = df[df$experiment ==      ""exp4"", ], method = ""ML"")",exploratory,11431774427183e9,748
anova(m),modeling,11431774427183e9,748
summary(m),exploratory,11431774427183e9,748
"m = lme(geom_exp_k ~ factor(condition), random = ~1 | pid, data = df[df$experiment ==      ""exp4"", ], method = ""ML"")",exploratory,11431774427183e9,748
anova(m),modeling,11431774427183e9,748
summary(m),exploratory,11431774427183e9,748
"wide_exp4 = reshape(df[df$experiment == ""exp4"", ], idvar = ""pid"",      timevar = ""condition"", direction = ""wide"")",data cleaning,11431774427183e9,748
"t.test(wide_exp4$geom_k_p.Bonus, wide_exp4$`geom_k_p.No Bonus`,      paired = TRUE, alternative = ""less"")",exploratory,11431774427183e9,748
"t.test(wide_exp4$geom_exp_k.Bonus, wide_exp4$`geom_exp_k.No Bonus`,      paired = TRUE, alternative = ""greater"")",exploratory,11431774427183e9,748
"wilcox.test(wide_exp4$geom_k_p.Bonus, wide_exp4$`geom_k_p.No Bonus`,      paired = TRUE, alternative = ""less"")",exploratory,11431774427183e9,748
"wilcox.test(wide_exp4$geom_exp_k.Bonus, wide_exp4$`geom_exp_k.No Bonus`,      paired = TRUE, alternative = ""greater"")",exploratory,11431774427183e9,748
"df = read.csv(""/Users/carlos/pu/multigoals/analysis/comparing-num-actions.csv"")",import,11431774427183e9,748
"onlyexp3 = df[df$high_stakes %in% c(""True"", ""False""), ]",exploratory,11431774427183e9,748
"m = lmer(num_actions ~ factor(no_bonus) + (1 | pid) + (1 | initial_state),      data = onlyexp3, REML = FALSE)",modeling,11431774427183e9,748
anova(m),not sure,11431774427183e9,748
"m = lmer(num_actions ~ factor(trial_repeat) + (1 | pid) + (1 |      initial_state), data = onlyexp3, REML = FALSE)",export,11431774427183e9,748
anova(m),data cleaning,11431774427183e9,748
comparing_experiments = df[],data cleaning,11431774427183e9,748
"if (aid_loc_China$longitude[i]%%0.5 == 0) aid_loc_China$longitude[i] <- aid_loc_China$longitude[i] +      max(min(rnorm(1)/100, 0.5), -0.5)",exploratory,913283198606223e8,749
"write.csv(aid_loc_China, file = ""/Users/Tilmanski/Documents/UNI/MPhil/Second Year/Thesis_Git/Analysis/input/AidData_China/locations_perturbed.csv"",      row.names = FALSE)",communication,913283198606223e8,749
"write(forgmt, file = ""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"",      ncolumns = length(forgmt), sep = ""\t"")",visualization,913283198606223e8,749
library(GSA),visualization,913283198606223e8,749
"test <- GSA.read.gmt(""/n/rinn_data1/users/agroff/GITHUB/BrainMap/analysis/support/sexdiffs.gmt"")",not sure,913283198606223e8,749
library(MuMIn),setup,240925158374011e8,750
library(lattice),setup,240925158374011e8,750
library(xlsx),setup,240925158374011e8,750
library(data.table),setup,240925158374011e8,750
library(gridExtra),setup,240925158374011e8,750
library(tidyr),setup,240925158374011e8,750
library(devtools),setup,240925158374011e8,750
library(GGally),setup,240925158374011e8,750
"install_github(""vqv/ggbiplot"")",setup,240925158374011e8,750
library(ggbiplot),setup,240925158374011e8,750
library(dplyr),setup,240925158374011e8,750
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,240925158374011e8,750
"source(""Analysis/flower_script.R"")",setup,240925158374011e8,750
"source(""Analysis/growth_script.R"")",setup,240925158374011e8,750
"source(""Analysis/seed_script.R"")",setup,240925158374011e8,750
"source(""Analysis/surv_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
"l_ply(plot.list, print)",setup,306411804864183e8,751
library(MuMIn),setup,240925158374011e8,750
library(lattice),setup,240925158374011e8,750
library(xlsx),setup,240925158374011e8,750
library(data.table),setup,240925158374011e8,750
library(gridExtra),setup,240925158374011e8,750
library(tidyr),setup,240925158374011e8,750
library(devtools),setup,240925158374011e8,750
library(GGally),setup,240925158374011e8,750
"install_github(""vqv/ggbiplot"")",setup,240925158374011e8,750
library(ggbiplot),setup,240925158374011e8,750
library(dplyr),setup,240925158374011e8,750
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,240925158374011e8,750
"source(""Analysis/flower_script.R"")",setup,240925158374011e8,750
"source(""Analysis/growth_script.R"")",setup,240925158374011e8,750
"source(""Analysis/seed_script.R"")",setup,240925158374011e8,750
dev.off(),not sure,306411804864183e8,751
"source(""Analysis/surv_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
library(MuMIn),setup,240925158374011e8,750
library(lattice),setup,240925158374011e8,750
library(xlsx),setup,240925158374011e8,750
library(data.table),setup,240925158374011e8,750
library(gridExtra),setup,240925158374011e8,750
library(tidyr),setup,240925158374011e8,750
library(devtools),setup,240925158374011e8,750
library(GGally),setup,240925158374011e8,750
"install_github(""vqv/ggbiplot"")",setup,240925158374011e8,750
library(ggbiplot),setup,240925158374011e8,750
library(dplyr),setup,240925158374011e8,750
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,240925158374011e8,750
"source(""Analysis/flower_script.R"")",setup,240925158374011e8,750
"source(""Analysis/growth_script.R"")",setup,240925158374011e8,750
"source(""Analysis/seed_script.R"")",setup,240925158374011e8,750
"source(""Analysis/surv_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
library(MuMIn),setup,240925158374011e8,750
library(lattice),setup,240925158374011e8,750
library(xlsx),setup,240925158374011e8,750
library(data.table),setup,240925158374011e8,750
library(gridExtra),setup,240925158374011e8,750
library(tidyr),setup,240925158374011e8,750
library(devtools),setup,240925158374011e8,750
library(GGally),setup,240925158374011e8,750
"install_github(""vqv/ggbiplot"")",setup,240925158374011e8,750
library(ggbiplot),setup,240925158374011e8,750
library(dplyr),setup,240925158374011e8,750
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,240925158374011e8,750
"source(""Analysis/flower_script.R"")",setup,240925158374011e8,750
"source(""Analysis/growth_script.R"")",setup,240925158374011e8,750
"source(""Analysis/seed_script.R"")",setup,240925158374011e8,750
"source(""Analysis/surv_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
library(MuMIn),setup,240925158374011e8,750
library(lattice),setup,240925158374011e8,750
library(xlsx),setup,240925158374011e8,750
library(data.table),setup,240925158374011e8,750
library(gridExtra),setup,240925158374011e8,750
library(tidyr),setup,240925158374011e8,750
library(devtools),setup,240925158374011e8,750
library(GGally),setup,240925158374011e8,750
"install_github(""vqv/ggbiplot"")",setup,240925158374011e8,750
library(ggbiplot),setup,240925158374011e8,750
library(dplyr),setup,240925158374011e8,750
"if (!file.exists(""Output"")) dir.create(""Output"")",setup,240925158374011e8,750
"source(""Analysis/flower_script.R"")",setup,240925158374011e8,750
"source(""Analysis/growth_script.R"")",setup,240925158374011e8,750
"source(""Analysis/seed_script.R"")",setup,240925158374011e8,750
"source(""Analysis/surv_script.R"")",setup,240925158374011e8,750
"source(""Analysis/pca_script.R"")",setup,240925158374011e8,750
xmin = 0,data cleaning,590217801043764e8,752
"par(mfrow = c(2, 1))",data cleaning,590217801043764e8,752
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,705130522372201e8,753
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,705130522372201e8,753
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,705130522372201e8,753
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,705130522372201e8,753
"ggsave(""Artikel im Zeitverlauf je Website.png"", plot = pa_9,      width = 20, height = 15, units = ""cm"", dpi = 320, path = ""./analysis/render_pictures/"")",export,705130522372201e8,753
gam.2mo.avg.dur.tx <- na.omit(gam.2mo.avg.dur.tx),data cleaning,377968390239403e8,754
RunPermutation <- function(sitetype) DataSite <- Data %>% filter(AAChange ==      sitetype),setup,610067067202181e8,755
par(new = T),not sure,721896060742438e8,756
"event_colors = list(upswing = color_to_hex(""forestgreen"", 0.1),      downswing = color_to_hex(""forestgreen"", 0.1))",visualization,721896060742438e8,756
as.numeric(p.hats > 0),modeling,34227596106939e9,757
"mean((p.hats > 0) == test$Result, na.rm = TRUE)",modeling,34227596106939e9,757
"source(""data-raw/fetch-raw-data.R"")",setup,940534900873899e7,758
"par(mfrow = c(3, 1))",modeling,347643661312759e8,759
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,347643661312759e8,759
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,347643661312759e8,759
"hist(pval[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : pvalue [600]"", length(pval) - length(del.ix.deseq)),      xlim = c(xmin, xmax), xlab = ""p=value"")",visualization,347643661312759e8,759
dev.off(),visualization,347643661312759e8,759
"setwd(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/fig/DESeqdebug/"")",setup,347643661312759e8,759
"pdf(""hist.statistic.pval.DESeq2.600.0.discrete.pooling.pdf"")",visualization,347643661312759e8,759
filter.cut = 0,data cleaning,347643661312759e8,759
"deseq.alt = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".alt.run/output/DESeq2.600.all.pval."",      filter.cut, "".txt""))))",import,347643661312759e8,759
"deseq.null = as.numeric(as.matrix(read.table(paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/"",      treatment, ""."", siteSize, ""."", strand, ""."", 100, "".null.run/output/DESeq2.600.all.pval."",      filter.cut, "".txt""))))",import,347643661312759e8,759
"del.ix.deseq = union(which(is.na(deseq.alt) == TRUE), which(is.na(deseq.null) ==      TRUE))",data cleaning,347643661312759e8,759
xmax = 1,visualization,347643661312759e8,759
xmin = 0,visualization,347643661312759e8,759
"par(mfrow = c(2, 1))",visualization,347643661312759e8,759
"hist(deseq.alt[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : alt test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,347643661312759e8,759
"hist(deseq.null[-del.ix.deseq], breaks = 200, main = paste0(filter.cut,      "" : null test statistic [600]""), xlim = c(xmin, xmax), xlab = ""p-value"")",visualization,347643661312759e8,759
dev.off(),visualization,347643661312759e8,759
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,846081048017368e8,760
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,846081048017368e8,760
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,846081048017368e8,760
"outputCOEFS = rep(names(output)[c(2:5, 16, 19, 20, 21, 22, 23,      24, 17, 18)], 2)",data cleaning,846081048017368e8,760
"statCOEFS = names(MCMaster500)[c(-(1:3), -17)]",data cleaning,846081048017368e8,760
"titles = c(""Noise"", ""House Size"", ""Lot Size"", ""Year Built"", ""Owner Occupancy"",      ""Median Income"", ""School Test Scores"", ""Distance to Lake"",      ""Distance to Park"", ""Distance to Shop"", ""Distance to CBD"",      ""Percent White"", ""Percent Under Age 18"")",data cleaning,846081048017368e8,760
"pdf(""analysis/04MonteCarloSim/Revision/MCsimResultsSDsk500and2000.pdf"",      height = 8, width = 6, family = ""Palatino"")",data cleaning,846081048017368e8,760
"par(oma = c(0.5, 0.5, 3, 0.5))",modeling,846081048017368e8,760
"layout(matrix(c(1, 1:14), 5, 3, byrow = TRUE))",modeling,846081048017368e8,760
"par(mar = c(0, 0, 0, 0))",modeling,846081048017368e8,760
"plot(0, 0, type = ""n"", ylab = """", xlab = """", axes = F)",modeling,846081048017368e8,760
"legend(""center"", c(""Simulated (2000)"", ""Actual (2000)"", ""Simulated (500)"",      ""Actual (500)""), col = c(""red"", ""red"", ""blue"", ""blue""), lty = c(1,      3, 1, 3), lwd = 2, box.col = ""white"", cex = 1.7)",visualization,846081048017368e8,760
"par(mar = c(2.5, 1, 2, 1.5))",visualization,846081048017368e8,760
coef <- fixef(surv_model),setup,774714665487409e8,761
"for (i in 14:26) MCplotter(outputCOEFS[i], statCOEFS[i])",visualization,846081048017368e8,760
"title(titles[i - 13], main.cex = 1.5, line = 0)",visualization,846081048017368e8,760
"setwd(""C:/Users/mcolvin/Documents/projects/Age and Growth/Analysis/Sample Size"")",setup,14103311416693e9,762
"source(""./src/1_global.R"")",import,14103311416693e9,762
"source(""./src/2_functions.R"")",import,14103311416693e9,762
"source(""./src/3_load.R"")",import,14103311416693e9,762
"source(""./src/4_clean.R"")",import,14103311416693e9,762
"source(""./src/5_tables.R"")",import,14103311416693e9,762
"source(""./src/6_figures.R"")",import,14103311416693e9,762
"source(""./src/7_analysis.R"")",import,14103311416693e9,762
"write.csv(tables(2), ""./output/vbgf_app.csv"")",export,14103311416693e9,762
"write.csv(tables(3), ""./output/struc_app.csv"")",export,14103311416693e9,762
"pathOutput <- ""F:/Projects/Nls/Links2011/Analysis/Df/2011-11-13/DoubleEntered.csv""",import,14103311416693e9,762
"R2_Geo = cor(y[-ind], fhat[-ind])^2",modeling,691087902290746e8,763
"X = Morph[!is.na(Y[, j]), ]",data cleaning,691087902290746e8,763
"X = scale(X, scale = FALSE)",data cleaning,691087902290746e8,763
"X = cbind(rep(1, nrow(X)), X)",data cleaning,691087902290746e8,763
theta_hat = theta[cvs[[j]][3]],data cleaning,691087902290746e8,763
"K = GaussKernel(t(X), theta_hat)",modeling,691087902290746e8,763
diag(K) = 1,visualization,691087902290746e8,763
n = nrow(K),setup,691087902290746e8,763
"v = matrix(1, n, 1)",import,691087902290746e8,763
M = diag(n) - v %*% t(v)/n,not sure,691087902290746e8,763
K = M %*% K %*% M,not sure,691087902290746e8,763
"inventory5$median.chfl[jj2] <- median(Tinventory[[nbparamT1 *      (jj2 - 1) + thvn + 6]], na.rm = TRUE)",exploratory,821054493775591e8,764
"inventory5$sd.chfl[jj2] <- sd(Tinventory[[nbparamT1 * (jj2 -      1) + thvn + 6]], na.rm = TRUE)",exploratory,821054493775591e8,764
"inventory5$mean.chC[jj2] <- mean(TinventoryC[[nbparamT1C * (jj2 -      1) + 5]], na.rm = TRUE)",exploratory,821054493775591e8,764
"inventory5$dint.chC[jj2] <- sum(weightarea * TinventoryC[[nbparamT1C *      (jj2 - 1) + 5]], na.rm = TRUE)",exploratory,821054493775591e8,764
"inventory5$se.chC[jj2] <- sum(weightarea * TinventoryC[nbparamT1C *      (kk2 - 1) + thCvn + 5], na.rm = TRUE)",exploratory,821054493775591e8,764
inventory5$t.mean <- area.dom * porosity.mean * inventory5$mean.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.med <- area.dom * porosity.mean * inventory5$median.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.sd <- area.dom * porosity.mean * inventory5$sd.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.dint <- area.dom * porosity.mean * inventory5$dint.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.se <- area.dom * porosity.mean * inventory5$se.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.meanfl <- area.dom * porosity.mean * inventory5$mean.chfl *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.medfl <- area.dom * porosity.mean * inventory5$median.chfl *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.dintfl <- area.dom * porosity.mean * inventory5$dint.chfl *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$t.sd <- area.dom * porosity.mean * inventory5$sd.ch *      1e-09 * 0.3048,exploratory,821054493775591e8,764
inventory5$tC.mean <- area.dom * porosity.mean * inventory5$mean.chC *      1e-09,exploratory,821054493775591e8,764
inventory5$tC.dint <- area.dom * porosity.mean * inventory5$dint.chC *      1e-09,exploratory,821054493775591e8,764
inventory5$tC.se <- area.dom * porosity.mean * inventory5$se.chC *      1e-09,exploratory,821054493775591e8,764
inventory5$tCD.mean <- inventory5$t.mean + inventory5$tC.mean,exploratory,821054493775591e8,764
inventory5$tCD.sd <- inventory5$t.sd + inventory5$tC.se,exploratory,821054493775591e8,764
inventory5$tCD.dint <- inventory5$t.dint + inventory5$tC.dint,exploratory,821054493775591e8,764
inventory5$tCD.se <- inventory5$t.se + inventory5$tC.se,exploratory,821054493775591e8,764
"saveRDS(inventory5, ""./analysis/processed_data/inventoryloesswithuncertaintyfinal.rdata"")",export,821054493775591e8,764
"Tinventory.final <- merge(inventoryja.csv, inventory5, by = ""MYEAR"")",data cleaning,821054493775591e8,764
"saveRDS(Tinventory.final, ""./analysis/processed_data/Tinventoryfinal.rdata"")",export,821054493775591e8,764
rm(TCfl),setup,821054493775591e8,764
rm(Tfl),setup,821054493775591e8,764
rm(fullfit),setup,821054493775591e8,764
rm(logfullfit),setup,821054493775591e8,764
rm(logt.loess),setup,821054493775591e8,764
rm(logtC.loess),setup,821054493775591e8,764
rm(t.loess),setup,821054493775591e8,764
rm(tC.loess),setup,821054493775591e8,764
rm(predlogt),setup,821054493775591e8,764
rm(predlogtC),setup,821054493775591e8,764
rm(predt),setup,821054493775591e8,764
rm(predtC),setup,821054493775591e8,764
"ECs = ECs[which(rownames(ECs) %in% rownames(Y)), ]",data cleaning,631898809690028e8,765
"G = G[which(rownames(G) %in% rownames(Y)), ]",data cleaning,631898809690028e8,765
"Morph = Morph[which(rownames(Morph) %in% rownames(Y)), ]",data cleaning,631898809690028e8,765
"Geo = Geo[which(rownames(Geo) %in% rownames(Y)), ]",data cleaning,631898809690028e8,765
dim(ECs),exploratory,631898809690028e8,765
dim(G),exploratory,631898809690028e8,765
dim(Geo),exploratory,631898809690028e8,765
dim(Y),exploratory,631898809690028e8,765
dim(Morph),exploratory,631898809690028e8,765
"set.seed(11151990, kind = ""L'Ecuyer-CMRG"")",setup,631898809690028e8,765
nsplit = 0.8,not sure,631898809690028e8,765
ndatasets = 1000,not sure,631898809690028e8,765
iter = 20000,not sure,631898809690028e8,765
burn = 10000,not sure,631898809690028e8,765
thin = 10,not sure,631898809690028e8,765
sigma = 1,setup,631898809690028e8,765
"load(""~/Dropbox/Columbia Radiogenomics/Analysis/Cross_Validation_Results/GaussCV_Results.RData"")",setup,631898809690028e8,765
"theta = seq(from = 0.1, to = 10, by = 0.1)",setup,631898809690028e8,765
registerDoParallel(cores = detectCores()),setup,631898809690028e8,765
"req <- c(""rstan"")",setup,315076210768893e8,766
"lapply(req, library, character.only = TRUE)",setup,315076210768893e8,766
rm(req),setup,315076210768893e8,766
set.seed(893749),setup,315076210768893e8,766
sessionInfo(),setup,315076210768893e8,766
"poisson_ods_full_centred <- stan_model(""./analysis/m01_poisson_ods_full_centred.stan"",      verbose = TRUE)",modeling,315076210768893e8,766
"save(poisson_ods_full_centred, file = ""./analysis/m01_poisson_ods_full_centred_compiled.Rdta"")",export,315076210768893e8,766
sink(),export,315076210768893e8,766
"multiscale.analysis.repodir <- scan("".multiscale_analysis.repodir.txt"",      what = character())",import,693254149053246e8,767
siteSize = 2048,setup,693254149053246e8,767
"treatment = ""Copper""",setup,693254149053246e8,767
null = FALSE,setup,693254149053246e8,767
"strand = ""both""",setup,693254149053246e8,767
"deseq.dat.path = ""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/run/deseq/""",setup,693254149053246e8,767
numSam = 6,setup,693254149053246e8,767
numS = siteSize%/%300,setup,693254149053246e8,767
"path = paste0(""/mnt/lustre/home/shim/multiscale_analysis/analysis/roger_ATAC/locus/"",      treatment, ""."", siteSize, "".numSites.txt"")",setup,693254149053246e8,767
numSites.list = scan(path),import,693254149053246e8,767
for (chr in 1:22) numSites = numSites.list[chr],setup,693254149053246e8,767
"deseq.dat = read.table(paste0(deseq.dat.path, treatment, ""."",      siteSize, ""."", strand, "".300.alt.run/data."", chr, "".txt""),      as.is = TRUE)",import,693254149053246e8,767
st = (1:numSites) * numS - (numS - 1),setup,693254149053246e8,767
en = (1:numSites) * numS,setup,693254149053246e8,767
"res = sapply(1:numSites, function(x, st.in, en.in, deseq.dat.in) return(as.numeric(apply(deseq.dat.in[(st[x]):(en[x]),      ], 2, sum))), st.in = st, en.in = en, deseq.dat.in = deseq.dat)",import,693254149053246e8,767
"survgrid[dirnum, 4] = rA[edge[length(edge)]]",export,936288222204894e8,768
"sink(paste(simdir, ""/SurvGrid.txt"", sep = """"))",not sure,936288222204894e8,768
print(survgrid),communication,936288222204894e8,768
sink(),not sure,936288222204894e8,768
str(large_plot_data),exploratory,616806673118845e8,769
list(delayed_assign = delayed_assign),not sure,616806673118845e8,769
neg.dif <- dif[dif < 0],data cleaning,882994174025953e7,770
"elf_statistics <- read.table(elf_statistics, header = TRUE, sep = "","")",setup,4042622896377e10,771
"write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",      region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,      quote = TRUE)",setup,4042622896377e10,771
return(elf_statistics),setup,4042622896377e10,771
return(elf_statistics),setup,4042622896377e10,771
"elf_statistics <- read.table(elf_statistics, header = TRUE, sep = "","")",setup,4042622896377e10,771
"write.csv(elf_statistics, file = paste(save_directory, ""ELF_Stats_Breakpoints."",      region, ""."", YV, ""."", XV, "".csv"", sep = """"), row.names = FALSE,      quote = TRUE)",setup,4042622896377e10,771
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,643763200147077e8,772
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",import,643763200147077e8,772
"save(constrainedLoadings, file = ""analysis/fitted/constrainedLoadings.Rda"")",export,643763200147077e8,772
rm(constrainedLoadings),setup,643763200147077e8,772
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,363352023297921e8,773
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,363352023297921e8,773
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,363352023297921e8,773
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,363352023297921e8,773
"source(""~/CaseStudy2/Analysis/preliminary_analysis.R"", echo = TRUE)",exploratory,363352023297921e8,773
"source(""~/CaseStudy2/Analysis/analysis_wGraphics.R"", echo = TRUE)",exploratory,363352023297921e8,773
print(filename),import,261470237048343e8,774
print(dat$strain[i]),visualization,261470237048343e8,774
dir.create(filename),visualization,261470237048343e8,774
setwd(filename),setup,261470237048343e8,774
strain <- dat$strain[i],setup,261470237048343e8,774
timepoint <- dat$sample[i],import,261470237048343e8,774
tissue <- dat$sample[i],import,261470237048343e8,774
alpha <- 0.05,import,261470237048343e8,774
dir <- dat$dir[i],setup,261470237048343e8,774
"knit2html(""/n/rinn_data2/users/agroff/seq/OtherMice/Lincp21/analysis/SupplementalFileX_Lincp21_StrainTemplate.Rmd"",      output = paste(filename, "".md"", sep = """"), quiet = TRUE)",import,261470237048343e8,774
"knit2html(""/n/rinn_data2/users/agroff/seq/OtherMice/Lincp21/analysis/SupplementalFileX_Lincp21_StrainTemplate.Rmd"",      output = paste(filename, "".md"", sep = """"), quiet = TRUE)",export,261470237048343e8,774
filename <- dat$filename[i],not sure,261470237048343e8,774
biocLite(),data cleaning,394548213575035e8,775
"biocLite(""ChIPseeker"")",data cleaning,394548213575035e8,775
"biocLite(""TxDb.Hsapiens.UCSC.hg38.knownGene"")",data cleaning,394548213575035e8,775
"biocLite(""clusterProfiler"")",data cleaning,394548213575035e8,775
"biocLite(""org.Hs.eg.db"")",data cleaning,394548213575035e8,775
"biocLite(""ReactomePA"")",communication,394548213575035e8,775
library(ChIPseeker),communication,394548213575035e8,775
library(TxDb.Hsapiens.UCSC.hg19.knownGene),communication,394548213575035e8,775
library(TxDb.Hsapiens.UCSC.hg38.knownGene),communication,394548213575035e8,775
library(clusterProfiler),communication,394548213575035e8,775
library(org.Hs.eg.db),communication,394548213575035e8,775
library(ReactomePA),communication,394548213575035e8,775
tx19 <- TxDb.Hsapiens.UCSC.hg19.knownGene,communication,394548213575035e8,775
tx38 <- TxDb.Hsapiens.UCSC.hg38.knownGene,communication,394548213575035e8,775
"promoter <- getPromoters(TxDb = tx38, upstream = 3000, downstream = 3000)",export,394548213575035e8,775
"par(mar = c(1, 4, 1, 1), cex = 0.97)",setup,682893374469131e8,776
"M_partFlags = matrix(c(2996, 24, 1764, 711, 397, 943, 0), ncol = 1,      byrow = T)",import,682893374469131e8,776
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,821674329228699e8,777
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,821674329228699e8,777
"colnames(modMat) <- gsub(""[()]"", """", colnames(modMat))",not sure,821674329228699e8,777
colnames(modMat),setup,821674329228699e8,777
"v <- voom(y, modMat, plot = FALSE)",import,821674329228699e8,777
pca <- as.data.frame(prcomp(t(v$E))$x),exploratory,821674329228699e8,777
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,677690900396556e8,778
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,677690900396556e8,778
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,677690900396556e8,778
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,677690900396556e8,778
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,677690900396556e8,778
count(is.na(mn.rentals$land.sqft)),data cleaning,677690900396556e8,778
summary(mn.rentals$sale.price.n),data cleaning,677690900396556e8,778
getmode(mn.rentals$sale.price.n),visualization,677690900396556e8,778
hist(log10(mn.rentals$sale.price.n)),visualization,677690900396556e8,778
hist(log10(mn.rentals$sale.price.n)),visualization,677690900396556e8,778
count(is.na(mn.rentals$land.sqft)),visualization,677690900396556e8,778
summary(mn.rentals$sale.price.n),visualization,677690900396556e8,778
getmode(mn.rentals$sale.price.n),visualization,677690900396556e8,778
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,161446125712246e7,779
"model <- train_stacked_model(formula, indels, indel_calls)",modeling,161446125712246e7,779
predict_function <- glmnetpredict,evaluation,161446125712246e7,779
"mn <- read.csv(""rollingsales_manhattan.csv"", skip = 4, header = TRUE)",setup,149454401573166e8,780
head(mn),import,149454401573166e8,780
summary(mn),exploratory,149454401573166e8,780
str(mn),exploratory,149454401573166e8,780
"mn$SALE.PRICE.N <- as.numeric(gsub(""[^[:digit:]]"", """", mn$SALE.PRICE))",exploratory,149454401573166e8,780
"d.0 <- read.table(""../history_0.txt"", skip = 2)",import,652709008194506e8,781
"outputs <- d.0[(no.agents + 1):length(d.0[, 1]), (4 + no.features +      1):(4 + no.features + 1 + no.features - 1)]",data cleaning,652709008194506e8,781
csim <- function(x1) x <- as.numeric(x1),data cleaning,652709008194506e8,781
y <- as.numeric(uber.proto),data cleaning,652709008194506e8,781
c <- x %*% y/sqrt(x %*% x * y %*% y),modeling,652709008194506e8,781
return(c),export,652709008194506e8,781
"d.sim <- apply(outputs, 1, csim)",data cleaning,652709008194506e8,781
"plot(d.sim, col = 2, type = ""b"", lty = 2, xlab = ""tick"", ylab = ""similarity to uber prototype"")",visualization,652709008194506e8,781
"VMSdf[, `:=`(c(""Longitude"", ""Latitude""), list(coordinates(VMS)[,      1], coordinates(VMS)[, 2])), with = FALSE]",import,844630658160895e8,782
rm(VMS),modeling,844630658160895e8,782
"setkey(VMSdf, NULL)",communication,844630658160895e8,782
"large_plot_data <- read.table(""./analysis/inundation_predicts_species_distributions/data/forestplot_160_spatial_data_UPDATE.txt"",      header = T)",modeling,636844055261463e7,783
head(large_plot_data),visualization,636844055261463e7,783
"abn <- with(large_plot_data, tapply(sp, sp, length))",exploratory,636844055261463e7,783
riskratio$abundance <- abn[which(names(abn) %in% riskratio$sp)],evaluation,636844055261463e7,783
"library(""parallel"")",setup,712274335557595e8,784
"load(""gl_1990_merge_rmNA.Rdata"")",import,712274335557595e8,784
"load(""gl_2015_merge_rmNA.Rdata"")",import,712274335557595e8,784
"pca_merge_1990 <- glPca(gl_1990_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",data cleaning,712274335557595e8,784
"save(pca_merge_1990, file = ""pca_merge_1990.Rdata"")",export,712274335557595e8,784
"pca_merge_2015 <- glPca(gl_2015_merge_rmNA, parallel = TRUE,      n.cores = 15, nf = 20)",modeling,712274335557595e8,784
"setwd(""/Users/rsimham/Documents/Ramesh/SMU/GitRepos/Case Studies/MSDS-CaseStudy1/Analysis/Data"")",setup,697690207976848e8,785
"par(mar = c(8, 8, 8, 8))",visualization,255693583050743e8,786
par(new = T),visualization,255693583050743e8,786
"plot(x = threshold_distance[winner]/max(threshold_distance),      y = event_distance[winner], xaxt = ""n"", yaxt = ""n"", xlim = c(0,          1), ylim = c(0, 1), xlab = """", ylab = """", bty = ""n"",      pch = 20, col = ""red"", cex = 3)",not sure,255693583050743e8,786
"lines(x = c(0, threshold_distance[winner]/max(threshold_distance)),      y = c(0, event_distance[winner]), lty = 2)",visualization,255693583050743e8,786
dev.off(),not sure,255693583050743e8,786
TP = nrow(agreement),setup,255693583050743e8,786
FP = nrow(disagreement_FP),exploratory,255693583050743e8,786
FN = nrow(disagreement_FN),exploratory,255693583050743e8,786
TN = nrow(disagreement_TN),exploratory,255693583050743e8,786
TPR = TP/(TP + FN),exploratory,255693583050743e8,786
FPR = FP/(FP + TN),exploratory,255693583050743e8,786
precision = TP/(TP + FP),exploratory,255693583050743e8,786
"return(list(TPR = TPR, FPR = FPR, precision = precision))",exploratory,255693583050743e8,786
"compare_optimized(""optimized_thresholds_SRP_2.RData"", ""analysis/SRP/replicates/SRP.csv"",      ""optimized_comparison_SRP_2"")",exploratory,255693583050743e8,786
"compare_optimized(""optimized_thresholds_F_0mM_2.RData"", ""analysis/F/replicates/F_0mM.csv"",      ""optimized_comparison_F_0mM_2"")",modeling,255693583050743e8,786
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",modeling,255693583050743e8,786
"compare_optimized(""optimized_thresholds_F_10mM_2.RData"", ""analysis/F/replicates/F_10mM.csv"",      ""optimized_comparison_F_10mM_2"")",modeling,255693583050743e8,786
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,328810680657625e7,787
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,328810680657625e7,787
summary(logistic_analysis),setup,585845557507127e7,788
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",data cleaning,401999333174899e8,789
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",data cleaning,797111216932535e8,790
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,852137601701543e8,791
"vol_terms.13.18 <- readr::read_csv(file = ""C:/Users/MonticT/Documents/AnalysisProjects/Vol_Terms/Vol. Terms2013-20182.csv"",      col_types = cols(.default = ""c""), progress = T)",setup,852137601701543e8,791
"colnames(vol_terms.13.18) <- colnames(vol_terms.13.18) %>% map_chr(function(x) x %>%      str_replace_all(pattern = ""EMPLOYEE_"", replacement = ""Emp_"") %>%      str_to_lower())",exploratory,852137601701543e8,791
"vol_terms.13.18 <- vol_terms.13.18 %>% mutate(term = ifelse(emp_quit_date >      0, 1, 0))",exploratory,852137601701543e8,791
"tidy.name.vector <- make.names(colnames(vol_terms.13.18), unique = TRUE)",data cleaning,852137601701543e8,791
colnames(vol_terms.13.18) <- tidy.name.vector,modeling,852137601701543e8,791
"source(""make_flowpic.R"")",setup,945217911852524e8,792
rm(list = ls()),data cleaning,945217911852524e8,792
"source(""compute_iut.R"")",setup,945217911852524e8,792
rm(list = ls()),data cleaning,945217911852524e8,792
"source(""make_supp_tables.R"")",setup,945217911852524e8,792
rm(list = ls()),setup,945217911852524e8,792
"df_ar$class[df_ar$class == ""ar_acf_42_1""] = ""AR 25""",evaluation,440923531772569e8,793
"df_ar$class = factor(df_ar$class, levels = c(""AR"", ""AR 25"", ""AR 50"",      ""AR 100""))",data cleaning,440923531772569e8,793
"write.table(df_ar, file = ""../data/hp/5a_ar_correction_analysis-hp-data-raw.dat"",      row.names = F)",export,440923531772569e8,793
library(Rmisc),setup,440923531772569e8,793
"y = df_ar %>% dplyr::group_by(class, metric) %>% dplyr::summarise(resp = Rmisc::CI(value)[2],      s1 = Rmisc::CI(value)[1], s2 = Rmisc::CI(value)[3])",evaluation,440923531772569e8,793
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,577554489253089e8,794
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,577554489253089e8,794
"dir.create(Sys.getenv(""R_LIBS_USER""), showWarnings = FALSE, recursive = TRUE)",setup,577554489253089e8,794
"install.packages(""iterators"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,577554489253089e8,794
"install.packages(""foreign"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,577554489253089e8,794
"install.packages(""foreach"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,577554489253089e8,794
"install.packages(""xtable"", Sys.getenv(""R_LIBS_USER""), repos = ""https://cran.cnr.berkeley.edu/"")",setup,577554489253089e8,794
"library(foreign, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,577554489253089e8,794
"library(foreach, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,577554489253089e8,794
"library(doParallel, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,577554489253089e8,794
"library(xtable, lib.loc = Sys.getenv(""R_LIBS_USER""))",setup,577554489253089e8,794
rm(list = ls()),setup,577554489253089e8,794
gc(),setup,577554489253089e8,794
set.seed(231),setup,577554489253089e8,794
ncores = 40,setup,577554489253089e8,794
"source(""butler_nickerson_analysis.R"")",setup,577554489253089e8,794
"source(""butler_tables.R"")",setup,577554489253089e8,794
"source(""butler_tables.R"")",setup,577554489253089e8,794
"data2 <- read.table(""Analysis/Data/data2"", sep = "","")",setup,413919740356505e8,795
MainData <- data2,evaluation,413919740356505e8,795
"cat(""Loading data...\n"")",setup,847689571790397e8,796
"load(""../../data/ideology_analysis/ideology_analysis_input.RData"")",import,847689571790397e8,796
"p <- ggplot(df, aes(x = ideology_dist, y = adjusted_alignment_score)) +      stat_binhex(bins = 80) + xlab(""Ideological Distance"") + ylab(""Alignment Score"") +      scale_fill_gradient(low = cbPalette[1], high = cbPalette[2],          trans = ""log"", labels = c(""1"", ""60"", ""3,000"", ""160,000"",              ""9,000,000"")) + guides(fill = guide_legend(title = ""Count"")) +      plot_theme",visualization,847689571790397e8,796
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",exploratory,707063377369195e8,797
mello_data <- as_data_frame(data),not sure,707063377369195e8,797
mello_data <- tbl_dt(mello_data),not sure,707063377369195e8,797
"plot.list[[5]] <- qplot(x = coverage, y = mean.err, ymin = mean.err -      2 * se.err, ymax = mean.err + 2 * se.err, data = power.cluster,      color = method, geom = c(""line"", ""errorbar"", ""point""))",visualization,916722579160705e8,798
"plot.list[[5]] <- plot.list[[5]] + facet_grid(offset.primary ~      eff.magnitude, labeller = function(var, value) round(value,      3))",visualization,916722579160705e8,798
"plot.list[[5]] <- plot.list[[5]] + labs(list(x = ""Coverage"",      y = ""Mean absolute error"", title = ""Model-based and Parzen window primary position errors\nby offset and effective magnitude""))",visualization,916722579160705e8,798
"plot.list[[6]] <- qplot(x = coverage, y = mean.err, ymin = mean.err -      2 * se.err, ymax = mean.err + 2 * se.err, data = power.by.coverage,      color = method, geom = c(""line"", ""errorbar"", ""point""))",visualization,916722579160705e8,798
"plot.list[[6]] <- plot.list[[6]] + labs(list(x = ""Coverage"",      y = ""Mean absolute error"", title = ""Model-based and Parzen window primary position position errors vs. coverage""))",visualization,916722579160705e8,798
"plot.list[[7]] <- qplot(x = eff.magnitude, y = mean.err, ymin = mean.err -      2 * se.err, ymax = mean.err + 2 * se.err, data = power.by.eff.magnitude,      color = method, geom = c(""line"", ""errorbar"", ""point""))",not sure,916722579160705e8,798
"plot.list[[7]] <- plot.list[[7]] + labs(list(x = ""Effective magnitude"",      y = ""Mean absolute error"", title = ""Model-based and Parzen window primary position position errors vs. effective magnitude""))",not sure,916722579160705e8,798
"plot.list[[8]] <- qplot(x = offset.primary, y = mean.err, ymin = mean.err -      2 * se.err, ymax = mean.err + 2 * se.err, data = power.by.offset,      color = method, geom = c(""line"", ""errorbar"", ""point""))",not sure,916722579160705e8,798
"plot.list[[8]] <- plot.list[[8]] + labs(list(x = ""Offset"", y = ""Mean absolute error"",      title = ""Model-based and Parzen window primary position position errors vs. effective magnitude""))",not sure,916722579160705e8,798
theme_set(theme_bw()),not sure,916722579160705e8,798
"pdf(""powerAnalysis/plots_compare_power.pdf"", 11, 11 * 0.62, onefile = TRUE)",not sure,916722579160705e8,798
"l_ply(plot.list, print)",not sure,916722579160705e8,798
dev.off(),not sure,916722579160705e8,798
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",not sure,623165901517495e8,799
"df_analysis = read.table(file = ""../../../multiple_types/hp/data/scaling-general-data.dat"",      header = T)",import,623165901517495e8,799
"test1 <- c(""peril_GEOB"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/GE_OB/"")",setup,247013163287193e8,800
"test2 <- c(""peril_kidney"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/Kidney/"")",setup,247013163287193e8,800
"test3 <- c(""peril_wholebrain"", ""/n/rinn_data1/users/agroff/seq/PERIL/data/diffs/cuffdiff_v221_newgtf/whole_brain"")",setup,247013163287193e8,800
"test_master_sheet <- (rbind(test1, test2, test3))",setup,247013163287193e8,800
"for (i in seq(1, (dim(test_master_sheet)[1]))) strain <- test_master_sheet[i,      1]",setup,247013163287193e8,800
"dir <- test_master_sheet[i, 2]",data cleaning,247013163287193e8,800
print(dir),exploratory,247013163287193e8,800
print(strain),export,247013163287193e8,800
"plot(mn.sale$gross.sqft, mn.sale$sale.price.n)",visualization,992216838058084e8,801
"write.csv(deliveriesFromCompletedMatches, ""../Analysis/deliveries.csv"")",import,890548685565591e7,802
"plot(log10(mn.sale$gross.sqft), log10(mn.sale$sale.price.n))",visualization,992216838058084e8,801
hist(log10(mn.sale$sale.price.n)),visualization,992216838058084e8,801
"qqplot(log10(mn.sale$gross.sqft), log10(mn.sale$sale.price.n))",visualization,992216838058084e8,801
"mn.condos <- mn.sale[which(grepl(""CONDOS"", mn.sale$building.class.category)),      ]",data cleaning,992216838058084e8,801
dim(mn.condos),exploratory,992216838058084e8,801
predRE,modeling,890548685565591e7,802
"plot(log10(mn.condos$gross.sqft), log10(mn.condos$sale.price.n))",visualization,992216838058084e8,801
hist(log10(mn.condos$sale.price.n)),visualization,992216838058084e8,801
"summary(mn.condos[which(mn.condos$sale.price.n < 1e+05), ])",exploratory,992216838058084e8,801
mn.condos$outliers <- (log10(mn.condos$sale.price.n) <= 5) +      0,data cleaning,992216838058084e8,801
"mn.condos <- mn.condos[which(mn.condos$outliers == 0), ]",data cleaning,992216838058084e8,801
"plot(mn.condos$gross.sqft, mn.condos$sale.price.n)",visualization,992216838058084e8,801
"write.csv(mn.condos, file = ""rollingsales_manhattan_condos.csv"")",export,992216838058084e8,801
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",setup,603278842754662e7,803
summary(model2),evaluation,382451118901372e8,804
"model3 <- lm(elev ~ dden, weights = abundance, riskratio)",modeling,382451118901372e8,804
"model4 <- lm(elev ~ diff_mort, weights = abundance, riskratio)",modeling,382451118901372e8,804
summary(model3),evaluation,382451118901372e8,804
summary(model4),evaluation,382451118901372e8,804
"par(mfrow = c(2, 2))",not sure,382451118901372e8,804
plot(model2),visualization,382451118901372e8,804
"save(model2, file = ""./analysis/inundation_predicts_species_distributions/models/elevation_Vs_wooddensityN_diff_mortality_abundance.R"")",export,382451118901372e8,804
"model2_glm <- glm(elev ~ dden + diff_mort, riskratio, weights = abundance,      family = ""gaussian"")",modeling,382451118901372e8,804
summary(model2_glm),evaluation,382451118901372e8,804
"save(model2_glm, file = ""./analysis/inundation_predicts_species_distributions/models/elevation_Vs_wooddensityN_diff_mortality_GLM_abundance.R"")",export,382451118901372e8,804
summary(model2),evaluation,382451118901372e8,804
library(matrixStats),import,382451118901372e8,804
"fits <- readRDS(""analysis/mcmc-runs/ToRaising-Stan-Fit3.RDS"")",import,382451118901372e8,804
"mats <- data.frame(Int1 = NULL, Slope1 = NULL, Slope2 = NULL,      Int2 = NULL, lp__ = NULL, s = NULL)",data cleaning,382451118901372e8,804
for (i in 1:length(fits)) if (!(is.null(fits[[i]]))) tmpdat <- as.data.frame(extract(fits[[i]])),data cleaning,382451118901372e8,804
tmpdat$s <- i,not sure,382451118901372e8,804
"mats <- as.data.frame(rbind(mats, tmpdat))",not sure,382451118901372e8,804
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,690822739852592e8,805
"downloadGSMbedFiles(""GSM1003583"", destDir = ""hg19"")",import,690822739852592e8,805
"K562_hg19_P300 <- ""GSM1003583_hg19_wgEncodeBroadHistoneK562P300StdPk.broadPeak""",not sure,690822739852592e8,805
K562_hg19_P300 <- readPeakFile(K562_hg19_P300),import,690822739852592e8,805
"downloadGSMbedFiles(""GSM1003578"", destDir = ""hg19"")",import,690822739852592e8,805
"A549_hg19_H3k27ac <- ""GSM1003578_hg19_wgEncodeBroadHistoneA549H3k27acEtoh02Pk.broadPeak""",not sure,690822739852592e8,805
A549_hg19_H3k27ac <- readPeakFile(A549_hg19_H3k27ac),import,690822739852592e8,805
GSM1003578,exploratory,690822739852592e8,805
"Cbp & P300 <- enrichPeakOverlap(hg19_Cbp, hg19_P300, TxDb = NULL,      pAdjustMethod = ""BH"", nShuffle = 1000, chainFile = NULL,      pool = TRUE, mc.cores = detectCores() - 1, verbose = TRUE)",exploratory,690822739852592e8,805
"K562_hg19_Cbp <- ""GSM1003574_hg19_wgEncodeBroadHistoneK562Cbpsc369Pk.broadPeak""",not sure,690822739852592e8,805
K562_hg19_Cbp <- readPeakFile(K562_hg19_Cbp),import,690822739852592e8,805
"K562_hg19_Cbp.tagMatrix <- getTagMatrix(K562_hg19_Cbp, windows = promoter)",data cleaning,690822739852592e8,805
"tagHeatmap(K562_hg19_Cbp.tagMatrix, xlim = c(-3000, 3000), color = ""red"")",visualization,690822739852592e8,805
peak <- K562_hg19_Cbp,setup,690822739852592e8,805
peak,exploratory,690822739852592e8,805
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",visualization,114939539693296e8,806
"source(""Rcode/get_behav_gp.r"")",setup,114939539693296e8,806
"source(""Rcode/analysis_for_paper1/multidimensional_analysis_prep_diffTW.R"")",setup,114939539693296e8,806
One_windowMIT = Multi_datainput_m %>% select(Distance_traveled6:groupingvar),data cleaning,114939539693296e8,806
"five_windowMIT = Multi_datainput_m %>% select(Distance_traveled1:Drink5,      groupingvar)",data cleaning,114939539693296e8,806
six_windowMIT = Multi_datainput_m,import,114939539693296e8,806
"groupingby = ""AOCF""",import,114939539693296e8,806
"source(""Rcode/get_behav_gp.r"")",setup,114939539693296e8,806
"source(""Rcode/analysis_for_paper1/multidimensional_analysis_prep_diffTW.R"")",setup,114939539693296e8,806
One_windowaocf = Multi_datainput_m %>% select(Distance_traveled6:groupingvar),data cleaning,114939539693296e8,806
"five_windowaocf = Multi_datainput_m %>% select(Distance_traveled1:Stretch5,      groupingvar)",data cleaning,114939539693296e8,806
six_windowaocf = Multi_datainput_m,import,114939539693296e8,806
"allwindowconc = list(One_windowMIT, five_windowMIT, six_windowMIT,      One_windowaocf, five_windowaocf, six_windowaocf)",import,114939539693296e8,806
"name_allwindowconc = c(""One_windowMIT"", ""five_windowMIT"", ""six_windowMIT"",      ""One_windowaocf"", ""five_windowaocf"", ""six_windowaocf"")",import,114939539693296e8,806
for (i in 1:6) data = allwindowconc[[i]],exploratory,114939539693296e8,806
data$groupingvar = as.numeric(data$groupingvar),data cleaning,114939539693296e8,806
temp = data %>% select(-groupingvar),data cleaning,114939539693296e8,806
cfreq <- colSums(temp),exploratory,114939539693296e8,806
"E1 = names(temp[, cfreq == 0])",data cleaning,114939539693296e8,806
"data = data[, !names(data) %in% c(E1)]",data cleaning,114939539693296e8,806
allwindowconc[[i]] = data,data cleaning,114939539693296e8,806
set.seed(74),setup,114939539693296e8,806
Acc_real = NA,data cleaning,114939539693296e8,806
for (i in 1:6) data = allwindowconc[[i]],data cleaning,114939539693296e8,806
"Code will appear in this box. Click on the classifier below that best fits the code, then click the NEXT button. Press START to begin.",evaluation,470132092246786e8,807
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,114939539693296e8,806
"route <- ""./analysis/seedling_mortality_analysis/""",import,470132092246786e8,807
x = as.data.frame(t(ACURRACY)),import,114939539693296e8,806
"as.data.frame(cbind(c(paste(name_allwindowconc[i], ""accuracy_logreg"",      sep = ""_""), ACURRACY[1]), c(paste(name_allwindowconc[i],      ""accuracy_svm_radial"", sep = ""_""), ACURRACY[2]), c(paste(name_allwindowconc[i],      ""accuracy_svm_linear"", sep = ""_""), ACURRACY[3])))",import,114939539693296e8,806
"names(x) = c(paste(name_allwindowconc[i], ""accuracy_logreg"",      sep = ""_""), paste(name_allwindowconc[i], ""accuracy_svm_radial"",      sep = ""_""), paste(name_allwindowconc[i], ""accuracy_svm_linear"",      sep = ""_""))",import,114939539693296e8,806
"Acc_real <- cbind(Acc_real, x)",import,114939539693296e8,806
"Acc_real = Acc_real[, -1]",data cleaning,114939539693296e8,806
Npermutation = 246,setup,114939539693296e8,806
"if (!exists(""Acc_cumm"")) Acc_cumm = Acc_real",data cleaning,114939539693296e8,806
for (j in (seq(1:Npermutation) + 1)) Acc_notreal = NA,data cleaning,114939539693296e8,806
for (i in 1:6) data = allwindowconc[[i]],data cleaning,114939539693296e8,806
data$groupingvar = sample(data$groupingvar),data cleaning,114939539693296e8,806
"source(""Rcode/analysis_for_paper1/SVM_logreg_accuracycalc.r"")",setup,114939539693296e8,806
x = as.data.frame(t(ACURRACY)),import,114939539693296e8,806
"as.data.frame(cbind(c(paste(name_allwindowconc[i], ""accuracy_logreg"",      sep = ""_""), ACURRACY[1]), c(paste(name_allwindowconc[i],      ""accuracy_svm_radial"", sep = ""_""), ACURRACY[2]), c(paste(name_allwindowconc[i],      ""accuracy_svm_linear"", sep = ""_""), ACURRACY[3])))",import,114939539693296e8,806
"names(x) = c(paste(name_allwindowconc[i], ""accuracy_logreg"",      sep = ""_""), paste(name_allwindowconc[i], ""accuracy_svm_radial"",      sep = ""_""), paste(name_allwindowconc[i], ""accuracy_svm_linear"",      sep = ""_""))",evaluation,114939539693296e8,806
"countryFedStatsUrl <- ""https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv""",modeling,564635686809197e8,808
"download.file(countryFedStatsUrl, destfile = ""./countryFedStats.csv"")",modeling,564635686809197e8,808
"countryFedStatsraw <- read.csv(""countryFedStats.csv"", stringsAsFactors = FALSE,      header = TRUE)",exploratory,564635686809197e8,808
dim(countryFedStatsraw),exploratory,564635686809197e8,808
str(countryFedStatsraw),data cleaning,564635686809197e8,808
"message(""Observations while reading the Federal Stats raw data file: \na. GDP data file contains Federal Stats on Income and some census survey data with 234 observations.\nb. The file has appropriate headers and kept it while reading\nc. Only Contry Code and Income Group has relavent and useful data for analysis\nd. The file contains various other data, incomplete, which is not be required for final analysis"")",data cleaning,564635686809197e8,808
"countryFedStatsUrl <- ""https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv""",communication,564635686809197e8,808
y_bmt,exploratory,564635686809197e8,808
y_bmt,exploratory,564635686809197e8,808
fit1_bmt <- survfit(y_bmt ~ 1),modeling,564635686809197e8,808
summary(fit1_bmt),exploratory,564635686809197e8,808
t2 <- Sys.time(),evaluation,564635686809197e8,808
print(t2 - t1),evaluation,564635686809197e8,808
"rm(list = setdiff(ls(), lsf.str()))",data cleaning,564635686809197e8,808
"dd2 <- df[c(""h2x_position"", ""h2y_position"", ""time"")]",import,678406700957566e8,809
"colnames(dd1) <- c(""x"", ""y"", ""time"")",data cleaning,678406700957566e8,809
"colnames(dd2) <- c(""x"", ""y"", ""time"")",data cleaning,678406700957566e8,809
"dd1$hand <- ""1""",import,678406700957566e8,809
"dd2$hand <- ""2""",import,678406700957566e8,809
"tn = paste(""out/TCGA_z1_z2_relatives_strict.tsv"", sep = ""_"")",setup,768624490825459e8,810
"write.table(rel_short_m2_same_withethni_ofinterest2, quote = F,      sep = ""\t"", row.names = FALSE, file = tn)",export,768624490825459e8,810
"dat[dat$organ == ""liv"", ]$organ_id <- 3",setup,427208057371899e8,811
"dat[dat$organ == ""spl"", ]$organ_id <- 4",setup,427208057371899e8,811
dat$organ_id <- as.numeric(as.character(dat$organ_id)),setup,427208057371899e8,811
dat$parasite <- as.factor(dat$parasite),data cleaning,427208057371899e8,811
"analysis_dat <- array(0, dim = c(26, 4, 5, 3))",data cleaning,427208057371899e8,811
"for (organ in 1:5) for (reps in 1:3) fillDat <- dat[dat$organ_id ==      organ & dat$rep == reps, ]",setup,427208057371899e8,811
"reports = drake_plan(benchmark_evaluation_report = knitr::knit(knitr_in(""analysis/rmd/benchmark-eval.Rmd""),      output = file_out(""analysis/rmd/output-benchmarks.md""), quiet = TRUE),      strings_in_dots = ""literals"")",modeling,946601889561862e8,812
"tikzDevice::tikz(file = ""figures/analysis.hsv.stocks.tex"", width = 4,      height = 2)",setup,6.4808185445144796e+22,813
"ggplot2::ggplot(dplyr::bind_rows(S, .id = ""uniqueID""), ggplot2::aes(x = time,      y = stock, group = uniqueID)) + ggplot2::geom_line(ggplot2::aes(alpha = 0.5)) +      theme(legend.position = ""none"") + ggplot2::labs(x = ""Time period"",      y = ""Stock price"")",visualization,6.4808185445144796e+22,813
"plot_cp(target_mgmt = ""GRND"", cp = 8, prop_table = prop_table,      cluster_ind = cluster_ind)",visualization,909463848453015e8,736
"source(""../dependency_files.R"")",import,955803442047909e8,814
exonSize = 49586385,not sure,955803442047909e8,814
"source(""C:/DSCaseStudy-1Project/Analysis/Data/IncomeData.R"",      echo = TRUE)",exploratory,208529334515333e8,815
"source(""C:/DSCaseStudy-1Project/Analysis/Data/MergeData.R"", echo = TRUE)",setup,208529334515333e8,815
library(tidyverse),setup,191155814332888e8,1
mtcars %>% select(mpg),exploratory,191155814332888e8,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,191155814332888e8,1
f <- function() test <- 1,not sure,191155814332888e8,1
"ggplot(mtcars, aes(mpg)) + geom_histogram()",visualization,191155814332888e8,1
if (TRUE) dothing <- TRUE,not sure,191155814332888e8,1
for (i in 1:10) print(i),not sure,191155814332888e8,1
"ifly <- ""test""",not sure,191155814332888e8,1
library(broom),setup,191155814332888e8,1
library(glue),setup,191155814332888e8,1
"m <- lm(mpg ~ am, data = mtcars)",modeling,191155814332888e8,1
t <- tidy(m),modeling,191155814332888e8,1
"glue_data(t, ""The point estimate for term term is estimate."")",communication,191155814332888e8,1
